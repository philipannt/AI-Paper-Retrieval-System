[
  {
    "query_id": 1,
    "query_text": "bayesian incentive mechanism",
    "source": "title",
    "source_value": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 109646,
        "paper_id": 2275,
        "chunk_idx": 0,
        "title": "Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer",
        "section_head": "Table 4 :",
        "score": 0.8235456347465515,
        "text_preview": "4 Comparison of GoR with static regularizers on QAT-KD. Method Weight (Œ±) Top-1 (%) 1.0 71.46 Static weighting 0.2 71.52 0.5 71.62 GoR (Ours) Learnable 71.79"
      },
      {
        "chunk_index": 6428,
        "paper_id": 116,
        "chunk_idx": 0,
        "title": "ACTOR-CRITIC WITHOUT ACTOR",
        "section_head": "Table 3 :",
        "score": 0.8072513341903687,
        "text_preview": "3 Normalized parameter counts. Method # Params SAC 1.000 QSM 1.000 DIPO 1.012 DACER 1.008 QVPO 1.007 SDAC 1.007 ACA (Ours) 0.677"
      },
      {
        "chunk_index": 69964,
        "paper_id": 1490,
        "chunk_idx": 0,
        "title": "INTEGRATING ATTENTION INTO EXPLANATION FRAMEWORKS FOR LANGUAGE AND VISION TRANSFORMERS",
        "section_head": "Shapley-Att-Mutual",
        "score": 0.7983652353286743,
        "text_preview": "Input token importances computed as Shapley values over attention weights that reflect mutual attention interactions among tokens in the player coalition. Eq. ( 22 )"
      },
      {
        "chunk_index": 52915,
        "paper_id": 1132,
        "chunk_idx": 0,
        "title": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs",
        "section_head": "Figure 3 :",
        "score": 0.7978744506835938,
        "text_preview": "3 Figure 3: AUROC for uncertainty based on FES, FCS and FESTA on (a) TREA-O, (b) TREA-D, and (c) TREA-C."
      },
      {
        "chunk_index": 120911,
        "paper_id": 2517,
        "chunk_idx": 0,
        "title": "Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers",
        "section_head": "Figure 2 :",
        "score": 0.7947056293487549,
        "text_preview": "2 Figure 2: Multi-modal attention mechanism. (a) Conceptual visualization of the attention map. (b-c) Ratios of attention assigned to image vs. text tokens. The dotted line denotes the ratio under uni"
      },
      {
        "chunk_index": 41111,
        "paper_id": 866,
        "chunk_idx": 0,
        "title": "Efficient Transformers: A Survey",
        "section_head": "Generalized Attention",
        "score": 0.7928513288497925,
        "text_preview": "The generalized attention entangles Q i , K j with a kernel function K. The attention matrix in Performer is computed via: A = [g(Q i )K(Q i K j )h(K j )] (6) where K(.) is a kernel function that maps"
      },
      {
        "chunk_index": 61670,
        "paper_id": 1317,
        "chunk_idx": 0,
        "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
        "section_head": "Figure 2 :",
        "score": 0.7896683216094971,
        "text_preview": "2 Figure2: Overview of grouped-query method. Multi-head attention has H query, key, and value heads. Multi-query attention shares single key and value heads across all query heads. Grouped-query atten"
      },
      {
        "chunk_index": 52916,
        "paper_id": 1132,
        "chunk_idx": 0,
        "title": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs",
        "section_head": "Figure 4 :",
        "score": 0.7600758671760559,
        "text_preview": "4 Figure 4: AUROC for uncertainty based on FES, FCS and FESTA on (a) BLINK, (b) VSR data."
      },
      {
        "chunk_index": 122859,
        "paper_id": 2558,
        "chunk_idx": 0,
        "title": "Set Transformer Architectures and Synthetic Data Generation for Flow-Guided Nanoscale Localization",
        "section_head": "Table 2 :",
        "score": 0.7582054138183594,
        "text_preview": "2 Set Transformer hyperparameter search space, 1ùëí -3 ] Weight decay (WD) {1ùëí -6 , 1ùëí -5 , 1ùëí -4 , 1ùëí -3 } Parameter Search Space Learning rate (LR) [1ùëí -5 AMSGrad {True, False} Hidden dimensions {128,"
      },
      {
        "chunk_index": 115983,
        "paper_id": 2419,
        "chunk_idx": 0,
        "title": "RLGF: Reinforcement Learning with Geometric Feedback for Autonomous Driving Video Generation",
        "section_head": "Table 7 :",
        "score": 0.7487094402313232,
        "text_preview": "7 Ablation studies on key RLGF hyperparameters. Hyperparameter Value 3D Detection mAP 3 30.89 Window Size (w) 5 (Ours) 31.42 8 31.25 Reward Weights (Œª) Equal Weights (all 0.2) Balanced (Ours) 30.76 31"
      },
      {
        "chunk_index": 7299,
        "paper_id": 136,
        "chunk_idx": 0,
        "title": "Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning",
        "section_head": "19 :",
        "score": 0.7480007410049438,
        "text_preview": "19 Client i trains assigned expert j parameters and router G i locally 20:Compute adaptive routing with weights œâ ‚Üê softmax(G i x) ‚àà R 2M -1"
      },
      {
        "chunk_index": 155064,
        "paper_id": 3180,
        "chunk_idx": 0,
        "title": "Why Bonds Fail Differently? Explainable Multimodal Learning for Multi-Class Default Prediction",
        "section_head": "Figure 7 :",
        "score": 0.745854377746582,
        "text_preview": "7 Figure 7: Inter-modal and intra-textual modality attention weight"
      },
      {
        "chunk_index": 69968,
        "paper_id": 1490,
        "chunk_idx": 0,
        "title": "INTEGRATING ATTENTION INTO EXPLANATION FRAMEWORKS FOR LANGUAGE AND VISION TRANSFORMERS",
        "section_head": "Barkan et al. (2021) Shapley-Grad-Att-CLS",
        "score": 0.7446613311767578,
        "text_preview": "Input token importances quantifying each token's contribution to the model output through its interactions with the classification token in the attention mechanism, computed as Shapley values over att"
      },
      {
        "chunk_index": 123937,
        "paper_id": 2584,
        "chunk_idx": 0,
        "title": "SIMPLIFYING TRANSFORMER BLOCKS",
        "section_head": "Figure 19 :Figure 20 :Figure 21 :Figure 22 :Figure 25 :",
        "score": 0.743211030960083,
        "text_preview": "1920212225 Figure19: Trajectories for shaped attention Œ≥ parameter."
      },
      {
        "chunk_index": 69969,
        "paper_id": 1490,
        "chunk_idx": 0,
        "title": "INTEGRATING ATTENTION INTO EXPLANATION FRAMEWORKS FOR LANGUAGE AND VISION TRANSFORMERS",
        "section_head": "Shapley-Grad-Att-Mutual",
        "score": 0.7417657375335693,
        "text_preview": "Input token importances quantifying the contribution to the model output via token interactions in the attention mechanism, computed as Shapley values over attention-weighted gradients that reflect mu"
      },
      {
        "chunk_index": 130764,
        "paper_id": 2709,
        "chunk_idx": 0,
        "title": "Stochastic Path Planning in Correlated Obstacle Fields",
        "section_head": "Softmax exploration method.",
        "score": 0.7404578924179077,
        "text_preview": "Although decaying œµ-greedy strategy encourages exploration, it treats all non-greedy decisions equally. Hence, we consider the softmax strategy using Boltzmann distribution, assigning the selection pr"
      },
      {
        "chunk_index": 54275,
        "paper_id": 1166,
        "chunk_idx": 0,
        "title": "FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation",
        "section_head": "Uncertainty Estimation in Medical Imaging",
        "score": 0.7391231060028076,
        "text_preview": "Uncertainty quantification enhances model interpretability and safety in medical AI. Gal and Ghahramani (2016) show that applying Monte Carlo Dropout (MCD) at test time enables estimation of epistemic"
      },
      {
        "chunk_index": 102678,
        "paper_id": 2129,
        "chunk_idx": 0,
        "title": "Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT",
        "section_head": "Fig. 3 .",
        "score": 0.7387195825576782,
        "text_preview": "3 Fig. 3. Conversion of Attention weight matrix to Policy label matrix for supervised training of policy network."
      },
      {
        "chunk_index": 85086,
        "paper_id": 1793,
        "chunk_idx": 0,
        "title": "Mastering the game of Go with deep neural networks and tree search",
        "section_head": "Table 5 |",
        "score": 0.7376410961151123,
        "text_preview": "5 Parameters used by AlphaGo Symbol Parameter Value Œ≤ Softmax temperature 0.67 Œª Mixing parameter 0.5 n vl Virtual loss 3 n thr Expansion threshold 40 c puct Exploration constant 5"
      },
      {
        "chunk_index": 23402,
        "paper_id": 478,
        "chunk_idx": 1,
        "title": "Challenges and Applications of Large Language Models",
        "section_head": "Efficient Attention Roughly two lines of work aim to accelerate attention mechanism computations by (i) lower-level hardware-aware modifications or (ii) higher-level sub-quadratic approximations of the attention mechanism.",
        "score": 0.7376254200935364,
        "text_preview": "With regards to the second stream of work, a common theme to improve the computational or memory complexity of the attention mechanism is to sparsify the attention matrix or introducing (linear) appro"
      }
    ]
  },
  {
    "query_id": 2,
    "query_text": "benchmark learning translate",
    "source": "title",
    "source_value": "A BENCHMARK FOR LEARNING TO TRANSLATE A NEW LANGUAGE FROM ONE GRAMMAR BOOK",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 96460,
        "paper_id": 2035,
        "chunk_idx": 0,
        "title": "Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation",
        "section_head": "Task & Data",
        "score": 0.9683787822723389,
        "text_preview": "We focus on many-to-many speech-to-text translation across six popular languages: EN, ZH, DE, ES, FR, and IT. We collect various open-source speech recognition datasets covering the six languages, inc"
      },
      {
        "chunk_index": 9766,
        "paper_id": 186,
        "chunk_idx": 0,
        "title": "ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models",
        "section_head": "Dataset",
        "score": 0.9554707407951355,
        "text_preview": "Our study mainly focuses on the QE dataset, which is derived from the WMT QE shared task (Zerva et al., 2022; Blain et al., 2023) . It contains source and translation pairs with human-annotated DA sco"
      },
      {
        "chunk_index": 31695,
        "paper_id": 664,
        "chunk_idx": 0,
        "title": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey",
        "section_head": "Text",
        "score": 0.9542357325553894,
        "text_preview": "Inform Request ... Select E m b e d d i n g s T r a n s f o r m e r E n c o d e r T r a n s f o r m e r E n c o d e r T r a n s f o r m e r E n c o d e r BERT For small-sample learning scenarios, the "
      },
      {
        "chunk_index": 121721,
        "paper_id": 2534,
        "chunk_idx": 2,
        "title": "Self-Supervised Speech Representation Learning: A Review",
        "section_head": "C. Datasets for evaluation",
        "score": 0.9469689130783081,
        "text_preview": "It consists of 1251 unique speakers and 352 hours of audio. FSC contains utterances of spoken English commands that one might use for a smart home or virtual assistant, and is used to evaluate the per"
      },
      {
        "chunk_index": 146774,
        "paper_id": 3023,
        "chunk_idx": 0,
        "title": "UNISS: UNIFIED EXPRESSIVE SPEECH-TO-SPEECH TRANSLATION WITH YOUR VOICE",
        "section_head": "D.1 S2ST Performance on Fleurs",
        "score": 0.9396715760231018,
        "text_preview": "To verify the robustness of our framework across datasets, we further evaluate performance on the FLEURS test set. FLEURS is a multilingual benchmark derived from the FLoRes corpus that provides high-"
      },
      {
        "chunk_index": 104416,
        "paper_id": 2164,
        "chunk_idx": 0,
        "title": "PEACH: a sentence-aligned Parallel English‚ÄìArabic Corpus for Healthcare",
        "section_head": "Conclusion",
        "score": 0.9302732348442078,
        "text_preview": "The peach corpus, introduced in this paper, serves as a novel linguistic resource with diverse applications. As a sentence-aligned parallel corpus comprising patient information leaflets and education"
      },
      {
        "chunk_index": 95708,
        "paper_id": 2021,
        "chunk_idx": 0,
        "title": "No Language Left Behind: Scaling Human-Centered Machine Translation",
        "section_head": "Large Scale Backtranslation",
        "score": 0.919874370098114,
        "text_preview": "Backtranslated data provides a form of weak supervision which is crucial for improving translation performance of low-resource languages. As we observed in Section 6.4.1, combining backtranslation dat"
      },
      {
        "chunk_index": 38960,
        "paper_id": 821,
        "chunk_idx": 0,
        "title": "DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment",
        "section_head": "Dataset",
        "score": 0.9184756278991699,
        "text_preview": "We conduct our experiments on CoVoST-2 dataset (Wang et al., 2020) , a large multilingual ST dataset that is based on Common Voice project (Ardila et al., 2020) . CoVoST-2 covers translation from 21 s"
      },
      {
        "chunk_index": 143490,
        "paper_id": 2961,
        "chunk_idx": 0,
        "title": "Transsion Multilingual Speech Recognition System for MLC-SLM 2025 Challenge",
        "section_head": "DATASET",
        "score": 0.9045671820640564,
        "text_preview": "The competition provides a multilingual conversational speech corpus consisting of 1,500 hours of real-world conversational speech recordings across 11 diverse languages: English (en), French (fr), Ge"
      },
      {
        "chunk_index": 93671,
        "paper_id": 1977,
        "chunk_idx": 0,
        "title": "MURAL: Multimodal, Multitask Retrieval Across Languages",
        "section_head": "A.4 Translate-Train Languages",
        "score": 0.9040037393569946,
        "text_preview": "For translate-train baseline, we translate the English captions to some other well-resourced languages. For Alt-Text translation we translate English Alt-Text to German, French, Czech, Japanese, Korea"
      },
      {
        "chunk_index": 95489,
        "paper_id": 2021,
        "chunk_idx": 0,
        "title": "No Language Left Behind: Scaling Human-Centered Machine Translation",
        "section_head": "Exploratory Interview Study Research Design",
        "score": 0.9029728174209595,
        "text_preview": "We designed a semi-structured interview protocol aimed at exploring the needs and concerns of low-resource language speakers vis-√†-vis machine translation. Although low-resource languages could be dee"
      },
      {
        "chunk_index": 7697,
        "paper_id": 147,
        "chunk_idx": 0,
        "title": "Advancing Dialectal Arabic to Modern Standard Arabic Machine Translation",
        "section_head": "Dataset Curation",
        "score": 0.9019818305969238,
        "text_preview": "This study used a curated set of high-quality DA-to-MSA parallel corpora to support both prompting and fine-tuning experiments. The selected datasets span both formal and informal domains, introducing"
      },
      {
        "chunk_index": 43913,
        "paper_id": 934,
        "chunk_idx": 0,
        "title": "Entropy-based Coarse and Compressed Semantic Speech Representation Learning",
        "section_head": "Experiment Setup",
        "score": 0.8986795544624329,
        "text_preview": "Datasets We utilize the English portion of the Multilingual LibriSpeech (MLS) dataset (Pratap et al., 2020) , comprising approximately 20,000 hours of speech, to pretrain the Entropy LLM and to provid"
      },
      {
        "chunk_index": 29759,
        "paper_id": 616,
        "chunk_idx": 0,
        "title": "CUPE: Contextless Universal Phoneme Encoder for Language-Agnostic Speech Processing *",
        "section_head": "Datasets",
        "score": 0.8975067138671875,
        "text_preview": "We evaluate our model on three diverse speech corpora: (1) FLEUR (Few-shot Learning Evaluation of Universal Representations of Speech) (Conneau et al., 2023) : Used exclusively for self-supervised pre"
      },
      {
        "chunk_index": 90085,
        "paper_id": 1898,
        "chunk_idx": 0,
        "title": "MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases",
        "section_head": "H.3. Reading Comprehension Tasks",
        "score": 0.8948553800582886,
        "text_preview": "RACE (Lai et al., 2017) is a large-scale reading comprehension dataset with more than 28,000 passages and nearly 100,000 questions. The dataset is collected from English examinations in China, which a"
      },
      {
        "chunk_index": 75387,
        "paper_id": 1595,
        "chunk_idx": 0,
        "title": "Large Language Models for Summarizing Czech Historical Documents and Beyond",
        "section_head": "Multilingual Datasets",
        "score": 0.8944215774536133,
        "text_preview": "XLSum (Hasan et al., 2021) provides over one million article-summary pairs across 44 languages, ranging from low-resource languages like Bengali and Swahili to high-resource languages such as English "
      },
      {
        "chunk_index": 70676,
        "paper_id": 1507,
        "chunk_idx": 0,
        "title": "Introducing OmniGEC: A Silver Multilingual Dataset for Grammatical Error Correction",
        "section_head": "Figure 5 :",
        "score": 0.8903195261955261,
        "text_preview": "5 Figure5: Token-length distributions by corpus and language for golden (MultiGEC-2025) and silver (OmniGEC) GEC datasets. We used the GPT-4o-mini tokenizer for assessing the length of the datasets."
      },
      {
        "chunk_index": 146740,
        "paper_id": 3023,
        "chunk_idx": 0,
        "title": "UNISS: UNIFIED EXPRESSIVE SPEECH-TO-SPEECH TRANSLATION WITH YOUR VOICE",
        "section_head": "The UniST Dataset",
        "score": 0.8890708684921265,
        "text_preview": "Training end-to-end expressive S2ST models faces a significant bottleneck due to the scarcity of large-scale, parallel data that preserves speaker characteristics. To address this limitation, we desig"
      },
      {
        "chunk_index": 84351,
        "paper_id": 1774,
        "chunk_idx": 0,
        "title": "Many-Shot In-Context Learning",
        "section_head": "Figure 15 |",
        "score": 0.888484001159668,
        "text_preview": "15 Figure 15 | Many-shot ICL with GPT-4-Turbo and Claude-3-Opus [3] on low-resource machine translation ( ¬ß2.1)."
      },
      {
        "chunk_index": 68810,
        "paper_id": 1467,
        "chunk_idx": 0,
        "title": "INDICGENBENCH: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages",
        "section_head": "Cross-Lingual Summarization: CROSSSUM-IN",
        "score": 0.8858819007873535,
        "text_preview": "We create CROSSSUM-IN based on Cross-Sum (Bhattacharjee et al., 2023) , a dataset for crosslingual summarization, which in turn is derived from XL-Sum (Hasan et al., 2021b) . CrossSum contains multi-w"
      }
    ]
  },
  {
    "query_id": 3,
    "query_text": "careful examination large",
    "source": "title",
    "source_value": "A Careful Examination of Large Language Model Performance on Grade School Arithmetic",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 104696,
        "paper_id": 2171,
        "chunk_idx": 0,
        "title": "PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models",
        "section_head": "Models.",
        "score": 0.8957858085632324,
        "text_preview": "In this benchmark, 12 Large Language Models, spanning a wide range of open-source and commercial models, are evaluated. To address Persian-specific performance, some models that are explicitly fine-tu"
      },
      {
        "chunk_index": 112745,
        "paper_id": 2349,
        "chunk_idx": 1,
        "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment",
        "section_head": "B. Models",
        "score": 0.8624691963195801,
        "text_preview": "Model SEQA NLPQA MLQA DSQA Overall Closed-Source Models GPT-4o Turbo 73.02 63.93 80.95 74.67 70.23 GPT-3.5 Turbo 57.14 59.02 65.08 50.67 53.82 Claude 3.5 Opus 65.44 56.33 69.04 53.55 57.88 Gemini 1.5 "
      },
      {
        "chunk_index": 58972,
        "paper_id": 1257,
        "chunk_idx": 0,
        "title": "Gemini: A Family of Highly Capable Multimodal Models",
        "section_head": "Model Assessment",
        "score": 0.8583438396453857,
        "text_preview": "We conduct model impact assessments to identify, assess, and document societal benefits and harms associated with the capabilities of Gemini models. Our impact assessments for Gemini API models descri"
      },
      {
        "chunk_index": 19323,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "query interpro",
        "score": 0.855398416519165,
        "text_preview": "Query the InterPro REST API using natural language or a direct endpoint to retrieve information about protein domains or families."
      },
      {
        "chunk_index": 59113,
        "paper_id": 1258,
        "chunk_idx": 0,
        "title": "Gemini: A Family of Highly Capable Multimodal Models",
        "section_head": "Model Assessment",
        "score": 0.8537981510162354,
        "text_preview": "We conduct model impact assessments to identify, assess, and document societal benefits and harms associated with the capabilities of Gemini models. Our impact assessments for Gemini API models descri"
      },
      {
        "chunk_index": 12494,
        "paper_id": 247,
        "chunk_idx": 0,
        "title": "AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data",
        "section_head": "Comparison models",
        "score": 0.8457854986190796,
        "text_preview": "Our focus was on Arabic-aware open-source models. We chose four models with strong performance in Arabic tasks: Llama 3.3 70B [14] , Mistral Large [15] , DeepSeek-V3 [16] , and Jais 70B [17] ."
      },
      {
        "chunk_index": 58959,
        "paper_id": 1257,
        "chunk_idx": 0,
        "title": "Gemini: A Family of Highly Capable Multimodal Models",
        "section_head": "Multimodal Vision",
        "score": 0.8425208330154419,
        "text_preview": "Multimodal post-training enhances the capabilities of our natively multimodal Gemini models for a wide range of useful applications. In the following, we discuss how image understanding ability is inc"
      },
      {
        "chunk_index": 59100,
        "paper_id": 1258,
        "chunk_idx": 0,
        "title": "Gemini: A Family of Highly Capable Multimodal Models",
        "section_head": "Multimodal Vision",
        "score": 0.8425170183181763,
        "text_preview": "Multimodal post-training enhances the capabilities of our natively multimodal Gemini models for a wide range of useful applications. In the following, we discuss how image understanding ability is inc"
      },
      {
        "chunk_index": 127274,
        "paper_id": 2656,
        "chunk_idx": 0,
        "title": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies",
        "section_head": "Text-Only LLMs used in this study",
        "score": 0.8336938619613647,
        "text_preview": "We evaluated nine LLMs spanning diverse model sizes and training objectives. GPT-4o (text-only) served as a benchmark, representing a proprietary high-capacity model with advanced language understandi"
      },
      {
        "chunk_index": 96749,
        "paper_id": 2041,
        "chunk_idx": 0,
        "title": "NVLM: Open Frontier-Class Multimodal LLMs",
        "section_head": "Results",
        "score": 0.8303313255310059,
        "text_preview": "In this section, we present a comprehensive evaluation of the NVLM-1.0 model family across a wide range of benchmarks to assess their multimodal capabilities, comparing them to other leading open-acce"
      },
      {
        "chunk_index": 154777,
        "paper_id": 3174,
        "chunk_idx": 0,
        "title": "Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models",
        "section_head": "Table 2 :",
        "score": 0.8267124891281128,
        "text_preview": "2 Depth Scoring Rubric Score Definition Example Snippet 0 Not mentioned No reference to the category. 1 Shallow People with vision impairments face chal- lenges. 2 Moderate People with vision impairme"
      },
      {
        "chunk_index": 56703,
        "paper_id": 1219,
        "chunk_idx": 0,
        "title": "From Fuzzy Speech to Medical Insight: Benchmarking LLMs on Noisy Patient Narratives",
        "section_head": "INTRODUCTION",
        "score": 0.826160728931427,
        "text_preview": "Large language models (LLMs) such as GPT-4, Med-PaLM 2, and Claude 3 have demonstrated impressive capabilities across a range of natural language processing (NLP) tasks, including question answering, "
      },
      {
        "chunk_index": 142459,
        "paper_id": 2937,
        "chunk_idx": 0,
        "title": "Training Compute-Optimal Large Language Models",
        "section_head": "Intended Uses",
        "score": 0.8243418335914612,
        "text_preview": "Primary Intended Uses The primary use is research on language models, including: research on the scaling behaviour of language models along with those listed in Rae et al. (2021) ."
      },
      {
        "chunk_index": 14031,
        "paper_id": 282,
        "chunk_idx": 0,
        "title": "Attention2Probability: Attention-Driven Terminology Probability Estimation for Robust Speech-to-Text System",
        "section_head": "Table 1 :",
        "score": 0.8215639591217041,
        "text_preview": "1 Statistics of all datasets.Prompt Example: This is an English audio recording. Please transcribe this audio into English text. Specialized terminology may appear in the audio. Please accurately reco"
      },
      {
        "chunk_index": 56705,
        "paper_id": 1219,
        "chunk_idx": 0,
        "title": "From Fuzzy Speech to Medical Insight: Benchmarking LLMs on Noisy Patient Narratives",
        "section_head": "A.",
        "score": 0.8212432265281677,
        "text_preview": "LLMs for Diagnostic Reasoning from Text Large language models (LLMs) have rapidly advanced over the past five years, transforming natural language processing in healthcare. Early transformer-based mod"
      },
      {
        "chunk_index": 146758,
        "paper_id": 3023,
        "chunk_idx": 0,
        "title": "UNISS: UNIFIED EXPRESSIVE SPEECH-TO-SPEECH TRANSLATION WITH YOUR VOICE",
        "section_head": "‰∏≠ÂõΩ‰∏éÂæ∑ÂõΩÂØπÂ∫îÁöÑÊ¶ÇÂøµ ÊòØÊ∞ë‰∫ãÊ≥ïÂæãË°å‰∏∫„ÄÇ",
        "score": 0.8212403655052185,
        "text_preview": "UniSS Ê∞ë‰∫ãÊ≥ïÂæãË°å‰∏∫ÊòØ‰∏≠ÂõΩ‰∏éÂæ∑ÂõΩ‰πãÈó¥ÁöÑÁõ∏ÂØπÊ¶ÇÂøµ„ÄÇ 49.5 Seamless-Ex Ê∞ë‰∫ãÊ≥ïÂæãÊòØ‰∏≠ÂõΩÂíåÂæ∑ÂõΩ‰πãÈó¥ÁöÑÁõ∏Â∫îÊ¶ÇÂøµ„ÄÇ 22.9 Seamless-L Ê∞ë‰∫ãÊ≥ïÂæãÊòØ‰∏≠ÂõΩÂíåÂæ∑ÂõΩ‰πãÈó¥ÁöÑÁõ∏Â∫îÊ¶ÇÂøµ„ÄÇ 22.9 GPT-4o ‰∏≠ÂõΩÂíåÂæ∑ÂõΩ‰πãÈó¥ÁöÑÂØπÂ∫îÊ¶ÇÂøµÊòØÊ∞ë‰∫ãÊ≥ï„ÄÇ 38.6 When nurses enter the workplace these badges are used to identify t"
      },
      {
        "chunk_index": 19321,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "query uniprot",
        "score": 0.8166999220848083,
        "text_preview": "Query the UniProt REST API using either natural language or a direct endpoint to retrieve protein information."
      },
      {
        "chunk_index": 102098,
        "paper_id": 2120,
        "chunk_idx": 0,
        "title": "Orca 2: Teaching Small Language Models How to Reason",
        "section_head": "Figure 13 :",
        "score": 0.8158036470413208,
        "text_preview": "13 Figure 13: Topical breakdown in performance of GPT-4, ChatGPT and Orca 2 in the AGIEval benchmark on professional and academic exams."
      },
      {
        "chunk_index": 102272,
        "paper_id": 2122,
        "chunk_idx": 0,
        "title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "section_head": "Figure 11 :",
        "score": 0.8158035278320312,
        "text_preview": "11 Figure 11: Topical breakdown in performance of GPT-4, ChatGPT and Orca in the AGIEval benchmark on professional and academic exams."
      },
      {
        "chunk_index": 136800,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Text-only Inputs",
        "score": 0.8151897192001343,
        "text_preview": "GPT-4V's strong language capability enables it to serve as an effective unimodal language model [38, 108, 23 ] with text-only inputs. Operating exclusively with text for both input and output, GPT-4V "
      }
    ]
  },
  {
    "query_id": 4,
    "query_text": "case against implicit",
    "source": "title",
    "source_value": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 82116,
        "paper_id": 1729,
        "chunk_idx": 0,
        "title": "Local and Central Differential Privacy for Robustness and Privacy in Federated Learning *",
        "section_head": "Robustness",
        "score": 0.967333197593689,
        "text_preview": "Poisoning attacks have been proposed in various settings, e.g., autoregressive models [3] , regression learning [50] , facial recognition [112] , support vector machines [7] , collaborative filtering "
      },
      {
        "chunk_index": 71697,
        "paper_id": 1528,
        "chunk_idx": 0,
        "title": "Jailbroken: How Does LLM Safety Training Fail? Content Warning: This paper contains examples of harmful language",
        "section_head": "Implications for Defense",
        "score": 0.9546438455581665,
        "text_preview": "We now discuss the implications of our findings for defense. We argue that (i) scaling alone will not resolve the failure modes of Section 3, and (ii) \"safety-capability parity\"-where safety mechanism"
      },
      {
        "chunk_index": 99168,
        "paper_id": 2083,
        "chunk_idx": 0,
        "title": "On the Opportunities and Risks of Foundation Models",
        "section_head": "Security choke points.",
        "score": 0.9541423320770264,
        "text_preview": "If adapted applications can inherit vulnerabilities from a foundation model, they can also inherit desirable security characteristics -such as robustness to adversarial examples or poisoning attacks. "
      },
      {
        "chunk_index": 12804,
        "paper_id": 253,
        "chunk_idx": 0,
        "title": "ARE MODERN SPEECH ENHANCEMENT SYSTEMS VULNERABLE TO ADVERSARIAL ATTACKS?",
        "section_head": "INTRODUCTION",
        "score": 0.9488091468811035,
        "text_preview": "Adversarial attacks are a method where adversarial noise, designed to be hardly perceivable by humans, is added to the data such that the output of a deep neural network (DNN) is yielding a result tha"
      },
      {
        "chunk_index": 54348,
        "paper_id": 1168,
        "chunk_idx": 1,
        "title": "FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks",
        "section_head": "A. Poisoning attacks in FL",
        "score": 0.9465399980545044,
        "text_preview": "In the context of FL, such attacks not only compromise the adversary's local model but can also propagate their effects to benign clients through the aggregation step. There are two types of poisoning"
      },
      {
        "chunk_index": 130314,
        "paper_id": 2703,
        "chunk_idx": 1,
        "title": "Stealing Part of a Production Language Model",
        "section_head": "Mitigations",
        "score": 0.9439175128936768,
        "text_preview": "Unfortunately this has several significant drawbacks: the threshold has to be independent of h (or learning the threshold would reveal h); the system would need to maintain state of all user queries t"
      },
      {
        "chunk_index": 52352,
        "paper_id": 1122,
        "chunk_idx": 0,
        "title": "FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning",
        "section_head": "Adversarial Threat Model",
        "score": 0.9354998469352722,
        "text_preview": "To evaluate the robustness of our framework against different threat profiles, we implement two distinct model poisoning attacks, inspired by the work of Fang et al. [5] : 1. Standard Poisoning Attack"
      },
      {
        "chunk_index": 157123,
        "paper_id": 3220,
        "chunk_idx": 18,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "A. Adversarial Perturbations to Disrupt Deepfake Generators",
        "score": 0.9336352348327637,
        "text_preview": "These challenges notwithstanding, AI models can enhance the resilience of adversarial perturbations with personalized perturbation generation, which uses AI to educate adversarial perturbations that p"
      },
      {
        "chunk_index": 8135,
        "paper_id": 156,
        "chunk_idx": 0,
        "title": "Adversarial Defence without Adversarial Defence: Enhancing Language Model Robustness via Instance-level Principal Component Removal",
        "section_head": "F.3 Potential Vulnerability to Adaptive Adversaries",
        "score": 0.9277113676071167,
        "text_preview": "Our evaluation uses established, general-purpose attackers. A more sophisticated, adaptive adversary who is aware of the PURE defence mechanism could potentially circumvent it. Such an adversary could"
      },
      {
        "chunk_index": 63205,
        "paper_id": 1348,
        "chunk_idx": 4,
        "title": "Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning",
        "section_head": "Introduction",
        "score": 0.9262304306030273,
        "text_preview": "Theoretically, this can reduce the operating window in which backdoors can succeed, potentially eliminating it. Empirically, combining Krum with CSFT, Krum + , yields the best defense among the possib"
      },
      {
        "chunk_index": 69066,
        "paper_id": 1471,
        "chunk_idx": 2,
        "title": "Information Security Based on LLM Approaches: A Review",
        "section_head": "DDoS Attack Prediction",
        "score": 0.9223800897598267,
        "text_preview": "This strategy generates semantic understanding and fine-tuning optimization through LLM under the premise of using a small number of labeled samples, and ultimately achieves higher detection accuracy "
      },
      {
        "chunk_index": 82120,
        "paper_id": 1729,
        "chunk_idx": 0,
        "title": "Local and Central Differential Privacy for Robustness and Privacy in Federated Learning *",
        "section_head": "Privacy",
        "score": 0.9201288223266602,
        "text_preview": "Essentially, attacks against privacy in ML involve an adversary who, given some access to a model, tries to infer some private information. More specifically, the adversary might infer: 1) information"
      },
      {
        "chunk_index": 117123,
        "paper_id": 2447,
        "chunk_idx": 1,
        "title": "RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing",
        "section_head": "Broader impacts",
        "score": 0.9193768501281738,
        "text_preview": "On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ‚Ä¢ The authors should consid"
      },
      {
        "chunk_index": 77738,
        "paper_id": 1644,
        "chunk_idx": 1,
        "title": "Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models",
        "section_head": "Broader Impacts",
        "score": 0.9193753004074097,
        "text_preview": "On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ‚Ä¢ The authors should consid"
      },
      {
        "chunk_index": 104257,
        "paper_id": 2162,
        "chunk_idx": 1,
        "title": "PDRL: Post-hoc Descriptor-based Residual Learning for Uncertainty-Aware Machine Learning Potentials",
        "section_head": "Broader impacts",
        "score": 0.919374942779541,
        "text_preview": "On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ‚Ä¢ The authors should consid"
      },
      {
        "chunk_index": 145404,
        "paper_id": 2995,
        "chunk_idx": 1,
        "title": "Uncovering Graph Reasoning in Decoder-only Transformers with Circuit Tracing",
        "section_head": "Broader impacts",
        "score": 0.919374942779541,
        "text_preview": "On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ‚Ä¢ The authors should consid"
      },
      {
        "chunk_index": 77055,
        "paper_id": 1628,
        "chunk_idx": 1,
        "title": "Learnable Sampler Distillation for Discrete Diffusion Models",
        "section_head": "Broader impacts",
        "score": 0.9193727970123291,
        "text_preview": "On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ‚Ä¢ The authors should consid"
      },
      {
        "chunk_index": 5487,
        "paper_id": 94,
        "chunk_idx": 1,
        "title": "A Theory of Multi-Agent Generative Flow Networks",
        "section_head": "Broader impacts",
        "score": 0.9193655252456665,
        "text_preview": "On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ‚Ä¢ The authors should consid"
      },
      {
        "chunk_index": 121133,
        "paper_id": 2524,
        "chunk_idx": 1,
        "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
        "section_head": "B. Threat model",
        "score": 0.9189612865447998,
        "text_preview": "The success of an attack is measured by the attack success rate (ASR), defined as the rate of successful misclassifications to the target class: ASR = E (x,y)‚àºD, y=ys [Pr(f (x)) = y t )] , (3) where y"
      },
      {
        "chunk_index": 146539,
        "paper_id": 3021,
        "chunk_idx": 0,
        "title": "Unifying Adversarial Perturbation for Graph Neural Networks",
        "section_head": "Adversarial Training",
        "score": 0.9168096780776978,
        "text_preview": "Adversarial training [2, 14, 20, 21, 25, 26, 30, 41] is a widely used countermeasure to tackle the vulnerability to intentional perturbations of deep neural networks on image and text data, which invo"
      }
    ]
  },
  {
    "query_id": 5,
    "query_text": "causal lens controllable",
    "source": "title",
    "source_value": "A Causal Lens for Controllable Text Generation",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 22300,
        "paper_id": 457,
        "chunk_idx": 0,
        "title": "CAUSAL FINGERPRINTS OF AI GENERATIVE MODELS",
        "section_head": "Multi_ Fingerprints",
        "score": 0.9413642883300781,
        "text_preview": "a. Causal Fingerprint(CF) 1 0 1 1 0 1 1 0 1 1 0 1 ... ..."
      },
      {
        "chunk_index": 104387,
        "paper_id": 2163,
        "chunk_idx": 0,
        "title": "PE R S O N AX: MULTIMODAL DATASETS WITH LLM-INFERRED BEHAVIOR TRAITS",
        "section_head": "Figure 4 :",
        "score": 0.8367874622344971,
        "text_preview": "4 Figure4: Multi-modality multi-measurement causal model. Latent space is in grey. s is shared latent variables across different modalities, z is modality-specific latent variables.x m,i denotes the m"
      },
      {
        "chunk_index": 84403,
        "paper_id": 1775,
        "chunk_idx": 1,
        "title": "MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer",
        "section_head": "Comparison with Unified Models",
        "score": 0.8356677293777466,
        "text_preview": "Overall Cultural Time Space Biology Physics Chemistry Overall Dedicated T2I Model SDXL-3.5B [69] 0.98 0.74 0.39 0.85 0.15 0.23 0.55 0.43 0.48 0.47 0.44 0.45 0.27 0.43 DALL-E 3 [65] 0.96 0.87 0.47 0.83"
      },
      {
        "chunk_index": 22367,
        "paper_id": 459,
        "chunk_idx": 4,
        "title": "Causal representation learning from network data",
        "section_head": "Introduction",
        "score": 0.832888126373291,
        "text_preview": "GRACE-VAE simultaneously learns: (1) the latent causal graph G, (2) the correspondence of interventions to latent targets via the intervention encoder's assignments, and (3) a generative model capable"
      },
      {
        "chunk_index": 14879,
        "paper_id": 300,
        "chunk_idx": 0,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Constructing Narratives with Autiverse",
        "score": 0.8277350664138794,
        "text_preview": "Based on the survey results and the feedback in debriefing, we illustrate how Autiverse guided adolescents' narrative construction through scaffolding and multimodal support."
      },
      {
        "chunk_index": 34561,
        "paper_id": 731,
        "chunk_idx": 0,
        "title": "Diffusion-LM Improves Controllable Text Generation",
        "section_head": "Problem Statement and Background",
        "score": 0.8235791921615601,
        "text_preview": "We first define controllable generation ( ¬ß3.1) and then review continuous diffusion models ( ¬ß3.3)."
      },
      {
        "chunk_index": 22512,
        "paper_id": 460,
        "chunk_idx": 0,
        "title": "CAUSAL TIME SERIES GENERATION VIA DIFFUSION MODELS",
        "section_head": "Figure 2 :",
        "score": 0.8169658184051514,
        "text_preview": "2 Figure 2: Structural Causal Models (SCMs) for different conditional time series generation paradigms."
      },
      {
        "chunk_index": 76815,
        "paper_id": 1625,
        "chunk_idx": 0,
        "title": "LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations",
        "section_head": "Methodology",
        "score": 0.8147834539413452,
        "text_preview": "We propose Latent Diffusion for Video Counterfactual Explanations (LD-ViCE), a novel framework for generating counterfactual video explanations, inspired by the image-based counterfactual generation p"
      },
      {
        "chunk_index": 115202,
        "paper_id": 2403,
        "chunk_idx": 0,
        "title": "Revealing Multimodal Causality with Large Language Models",
        "section_head": "X k",
        "score": 0.8019461631774902,
        "text_preview": "The k-th multimodal sample in the dataset D. X ‚Ä≤ k The generated counterfactual multimodal sample of X k . x ki The i-th modality of the k-th multimodal sample X k . x ‚Ä≤ ki The generated counterfactua"
      },
      {
        "chunk_index": 84576,
        "paper_id": 1780,
        "chunk_idx": 0,
        "title": "MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models",
        "section_head": "MarkLLM Generative Large Language Models (Text)",
        "score": 0.7993311882019043,
        "text_preview": "A comprehensive toolkit for generative text watermarking."
      },
      {
        "chunk_index": 38142,
        "paper_id": 805,
        "chunk_idx": 0,
        "title": "DreamControl: Human-Inspired Whole-Body Humanoid Control for Scene Interaction via Guided Diffusion",
        "section_head": "1 1",
        "score": 0.7912778854370117,
        "text_preview": "1 Appendix linkA. Stage 1: Generating Reference Trajectory from a Human Motion Prior"
      },
      {
        "chunk_index": 115221,
        "paper_id": 2403,
        "chunk_idx": 0,
        "title": "Revealing Multimodal Causality with Large Language Models",
        "section_head": "14:",
        "score": 0.7894976139068604,
        "text_preview": "// Multimodal Counterfactual Reasoning 15: Initialize set of validated counterfactuals D CF ‚Üê ‚àÖ."
      },
      {
        "chunk_index": 155606,
        "paper_id": 3192,
        "chunk_idx": 0,
        "title": "WORLDFORGE: UNLOCKING EMERGENT 3D/4D GENERATION IN VIDEO DIFFUSION MODEL VIA TRAINING-FREE GUIDANCE",
        "section_head": "RELATED WORKS",
        "score": 0.7857736945152283,
        "text_preview": "We review prior work in three areas most relevant to ours: 3D static scene generation, 4D trajectorycontrolled video generation, and guidance strategies for generative models."
      },
      {
        "chunk_index": 18118,
        "paper_id": 369,
        "chunk_idx": 0,
        "title": "Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing",
        "section_head": "Figure 6 :",
        "score": 0.7857540845870972,
        "text_preview": "6 Figure 6: (a) An example of a causal graph, where X transmits information to the outcome Y via the mediator variable M . (b) The process of counterfactual intervention, observing the influence of X "
      },
      {
        "chunk_index": 22422,
        "paper_id": 460,
        "chunk_idx": 2,
        "title": "CAUSAL TIME SERIES GENERATION VIA DIFFUSION MODELS",
        "section_head": "INTRODUCTION",
        "score": 0.7831470966339111,
        "text_preview": "Pearl's causal ladder (Pearl, 2009) offers a precise vocabulary for this extension, which organizes causal tasks into three levels: association, intervention, and counterfactual. Within this framing, "
      },
      {
        "chunk_index": 32453,
        "paper_id": 681,
        "chunk_idx": 0,
        "title": "DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform",
        "section_head": "Figure 5 .",
        "score": 0.7768932580947876,
        "text_preview": "5 Figure 5. Consistency finetuning reduces number of function evaluations of diffusion models in the sampling process."
      },
      {
        "chunk_index": 68128,
        "paper_id": 1450,
        "chunk_idx": 0,
        "title": "Improving language models by retrieving from trillions of tokens",
        "section_head": "E. Qualitative experiments",
        "score": 0.7764680981636047,
        "text_preview": "We illustrate the usage of Retro models by looking at the perplexity of evaluation samples and by producing samples autoregressively."
      },
      {
        "chunk_index": 91270,
        "paper_id": 1921,
        "chunk_idx": 0,
        "title": "MORA: ENABLING GENERALIST VIDEO GENERATION VIA A MULTI-AGENT FRAMEWORK",
        "section_head": "Table 5 :",
        "score": 0.7759732007980347,
        "text_preview": "5 Ablation study on different variants of Mora model for text-to-video generation performance. The Random Initial modulation (RI-modulated) embeddings represent {z i ‚àà R 1√ótext_encoderi_feature } n i="
      },
      {
        "chunk_index": 13052,
        "paper_id": 260,
        "chunk_idx": 3,
        "title": "ArtifactGen: Benchmarking WGAN-GP vs Diffusion for Label-Aware EEG Artifact Synthesis",
        "section_head": "Background",
        "score": 0.7750678658485413,
        "text_preview": "Together, these developments motivate a careful, label-aware comparison between conditional WGAN-GP and conditional diffusion for artifact synthesis on TUAR, under subject-wise splits and an evaluatio"
      },
      {
        "chunk_index": 135045,
        "paper_id": 2794,
        "chunk_idx": 0,
        "title": "TeRA: Rethinking Text-guided Realistic 3D Avatar Generation",
        "section_head": "Figure 2 .",
        "score": 0.7714676856994629,
        "text_preview": "2 Figure 2. Overall method. (a) Given the annotated multi-view human dataset, we train a text conditioned 3D avatar generative model. (b) The model is established upon a structured 3D human representa"
      }
    ]
  },
  {
    "query_id": 6,
    "query_text": "chinese heart failure",
    "source": "title",
    "source_value": "A Chinese Heart Failure Status Speech Database with Universal and Personalised Classification",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 107596,
        "paper_id": 2229,
        "chunk_idx": 0,
        "title": "Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques",
        "section_head": "Table 4",
        "score": 0.8225197792053223,
        "text_preview": "4 Selected patient's characteristics for pasa dataset. Data are represented as median [Q1-Q3] or number (%). Characteristics Cohort (n=71082) Age at time of surgery (years) 59.00 [46.00-69.00] Gender "
      },
      {
        "chunk_index": 86176,
        "paper_id": 1816,
        "chunk_idx": 0,
        "title": "MedGemma Technical Report",
        "section_head": "Patient Summary:",
        "score": 0.7958990335464478,
        "text_preview": "‚Ä¢ Diagnosis: Heart Failure with Reduced Ejection Fraction (HFrEF), EF 35%. ‚Ä¢ Symptoms: Dyspnea on exertion (1 flight of stairs), NYHA Class II-III. ‚Ä¢ Current HFrEF Medications: Lisinopril (ACE inhibit"
      },
      {
        "chunk_index": 19974,
        "paper_id": 404,
        "chunk_idx": 0,
        "title": "Blockchain-Enabled Federated Learning",
        "section_head": "Table 1 .",
        "score": 0.7812333106994629,
        "text_preview": "1 Coordination structure comparison across key properties Property Centralized Hierarchical Decentralized Coordination Complexity O(n) O(log n) O(n log n) Single Point of Failure Yes Partial No Scalab"
      },
      {
        "chunk_index": 107570,
        "paper_id": 2229,
        "chunk_idx": 1,
        "title": "Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques",
        "section_head": "Data description",
        "score": 0.7689361572265625,
        "text_preview": "The majority were Chinese (73.29%), followed by Indian (9.96%), Malay (9.41%), and Caucasian (0.62%). General comorbidities included smoking history (10.69%), alcohol consumption (3.18%), and hyperten"
      },
      {
        "chunk_index": 30003,
        "paper_id": 621,
        "chunk_idx": 1,
        "title": "Cyst-X: AI-Powered Pancreatic Cancer Risk Prediction from Multicenter MRI in Centralized and Federated Learning",
        "section_head": "Table 4 :",
        "score": 0.7683505415916443,
        "text_preview": "Data Centers NYU MCF NU AHN MCA IU EMC Imaging Device Siemens, GE Siemens, GE Siemens N/A Siemens, GE Siemens, Philips Siemens, GE MRI Magnet(T) 1.5, 3 1.5, 3 1.5, 3 N/A 1.5, 3 1.5, 1.5 1.5, 1.5 Demog"
      },
      {
        "chunk_index": 1780,
        "paper_id": 31,
        "chunk_idx": 3,
        "title": "A General Language Assistant as a Laboratory for Alignment",
        "section_head": "C.1 Preference Model Pre-training",
        "score": 0.7659836411476135,
        "text_preview": "Instead we include the subreddits: tifu, explainlikeimfive, WritingPrompts, changemyview, LifeProTips, todayilearned, science, askscience, ifyoulikeblank, UpliftingNews, Foodforthought, IWantToLearn, "
      },
      {
        "chunk_index": 29995,
        "paper_id": 621,
        "chunk_idx": 0,
        "title": "Cyst-X: AI-Powered Pancreatic Cancer Risk Prediction from Multicenter MRI in Centralized and Federated Learning",
        "section_head": "Fig. 4 :",
        "score": 0.7545970678329468,
        "text_preview": "4 Fig. 4: t-SNE Visualization. 0: No risk. 1: Low risk. 2: High risk."
      },
      {
        "chunk_index": 9115,
        "paper_id": 174,
        "chunk_idx": 0,
        "title": "AImoclips: A Benchmark for Evaluating Emotion Conveyance in Text-to-Music Generation",
        "section_head": "Table 1",
        "score": 0.743732213973999,
        "text_preview": "1 Words chosen for emotion intent of TTM generation Quadrant Valence Arousal Words Q1 High High happy, excited, energetic Q2 Low High angry, anxious, scared Q3 Low Low sad, gloomy, dull Q4 High Low re"
      },
      {
        "chunk_index": 57511,
        "paper_id": 1232,
        "chunk_idx": 0,
        "title": "FROM TEXT TO TALK: AUDIO-LANGUAGE MODEL NEEDS NON-AUTOREGRESSIVE JOINT TRAINING",
        "section_head": "Figure 1 :",
        "score": 0.7338438034057617,
        "text_preview": "1 Figure 1: (a) Distinct dependency structures for text and audio modality. (b) Due to disparate tokenization rates, the last audio span is of variable length."
      },
      {
        "chunk_index": 137067,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.7287697792053223,
        "text_preview": "The text in the image is in Chinese and translates to \"Mapo Tofu.\" Mapo tofu is a popular Chinese dish made with tofu and minced meat in a spicy sauce."
      },
      {
        "chunk_index": 118670,
        "paper_id": 2475,
        "chunk_idx": 0,
        "title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning",
        "section_head": "Figure 13 :",
        "score": 0.7280210256576538,
        "text_preview": "13 Figure 13: turtle swimming underwater. aesthetic. Fantasy., elephant swimming underwater. aesthetic. Fantasy., flock of sheep. aesthetic. Fantasy."
      },
      {
        "chunk_index": 152330,
        "paper_id": 3140,
        "chunk_idx": 0,
        "title": "What Do Humans Hear When Interacting? Experiments on Selective Listening for Evaluating ASR of Spoken Dialogue Systems",
        "section_head": "Table 6 :",
        "score": 0.7272533178329468,
        "text_preview": "6 H-WWER on Transcriptions (A: audio, V: visual) Model Human Base Large Base Large Modality A+V A A A+V A+V H-WWER 0.48 0.56 0.28 0.57 0.33 H-WCER 0.38 0.41 0.20 0.44 0.26"
      },
      {
        "chunk_index": 141646,
        "paper_id": 2918,
        "chunk_idx": 0,
        "title": "Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech",
        "section_head": "Figure 1 :",
        "score": 0.727013349533081,
        "text_preview": "1 Figure 1: A conversational agent with (Top) text, (Middle) text and audio, (Bottom) text, audio, and paralinguistic signals."
      },
      {
        "chunk_index": 80838,
        "paper_id": 1702,
        "chunk_idx": 2,
        "title": "LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model",
        "section_head": "Table 12 :",
        "score": 0.7236031293869019,
        "text_preview": "Settings Linguistic Task Category GigaSpeech < Textual Instruction, LibriSpeech Audio Input > 12M (LLaSO-Align)&- 47K&- ASR Automatic Speech Recognition LJ Speech and Open-ended VCTK < Audio Instructi"
      },
      {
        "chunk_index": 86181,
        "paper_id": 1816,
        "chunk_idx": 0,
        "title": "MedGemma Technical Report",
        "section_head": "MedGemma 27B output",
        "score": 0.718120813369751,
        "text_preview": "Yes, Entresto is indicated. Rationale: This patient has symptomatic Heart Failure with reduced Ejection Fraction (HFrEF) (EF 35%, NYHA Class II) despite being on foundational guideline-directed medica"
      },
      {
        "chunk_index": 39227,
        "paper_id": 828,
        "chunk_idx": 0,
        "title": "Dynamic Fusion Multimodal Network for SpeechWellness Detection",
        "section_head": "Fig. 2 :",
        "score": 0.7175629734992981,
        "text_preview": "2 Fig. 2: Mel-spectrogram comparison between suicidal risk (left) and non-suicidal risk (right) speech samples"
      },
      {
        "chunk_index": 152032,
        "paper_id": 3133,
        "chunk_idx": 1,
        "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing",
        "section_head": "5) Weight Analysis:",
        "score": 0.7130272388458252,
        "text_preview": "Model Unlabled Data LM test-clean test-other 1-hour labeled wav2vec 2.0 Base LS-960 None 24.5 29.7 WavLM Base LS-960 None 24.5 29.2 WavLM Base+ MIX-94k None 22.8 26.7 DeCoAR 2.0 LS-960 4-gram 13.8 29."
      },
      {
        "chunk_index": 575,
        "paper_id": 12,
        "chunk_idx": 1,
        "title": "A Comprehensive Review of Datasets for Clinical Mental Health AI Systems",
        "section_head": "Dataset Modalities",
        "score": 0.706175684928894,
        "text_preview": "The Ex-Ray 69 dataset also contains psychological reports for clustering patients. Several others explore text classification of schizophrenia [52] [53] [54] [55] [56] [57] , though many also collect "
      },
      {
        "chunk_index": 29193,
        "paper_id": 601,
        "chunk_idx": 0,
        "title": "CRITIC: LARGE LANGUAGE MODELS CAN SELF-CORRECT WITH TOOL-INTERACTIVE CRITIQUING",
        "section_head": "Table 2 :",
        "score": 0.7061694860458374,
        "text_preview": "2 Mathematical program synthesis results. See Table9in the Appendix for LLaMA-2 7B and 13B results. * indicates an oracle setting where we only apply correction on the incorrect answers. GPT-3.5-Turbo"
      },
      {
        "chunk_index": 127572,
        "paper_id": 2666,
        "chunk_idx": 1,
        "title": "Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences",
        "section_head": "Dataset Compositions and Audio Annotation",
        "score": 0.7032867670059204,
        "text_preview": "-S2L-equations (Russian): 4,274 unique equations, 10 human-annotators, total 18,134 audio. -S2L-sentences (English): 12,395 unique sentences, 20 human-annotators, total 24,794 audio. ‚Ä¢ Artificial anno"
      }
    ]
  },
  {
    "query_id": 7,
    "query_text": "closer look model",
    "source": "title",
    "source_value": "A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 153925,
        "paper_id": 3155,
        "chunk_idx": 0,
        "title": "When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets",
        "section_head": "Original Expanded",
        "score": 0.9453662037849426,
        "text_preview": "Query: Is it possible to take a mortgage using Bitcoin as collateral? ... suggest that they borrow the money to invest with you. They can use their bitcoins as collateral for the loan. That way, they "
      },
      {
        "chunk_index": 136976,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.9411108493804932,
        "text_preview": "This meme highlights the deterioration of a person's handwriting during an exam. The first two pages show neat and legible handwriting, the middle page shows slightly messier handwriting, and the last"
      },
      {
        "chunk_index": 88038,
        "paper_id": 1853,
        "chunk_idx": 0,
        "title": "MINIGPT-4: ENHANCING VISION-LANGUAGE UNDERSTANDING WITH ADVANCED LARGE LANGUAGE MODELS",
        "section_head": "MiniGPT-4 LocNa",
        "score": 0.9410634636878967,
        "text_preview": "This meme is funny because it shows a sma floor with its legs stretched out, seemingly The caption, \"Monday just monday,\" adds suggesting that the dog is so relaxed that it the energy to get up. The i"
      },
      {
        "chunk_index": 36168,
        "paper_id": 765,
        "chunk_idx": 2,
        "title": "Distilling the Knowledge in a Neural Network",
        "section_head": "Introduction",
        "score": 0.9397565126419067,
        "text_preview": "For cumbersome models that learn to discriminate between a large number of classes, the normal training objective is to maximize the average log probability of the correct answer, but a side-effect of"
      },
      {
        "chunk_index": 131210,
        "paper_id": 2717,
        "chunk_idx": 0,
        "title": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI",
        "section_head": "POI Investigation Navigation",
        "score": 0.9395925402641296,
        "text_preview": "Mean Median SD Mean Median SD How well 6.0 6.0 0.7 6.0 6.0 0.9 How valuable 6.4 7.0 0.6 6.1 6.5 1.1 How accurate 5.7 6.0 0.9 5.5 5.5 1. 2 Table 8 : Post-hoc 7-point Likert scale ratings (7 is best). P"
      },
      {
        "chunk_index": 140611,
        "paper_id": 2900,
        "chunk_idx": 0,
        "title": "Towards a Human-like Open-Domain Chatbot",
        "section_head": "Addressing Cross-turn Repetitions",
        "score": 0.9381124973297119,
        "text_preview": "In interactive evaluation, about one third of the conversations with Meena (base) contain crossturn repetitions toward the end. Cross-turn repetition means that one turn somewhat repeats an earlier tu"
      },
      {
        "chunk_index": 138625,
        "paper_id": 2856,
        "chunk_idx": 0,
        "title": "The Photographer's Eye: Teaching Multimodal Large Language Models to See and Critique like Photographers",
        "section_head": "# 1 :# 2 :# 3 :",
        "score": 0.9343078136444092,
        "text_preview": "123 Very good one, even if the unsharp mask is too strong. This is gorgeous. The use of parallel lines and the vanishing point really leads us into this photo. And the mixture of warm and cool colors "
      },
      {
        "chunk_index": 79791,
        "paper_id": 1685,
        "chunk_idx": 20,
        "title": "Likelihood-Based Diffusion Language Models",
        "section_head": "D.1 Unconditional",
        "score": 0.9343016743659973,
        "text_preview": "Like Ridley, Whitfield concludes that this means \"even if you're at the bottom you're one generation away from obesity\".\\n\\nThis is certainly true, though there are two big problems with it. First, BA"
      },
      {
        "chunk_index": 123522,
        "paper_id": 2575,
        "chunk_idx": 2,
        "title": "Sigmoid Loss for Language Image Pre-Training",
        "section_head": "Negative ratio in sigmoid loss",
        "score": 0.9323028922080994,
        "text_preview": "We also look at the value of the learned bias at the end of training as well as the average logit value for positive and negative examples across these settings, and find the result mostly follows wha"
      },
      {
        "chunk_index": 118399,
        "paper_id": 2471,
        "chunk_idx": 2,
        "title": "SCALE EFFICIENTLY: INSIGHTS FROM PRE-TRAINING AND FINE-TUNING TRANSFORMERS",
        "section_head": "MODEL SHAPE MATTERS",
        "score": 0.9321475028991699,
        "text_preview": "Preprint 1.1e+12 2.2e+12 4.4e+12 8.8e+12 1.8e+13 Zooming in Versus Zooming Out Here, one may argue that a general trend (even on downstream) may still exist if we zoom out and cover a very wide range "
      },
      {
        "chunk_index": 72393,
        "paper_id": 1543,
        "chunk_idx": 0,
        "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
        "section_head": "Figure 11: An example of position bias.",
        "score": 0.930870532989502,
        "text_preview": "When Assistant A is placed in the first position, GPT-4 thinks A is better, but its verdict changes when we swap the position of A and B. We observe similar pattern from other LLM judges such as Claud"
      },
      {
        "chunk_index": 2085,
        "paper_id": 37,
        "chunk_idx": 1,
        "title": "A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts",
        "section_head": "QMSUM",
        "score": 0.9305570125579834,
        "text_preview": "Since other datasets don't have such a strong performance improvement, we suspect that QMSum is in some sense a more challenging dataset, requiring the model to actively search through the gisted tran"
      },
      {
        "chunk_index": 77938,
        "paper_id": 1648,
        "chunk_idx": 1,
        "title": "Learning to generate pointing gestures in situated embodied conversational agents",
        "section_head": "Sampling test pointing targets and distractors",
        "score": 0.9290798306465149,
        "text_preview": "We note that the distance range 20-40cm effectively determines the difficulty of the distractors. Referential game is more difficult if the distractors are closer to the actual pointing target. Throug"
      },
      {
        "chunk_index": 51017,
        "paper_id": 1093,
        "chunk_idx": 2,
        "title": "FedFlex: Federated Learning for Diverse Netflix Recommendations",
        "section_head": "Results",
        "score": 0.9286736845970154,
        "text_preview": "This also means that SVD would occasionally rate shows for users very high and overwhelm the reranker to an extent, which explains why, in the case of SVD, the reranker sticks closer to the original r"
      },
      {
        "chunk_index": 135144,
        "paper_id": 2796,
        "chunk_idx": 5,
        "title": "Testing chatbots on the creation of encoders for audio conditioned image generation",
        "section_head": "Results and Analysis",
        "score": 0.9284032583236694,
        "text_preview": "The reason to this phenomenon is unclear, but we suspect that this is likely a sign of a lack of enough training time, specially when considering that these two are the biggest models. Nevertheless, l"
      },
      {
        "chunk_index": 82386,
        "paper_id": 1733,
        "chunk_idx": 0,
        "title": "Locating and Editing Factual Associations in GPT",
        "section_head": "G.1 GPT-2 XL (1.5B) Generation Examples",
        "score": 0.9274196028709412,
        "text_preview": "We select four additional cases from COUNTERFACT to examine qualitatively, selecting representative generations to display. Green text indicates generations that are consistent with the edited fact, w"
      },
      {
        "chunk_index": 152786,
        "paper_id": 3143,
        "chunk_idx": 3,
        "title": "What Every Programmer Should Know About Memory",
        "section_head": "Cache and Memory Bandwidth",
        "score": 0.9272189140319824,
        "text_preview": "The processor does not have a Write-Through policy; written data is stored in L1d and only evicted when necessary. This allows for write speeds close to the optimal 16 bytes per cycle. Once L1d is not"
      },
      {
        "chunk_index": 79792,
        "paper_id": 1685,
        "chunk_idx": 21,
        "title": "Likelihood-Based Diffusion Language Models",
        "section_head": "D.1 Unconditional",
        "score": 0.9269593954086304,
        "text_preview": "This means that being at the top of the income distribution does not necessarily give someone \"higher\" status, or more privileged.\\n\\nSecond, even if you control for socioeconomic status, people who a"
      },
      {
        "chunk_index": 71499,
        "paper_id": 1525,
        "chunk_idx": 0,
        "title": "Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis",
        "section_head": "GloVe",
        "score": 0.9268125295639038,
        "text_preview": "Substitute or insert word randomly using word embeddings similarity. In office the theology is not good around recognition of harvard peace, particularly those of new cornell. Merit stirs need likely "
      },
      {
        "chunk_index": 142721,
        "paper_id": 2943,
        "chunk_idx": 3,
        "title": "Training language models to follow instructions with human feedback",
        "section_head": "Excerpt of labeling instructions on the API prompt distribution",
        "score": 0.9265034198760986,
        "text_preview": "Use the following guidelines to help select between outputs when making these trade-offs: For most tasks, being harmless and truthful is more important than being helpful. So in most cases, rate an ou"
      }
    ]
  },
  {
    "query_id": 8,
    "query_text": "comparative benchmark federated",
    "source": "title",
    "source_value": "A Comparative Benchmark of Federated Learning Strategies for Mortality Prediction on Heterogeneous a",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 129342,
        "paper_id": 2686,
        "chunk_idx": 1,
        "title": "Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select",
        "section_head": "D. Ablation Studies",
        "score": 0.9585566520690918,
        "text_preview": "(%) Fairness (Œ≥) Ablation (T=1.0, Œ∑ = 0.3, ¬µ = 0.01) HeteRo-Select (Œ≥ = 0.0) 0.0 0.3 0.01 65.35 56.21 HeteRo-Select (Œ≥ = 0.3) 0.3 0.3 0.01 62.19 44.77 HeteRo-Select (Œ≥ = 0.7) 0.7 0.3 0.01 66.90 66.90 "
      },
      {
        "chunk_index": 47629,
        "paper_id": 1015,
        "chunk_idx": 0,
        "title": "FairEquityFL -A Fair and Equitable Client Selection in Federated Learning for Heterogeneous IoV Networks",
        "section_head": "Fig. 4 :",
        "score": 0.9487051367759705,
        "text_preview": "4 Fig.4: Time-to-convergence comparison for the baseline FL frameworks vis-√†-vis our envisaged FairEquityFL framework."
      },
      {
        "chunk_index": 33635,
        "paper_id": 706,
        "chunk_idx": 0,
        "title": "DFed-SST: Building Semantic-and Structure-aware Topologies for Decentralized Federated Graph Learning",
        "section_head": "Figure 4 :",
        "score": 0.9432907104492188,
        "text_preview": "4 Figure 4: Convergence curves of our proposed DFed-SST and baseline methods on four graph datasets with 10 participating clients."
      },
      {
        "chunk_index": 51334,
        "paper_id": 1100,
        "chunk_idx": 0,
        "title": "FEDHK-MVFC: FEDERATED HEAT KERNEL MULTI-VIEW CLUSTERING",
        "section_head": "Experimental Setup and Evaluation Metrics 6.3.1 Baseline Algorithms",
        "score": 0.940814197063446,
        "text_preview": "We compare our proposed HK-MVFC and FedHK-MVFC algorithms against state-of-the-art multi-view clustering methods: ‚Ä¢"
      },
      {
        "chunk_index": 65803,
        "paper_id": 1402,
        "chunk_idx": 0,
        "title": "Hybrid Reputation Aggregation: A Robust Defense Mechanism for Adversarial Federated Learning in 5G and Edge Network Environments",
        "section_head": "EXPERIMENTAL RESULTS AND ABLATION STUDY",
        "score": 0.9367474317550659,
        "text_preview": "In this section, we evaluate the performance of our proposed hybrid reputation aggregation mechanism against several baseline aggregation methods in a federated learning setting under adversarial cond"
      },
      {
        "chunk_index": 361,
        "paper_id": 8,
        "chunk_idx": 0,
        "title": "A Comparative Benchmark of Federated Learning Strategies for Mortality Prediction on Heterogeneous and Imbalanced Clinical Data",
        "section_head": "Results",
        "score": 0.9247043132781982,
        "text_preview": "The section presents the empirical results of our comparative analysis of five federated learning strategies. We evaluate the strategies based on their performance evolution across communication round"
      },
      {
        "chunk_index": 28118,
        "paper_id": 577,
        "chunk_idx": 0,
        "title": "Contextualized Multimodal Lifelong Person Re-Identification in Hybrid Clothing States",
        "section_head": "Experiments",
        "score": 0.9245051741600037,
        "text_preview": "To rigorously evaluate the effectiveness of our proposed Contextualized Multimodal Lifelong Re-ID (CMLReID) framework, we conducted extensive experiments under the challenging LReID-Hybrid setting. Th"
      },
      {
        "chunk_index": 32507,
        "paper_id": 682,
        "chunk_idx": 0,
        "title": "Degree of Staleness-Aware Data Updating in Federated Learning",
        "section_head": "Figure 4 :",
        "score": 0.9214379787445068,
        "text_preview": "4 Figure 4: Comparative analysis of utility function U k of client k over various strategies ‚àÜ k ."
      },
      {
        "chunk_index": 43237,
        "paper_id": 918,
        "chunk_idx": 0,
        "title": "Enhancing Privacy Preservation and Reducing Analysis Time with Federated Transfer Learning in Digital Twins-based Computed Tomography Scan Analysis",
        "section_head": "Performance Evaluation",
        "score": 0.9196255803108215,
        "text_preview": "This section uses various performance evaluations to assess our proposed framework using Federated Transfer Learning."
      },
      {
        "chunk_index": 62098,
        "paper_id": 1327,
        "chunk_idx": 0,
        "title": "Graph Federated Learning for Personalized Privacy Recommendation",
        "section_head": "Baselines and Implementation Details",
        "score": 0.9193023443222046,
        "text_preview": "Baselines. We compare our proposed federated recommendation method against a series of representative baselines under both centralized and federated settings. All compared methods operate solely on us"
      },
      {
        "chunk_index": 140897,
        "paper_id": 2906,
        "chunk_idx": 0,
        "title": "Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift",
        "section_head": "Baselines",
        "score": 0.913677453994751,
        "text_preview": "We compare our method against two categories of baselines: Collaborative Fairness algorithms designed for non-IID data, and Covariate Shift algorithms focusing on feature-level discrepancies. Specific"
      },
      {
        "chunk_index": 48624,
        "paper_id": 1039,
        "chunk_idx": 0,
        "title": "FED-REACT: FEDERATED REPRESENTATION LEARNING FOR HETEROGENEOUS AND EVOLVING DATA",
        "section_head": "Experiments",
        "score": 0.9128422141075134,
        "text_preview": "In Section 4.1, we compare Fed-REACT with supervised learning baselines on a range of time series tasks, demonstrating its superior performance. Section 4.2 evaluates Fed-REACT against clustered FL me"
      },
      {
        "chunk_index": 129341,
        "paper_id": 2686,
        "chunk_idx": 0,
        "title": "Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select",
        "section_head": "D. Ablation Studies",
        "score": 0.9065550565719604,
        "text_preview": "Our results in Table I have already established that our champion HeteRo-Select configuration is superior to the main baselines. To further understand the impact of various hyperparameters and design "
      },
      {
        "chunk_index": 7270,
        "paper_id": 136,
        "chunk_idx": 0,
        "title": "Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning",
        "section_head": "Experiment",
        "score": 0.8992832899093628,
        "text_preview": "In this section, we evaluate the performance of FedLEASE, against baseline methods on two types of datasets: natural language understanding (NLU) and natural language generation (NLG). Baseline Method"
      },
      {
        "chunk_index": 25129,
        "paper_id": 507,
        "chunk_idx": 0,
        "title": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation",
        "section_head": "A. Overview",
        "score": 0.8989436626434326,
        "text_preview": "The supplementary material is structured as follows: ‚Ä¢ In Section B, we provide an algorithm for the overall setup of our proposed Practical Semi-Supervised Federated Learning (PSSFL). ‚Ä¢ In Section C,"
      },
      {
        "chunk_index": 7240,
        "paper_id": 135,
        "chunk_idx": 0,
        "title": "Adaptive LLM Routing Under Budget Constraints",
        "section_head": "Table 1 :",
        "score": 0.8961523771286011,
        "text_preview": "1 Overview of Experiments: Summary of empirical evaluations conducted to assess PILOT's performance. Section 5.1"
      },
      {
        "chunk_index": 25118,
        "paper_id": 507,
        "chunk_idx": 0,
        "title": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation",
        "section_head": "Discussion",
        "score": 0.8918390274047852,
        "text_preview": "To further demonstrate the effectiveness of our proposed method and gain more insights, we conduct more experiments on BDD100K with 9 clients."
      },
      {
        "chunk_index": 108179,
        "paper_id": 2244,
        "chunk_idx": 1,
        "title": "Privacy-Preserving Personalization in Education: A Federated Recommender System for Student Performance Prediction",
        "section_head": "RQ3:",
        "score": 0.8901761770248413,
        "text_preview": "We provide a comparative analysis against a powerful centralized baseline (XGBoost), quantifying the trade-off between privacy and performance and showing that our federated model achieves 82.85% of t"
      },
      {
        "chunk_index": 133276,
        "paper_id": 2757,
        "chunk_idx": 0,
        "title": "SYNERGYNET: FUSING GENERATIVE PRIORS AND STATE-SPACE MODELS FOR FACIAL BEAUTY PREDICTION",
        "section_head": "Automatic Mixed Precision (AMP). 4 Experiments",
        "score": 0.8900748491287231,
        "text_preview": "To empirically validate the efficacy and architectural design of our proposed Mamba-Diffusion Network (MD-Net), we conducted a series of comprehensive experiments. This section provides a detailed acc"
      },
      {
        "chunk_index": 49187,
        "paper_id": 1051,
        "chunk_idx": 0,
        "title": "FedDAF: Federated Domain Adaptation Using Model Functional Distance",
        "section_head": "Experiments",
        "score": 0.8894248008728027,
        "text_preview": "To validate our proposed method, we conduct extensive experiments on different real life datasets in federated domain adaptation frameworks. In this section, we describe datasets, experimental setup a"
      }
    ]
  },
  {
    "query_id": 9,
    "query_text": "comparative benchmark real-time",
    "source": "title",
    "source_value": "A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Man",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 43962,
        "paper_id": 935,
        "chunk_idx": 0,
        "title": "EnvX: Agentize Everything with Agentic AI",
        "section_head": "Evaluation Setup",
        "score": 0.9467689990997314,
        "text_preview": "We compare our system against three existing coding-agent frameworks designed for repository-level task execution, using three widely adopted LLM backbones. Details are as follows."
      },
      {
        "chunk_index": 50603,
        "paper_id": 1084,
        "chunk_idx": 0,
        "title": "Federated Nonlinear System Identification",
        "section_head": "Experiments",
        "score": 0.9241712093353271,
        "text_preview": "We conducted experiments on a range of systems, encompassing both synthetic benchmarks and real-world dynamical systems. In the following, we provide details regarding datasets employed, hyperparamete"
      },
      {
        "chunk_index": 19356,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "Figure 16 :",
        "score": 0.9234592914581299,
        "text_preview": "16 Figure16: Detailed analysis on the tools, datasets, and software used for variant prioritization task."
      },
      {
        "chunk_index": 119618,
        "paper_id": 2493,
        "chunk_idx": 0,
        "title": "Scene-Aware Vectorized Memory Multi-Agent Framework with Cross-Modal Differentiated Quantization VLMs for Visually Impaired Assistance",
        "section_head": "A. Detailed Scene Analysis Results",
        "score": 0.9114915728569031,
        "text_preview": "In this appendix, detailed analysis results from the experimental evaluation of the multi-agent assistance framework are provided. Tables 4 , 5 , and 6 present the comprehensive processing results for"
      },
      {
        "chunk_index": 49187,
        "paper_id": 1051,
        "chunk_idx": 0,
        "title": "FedDAF: Federated Domain Adaptation Using Model Functional Distance",
        "section_head": "Experiments",
        "score": 0.9036178588867188,
        "text_preview": "To validate our proposed method, we conduct extensive experiments on different real life datasets in federated domain adaptation frameworks. In this section, we describe datasets, experimental setup a"
      },
      {
        "chunk_index": 19355,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "Figure 15 :",
        "score": 0.9023688435554504,
        "text_preview": "15 Figure 15: Detailed analysis on the tools, datasets, and software used for scRNA annotation task."
      },
      {
        "chunk_index": 19354,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "Figure 14 :",
        "score": 0.8953951597213745,
        "text_preview": "14 Figure 14: Detailed analysis on the tools, datasets, and software used for drug repurposing task."
      },
      {
        "chunk_index": 19349,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "Figure 9 :",
        "score": 0.8914281129837036,
        "text_preview": "9 Figure9: Detailed analysis on the tools, datasets, and software used for Gene Perturbation task."
      },
      {
        "chunk_index": 28118,
        "paper_id": 577,
        "chunk_idx": 0,
        "title": "Contextualized Multimodal Lifelong Person Re-Identification in Hybrid Clothing States",
        "section_head": "Experiments",
        "score": 0.8913970589637756,
        "text_preview": "To rigorously evaluate the effectiveness of our proposed Contextualized Multimodal Lifelong Re-ID (CMLReID) framework, we conducted extensive experiments under the challenging LReID-Hybrid setting. Th"
      },
      {
        "chunk_index": 18488,
        "paper_id": 375,
        "chunk_idx": 0,
        "title": "Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit domain rules",
        "section_head": "Results and Analysis",
        "score": 0.8899732232093811,
        "text_preview": "We assess DART-VAE in the aircraft and automotive domains through extensive experimental setups to illustrate the incremental advantages of including domain constraints. All experiments employ appropr"
      },
      {
        "chunk_index": 101400,
        "paper_id": 2111,
        "chunk_idx": 0,
        "title": "Optimization Methods and Software for Federated Learning Dissertation by Konstantin Burlachenko In Partial Fulfillment of the Requirements For the Degree of Doctor of Philosophy",
        "section_head": "Benchmarking Against Best-Practice Solutions.",
        "score": 0.8892706632614136,
        "text_preview": "We conduct an extensive evaluation of BurTorch by benchmarking it against several computational libraries, including JAX, TensorFlow, PyTorch, Apple MLX, Autograd, TFLite, and Micrograd. Our experimen"
      },
      {
        "chunk_index": 19350,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "Figure 10 :",
        "score": 0.883493185043335,
        "text_preview": "10 Figure 10: Detailed analysis on the tools, datasets, and software used for GWAS causal gene detection task."
      },
      {
        "chunk_index": 14875,
        "paper_id": 300,
        "chunk_idx": 0,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Findings",
        "score": 0.883184552192688,
        "text_preview": "In this section, we present key findings from our experimental study: (1) Overall system usage, (2) adolescents' narrative construction with Autiverse, (3) their interactions with AI peer, (4) the imp"
      },
      {
        "chunk_index": 31652,
        "paper_id": 663,
        "chunk_idx": 0,
        "title": "Deep Interest Network for Click-Through Rate Prediction",
        "section_head": "EXPERIMENTS",
        "score": 0.881770133972168,
        "text_preview": "In this section, we present our experiments in detail, including datasets, evaluation metric, experimental setup, model comparison and the corresponding analysis. Experiments on two public datasets wi"
      },
      {
        "chunk_index": 95111,
        "paper_id": 2012,
        "chunk_idx": 0,
        "title": "Neural Scene Designer: Self-Styled Semantic Image Manipulation",
        "section_head": "V. EXPERIMENTS",
        "score": 0.8807095885276794,
        "text_preview": "In this section, we provide a comprehensive assessment of the proposed NSD framework. This includes detailed implementation details, along with quantitative and qualitative analyses conducted based on"
      },
      {
        "chunk_index": 18039,
        "paper_id": 368,
        "chunk_idx": 0,
        "title": "Beyond Sliders: Mastering the Art of Diffusion-based Image Manipulation",
        "section_head": "IV. EXPERIMENTS",
        "score": 0.8767983913421631,
        "text_preview": "In this section, we conducted multiple experiments to assess the performance and efficacy of our approach. These include evaluations across text-based and real-world scenarios, studies on rectifying f"
      },
      {
        "chunk_index": 37055,
        "paper_id": 787,
        "chunk_idx": 0,
        "title": "DOES FLUX ALREADY KNOW HOW TO PERFORM PHYSICALLY PLAUSIBLE IMAGE COMPOSITION?",
        "section_head": "Figure 6 :",
        "score": 0.8758173584938049,
        "text_preview": "6 Figure 6: Qualitative comparison of our method with multiple baselines in challenging scenarios, drawn from our benchmark dataset. More qualitative comparisons are available in Appendix K."
      },
      {
        "chunk_index": 106549,
        "paper_id": 2205,
        "chunk_idx": 0,
        "title": "Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models",
        "section_head": "Figure 21 .",
        "score": 0.8743692636489868,
        "text_preview": "21 Figure 21. Further qualitative comparisons of our method against state-of-the-art story visualization techniques, including StoryDiffusion, ConsiStory, AutoStudio, and Intelligent Grimm."
      },
      {
        "chunk_index": 19353,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "Figure 13 :",
        "score": 0.873022198677063,
        "text_preview": "13 Figure13: Detailed analysis on the tools, datasets, and software used for rare disease diagnosis task."
      },
      {
        "chunk_index": 45650,
        "paper_id": 974,
        "chunk_idx": 0,
        "title": "Experience Deploying Containerized GenAI Services at an HPC Center",
        "section_head": "Case Study: GenAI Inference Serving",
        "score": 0.8711207509040833,
        "text_preview": "This section presents a case study demonstrating the deployment of GenAI inference services on HPC and Kubernetes platforms. We cover the complete end-to-end workflow, including downloading models fro"
      }
    ]
  },
  {
    "query_id": 10,
    "query_text": "comparison human gpt-3",
    "source": "title",
    "source_value": "A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 54890,
        "paper_id": 1174,
        "chunk_idx": 0,
        "title": "FLASK: FINE-GRAINED LANGUAGE MODEL EVALUATION BASED ON ALIGNMENT SKILL SETS",
        "section_head": "Figure 21 :",
        "score": 0.8845028877258301,
        "text_preview": "21 Figure 20: Comparing GPT-3.5, VICUNA 13B, SELFEE 13B via FLASK."
      },
      {
        "chunk_index": 146523,
        "paper_id": 3020,
        "chunk_idx": 0,
        "title": "UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets",
        "section_head": "Figure 3 :",
        "score": 0.8794152736663818,
        "text_preview": "3 Figure 3: Generation evaluation for different models."
      },
      {
        "chunk_index": 39519,
        "paper_id": 837,
        "chunk_idx": 0,
        "title": "EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs",
        "section_head": "Figure 8 :",
        "score": 0.8757380247116089,
        "text_preview": "8 Figure 8: Human evaluation results."
      },
      {
        "chunk_index": 38936,
        "paper_id": 820,
        "chunk_idx": 0,
        "title": "DTPA: Dynamic Token-level Prefix Augmentation for Controllable Text Generation",
        "section_head": "Figure 3 :",
        "score": 0.8706504702568054,
        "text_preview": "3 Figure 3: Comparison of human evaluation results for DTPA and Air-Decoding."
      },
      {
        "chunk_index": 85709,
        "paper_id": 1805,
        "chunk_idx": 0,
        "title": "MDPO: Conditional Preference Optimization for Multimodal Large Language Models",
        "section_head": "Figure 4 :",
        "score": 0.865017294883728,
        "text_preview": "4 Figure 4: Human evaluation on MMHalBench."
      },
      {
        "chunk_index": 103422,
        "paper_id": 2141,
        "chunk_idx": 0,
        "title": "PaLM: Scaling Language Modeling with Pathways",
        "section_head": "Figure 15 :",
        "score": 0.8474671840667725,
        "text_preview": "15 Figure 15: Comparison of PaLM on 0-shot translation tasks. (left) Comparison with previous large language models. (right) Comparison of different PaLM model scales."
      },
      {
        "chunk_index": 85881,
        "paper_id": 1810,
        "chunk_idx": 0,
        "title": "MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING",
        "section_head": "Figure 6 :",
        "score": 0.8466569185256958,
        "text_preview": "6 Figure 6: GPT-3 (few-shot) and UnifiedQA results."
      },
      {
        "chunk_index": 30320,
        "paper_id": 633,
        "chunk_idx": 0,
        "title": "Data-Driven Loss Functions for Inference-Time Optimization in Text-to-Image Generation",
        "section_head": "C. Additional Qualitative Results",
        "score": 0.8429723978042603,
        "text_preview": "We perform extensive comparisons on both GenEval (Fig- 16, 17, and 18). Figure 16. FLUX.1-schnell on the T2I-CompBech benchmark"
      },
      {
        "chunk_index": 92785,
        "paper_id": 1957,
        "chunk_idx": 0,
        "title": "Multimodal Few-Shot Learning with Frozen Language Models",
        "section_head": "Figure 4 :",
        "score": 0.8388344049453735,
        "text_preview": "4 Figure 4: Examples of (a) the Open-Ended miniImageNet evaluation (b) the Fast VQA evaluation."
      },
      {
        "chunk_index": 78014,
        "paper_id": 1650,
        "chunk_idx": 0,
        "title": "LEARNING TO SUMMARIZE BY LEARNING TO QUIZ: ADVERSARIAL AGENTIC COLLABORATION FOR LONG DOCUMENT SUMMARIZATION",
        "section_head": "Figure 3 :",
        "score": 0.8357665538787842,
        "text_preview": "3 Figure 3: Human evaluation results comparing GPT-4O, O3, SUMMQ COMBO , and SUMMQ COMBOR ."
      },
      {
        "chunk_index": 58160,
        "paper_id": 1244,
        "chunk_idx": 0,
        "title": "G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment",
        "section_head": "Figure 2 :",
        "score": 0.8323120474815369,
        "text_preview": "2 Figure2: Averaged G-EVAL-4's scores for humanwritten summaries and GPT-3.5 summaries, divided by human judges' preference."
      },
      {
        "chunk_index": 23043,
        "paper_id": 471,
        "chunk_idx": 0,
        "title": "CHAIN-OF-KNOWLEDGE: GROUNDING LARGE LAN-GUAGE MODELS VIA DYNAMIC KNOWLEDGE ADAPT-ING OVER HETEROGENEOUS SOURCES",
        "section_head": "Figure",
        "score": 0.828112781047821,
        "text_preview": "Figure 5: Human evaluation questions."
      },
      {
        "chunk_index": 23042,
        "paper_id": 471,
        "chunk_idx": 0,
        "title": "CHAIN-OF-KNOWLEDGE: GROUNDING LARGE LAN-GUAGE MODELS VIA DYNAMIC KNOWLEDGE ADAPT-ING OVER HETEROGENEOUS SOURCES",
        "section_head": "Figure 4 :",
        "score": 0.8236507177352905,
        "text_preview": "4 Figure 4: Human evaluation instructions."
      },
      {
        "chunk_index": 120362,
        "paper_id": 2508,
        "chunk_idx": 0,
        "title": "Secrets of RLHF in Large Language Models Part I: PPO",
        "section_head": "Figure 10 :",
        "score": 0.816506028175354,
        "text_preview": "10 Figure 10: Preference evaluations, compared RLHF models with SFT models in human evaluation and GPT-4 evaluation (right)."
      },
      {
        "chunk_index": 136490,
        "paper_id": 2822,
        "chunk_idx": 0,
        "title": "The Claude 3 Model Family: Opus, Sonnet, Haiku",
        "section_head": "Figure 10",
        "score": 0.8164294958114624,
        "text_preview": "This figure shows results from the Multilingual MMLU evaluation on Claude 3 models."
      },
      {
        "chunk_index": 147004,
        "paper_id": 3027,
        "chunk_idx": 0,
        "title": "UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units",
        "section_head": "Figure 6 :",
        "score": 0.8155810832977295,
        "text_preview": "6 Figure 6: Results of human evaluation on multi-domain Es‚ÜíEn corpus"
      },
      {
        "chunk_index": 100343,
        "paper_id": 2101,
        "chunk_idx": 0,
        "title": "OPENCHAT: ADVANCING OPEN-SOURCE LANGUAGE MODELS WITH MIXED-QUALITY DATA",
        "section_head": "Fig. 2",
        "score": 0.8121116757392883,
        "text_preview": "2 Figure 3: Quality distribution of GPT-3.5 and GPT-4 conversations in the ShareGPT dataset."
      },
      {
        "chunk_index": 100347,
        "paper_id": 2101,
        "chunk_idx": 0,
        "title": "OPENCHAT: ADVANCING OPEN-SOURCE LANGUAGE MODELS WITH MIXED-QUALITY DATA",
        "section_head": "Figure 8 :",
        "score": 0.8114884495735168,
        "text_preview": "8 Figure 8: The consistency between GPT-3.5 and Claude-2 in AlpacaEval benchmark."
      },
      {
        "chunk_index": 118634,
        "paper_id": 2474,
        "chunk_idx": 0,
        "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation",
        "section_head": "Figure 25 :Figure 26 :",
        "score": 0.8113003969192505,
        "text_preview": "2526 Figure 25: Human evaluation setup."
      },
      {
        "chunk_index": 108755,
        "paper_id": 2255,
        "chunk_idx": 0,
        "title": "PROMETHEUS: INDUCING FINE-GRAINED EVALUATION CAPABILITY IN LANGUAGE MODELS",
        "section_head": "I",
        "score": 0.810884952545166,
        "text_preview": "Figure16, Figure17, Figure18, Figure19shows a qualitative example of feedback generated by either GPT-4, PROMETHEUS (13B), and Code-Llama trained on the FEEDBACK COLLECTION."
      }
    ]
  },
  {
    "query_id": 11,
    "query_text": "comprehensive data-centric overview",
    "source": "title",
    "source_value": "A Comprehensive Data-centric Overview of Federated Graph Learning",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 62642,
        "paper_id": 1336,
        "chunk_idx": 0,
        "title": "GRAPHUNIVERSE: ENABLING SYSTEMATIC EVALUA-TION OF INDUCTIVE GENERALIZATION",
        "section_head": "Figure 1 :",
        "score": 0.9802639484405518,
        "text_preview": "1 Figure 1: Overview of GraphUniverse generation methodology."
      },
      {
        "chunk_index": 127272,
        "paper_id": 2656,
        "chunk_idx": 0,
        "title": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies",
        "section_head": "METHODS",
        "score": 0.9115186333656311,
        "text_preview": "Figure 1 provides and overview of the methodology of the study."
      },
      {
        "chunk_index": 44757,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Figure 2 :",
        "score": 0.9036334753036499,
        "text_preview": "2 Figure2: An overview of studies on knowledge and capability evaluation for LLMs."
      },
      {
        "chunk_index": 102624,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Experiments",
        "score": 0.9031050205230713,
        "text_preview": "We evaluate ReT-Eval in multiple dimensions: knowledge thread construction quality, reasoning thread optimization, and instruction generation performance. Our evaluation methodology follows a structur"
      },
      {
        "chunk_index": 91696,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "Framework of MTalk-Bench",
        "score": 0.9024835824966431,
        "text_preview": "MTalk-Bench adopts a dual-method evaluation framework, encompassing both comprehensive scenarios (i.e., where to evaluate) and hierarchical capabilities (i.e., what to evaluate), detailed in ¬ß3.1 and "
      },
      {
        "chunk_index": 38399,
        "paper_id": 811,
        "chunk_idx": 0,
        "title": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth",
        "section_head": "Task Design",
        "score": 0.8928432464599609,
        "text_preview": "To evaluate an LLM's ability to understand Drivelology, we designed four tasks to assess different facets of social and non-linear reasoning. An overview of these tasks is provided in Figure 2 ."
      },
      {
        "chunk_index": 44572,
        "paper_id": 952,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis",
        "section_head": "Fig. 5",
        "score": 0.8886796236038208,
        "text_preview": "5 Fig. 5 Comparative analysis across the evaluation criteria"
      },
      {
        "chunk_index": 44760,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Figure 5 :",
        "score": 0.8767104148864746,
        "text_preview": "5 Figure 5: Overview of specialized LLMs evaluation."
      },
      {
        "chunk_index": 4939,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Fig. 27 :",
        "score": 0.8748514652252197,
        "text_preview": "27 Fig. 27: Scientific data construction pipeline: multi-source data acquisition, data synthesis pipelines for pre-training, posttraining and evaluation stages, and comprehensive review framework inco"
      },
      {
        "chunk_index": 44758,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Figure 3 :",
        "score": 0.8747757077217102,
        "text_preview": "3 Figure 3: Overview of alignment evaluations."
      },
      {
        "chunk_index": 65180,
        "paper_id": 1388,
        "chunk_idx": 0,
        "title": "How Good are Foundation Models in Step-by-Step Embodied Reasoning?",
        "section_head": "Evaluation Framework",
        "score": 0.8741099834442139,
        "text_preview": "To effectively evaluate the embodied reasoning capabilities of LMMs, we propose a structured evaluation framework that goes beyond simple accuracy metrics. We leverage an LLM-as-judge approach for aut"
      },
      {
        "chunk_index": 53886,
        "paper_id": 1155,
        "chunk_idx": 0,
        "title": "Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach",
        "section_head": "Fig. 5 .",
        "score": 0.8593755960464478,
        "text_preview": "5 Fig. 5. The process for comparative evaluation of MelcotCR"
      },
      {
        "chunk_index": 65157,
        "paper_id": 1387,
        "chunk_idx": 0,
        "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective",
        "section_head": "Figure 1 :",
        "score": 0.8571894764900208,
        "text_preview": "1 Figure 1: Overview of the evaluation and recovery pipeline"
      },
      {
        "chunk_index": 93728,
        "paper_id": 1979,
        "chunk_idx": 0,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "User Study",
        "score": 0.8513205051422119,
        "text_preview": "We conducted a comprehensive user study to assess perceptual and cognitive aspects of music quality. The subjective criteria defined in Table 1 are employed to enable crossmodel comparison from a huma"
      },
      {
        "chunk_index": 9129,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "A. Dataset Construction via Human-AI Collaboration",
        "score": 0.8438237905502319,
        "text_preview": "To evaluate AISSISTANT, we generated a dataset of 48 research papers generated through Human-AI collaboration, evenly split between 24 perspective papers and 24 review papers. Each paper was produced "
      },
      {
        "chunk_index": 93259,
        "paper_id": 1970,
        "chunk_idx": 0,
        "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face",
        "section_head": "A.1 Survey Questionnaire and Responses",
        "score": 0.8397456407546997,
        "text_preview": "To provide transparency on the survey methodology, we include the full list of questions and a summary of responses. The survey was conducted among researchers in multimodal and sign language processi"
      },
      {
        "chunk_index": 88483,
        "paper_id": 1859,
        "chunk_idx": 0,
        "title": "Mining Mental Health Signals: A Comparative Study of Four Machine Learning Methods for Depression Detection from Social Media Posts in Sorani Kurdish",
        "section_head": "Figure 1 :",
        "score": 0.8379703164100647,
        "text_preview": "1 Figure 1: Research methodology"
      },
      {
        "chunk_index": 9133,
        "paper_id": 175,
        "chunk_idx": 2,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "C. Context Window Management",
        "score": 0.8369169235229492,
        "text_preview": "Their responsibilities spanned the pipeline: i) Reference Provision and Curation: collaborators provided initial seed references and curated AI-retrieved literature to ensure contextual relevance and "
      },
      {
        "chunk_index": 44945,
        "paper_id": 958,
        "chunk_idx": 0,
        "title": "Evaluating Reward Models for Language Modeling",
        "section_head": "H Dataset Characteristics",
        "score": 0.8345131874084473,
        "text_preview": "The following subsections will discuss our analyses of some high-level characteristics of the evaluation dataset."
      },
      {
        "chunk_index": 41008,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Figure 5 :",
        "score": 0.8344707489013672,
        "text_preview": "5 Figure5: Guideline for human evaluation on GSM8K mathematical reasoning."
      }
    ]
  },
  {
    "query_id": 12,
    "query_text": "comprehensive review datasets",
    "source": "title",
    "source_value": "A Comprehensive Review of Datasets for Clinical Mental Health AI Systems",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 53864,
        "paper_id": 1155,
        "chunk_idx": 0,
        "title": "Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach",
        "section_head": "Experimental settings",
        "score": 0.9671988487243652,
        "text_preview": "Experimental settings include datasets, benchmark models, and evaluation metrics."
      },
      {
        "chunk_index": 40559,
        "paper_id": 856,
        "chunk_idx": 0,
        "title": "Efficient Hate Speech Detection: Evaluating 38 Models from Traditional Methods to Transformers",
        "section_head": "Large-Scale Dataset Configurations",
        "score": 0.9560713171958923,
        "text_preview": "Our experimental evaluation extends to three larger-scale datasets:"
      },
      {
        "chunk_index": 59258,
        "paper_id": 1260,
        "chunk_idx": 0,
        "title": "Gemma: Open Models Based on Gemini Research and Technology",
        "section_head": "Evaluation",
        "score": 0.9463109970092773,
        "text_preview": "We evaluate Gemma across a broad range of domains, using both automated benchmarks and human evaluation."
      },
      {
        "chunk_index": 21849,
        "paper_id": 448,
        "chunk_idx": 0,
        "title": "Can NLP Tackle Hate Speech in the Real World? Stakeholder-Informed Feedback and Survey on Counterspeech",
        "section_head": "Summary of included resources",
        "score": 0.9432332515716553,
        "text_preview": "After following the systematic survey process, we were left with 74 items for systematic review that cover wholly or partially automatically generated counterspeech, and the computational analysis of "
      },
      {
        "chunk_index": 18143,
        "paper_id": 370,
        "chunk_idx": 0,
        "title": "Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM",
        "section_head": "A. Data Collection & Pre-processing",
        "score": 0.9430497288703918,
        "text_preview": "We utilize three heterogeneous app review datasets: ‚Ä¢ Google Play Store App Reviews: A comprehensive collection of user reviews and corresponding star ratings for various mobile applications. The data"
      },
      {
        "chunk_index": 81930,
        "paper_id": 1726,
        "chunk_idx": 0,
        "title": "LLMs as Architects and Critics for Multi-Source Opinion Summarization",
        "section_head": "D.1 Study Design and Methodology",
        "score": 0.942435085773468,
        "text_preview": "We conducted a large-scale user study (N = 300) comparing M-OS (Multi-Source Opinion Summaries) with traditional opinion summaries. Each participant evaluated four pairs of summaries. Participants pro"
      },
      {
        "chunk_index": 121988,
        "paper_id": 2539,
        "chunk_idx": 0,
        "title": "Semantic and Visual Crop-Guided Diffusion Models for Heterogeneous Tissue Synthesis in Histopathology",
        "section_head": "Qualitative Evaluation -Certified Pathologist Assessment.",
        "score": 0.9308477640151978,
        "text_preview": "To complement the quantitative metrics and downstream task performance, a comprehensive pathologist evaluation was conducted to assess the clinical realism and diagnostic utility of synthetic images. "
      },
      {
        "chunk_index": 60431,
        "paper_id": 1289,
        "chunk_idx": 0,
        "title": "GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning",
        "section_head": "C Evaluation",
        "score": 0.9250891804695129,
        "text_preview": "All evaluation is conducted using the VLMEvalKit toolkit 2 , ensuring standardized and reproducible evaluation metrics."
      },
      {
        "chunk_index": 9129,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "A. Dataset Construction via Human-AI Collaboration",
        "score": 0.9214409589767456,
        "text_preview": "To evaluate AISSISTANT, we generated a dataset of 48 research papers generated through Human-AI collaboration, evenly split between 24 perspective papers and 24 review papers. Each paper was produced "
      },
      {
        "chunk_index": 70194,
        "paper_id": 1496,
        "chunk_idx": 0,
        "title": "INTENTION-AWARE HIERARCHICAL DIFFUSION MODEL FOR LONG-TERM TRAJECTORY ANOMALY DETECTION",
        "section_head": "Experimental Setup",
        "score": 0.9197756052017212,
        "text_preview": "The experimental setup includes datasets, anomaly generation, baselines and evaluation metrics."
      },
      {
        "chunk_index": 10734,
        "paper_id": 209,
        "chunk_idx": 4,
        "title": "An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques",
        "section_head": "Related Work",
        "score": 0.9111829996109009,
        "text_preview": "In addition, the authors performed an extensive human evaluation of the model-generated summaries to attain a thorough comprehension of the summarization capabilities exhibited by LLMs. The authors in"
      },
      {
        "chunk_index": 141422,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "Clinician evaluation of radiology report generation",
        "score": 0.9097540378570557,
        "text_preview": "To further assess the quality and clinical applicability of chest X-ray reports generated by Med-PaLM M and understand the effect of model scaling, we conducted a human evaluation using the MIMIC-CXR "
      },
      {
        "chunk_index": 40597,
        "paper_id": 857,
        "chunk_idx": 0,
        "title": "EfficienT-HDR: An Efficient Transformer-Based Framework via Multi-Exposure Fusion for HDR Reconstruction",
        "section_head": "II. RELATED WORK",
        "score": 0.9093246459960938,
        "text_preview": "This study focuses on addressing three key challenges: exposure correction, multi-exposure fusion, and high dynamic range (HDR) imaging. The following provides a literature review on these three topic"
      },
      {
        "chunk_index": 117590,
        "paper_id": 2457,
        "chunk_idx": 0,
        "title": "SAGE: A Realistic Benchmark for Semantic Understanding",
        "section_head": "A. 1",
        "score": 0.907568097114563,
        "text_preview": "1 Dataset DetailsA.1.1 OpenAI Summarize from Feedback Dataset Source and Citation: The Summarize from Feedback dataset was introduced by Stiennon et al. [35] as part of their work on learning to summa"
      },
      {
        "chunk_index": 35226,
        "paper_id": 746,
        "chunk_idx": 0,
        "title": "Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference",
        "section_head": "Evaluation Protocol.",
        "score": 0.9071351885795593,
        "text_preview": "Automatic metrics. We assess image quality using established metrics on the HPDv2 benchmark (3,200 prompts). Our evaluation combines four standard measures: Aesthetic Score v2.5 [1, 27], PickScore [12"
      },
      {
        "chunk_index": 4939,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Fig. 27 :",
        "score": 0.9061138033866882,
        "text_preview": "27 Fig. 27: Scientific data construction pipeline: multi-source data acquisition, data synthesis pipelines for pre-training, posttraining and evaluation stages, and comprehensive review framework inco"
      },
      {
        "chunk_index": 149741,
        "paper_id": 3078,
        "chunk_idx": 0,
        "title": "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models",
        "section_head": "Ensuring Automatic Annotation Pipeline Consistency:",
        "score": 0.8994508385658264,
        "text_preview": "To ensure consistency between our automatic evaluation pipeline and human assessments, we conducted a blind test comparing QA pairs from human and semi-automatically annotated sources using 50 randoml"
      },
      {
        "chunk_index": 84586,
        "paper_id": 1780,
        "chunk_idx": 0,
        "title": "MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models",
        "section_head": "Figure 5 :",
        "score": 0.896652340888977,
        "text_preview": "5 VideoQualityAnalysisPipeline +dataset: BaseDataset +analyzer:List<VideoQualityAnalyzer> +evaluate() +prepare_dataset() +analyze_quality()"
      },
      {
        "chunk_index": 9147,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "B. Human Reviewer Assessments",
        "score": 0.8902819752693176,
        "text_preview": "Human assessments of the same Review and Perspective Papers were collected using AISSISTANT powered by GPT-4o-mini and OpenAI o1, following standard NeurIPS-style criteria: soundness, quality, clarity"
      },
      {
        "chunk_index": 22856,
        "paper_id": 468,
        "chunk_idx": 0,
        "title": "CEMTM: Contextual Embedding-based Multimodal Topic Modeling",
        "section_head": "Datasets",
        "score": 0.890088677406311,
        "text_preview": "We evaluate CEMTM across a diverse set of multimodal and long-document datasets spanning encyclopedic, scientific, narrative, educational, and social domains. Table 1 summarizes the datasets used in t"
      }
    ]
  },
  {
    "query_id": 13,
    "query_text": "comprehensive review transformer-based",
    "source": "title",
    "source_value": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 70740,
        "paper_id": 1508,
        "chunk_idx": 0,
        "title": "Intuition to Evidence: Measuring AI's True Impact on Developer Productivity",
        "section_head": "Figure 3 :",
        "score": 0.9243776202201843,
        "text_preview": "3 Figure 3: Pull Request Review Architecture: Multiagent system architecture with six specialized agents running in parallel for comprehensive code review analysis."
      },
      {
        "chunk_index": 44572,
        "paper_id": 952,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis",
        "section_head": "Fig. 5",
        "score": 0.9162818193435669,
        "text_preview": "5 Fig. 5 Comparative analysis across the evaluation criteria"
      },
      {
        "chunk_index": 93728,
        "paper_id": 1979,
        "chunk_idx": 0,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "User Study",
        "score": 0.9017580151557922,
        "text_preview": "We conducted a comprehensive user study to assess perceptual and cognitive aspects of music quality. The subjective criteria defined in Table 1 are employed to enable crossmodel comparison from a huma"
      },
      {
        "chunk_index": 93259,
        "paper_id": 1970,
        "chunk_idx": 0,
        "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face",
        "section_head": "A.1 Survey Questionnaire and Responses",
        "score": 0.901504635810852,
        "text_preview": "To provide transparency on the survey methodology, we include the full list of questions and a summary of responses. The survey was conducted among researchers in multimodal and sign language processi"
      },
      {
        "chunk_index": 9086,
        "paper_id": 173,
        "chunk_idx": 0,
        "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review",
        "section_head": "Methodology",
        "score": 0.8925192356109619,
        "text_preview": "To compile and structure the literature for this survey, we employed a systematic and multi-stage methodology. The process was designed to ensure a comprehensive, relevant, and high-quality selection "
      },
      {
        "chunk_index": 9133,
        "paper_id": 175,
        "chunk_idx": 2,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "C. Context Window Management",
        "score": 0.890955924987793,
        "text_preview": "Their responsibilities spanned the pipeline: i) Reference Provision and Curation: collaborators provided initial seed references and curated AI-retrieved literature to ensure contextual relevance and "
      },
      {
        "chunk_index": 91782,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "D.3 Evaluator Protocols",
        "score": 0.8890155553817749,
        "text_preview": "We employ both human and LLM evaluators to ensure comprehensive assessment while providing baseline comparisons for automated evaluation methods."
      },
      {
        "chunk_index": 91696,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "Framework of MTalk-Bench",
        "score": 0.8855447769165039,
        "text_preview": "MTalk-Bench adopts a dual-method evaluation framework, encompassing both comprehensive scenarios (i.e., where to evaluate) and hierarchical capabilities (i.e., what to evaluate), detailed in ¬ß3.1 and "
      },
      {
        "chunk_index": 9129,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "A. Dataset Construction via Human-AI Collaboration",
        "score": 0.8854854106903076,
        "text_preview": "To evaluate AISSISTANT, we generated a dataset of 48 research papers generated through Human-AI collaboration, evenly split between 24 perspective papers and 24 review papers. Each paper was produced "
      },
      {
        "chunk_index": 102646,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 4 :",
        "score": 0.8853821754455566,
        "text_preview": "4 Human expert evaluation resultsApproach Actionability Coherence Domain Spec. Tech Spec. Understand. User Focus Overall ReT-Eval 4.2 ¬± 0.7 4.1 ¬± 0.8 4.0 ¬± 0.8 4.0 ¬± 0.7 4.3 ¬± 0.6 4.1 ¬± 0.7 4.1 GNN"
      },
      {
        "chunk_index": 141472,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "Figure A. 3 |",
        "score": 0.8819581270217896,
        "text_preview": "3 Figure A.3 | Side-by-side human evaluation task interface. Radiologist raters ranked four findings paragraphs based on overall quality, given a chest X-ray and indication. The four findings correspo"
      },
      {
        "chunk_index": 53886,
        "paper_id": 1155,
        "chunk_idx": 0,
        "title": "Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach",
        "section_head": "Fig. 5 .",
        "score": 0.881687581539154,
        "text_preview": "5 Fig. 5. The process for comparative evaluation of MelcotCR"
      },
      {
        "chunk_index": 22277,
        "paper_id": 456,
        "chunk_idx": 0,
        "title": "Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG",
        "section_head": "Experiment",
        "score": 0.8726011514663696,
        "text_preview": "The Causal-Counterfactual RAG is evaluated through a comparative study against Regular RAG to assess its performance across various metrics, providing a comprehensive understanding of its strengths an"
      },
      {
        "chunk_index": 35381,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 18 :",
        "score": 0.872377336025238,
        "text_preview": "18 Figure 18: Evaluation criteria for quality of generated discharge summaries. System Prompt for Group B: Objective Evaluation: Evidence-Based Factuality & Completeness."
      },
      {
        "chunk_index": 4939,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Fig. 27 :",
        "score": 0.8658428192138672,
        "text_preview": "27 Fig. 27: Scientific data construction pipeline: multi-source data acquisition, data synthesis pipelines for pre-training, posttraining and evaluation stages, and comprehensive review framework inco"
      },
      {
        "chunk_index": 14879,
        "paper_id": 300,
        "chunk_idx": 0,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Constructing Narratives with Autiverse",
        "score": 0.86085045337677,
        "text_preview": "Based on the survey results and the feedback in debriefing, we illustrate how Autiverse guided adolescents' narrative construction through scaffolding and multimodal support."
      },
      {
        "chunk_index": 60431,
        "paper_id": 1289,
        "chunk_idx": 0,
        "title": "GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning",
        "section_head": "C Evaluation",
        "score": 0.859758734703064,
        "text_preview": "All evaluation is conducted using the VLMEvalKit toolkit 2 , ensuring standardized and reproducible evaluation metrics."
      },
      {
        "chunk_index": 21849,
        "paper_id": 448,
        "chunk_idx": 0,
        "title": "Can NLP Tackle Hate Speech in the Real World? Stakeholder-Informed Feedback and Survey on Counterspeech",
        "section_head": "Summary of included resources",
        "score": 0.8586066365242004,
        "text_preview": "After following the systematic survey process, we were left with 74 items for systematic review that cover wholly or partially automatically generated counterspeech, and the computational analysis of "
      },
      {
        "chunk_index": 141289,
        "paper_id": 2912,
        "chunk_idx": 0,
        "title": "Towards Expert-Level Medical Question Answering with Large Language Models",
        "section_head": "Long-form evaluation",
        "score": 0.8585097789764404,
        "text_preview": "To assess the performance of Med-PaLM 2 on long-form consumer medical question-answering, we conducted a series of human evaluations."
      },
      {
        "chunk_index": 13292,
        "paper_id": 266,
        "chunk_idx": 0,
        "title": "Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models",
        "section_head": "Reproducible Research Infrastructure:",
        "score": 0.856587827205658,
        "text_preview": "We release comprehensive open-source tools and experimental frameworks that enable researchers and practitioners to assess memorization risks in their own models."
      }
    ]
  },
  {
    "query_id": 14,
    "query_text": "comprehensive survey hallucination",
    "source": "title",
    "source_value": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 44572,
        "paper_id": 952,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis",
        "section_head": "Fig. 5",
        "score": 0.9147936105728149,
        "text_preview": "5 Fig. 5 Comparative analysis across the evaluation criteria"
      },
      {
        "chunk_index": 93728,
        "paper_id": 1979,
        "chunk_idx": 0,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "User Study",
        "score": 0.8969894647598267,
        "text_preview": "We conducted a comprehensive user study to assess perceptual and cognitive aspects of music quality. The subjective criteria defined in Table 1 are employed to enable crossmodel comparison from a huma"
      },
      {
        "chunk_index": 35381,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 18 :",
        "score": 0.8967791795730591,
        "text_preview": "18 Figure 18: Evaluation criteria for quality of generated discharge summaries. System Prompt for Group B: Objective Evaluation: Evidence-Based Factuality & Completeness."
      },
      {
        "chunk_index": 93259,
        "paper_id": 1970,
        "chunk_idx": 0,
        "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face",
        "section_head": "A.1 Survey Questionnaire and Responses",
        "score": 0.895337700843811,
        "text_preview": "To provide transparency on the survey methodology, we include the full list of questions and a summary of responses. The survey was conducted among researchers in multimodal and sign language processi"
      },
      {
        "chunk_index": 9127,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "h) Results & Analysis:",
        "score": 0.889426589012146,
        "text_preview": "For review papers, findings are organized by themes or research questions; for perspective papers, key claims are articulated and supported with evidence. Human collaborators may refine interpretation"
      },
      {
        "chunk_index": 42560,
        "paper_id": 902,
        "chunk_idx": 0,
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "section_head": "Automatic Evaluation",
        "score": 0.8858253955841064,
        "text_preview": "Our benchmark measures the following three dimensions of system responses: ‚Ä¢ Fluency: whether the model's generated text is fluent and coherent. ‚Ä¢ Correctness: whether the answer is accurate and cover"
      },
      {
        "chunk_index": 120831,
        "paper_id": 2515,
        "chunk_idx": 0,
        "title": "Seeing is Not Understanding: A Benchmark on Perception-Cognition Disparities in Large Language Models",
        "section_head": "4.",
        "score": 0.8825373649597168,
        "text_preview": "Comprehensive Evaluation: It should combine multiple-choice and open-ended questions to ensure both objective assessment and an evaluation of the accuracy and richness of generated content."
      },
      {
        "chunk_index": 91782,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "D.3 Evaluator Protocols",
        "score": 0.8812705278396606,
        "text_preview": "We employ both human and LLM evaluators to ensure comprehensive assessment while providing baseline comparisons for automated evaluation methods."
      },
      {
        "chunk_index": 53886,
        "paper_id": 1155,
        "chunk_idx": 0,
        "title": "Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach",
        "section_head": "Fig. 5 .",
        "score": 0.876737654209137,
        "text_preview": "5 Fig. 5. The process for comparative evaluation of MelcotCR"
      },
      {
        "chunk_index": 47299,
        "paper_id": 1010,
        "chunk_idx": 0,
        "title": "FACTOOL: Factuality Detection in Generative AI A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios",
        "section_head": "Scientific Literature Review Writing",
        "score": 0.8762672543525696,
        "text_preview": "The scientific literature review writing task (Jha et al., 2015) aims to analyze and synthesize existing research on a specific topic in a field of study. In this task, we define factuality as whether"
      },
      {
        "chunk_index": 65159,
        "paper_id": 1387,
        "chunk_idx": 0,
        "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective",
        "section_head": "Figure 3 :",
        "score": 0.8742810487747192,
        "text_preview": "3 Figure 2: Quality Analysis through plan recovery"
      },
      {
        "chunk_index": 35380,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 17 :",
        "score": 0.869503378868103,
        "text_preview": "17 Figure 17: Evaluation criteria for quality of generated discharge summaries. System Prompt for Group A: Subjective Evaluation: Language Quality & Appropriateness."
      },
      {
        "chunk_index": 137855,
        "paper_id": 2840,
        "chunk_idx": 0,
        "title": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs",
        "section_head": "Human Evaluation: The Gold Standard",
        "score": 0.8687469959259033,
        "text_preview": "Before analyzing the technical problems of hallucination detection methods, we first establish that commonly used evaluation metrics-specifically ROUGE-are poorly aligned with human judgments of factu"
      },
      {
        "chunk_index": 9129,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "A. Dataset Construction via Human-AI Collaboration",
        "score": 0.8677011132240295,
        "text_preview": "To evaluate AISSISTANT, we generated a dataset of 48 research papers generated through Human-AI collaboration, evenly split between 24 perspective papers and 24 review papers. Each paper was produced "
      },
      {
        "chunk_index": 141472,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "Figure A. 3 |",
        "score": 0.8672868013381958,
        "text_preview": "3 Figure A.3 | Side-by-side human evaluation task interface. Radiologist raters ranked four findings paragraphs based on overall quality, given a chest X-ray and indication. The four findings correspo"
      },
      {
        "chunk_index": 102646,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 4 :",
        "score": 0.8643074631690979,
        "text_preview": "4 Human expert evaluation resultsApproach Actionability Coherence Domain Spec. Tech Spec. Understand. User Focus Overall ReT-Eval 4.2 ¬± 0.7 4.1 ¬± 0.8 4.0 ¬± 0.8 4.0 ¬± 0.7 4.3 ¬± 0.6 4.1 ¬± 0.7 4.1 GNN"
      },
      {
        "chunk_index": 91696,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "Framework of MTalk-Bench",
        "score": 0.86301589012146,
        "text_preview": "MTalk-Bench adopts a dual-method evaluation framework, encompassing both comprehensive scenarios (i.e., where to evaluate) and hierarchical capabilities (i.e., what to evaluate), detailed in ¬ß3.1 and "
      },
      {
        "chunk_index": 141289,
        "paper_id": 2912,
        "chunk_idx": 0,
        "title": "Towards Expert-Level Medical Question Answering with Large Language Models",
        "section_head": "Long-form evaluation",
        "score": 0.8577075600624084,
        "text_preview": "To assess the performance of Med-PaLM 2 on long-form consumer medical question-answering, we conducted a series of human evaluations."
      },
      {
        "chunk_index": 141473,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "Figure A. 4 |",
        "score": 0.857093334197998,
        "text_preview": "4 Figure A.4 | Independent human evaluation task interface. Radiologist raters annotated a findings paragraph generated by Med-PaLM M (red) for errors and omissions, given a chest X-ray, the indicatio"
      },
      {
        "chunk_index": 9133,
        "paper_id": 175,
        "chunk_idx": 2,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "C. Context Window Management",
        "score": 0.8570058345794678,
        "text_preview": "Their responsibilities spanned the pipeline: i) Reference Provision and Curation: collaborators provided initial seed references and curated AI-retrieved literature to ensure contextual relevance and "
      }
    ]
  },
  {
    "query_id": 15,
    "query_text": "comprehensive survey vector",
    "source": "title",
    "source_value": "A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 91696,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "Framework of MTalk-Bench",
        "score": 0.9532890319824219,
        "text_preview": "MTalk-Bench adopts a dual-method evaluation framework, encompassing both comprehensive scenarios (i.e., where to evaluate) and hierarchical capabilities (i.e., what to evaluate), detailed in ¬ß3.1 and "
      },
      {
        "chunk_index": 44572,
        "paper_id": 952,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis",
        "section_head": "Fig. 5",
        "score": 0.9420206546783447,
        "text_preview": "5 Fig. 5 Comparative analysis across the evaluation criteria"
      },
      {
        "chunk_index": 93259,
        "paper_id": 1970,
        "chunk_idx": 0,
        "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face",
        "section_head": "A.1 Survey Questionnaire and Responses",
        "score": 0.9245822429656982,
        "text_preview": "To provide transparency on the survey methodology, we include the full list of questions and a summary of responses. The survey was conducted among researchers in multimodal and sign language processi"
      },
      {
        "chunk_index": 115942,
        "paper_id": 2419,
        "chunk_idx": 0,
        "title": "RLGF: Reinforcement Learning with Geometric Feedback for Autonomous Driving Video Generation",
        "section_head": "Hierarchical Geometric Reward (HGR)",
        "score": 0.9243462085723877,
        "text_preview": "The Hierarchical Geometric Reward (R) is designed to provide comprehensive, multi-level feedback on the geometric integrity and scene coherence of generated video latents. It evaluates consistency acr"
      },
      {
        "chunk_index": 93728,
        "paper_id": 1979,
        "chunk_idx": 0,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "User Study",
        "score": 0.9203447103500366,
        "text_preview": "We conducted a comprehensive user study to assess perceptual and cognitive aspects of music quality. The subjective criteria defined in Table 1 are employed to enable crossmodel comparison from a huma"
      },
      {
        "chunk_index": 9086,
        "paper_id": 173,
        "chunk_idx": 0,
        "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review",
        "section_head": "Methodology",
        "score": 0.8993293642997742,
        "text_preview": "To compile and structure the literature for this survey, we employed a systematic and multi-stage methodology. The process was designed to ensure a comprehensive, relevant, and high-quality selection "
      },
      {
        "chunk_index": 35381,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 18 :",
        "score": 0.8933593034744263,
        "text_preview": "18 Figure 18: Evaluation criteria for quality of generated discharge summaries. System Prompt for Group B: Objective Evaluation: Evidence-Based Factuality & Completeness."
      },
      {
        "chunk_index": 102624,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Experiments",
        "score": 0.8932678699493408,
        "text_preview": "We evaluate ReT-Eval in multiple dimensions: knowledge thread construction quality, reasoning thread optimization, and instruction generation performance. Our evaluation methodology follows a structur"
      },
      {
        "chunk_index": 53886,
        "paper_id": 1155,
        "chunk_idx": 0,
        "title": "Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach",
        "section_head": "Fig. 5 .",
        "score": 0.8931063413619995,
        "text_preview": "5 Fig. 5. The process for comparative evaluation of MelcotCR"
      },
      {
        "chunk_index": 9129,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "A. Dataset Construction via Human-AI Collaboration",
        "score": 0.8912040591239929,
        "text_preview": "To evaluate AISSISTANT, we generated a dataset of 48 research papers generated through Human-AI collaboration, evenly split between 24 perspective papers and 24 review papers. Each paper was produced "
      },
      {
        "chunk_index": 141472,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "Figure A. 3 |",
        "score": 0.8880887031555176,
        "text_preview": "3 Figure A.3 | Side-by-side human evaluation task interface. Radiologist raters ranked four findings paragraphs based on overall quality, given a chest X-ray and indication. The four findings correspo"
      },
      {
        "chunk_index": 102646,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 4 :",
        "score": 0.8863959312438965,
        "text_preview": "4 Human expert evaluation resultsApproach Actionability Coherence Domain Spec. Tech Spec. Understand. User Focus Overall ReT-Eval 4.2 ¬± 0.7 4.1 ¬± 0.8 4.0 ¬± 0.8 4.0 ¬± 0.7 4.3 ¬± 0.6 4.1 ¬± 0.7 4.1 GNN"
      },
      {
        "chunk_index": 91782,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "D.3 Evaluator Protocols",
        "score": 0.8842875957489014,
        "text_preview": "We employ both human and LLM evaluators to ensure comprehensive assessment while providing baseline comparisons for automated evaluation methods."
      },
      {
        "chunk_index": 14879,
        "paper_id": 300,
        "chunk_idx": 0,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Constructing Narratives with Autiverse",
        "score": 0.8838331699371338,
        "text_preview": "Based on the survey results and the feedback in debriefing, we illustrate how Autiverse guided adolescents' narrative construction through scaffolding and multimodal support."
      },
      {
        "chunk_index": 18163,
        "paper_id": 370,
        "chunk_idx": 0,
        "title": "Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM",
        "section_head": "Fig. 2 .",
        "score": 0.8810031414031982,
        "text_preview": "2 Fig. 2. Modular LLM-based review analysis framework. Preprocessed reviews feed into three independent components: (1) Aspect-sentiment extraction with recommendations, (2) topic modeling to surface "
      },
      {
        "chunk_index": 76311,
        "paper_id": 1613,
        "chunk_idx": 0,
        "title": "Layer by Layer: Uncovering Hidden Representations in Language Models",
        "section_head": "Representation Evaluation Metrics",
        "score": 0.8778222799301147,
        "text_preview": "Key Takeaway: Information-theoretic, geometric, and invariance-based metrics offer complementary perspectives on representation quality that can all be understood through matrix-based entropy. We now "
      },
      {
        "chunk_index": 35380,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 17 :",
        "score": 0.8751063346862793,
        "text_preview": "17 Figure 17: Evaluation criteria for quality of generated discharge summaries. System Prompt for Group A: Subjective Evaluation: Language Quality & Appropriateness."
      },
      {
        "chunk_index": 21849,
        "paper_id": 448,
        "chunk_idx": 0,
        "title": "Can NLP Tackle Hate Speech in the Real World? Stakeholder-Informed Feedback and Survey on Counterspeech",
        "section_head": "Summary of included resources",
        "score": 0.8748311400413513,
        "text_preview": "After following the systematic survey process, we were left with 74 items for systematic review that cover wholly or partially automatically generated counterspeech, and the computational analysis of "
      },
      {
        "chunk_index": 9133,
        "paper_id": 175,
        "chunk_idx": 2,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "C. Context Window Management",
        "score": 0.8729839324951172,
        "text_preview": "Their responsibilities spanned the pipeline: i) Reference Provision and Curation: collaborators provided initial seed references and curated AI-retrieved literature to ensure contextual relevance and "
      },
      {
        "chunk_index": 60431,
        "paper_id": 1289,
        "chunk_idx": 0,
        "title": "GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning",
        "section_head": "C Evaluation",
        "score": 0.8685815334320068,
        "text_preview": "All evaluation is conducted using the VLMEvalKit toolkit 2 , ensuring standardized and reproducible evaluation metrics."
      }
    ]
  },
  {
    "query_id": 16,
    "query_text": "comprehensive taxonomy hallucinations",
    "source": "title",
    "source_value": "A comprehensive taxonomy of hallucinations in Large Language Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 44572,
        "paper_id": 952,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis",
        "section_head": "Fig. 5",
        "score": 0.9042353630065918,
        "text_preview": "5 Fig. 5 Comparative analysis across the evaluation criteria"
      },
      {
        "chunk_index": 35381,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 18 :",
        "score": 0.9012744426727295,
        "text_preview": "18 Figure 18: Evaluation criteria for quality of generated discharge summaries. System Prompt for Group B: Objective Evaluation: Evidence-Based Factuality & Completeness."
      },
      {
        "chunk_index": 9127,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "h) Results & Analysis:",
        "score": 0.8919297456741333,
        "text_preview": "For review papers, findings are organized by themes or research questions; for perspective papers, key claims are articulated and supported with evidence. Human collaborators may refine interpretation"
      },
      {
        "chunk_index": 93728,
        "paper_id": 1979,
        "chunk_idx": 0,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "User Study",
        "score": 0.8846749663352966,
        "text_preview": "We conducted a comprehensive user study to assess perceptual and cognitive aspects of music quality. The subjective criteria defined in Table 1 are employed to enable crossmodel comparison from a huma"
      },
      {
        "chunk_index": 42560,
        "paper_id": 902,
        "chunk_idx": 0,
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "section_head": "Automatic Evaluation",
        "score": 0.8838425874710083,
        "text_preview": "Our benchmark measures the following three dimensions of system responses: ‚Ä¢ Fluency: whether the model's generated text is fluent and coherent. ‚Ä¢ Correctness: whether the answer is accurate and cover"
      },
      {
        "chunk_index": 120831,
        "paper_id": 2515,
        "chunk_idx": 0,
        "title": "Seeing is Not Understanding: A Benchmark on Perception-Cognition Disparities in Large Language Models",
        "section_head": "4.",
        "score": 0.8836894035339355,
        "text_preview": "Comprehensive Evaluation: It should combine multiple-choice and open-ended questions to ensure both objective assessment and an evaluation of the accuracy and richness of generated content."
      },
      {
        "chunk_index": 91696,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "Framework of MTalk-Bench",
        "score": 0.8781490325927734,
        "text_preview": "MTalk-Bench adopts a dual-method evaluation framework, encompassing both comprehensive scenarios (i.e., where to evaluate) and hierarchical capabilities (i.e., what to evaluate), detailed in ¬ß3.1 and "
      },
      {
        "chunk_index": 9129,
        "paper_id": 175,
        "chunk_idx": 0,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "A. Dataset Construction via Human-AI Collaboration",
        "score": 0.8750408887863159,
        "text_preview": "To evaluate AISSISTANT, we generated a dataset of 48 research papers generated through Human-AI collaboration, evenly split between 24 perspective papers and 24 review papers. Each paper was produced "
      },
      {
        "chunk_index": 91782,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "D.3 Evaluator Protocols",
        "score": 0.8685125112533569,
        "text_preview": "We employ both human and LLM evaluators to ensure comprehensive assessment while providing baseline comparisons for automated evaluation methods."
      },
      {
        "chunk_index": 9133,
        "paper_id": 175,
        "chunk_idx": 2,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "C. Context Window Management",
        "score": 0.8675073385238647,
        "text_preview": "Their responsibilities spanned the pipeline: i) Reference Provision and Curation: collaborators provided initial seed references and curated AI-retrieved literature to ensure contextual relevance and "
      },
      {
        "chunk_index": 93259,
        "paper_id": 1970,
        "chunk_idx": 0,
        "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face",
        "section_head": "A.1 Survey Questionnaire and Responses",
        "score": 0.8668716549873352,
        "text_preview": "To provide transparency on the survey methodology, we include the full list of questions and a summary of responses. The survey was conducted among researchers in multimodal and sign language processi"
      },
      {
        "chunk_index": 47299,
        "paper_id": 1010,
        "chunk_idx": 0,
        "title": "FACTOOL: Factuality Detection in Generative AI A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios",
        "section_head": "Scientific Literature Review Writing",
        "score": 0.8657622337341309,
        "text_preview": "The scientific literature review writing task (Jha et al., 2015) aims to analyze and synthesize existing research on a specific topic in a field of study. In this task, we define factuality as whether"
      },
      {
        "chunk_index": 35380,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 17 :",
        "score": 0.8647124767303467,
        "text_preview": "17 Figure 17: Evaluation criteria for quality of generated discharge summaries. System Prompt for Group A: Subjective Evaluation: Language Quality & Appropriateness."
      },
      {
        "chunk_index": 102646,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 4 :",
        "score": 0.8633599281311035,
        "text_preview": "4 Human expert evaluation resultsApproach Actionability Coherence Domain Spec. Tech Spec. Understand. User Focus Overall ReT-Eval 4.2 ¬± 0.7 4.1 ¬± 0.8 4.0 ¬± 0.8 4.0 ¬± 0.7 4.3 ¬± 0.6 4.1 ¬± 0.7 4.1 GNN"
      },
      {
        "chunk_index": 65159,
        "paper_id": 1387,
        "chunk_idx": 0,
        "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective",
        "section_head": "Figure 3 :",
        "score": 0.8628594875335693,
        "text_preview": "3 Figure 2: Quality Analysis through plan recovery"
      },
      {
        "chunk_index": 4939,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Fig. 27 :",
        "score": 0.8624573945999146,
        "text_preview": "27 Fig. 27: Scientific data construction pipeline: multi-source data acquisition, data synthesis pipelines for pre-training, posttraining and evaluation stages, and comprehensive review framework inco"
      },
      {
        "chunk_index": 38363,
        "paper_id": 810,
        "chunk_idx": 0,
        "title": "DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture",
        "section_head": "Human Verification Protocol.",
        "score": 0.8621088266372681,
        "text_preview": "To mitigate risks of hallucination or mistranslation (Sahoo et al., 2024b) , a two-stage human verification pipeline was adopted: ‚Ä¢ Stage 1: Bilingual reviewers verified semantic consistency, fluency,"
      },
      {
        "chunk_index": 53886,
        "paper_id": 1155,
        "chunk_idx": 0,
        "title": "Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach",
        "section_head": "Fig. 5 .",
        "score": 0.8575994968414307,
        "text_preview": "5 Fig. 5. The process for comparative evaluation of MelcotCR"
      },
      {
        "chunk_index": 115503,
        "paper_id": 2410,
        "chunk_idx": 0,
        "title": "Revisiting Rule-Based Stuttering Detection: A Comprehensive Analysis of Interpretable Models for Clinical Applications",
        "section_head": "Evaluation Challenges",
        "score": 0.8543425798416138,
        "text_preview": "Bayerl et al.'s comprehensive review highlights critical evaluation issues [13] . Event-based vs. interval-based segmentation produces incomparable metrics. Label definitions vary across corpora (e.g."
      },
      {
        "chunk_index": 137855,
        "paper_id": 2840,
        "chunk_idx": 0,
        "title": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs",
        "section_head": "Human Evaluation: The Gold Standard",
        "score": 0.8529180288314819,
        "text_preview": "Before analyzing the technical problems of hallucination detection methods, we first establish that commonly used evaluation metrics-specifically ROUGE-are poorly aligned with human judgments of factu"
      }
    ]
  },
  {
    "query_id": 17,
    "query_text": "computational framework identify",
    "source": "title",
    "source_value": "A Computational Framework to Identify Self-Aspects in Text",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 57532,
        "paper_id": 1233,
        "chunk_idx": 0,
        "title": "FROM TURN-TAKING TO SYNCHRONOUS DIALOGUE: A SURVEY OF FULL-DUPLEX SPOKEN LANGUAGE MODELS",
        "section_head": "External controllers.",
        "score": 0.9231688976287842,
        "text_preview": "External controllers maintain independence from the core engine. FlexDuo introduces a ternary FSM with an idle state for selective attention [7] . Semantic VAD uses lightweight (‚àº0.5B) models analyzin"
      },
      {
        "chunk_index": 22351,
        "paper_id": 458,
        "chunk_idx": 0,
        "title": "Causal Representation Learning from Multimodal Clinical Records under Non-Random Modality Missingness",
        "section_head": "C.5 Computational Efficiency Analysis",
        "score": 0.918956995010376,
        "text_preview": "Our framework is computationally efficient, requiring 12-16 hours of training on 20,000 patients using an RTX A6000 GPU (48GB) and only 50-100 milliseconds for a single patient prediction. Memory dema"
      },
      {
        "chunk_index": 132553,
        "paper_id": 2741,
        "chunk_idx": 0,
        "title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?",
        "section_head": "ALUE: Arabic Language Understanding Evaluation.",
        "score": 0.9156562089920044,
        "text_preview": "FRACAS: Framework for Computational Semantics."
      },
      {
        "chunk_index": 148941,
        "paper_id": 3070,
        "chunk_idx": 0,
        "title": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software",
        "section_head": "Contributions. We summarize the contributions below:",
        "score": 0.8925459384918213,
        "text_preview": "‚Ä¢ To the best of our knowledge, this is the first paper to study the lack of inference auditing problem in VFL. ‚Ä¢ We design VeFIA, an inference auditing framework, to efficiently validate the executio"
      },
      {
        "chunk_index": 64843,
        "paper_id": 1380,
        "chunk_idx": 0,
        "title": "Home-made Diffusion Model from Scratch to Hatch",
        "section_head": "XUT variants",
        "score": 0.8916754722595215,
        "text_preview": "To achieve efficient pretraining and inference on consumer hardware while maintaining competitive generation quality, we carefully balance model size with capability requirements. We propose three HDM"
      },
      {
        "chunk_index": 14077,
        "paper_id": 284,
        "chunk_idx": 1,
        "title": "AU-HARNESS: AN OPEN-SOURCE TOOLKIT FOR HOLISTIC EVALUATION OF AUDIO-LLMS",
        "section_head": "INFERENCE EFFICIENCY",
        "score": 0.8890810012817383,
        "text_preview": "Furthermore, we allow user-specified retry counts on request errors, enabling users to set higher request limits with the assurance that occasional failures will be re-tried and successfully completed"
      },
      {
        "chunk_index": 85110,
        "paper_id": 1794,
        "chunk_idx": 0,
        "title": "MATCHA-TTS: A FAST TTS ARCHITECTURE WITH CONDITIONAL FLOW MATCHING",
        "section_head": "Fig. 1 :",
        "score": 0.8810226917266846,
        "text_preview": "1 Fig. 1: Overview of the proposed approach at synthesis time."
      },
      {
        "chunk_index": 148956,
        "paper_id": 3070,
        "chunk_idx": 0,
        "title": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software",
        "section_head": "Insight",
        "score": 0.86902916431427,
        "text_preview": "The privacy-efficiency-auditing contradiction refers to the challenge of auditing the correctness of the P ùëë 's inference software during large-scale inferences without compromising P ùëë 's data privac"
      },
      {
        "chunk_index": 2233,
        "paper_id": 38,
        "chunk_idx": 0,
        "title": "A HYBRID AI FRAMEWORK FOR STRATEGIC PATENT PORTFOLIO PRUNING: INTEGRATING LEARNING-TO-RANK AND MARKET-NEED ANALYSIS FOR TECHNOLOGY TRANSFER OPTIMIZATION",
        "section_head": "Phase 3 in Practice: Advanced Ranking and the Need-Seed Nexus",
        "score": 0.8682214617729187,
        "text_preview": "With a manageable subset of patents identified, the framework deploys its core analytical engines. [34]"
      },
      {
        "chunk_index": 114873,
        "paper_id": 2396,
        "chunk_idx": 0,
        "title": "Retrieval And Structuring Augmented Generation with Large Language Models",
        "section_head": "Structure-Enhanced LLM Generation.",
        "score": 0.866729736328125,
        "text_preview": "Once knowledge is structured into a comprehensive KG, the challenge shifts to leveraging this representation to enhance LLM outputs. Structure-enhanced LLM generation grounds model responses in explic"
      },
      {
        "chunk_index": 8363,
        "paper_id": 161,
        "chunk_idx": 0,
        "title": "Agent LUMOS: Unified and Modular Training for Open-Source Language Agents",
        "section_head": "Figure 2 :",
        "score": 0.8666902780532837,
        "text_preview": "2 Figure 2: Overall framework of LUMOS. LUMOS are trained with 56K high-quality training annotations. We propose two agent training and inference formulations, LUMOS-O ( ¬ß2.2) and LUMOS-I ( ¬ß2.3). LUM"
      },
      {
        "chunk_index": 279,
        "paper_id": 7,
        "chunk_idx": 0,
        "title": "A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective",
        "section_head": "Highlight of Observations:",
        "score": 0.861418604850769,
        "text_preview": "The generated data progressively collapses into numerous compact local clusters over model collapse iterations, as evidenced by both the sharp decline in entropy over iterations and visualizations. Th"
      },
      {
        "chunk_index": 129761,
        "paper_id": 2695,
        "chunk_idx": 2,
        "title": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models",
        "section_head": "Figure 1: State change sequence diagram of commercial vehicle",
        "score": 0.8589661717414856,
        "text_preview": "This model divides the generation of long-term time series into staged generation and inter-stage information transfer. First, inter-stage information transfer ensures consistency in long-term tempora"
      },
      {
        "chunk_index": 126877,
        "paper_id": 2646,
        "chunk_idx": 0,
        "title": "SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching",
        "section_head": "SpeCa Framework Overview",
        "score": 0.8579481840133667,
        "text_preview": "Diffusion models incur high computational costs due to their sequential sampling, requiring full computation at each timestep. To mitigate this, we introduce SpeCa, a framework that adapts the predict"
      },
      {
        "chunk_index": 106783,
        "paper_id": 2210,
        "chunk_idx": 1,
        "title": "Pointing to a Llama and Call it a Camel On the Sycophancy of Multimodal Large Language Models",
        "section_head": "Vanilla Supervised Fine-tuning",
        "score": 0.8574514389038086,
        "text_preview": "This is undesirable, as the model cannot always reliably produce correct responses, which makes the ability to adapt its initial response based on corrective hints from users a crucial fea- 5 Sycophan"
      },
      {
        "chunk_index": 16276,
        "paper_id": 326,
        "chunk_idx": 4,
        "title": "BANG: Billion-Scale Approximate Nearest Neighbour Search using a Single GPU",
        "section_head": "I. INTRODUCTION",
        "score": 0.8565628528594971,
        "text_preview": "Thus, this paper explores an important question: Can we increase the throughput of ANNS queries without compromising their recall by using a single GPU? In this paper, we introduce BANG, a novel GPU-b"
      },
      {
        "chunk_index": 126913,
        "paper_id": 2646,
        "chunk_idx": 0,
        "title": "SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching",
        "section_head": "Figure 3 :",
        "score": 0.8531309962272644,
        "text_preview": "3 Figure 3: Overview of the SpeCa framework, which introduces speculative sampling to diffusion models via feature caching. (a) TaylorSeer, a lightweight draft model, predicts future activation featur"
      },
      {
        "chunk_index": 936,
        "paper_id": 16,
        "chunk_idx": 0,
        "title": "A comprehensive taxonomy of hallucinations in Large Language Models",
        "section_head": "Architectural mitigation strategies",
        "score": 0.8526303172111511,
        "text_preview": "Architectural strategies operate at the model level and seek to reduce hallucination risk by directly improving the model's grounding, reasoning, or factual alignment capabilities. These interventions"
      },
      {
        "chunk_index": 7137,
        "paper_id": 133,
        "chunk_idx": 2,
        "title": "ADAPTIVE GUIDANCE SEMANTICALLY ENHANCED VIA MULTIMODAL LLM FOR EDGE-CLOUD OBJECT DETECTION",
        "section_head": "INTRODUCTION",
        "score": 0.8520276546478271,
        "text_preview": "The MLLM is instruction-tuned to produce structured JSON outputs, overcoming free-text variability and hallucinations. A lightweight mapping module then converts these semantics into core parameters f"
      },
      {
        "chunk_index": 129779,
        "paper_id": 2695,
        "chunk_idx": 0,
        "title": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models",
        "section_head": "CONCLUSION",
        "score": 0.8513298630714417,
        "text_preview": "In this paper, we propose a stage-based long-term time series generation method, Stage-Diff, based on a diffusion model. By repeatedly"
      }
    ]
  },
  {
    "query_id": 18,
    "query_text": "contrastive learning framework",
    "source": "title",
    "source_value": "A Contrastive Learning Framework for Breast Cancer Detection",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 26596,
        "paper_id": 539,
        "chunk_idx": 0,
        "title": "CoMelSinger: Discrete Token-Based Zero-Shot Singing Synthesis With Structured Melody Control and Guidance",
        "section_head": "Fig. 4 :",
        "score": 0.9669445753097534,
        "text_preview": "4 Fig. 4: Overview of the coarse-to-fine contrastive learning strategy. (a) Sequence-level contrastive learning encourages timbre consistency across different melodies. (b) Frame-level contrastive lea"
      },
      {
        "chunk_index": 31328,
        "paper_id": 656,
        "chunk_idx": 3,
        "title": "Decoupled Contrastive Learning for Federated Learning",
        "section_head": "Introduction",
        "score": 0.8944591283798218,
        "text_preview": "In this paper, we propose Decoupled Contrastive Learning for Federated Learning (DCFL), a novel framework for robust representation learning in FL. Unlike existing contrastive regularization methods t"
      },
      {
        "chunk_index": 66338,
        "paper_id": 1412,
        "chunk_idx": 0,
        "title": "i-Code: An Integrative and Composable Multimodal Learning Framework",
        "section_head": "Pretraining i-Code",
        "score": 0.8802036046981812,
        "text_preview": "In this subsection, we introduce how we pretrain i-Code. We first discuss the multimodal pretraining objectives: masked units modeling and cross-modality contrastive learning. Then we introduce the op"
      },
      {
        "chunk_index": 97402,
        "paper_id": 2053,
        "chunk_idx": 0,
        "title": "Offline Goal-conditioned Reinforcement Learning with Quasimetric Representations",
        "section_head": "Related Work",
        "score": 0.8800563812255859,
        "text_preview": "We provide a unifying framework that connects metric learning to (optimal) offline goal-conditioned reinforcement learning (GCRL)."
      },
      {
        "chunk_index": 95255,
        "paper_id": 2016,
        "chunk_idx": 0,
        "title": "New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR",
        "section_head": "Fig. 1 .",
        "score": 0.8715210556983948,
        "text_preview": "1 Fig. 1. The proposed cross-modal knowledge transfer learning framework for ASR."
      },
      {
        "chunk_index": 73110,
        "paper_id": 1558,
        "chunk_idx": 0,
        "title": "Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems",
        "section_head": "Fig. 4 A",
        "score": 0.8698117136955261,
        "text_preview": "4 Fig. 4 A unified graph-based framework for ecohydrological modeling integrating processbased mechanisms, machine learning, and spatial heterogeneity."
      },
      {
        "chunk_index": 34286,
        "paper_id": 723,
        "chunk_idx": 0,
        "title": "Diffusion-Augmented Contrastive Learning: A Noise-Robust Encoder for Biosignal Representations",
        "section_head": "A. Framework Overview",
        "score": 0.8514246940612793,
        "text_preview": "This paper introduces Diffusion-Augmented Contrastive Learning (DACL), a novel hybrid framework that synthesizes principles from diffusion models and supervised contrastive learning to learn noise-rob"
      },
      {
        "chunk_index": 51959,
        "paper_id": 1114,
        "chunk_idx": 0,
        "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model",
        "section_head": "2 : 3 :",
        "score": 0.8441111445426941,
        "text_preview": "23 [13], This paper proposed a Bayesian transfer learning concept Algorithm 4 FedOpt: Adaptive Federated Optimization 1: Input: Œ∏ 0 , CLIENTOPT, SERVEROPT for r = 0, . . . , R -1 do"
      },
      {
        "chunk_index": 34703,
        "paper_id": 733,
        "chunk_idx": 0,
        "title": "Diffusion Model with Nuclear Regularization for Ultra-low-dose PET Reconstruction",
        "section_head": "Fig. 4 .",
        "score": 0.8439854979515076,
        "text_preview": "4 Fig. 4. Comparative illustration of a traditional deep learning-based model and the DCDM framework for unknown DRF reconstruction."
      },
      {
        "chunk_index": 4966,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "System Trust",
        "score": 0.8422434329986572,
        "text_preview": "Utilizes secured data to develop intelligent models through federated, distributed, and reinforcement learning."
      },
      {
        "chunk_index": 90959,
        "paper_id": 1917,
        "chunk_idx": 1,
        "title": "MOLECULAR MACHINE LEARNING IN CHEMICAL PROCESS DESIGN",
        "section_head": "Advancing Predictive Models",
        "score": 0.839477002620697,
        "text_preview": "Hybrid models include the combination of a molecular ML with a semi-empirical model in either a sequential, parallel, or embedded way. In the parallel setting, the ML model predicts the error of a sem"
      },
      {
        "chunk_index": 1044,
        "paper_id": 18,
        "chunk_idx": 0,
        "title": "A Contrastive Learning Framework for Breast Cancer Detection",
        "section_head": "Figure 2 .",
        "score": 0.8360981345176697,
        "text_preview": "2 Figure 2. Block diagram of the Contrastive Learning framework"
      },
      {
        "chunk_index": 113633,
        "paper_id": 2369,
        "chunk_idx": 0,
        "title": "Representation Learning with Contrastive Predictive Coding",
        "section_head": "Figure 1 :",
        "score": 0.8355698585510254,
        "text_preview": "1 Figure 1: Overview of Contrastive Predictive Coding, the proposed representation learning approach. Although this figure shows audio as input, we use the same setup for images, text and reinforcemen"
      },
      {
        "chunk_index": 72471,
        "paper_id": 1545,
        "chunk_idx": 0,
        "title": "Kalman Filter Aided Federated Koopman Learning",
        "section_head": "IV. FEDERATED LEARNING OF KOOPMAN OPERATOR",
        "score": 0.8322118520736694,
        "text_preview": "To achieve collaborative linearization, we first introduce the Deep Koopman Network (DKN), which learns the K and (œÜ, œÜ -1 ) introduced in Section III-B. Then, we propose a framework wherein federated"
      },
      {
        "chunk_index": 14530,
        "paper_id": 293,
        "chunk_idx": 0,
        "title": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning",
        "section_head": "Impact of Think Reward",
        "score": 0.8221715092658997,
        "text_preview": "The integration of thinking rewards during reinforcement learning improves model performance."
      },
      {
        "chunk_index": 101918,
        "paper_id": 2118,
        "chunk_idx": 0,
        "title": "OptiProxy-NAS: Optimization Proxy based End-to-End Neural Architecture Search",
        "section_head": "Figure 1 :",
        "score": 0.8191903829574585,
        "text_preview": "1 Figure 1: Framework for Optimization Proxy based end-to-end Neural Architecture Search (OptiProxy-NAS)."
      },
      {
        "chunk_index": 59572,
        "paper_id": 1267,
        "chunk_idx": 0,
        "title": "GENERALIZABLE GEOMETRIC IMAGE CAPTION SYNTHESIS",
        "section_head": "Conclusion",
        "score": 0.817499041557312,
        "text_preview": "In this paper, we propose Geo-Image-Textualization, a novel reinforcement learning-based framework designed to symbolically synthesize high-quality, geometry-centered multimodal data. Leveraging this "
      },
      {
        "chunk_index": 2995,
        "paper_id": 57,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy",
        "section_head": "Fig. 1 .",
        "score": 0.8173708319664001,
        "text_preview": "1 Fig. 1.System architecture of the federated learning framework"
      },
      {
        "chunk_index": 4191,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Meta-Learning in Multi-Agent Systems -Finn et al. (2017)",
        "score": 0.8158055543899536,
        "text_preview": "Metalearning (learning to learn) has been applied in multi-agent reinforcement learning to enable fast adaptation to new tasks. One prominent approach is MAML (Model-Agnostic Meta-Learning), which opt"
      },
      {
        "chunk_index": 67966,
        "paper_id": 1449,
        "chunk_idx": 1,
        "title": "Improving Generalization in Federated Learning with Highly Heterogeneous Data via Momentum-Based Stochastic Controlled Weight Averaging",
        "section_head": "Contributions: We propose a new FL generalization",
        "score": 0.8155569434165955,
        "text_preview": "Algorithm Generalization error Optimization error FedSAM (Qu et al., 2022) O L mnŒ≤ e 1+ 1 T (cL + cœÉ g + cœÉ) O Œ≤F ‚àö T Ks + ‚àö KœÉg 2 ‚àö T s + L 2 œÉ 2 T 3/2 K + L 2 T 2 MoFedSAM (Qu et al., 2022) O L mnŒ≤ "
      }
    ]
  },
  {
    "query_id": 19,
    "query_text": "convnet",
    "source": "title",
    "source_value": "A ConvNet for the 2020s",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 1105,
        "paper_id": 19,
        "chunk_idx": 0,
        "title": "A ConvNet for the 2020s",
        "section_head": "Table 9 .",
        "score": 0.8263548612594604,
        "text_preview": "9 Detailed architecture specifications for ResNet-50, ConvNeXt-T and Swin-T. output size ‚Ä¢ ResNet-50 ‚Ä¢ ConvNeXt-T ‚Ä¢ Swin-T stem 56√ó56 7√ó7, 64, stride 2 3√ó3 max pool, stride 2 4√ó4, 96, stride 4 4√ó4, 96"
      },
      {
        "chunk_index": 6061,
        "paper_id": 108,
        "chunk_idx": 0,
        "title": "ACCELERATING SLIDE DEEP LEARNING ON MODERN CPUS: VECTORIZATION, QUANTIZATIONS, MEMORY OPTIMIZATIONS, AND MORE",
        "section_head": "Figure 4 .",
        "score": 0.7808051109313965,
        "text_preview": "4 Figure 4. Matrix-vector multiplication with dense x and sparse or dense y."
      },
      {
        "chunk_index": 14341,
        "paper_id": 290,
        "chunk_idx": 0,
        "title": "Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval",
        "section_head": "Table 12 :",
        "score": 0.7762762308120728,
        "text_preview": "12 Comparison on flops and params. Method Flops(G) Params(M) R1@7 EAMAT 9.97 94.12 41.96 BAM-DETR 1.39 13.43 39.38 FlashVTG 1.05 8.73 38.01 QD-DETR 0.82 6.36 32.55 Moment-DETR 0.26 3.23 38.01 ADPN 0.3"
      },
      {
        "chunk_index": 142523,
        "paper_id": 2938,
        "chunk_idx": 0,
        "title": "Training data-efficient image transformers & distillation through attention",
        "section_head": "Table 4 :",
        "score": 0.7443563938140869,
        "text_preview": "4 Disagreement analysis between convnet, image transformers and distillated transformers: We report the fraction of sample classified differently for all classifier pairs, i.e., the rate of different "
      },
      {
        "chunk_index": 149512,
        "paper_id": 3074,
        "chunk_idx": 0,
        "title": "VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION",
        "section_head": "Table 6 :",
        "score": 0.7346261739730835,
        "text_preview": "6 Multiple ConvNet fusion results. Combined ConvNet models"
      },
      {
        "chunk_index": 46160,
        "paper_id": 987,
        "chunk_idx": 1,
        "title": "Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language",
        "section_head": "A.7 Example Outputs",
        "score": 0.7266600728034973,
        "text_preview": "0.0 0.2 0.4 0.6 0.8 1.0 1.2 GPT Male Female Gender Claude Male Female Gender 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Nemo Male Female Gender Llama Male Female Gender 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Sauerkraut Male Fe"
      },
      {
        "chunk_index": 103616,
        "paper_id": 2146,
        "chunk_idx": 1,
        "title": "PARALLELTIME: DYNAMICALLY WEIGHTING THE BALANCE OF SHORT-AND LONG-TERM TEMPORAL DEPENDENCIES",
        "section_head": "Table 7 :",
        "score": 0.7263622283935547,
        "text_preview": "Dataset Pred Len MSE MAE Fwd FLOPs Fwd+Bwd FLOPs #Params ParallelTime PatchTST ParallelTime PatchTST ParallelTime PatchTST ParallelTime PatchTST ParallelTime PatchTST 96 0.365 (‚Üì1.4%) 0.370 0.398 (‚Üì0."
      },
      {
        "chunk_index": 87303,
        "paper_id": 1837,
        "chunk_idx": 1,
        "title": "Meta-Transformer: A Unified Framework for Multimodal Learning",
        "section_head": "Table 4 :",
        "score": 0.7139248847961426,
        "text_preview": "Method Classification Res #Params #FLOPs Acc (%) #Params #FLOPs AP (%) #Params #FLOPs mIoU (%) Object Detection Semantic Segmentation PVT-L [70] 224 2 61.4M 9.8G 81.7 81.0M - 42.9 65.1M 79.6G 44.8 Swi"
      },
      {
        "chunk_index": 149511,
        "paper_id": 3074,
        "chunk_idx": 0,
        "title": "VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION",
        "section_head": "Table 5 :",
        "score": 0.7051861882209778,
        "text_preview": "5 ConvNet ConvNet config. (Table 1) Evaluation method top-1 val. error (%) top-5 val. error (%) dense 24.8 7.5 D multi-crop 24.6 7.5 multi-crop & dense 24.4 7.2 dense 24.8 7.5 E multi-crop 24.6 7.4 mu"
      },
      {
        "chunk_index": 3594,
        "paper_id": 69,
        "chunk_idx": 1,
        "title": "A SIMPLE AND EFFECTIVE PRUNING APPROACH FOR LARGE LANGUAGE MODELS",
        "section_head": "Table 23 :",
        "score": 0.7039411067962646,
        "text_preview": "Params Method BoolQ RTE HellaSwag WinoGrande ARC-e ARC-c OBQA Mean Dense 75.05 66.43 56.92 69.93 75.34 41.89 34.40 59.99 7B Magnitude 54.59 54.51 45.49 59.19 58.84 33.53 22.40 46.94 SparseGPT 72.05 54"
      },
      {
        "chunk_index": 46161,
        "paper_id": 987,
        "chunk_idx": 2,
        "title": "Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language",
        "section_head": "A.7 Example Outputs",
        "score": 0.6967870593070984,
        "text_preview": "male female nA male female 30.83% 17.50% 1.67% 17.41% 31.36% 1.23% GPT male female nA male female 15.04% 31.36% 3.60% 3.95% 45.26% 0.79% Claude male female nA male female 29.16% 11.07% 9.75% 19.54% 21"
      },
      {
        "chunk_index": 45845,
        "paper_id": 979,
        "chunk_idx": 1,
        "title": "Exploiting Edge Features for Graph Neural Networks",
        "section_head": "Citation networks",
        "score": 0.6926383972167969,
        "text_preview": "Dataset Cora CiteSeer Pubmed Splitting Sparse Dense Sparse Dense Sparse Dense GCN 72.9 ¬± 0.8% 72.0 ¬± 1.2% 69.2 ¬± 0.7% 75.3 ¬± 0.4% 83.3 ¬± 0.4% 83.4 ¬± 0.2% GAT 75.5 ¬± 1.1% 79.0 ¬± 1.0% 69.5 ¬± 0.5% 74.9 ¬±"
      },
      {
        "chunk_index": 150956,
        "paper_id": 3102,
        "chunk_idx": 0,
        "title": "Visual Instruction Inversion: Image Editing via Visual Prompting",
        "section_head": "InstructPix2Pix",
        "score": 0.6863408088684082,
        "text_preview": "+\"‚Ä¶, female\" + \"..., female with sunflowers\" + \"‚Ä¶, female with roses\" + \"‚Ä¶, Asian\" + \"‚Ä¶, female with a gun\""
      },
      {
        "chunk_index": 134747,
        "paper_id": 2788,
        "chunk_idx": 0,
        "title": "Temporal social network modeling of mobile connectivity data with graph neural networks",
        "section_head": "Table 2 .",
        "score": 0.6833717823028564,
        "text_preview": "2 Mean Connection Method Female to Female Female to Male Male to Female Male to Male rEdgeBank 3.32 (5.17) 3.09 (5.54) 3.09 (5.39) 3.34 (5.21) GCRN 3.79 (5.73) 3.62 (6.09) 3.62 (6.09) 3.89 (5.72) Call"
      },
      {
        "chunk_index": 3595,
        "paper_id": 69,
        "chunk_idx": 0,
        "title": "A SIMPLE AND EFFECTIVE PRUNING APPROACH FOR LARGE LANGUAGE MODELS",
        "section_head": "Table 24 :",
        "score": 0.6828118562698364,
        "text_preview": "24 Accuracies (%) of LLaMA for 7 zero-shot tasks with 4:8 sparsity. Params Method BoolQ RTE HellaSwag WinoGrande ARC-e ARC-c OBQA Mean Dense 75.05 66.43 56.92 69.93 75.34 41.89 34.40 59.99 7B Magnitud"
      },
      {
        "chunk_index": 46209,
        "paper_id": 988,
        "chunk_idx": 0,
        "title": "Exploring Gender Differences in Chronic Pain Discussions on Reddit",
        "section_head": "Table 5 :",
        "score": 0.679140031337738,
        "text_preview": "5 Efficacy and Emotion Distribution Percentages of Drugs by Gender Total Drug Gender Mentions Effective (%) Ineffective (%) Side Effect (%) Anger (%) Fear (%) Joy (%) Sadness (%) Amitriptyline Female "
      },
      {
        "chunk_index": 3598,
        "paper_id": 69,
        "chunk_idx": 0,
        "title": "A SIMPLE AND EFFECTIVE PRUNING APPROACH FOR LARGE LANGUAGE MODELS",
        "section_head": "Table 27 :",
        "score": 0.6700411438941956,
        "text_preview": "27 Accuracies (%) of LLaMA-2 for 7 zero-shot tasks with 4:8 sparsity. Params Method BoolQ RTE HellaSwag WinoGrande ARC-e ARC-c OBQA Mean Dense 77.74 62.82 57.17 68.90 76.39 43.52 31.40 59.71 7B Magnit"
      },
      {
        "chunk_index": 155564,
        "paper_id": 3190,
        "chunk_idx": 0,
        "title": "Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration",
        "section_head": "Table 4 :",
        "score": 0.6648416519165039,
        "text_preview": "4 Agent generalization performance on VMAS tasks. ‚àÜ denotes the performance drop from dense-trained to sparse-trained. Method Balance * Give Way * Passage * Sparse‚Üë Dense‚Üë ‚àÜ ‚Üì Sparse‚Üë Dense‚Üë ‚àÜ Sparse‚Üë"
      },
      {
        "chunk_index": 59686,
        "paper_id": 1270,
        "chunk_idx": 0,
        "title": "Generating Long Sequences with Sparse Transformers",
        "section_head": "Table 2 .",
        "score": 0.6642632484436035,
        "text_preview": "2 Sparse patterns showed increased speed and also better loss on the datasets where we could compare both, which may point to a useful inductive bias in the patterns we learned or an underlying optimi"
      },
      {
        "chunk_index": 33394,
        "paper_id": 700,
        "chunk_idx": 0,
        "title": "Designing Network Design Spaces",
        "section_head": "Table 5 .",
        "score": 0.6640927195549011,
        "text_preview": "5 RESNE(X)T comparisons on ImageNetV2. flops params acts batch infer train error (B) (M) (M) size (ms) (hr) (top-1) EFFICIENTNET-B0 0.4 5.3 6.7 256 34 11.7 37.1¬±0.22 REGNETY-400MF 0.4 4.3 3.9 1024 19 "
      }
    ]
  },
  {
    "query_id": 20,
    "query_text": "coopetitive-compatible data generation",
    "source": "title",
    "source_value": "A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 71394,
        "paper_id": 1523,
        "chunk_idx": 0,
        "title": "IS¬≥ : Generic Impulsive-Stationary Sound Separation in Acoustic Scenes using Deep Filtering",
        "section_head": "Fig. 2 :",
        "score": 0.9668875932693481,
        "text_preview": "2 Fig. 2: Data generation pipeline."
      },
      {
        "chunk_index": 150042,
        "paper_id": 3083,
        "chunk_idx": 0,
        "title": "VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception",
        "section_head": "Figure 4 :",
        "score": 0.9245534539222717,
        "text_preview": "4 Figure 4: VTTS-80K dataset generation pipeline and data distribution."
      },
      {
        "chunk_index": 75922,
        "paper_id": 1605,
        "chunk_idx": 0,
        "title": "Latent Gene Diffusion for Spatial Transcriptomics Completion",
        "section_head": "Completed Gene Expression Central Spot",
        "score": 0.9091862440109253,
        "text_preview": "HSGAs a. LGDiST Training Process b. LGDiST Inference Process Filter-out CGs"
      },
      {
        "chunk_index": 57003,
        "paper_id": 1222,
        "chunk_idx": 0,
        "title": "FROM PHYSICS TO MACHINE LEARNING AND BACK: PART II -LEARNING AND OBSERVATIONAL BIAS IN PHM",
        "section_head": "Figure 7 :",
        "score": 0.9071448445320129,
        "text_preview": "7 Figure7: General framework of generative modeling for PHM applications. The process consists of three main stages: (1) Data collection and pre-processing: collect real-world data, optionally augment"
      },
      {
        "chunk_index": 30044,
        "paper_id": 622,
        "chunk_idx": 0,
        "title": "D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data",
        "section_head": "Fig. 5 :",
        "score": 0.8844301700592041,
        "text_preview": "5 Fig. 5: Sample Ausgrid data of a substation with gen-extreme distribution without detrending"
      },
      {
        "chunk_index": 62555,
        "paper_id": 1334,
        "chunk_idx": 0,
        "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?",
        "section_head": "Figure 1 :",
        "score": 0.8836228847503662,
        "text_preview": "1 Figure 1: (a) Data generation for public usage. (b) & (c): Generation process with two GraphMaker variants."
      },
      {
        "chunk_index": 15379,
        "paper_id": 307,
        "chunk_idx": 0,
        "title": "Autoguided Online Data Curation for Diffusion Model Training",
        "section_head": "Figure 5 .",
        "score": 0.8782702684402466,
        "text_preview": "5 Figure 5. Iterative sampling process for JEST data selection."
      },
      {
        "chunk_index": 73662,
        "paper_id": 1569,
        "chunk_idx": 0,
        "title": "LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain Translation",
        "section_head": "Fig. 2 :",
        "score": 0.8664442300796509,
        "text_preview": "2 Fig. 2: Model architecture (training and inference). LADM training: (1) Infer latents from source(s) using pretrained source LDM(s), then construct paired latent-to-target correspondences. (2) Coupl"
      },
      {
        "chunk_index": 59818,
        "paper_id": 1275,
        "chunk_idx": 4,
        "title": "Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model",
        "section_head": "C. Execution Strategies",
        "score": 0.8663038015365601,
        "text_preview": "Additionally, [98] employs a VAE to learn channel characteristics, effectively enhancing the accuracy of channel prediction. 2) Generative Models as Plugins: In addition to directly participating in w"
      },
      {
        "chunk_index": 34382,
        "paper_id": 726,
        "chunk_idx": 0,
        "title": "Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks",
        "section_head": "A. Diffusion Models",
        "score": 0.8657232522964478,
        "text_preview": "Diffusion Models learn to sample from a data distribution by approximating the reverse-time dynamics of a Gaussian diffusion process. Let {z i } N i=1 be independent and identically distributed sample"
      },
      {
        "chunk_index": 114105,
        "paper_id": 2380,
        "chunk_idx": 0,
        "title": "ReST-MCTS * : LLM Self-Training via Process Reward Guided Tree Search",
        "section_head": "Figure 4 :",
        "score": 0.8532698154449463,
        "text_preview": "4 Figure 4: Detailed process of new sample data generation for the self-training framework."
      },
      {
        "chunk_index": 72929,
        "paper_id": 1554,
        "chunk_idx": 0,
        "title": "KillChainGraph: ML Framework for Predicting and Mapping ATT&CK Techniques",
        "section_head": "Fig. 1 .",
        "score": 0.8489785194396973,
        "text_preview": "1 Fig. 1. Model Training Process Flow for predicting ATT&CK technique"
      },
      {
        "chunk_index": 1551,
        "paper_id": 26,
        "chunk_idx": 0,
        "title": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds",
        "section_head": "Figure 16 :Figure 17 :Figure 18 :Figure 19 :",
        "score": 0.8475930690765381,
        "text_preview": "16171819 Figure 16: Original healthy data sample"
      },
      {
        "chunk_index": 68972,
        "paper_id": 1470,
        "chunk_idx": 0,
        "title": "Influence Scores at Scale for Efficient Language Data Sampling",
        "section_head": "Sampling Technique:",
        "score": 0.844440221786499,
        "text_preview": "We benchmarked VoGbased data sampling against random sampling and stratified sampling. 14 In stratified sampling, we sample utterances randomly while preserving the domain distribution of the training"
      },
      {
        "chunk_index": 121293,
        "paper_id": 2528,
        "chunk_idx": 0,
        "title": "Self-Consuming Generative Models Go MAD",
        "section_head": "Autophagous processes",
        "score": 0.8402903079986572,
        "text_preview": "Consider a sequence of generative models (G t ) t‚ààN , where the goal is to train each model to approximate a reference probability distribution P r . At each generation t ‚àà N, the model G t is trained"
      },
      {
        "chunk_index": 82262,
        "paper_id": 1732,
        "chunk_idx": 0,
        "title": "Locality in Image Diffusion Models Emerges from Data Statistics",
        "section_head": "Denoising diffusion models.",
        "score": 0.8398129940032959,
        "text_preview": "Score-based image generative models [8, 27, 28] learn to reverse the process of adding Gaussian noise to clean data. During training, we sample a data point x 0 from the training data distribution X, "
      },
      {
        "chunk_index": 69799,
        "paper_id": 1487,
        "chunk_idx": 0,
        "title": "InstructPix2Pix: Learning to Follow Image Editing Instructions",
        "section_head": "InstructPix2Pix",
        "score": 0.8378293514251709,
        "text_preview": "We use our generated training data to train a conditional diffusion model that edits images from written instructions. We base our model on Stable Diffusion, a large-scale textto-image latent diffusio"
      },
      {
        "chunk_index": 127819,
        "paper_id": 2672,
        "chunk_idx": 0,
        "title": "SpeechOp: Inference-Time Task Composition for Generative Speech Processing",
        "section_head": "Diffusion Training.",
        "score": 0.8375974893569946,
        "text_preview": "During training, we sample noise levels using a shifted cosine schedule (s=0.5) [14] , following Lovelace et al. [32] . We employ the Sigmoid diffusion loss weighting from Hoogeboom et al. [15] with a"
      },
      {
        "chunk_index": 24305,
        "paper_id": 491,
        "chunk_idx": 0,
        "title": "ChipNeMo: Domain-Adapted LLMs for Chip Design",
        "section_head": "Figure 15 :",
        "score": 0.8350158333778381,
        "text_preview": "15 Figure 15: Sample Generation For Retrieval Model Training A.8.1. DATASET SAMPLING PROCEDURE Figure 15 describes the steps taken to generate a sample:"
      },
      {
        "chunk_index": 45998,
        "paper_id": 983,
        "chunk_idx": 0,
        "title": "Exploring a Graph-based Approach to Offline Reinforcement Learning for Sepsis Treatment",
        "section_head": "Figure 8 :",
        "score": 0.8349347114562988,
        "text_preview": "8 Figure 8: Training GNN-SAGEConv and GNN-GATv2Conv based autoencoders."
      }
    ]
  },
  {
    "query_id": 21,
    "query_text": "corpus classification fine-grained",
    "source": "title",
    "source_value": "A CORPUS FOR CLASSIFICATION AND FINE-GRAINED LOCALIZATION OF AI-WRITTEN TEXT",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 82856,
        "paper_id": 1742,
        "chunk_idx": 0,
        "title": "LOOK BEFORE YOU LEAP: ESTIMATING LLM BENCHMARK SCORES FROM DESCRIPTIONS",
        "section_head": "Source Papers: result paper=2306.16638",
        "score": 0.9313533306121826,
        "text_preview": "Model: GPT-4 Description ‚Ä¢ Task: -Binary classification of sentence pairs. -Input: two short natural-language sentences presented as a pair. -Label space: two classes indicating whether the second sen"
      },
      {
        "chunk_index": 114861,
        "paper_id": 2396,
        "chunk_idx": 0,
        "title": "Retrieval And Structuring Augmented Generation with Large Language Models",
        "section_head": "Hierarchical Classification.",
        "score": 0.9296417236328125,
        "text_preview": "Hierarchical text classification assigns input text to one or more nodes within a taxonomy-structured label space, presenting a greater challenge than flat classification due to its extensive structur"
      },
      {
        "chunk_index": 18106,
        "paper_id": 369,
        "chunk_idx": 0,
        "title": "Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing",
        "section_head": "C.3 Debiasing Category Distribution",
        "score": 0.9187990427017212,
        "text_preview": "For completeness, we summarize the training-set distribution of debiasing categories (InternVL2.5). The majority of samples are labeled None, yet a non-trivial portion requires single-or dual-modality"
      },
      {
        "chunk_index": 64801,
        "paper_id": 1379,
        "chunk_idx": 0,
        "title": "Holistic Evaluation of Language Models",
        "section_head": "Figure 16 :",
        "score": 0.9121441841125488,
        "text_preview": "16 Figure16: Example of miscellaneous text classification. An example instance for miscellaneous text classification from RAFT (subset=Banking77)."
      },
      {
        "chunk_index": 91844,
        "paper_id": 1934,
        "chunk_idx": 2,
        "title": "MTEB: Massive Text Embedding Benchmark",
        "section_head": "A.1 Clustering ArxivClusteringS2S,",
        "score": 0.9037591218948364,
        "text_preview": "Clustering of 25 splits, each with 10-50 classes, and each class with 100 -1000 sentences RedditClusteringP2P Dataset created for MTEB using available data from Reddit posts foot_10 . The task consist"
      },
      {
        "chunk_index": 42934,
        "paper_id": 911,
        "chunk_idx": 0,
        "title": "Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models",
        "section_head": "Binary Classification Scope.",
        "score": 0.8948649168014526,
        "text_preview": "Although binary classification is appropriate for this optimization study, its focus limits direct generalizability to multi-class clinical classification tasks."
      },
      {
        "chunk_index": 2671,
        "paper_id": 50,
        "chunk_idx": 0,
        "title": "A New Dataset and Benchmark for Grounding Multimodal Misinformation",
        "section_head": "Fact-Check Articles",
        "score": 0.8878586888313293,
        "text_preview": "Human Annotator (6 fake types) Guidelines Grounding Classes information, where key errors may occur in any modality or arise from cross-modal inconsistencies, we propose a three-level hierarchical ann"
      },
      {
        "chunk_index": 115295,
        "paper_id": 2404,
        "chunk_idx": 0,
        "title": "Revealing Temporal Label Noise in Multimodal Hateful Video Classification",
        "section_head": "Dataset Preprocessing and Trimming",
        "score": 0.8850810527801514,
        "text_preview": "The literature review reveals that while multimodal hate detection has advanced significantly, the impact of temporal label granularity remains unexplored. To address this gap, we conduct a systematic"
      },
      {
        "chunk_index": 155843,
        "paper_id": 3195,
        "chunk_idx": 0,
        "title": "X-Troll: eXplainable Detection of State-Sponsored Information Operations Agents",
        "section_head": "Figure 3 :",
        "score": 0.8840227127075195,
        "text_preview": "3 Figure 3: X-Troll's rationale selection on Russia-IRA examples, with diagnostic tokens highlighted. The correctly classified troll post (top) shows characteristic geopolitical framing and conflict n"
      },
      {
        "chunk_index": 7843,
        "paper_id": 150,
        "chunk_idx": 4,
        "title": "Advancing Mental Disorder Detection: A Comparative Evaluation of Transformer and LSTM Architectures on Social Media",
        "section_head": "1) Linguistic Analysis:",
        "score": 0.8660697937011719,
        "text_preview": "Text preprocessing involved extracting bigram and trigram phrases using the GENSIM 3 library from each post's title and content. These phrases were then transformed into a Term Frequency-Inverse Docum"
      },
      {
        "chunk_index": 23980,
        "paper_id": 486,
        "chunk_idx": 3,
        "title": "chDzDT: Word-level morphology-aware language model for Algerian social media text",
        "section_head": "Data merging and labeling",
        "score": 0.8647407293319702,
        "text_preview": "‚Ä¢ Significant counts in hybrid categories such as AR-DZ (529,010), DZ-FR (64,710), and DZ-EN (29,139) confirm the strong influence of Arabic, French, and English on Algerian online discourse. These fi"
      },
      {
        "chunk_index": 38400,
        "paper_id": 811,
        "chunk_idx": 0,
        "title": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth",
        "section_head": "Drivelology Detection. A binary classification task where the model must determine if a given text is Drivelology or non-Drivelology.",
        "score": 0.8638534545898438,
        "text_preview": "Drivelology Tagging. A multi-label classification task where the model assigns one or more descriptive categories (see ¬ß3.1) to a Drivelology sample to capture its layered rhetorical structure."
      },
      {
        "chunk_index": 9893,
        "paper_id": 189,
        "chunk_idx": 2,
        "title": "ALScope: A Unified Toolkit for Deep Active Learning",
        "section_head": "Tasks and Datasets",
        "score": 0.8622147440910339,
        "text_preview": "2025): 5-class sentiment analysis; (3) IMDB (Maas et al. 2011): binary sentiment classification (positive/negative); (4) SST-5 (Socher et al. 2013): 5 sentiment classes for finegrained movie review an"
      },
      {
        "chunk_index": 1195,
        "paper_id": 21,
        "chunk_idx": 0,
        "title": "A CORPUS FOR CLASSIFICATION AND FINE-GRAINED LOCALIZATION OF AI-WRITTEN TEXT",
        "section_head": "Table 14 :",
        "score": 0.8610337972640991,
        "text_preview": "14 Metrics for each dataset and data type. Dataset Data Type AI F1 Human F1 Mean Accuracy TPR@FPR=0.01 Article 0,9864 0,9829 0,9857 0,9798 Factual text 0,9867 0,9803 0,9852 0,9796 News 0,9881 0,9866 0"
      },
      {
        "chunk_index": 17121,
        "paper_id": 347,
        "chunk_idx": 0,
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "section_head": "SST-2",
        "score": 0.8607068061828613,
        "text_preview": "The Stanford Sentiment Treebank is a binary single-sentence classification task consisting of sentences extracted from movie reviews with human annotations of their sentiment (Socher et al., 2013) . C"
      },
      {
        "chunk_index": 15541,
        "paper_id": 310,
        "chunk_idx": 0,
        "title": "Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework",
        "section_head": "Automated Generation and Visualization of Structured Research Workflows for NLP Papers",
        "score": 0.8601521849632263,
        "text_preview": "We have derived structured research workflows for NLP papers by identifying workflow-descriptive paragraphs, generating concise workflow phrases based on paragraph contents, and categorizing these phr"
      },
      {
        "chunk_index": 2686,
        "paper_id": 50,
        "chunk_idx": 0,
        "title": "A New Dataset and Benchmark for Grounding Multimodal Misinformation",
        "section_head": "Case Study (Q3)",
        "score": 0.8583545684814453,
        "text_preview": "Our qualitative analysis reveals GroundMM's core challenges. In Figure 5 (a) and (d), the model successfully performed binary classification and multi-label classification , achieving acceptable groun"
      },
      {
        "chunk_index": 95411,
        "paper_id": 2019,
        "chunk_idx": 0,
        "title": "NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation",
        "section_head": "Topic Visualization",
        "score": 0.8575676679611206,
        "text_preview": "We conduct a topic visualization analysis for a better understanding of the semantic meanings captured by the learned topics. We first randomly sample three latent vectors from each topic distribution"
      },
      {
        "chunk_index": 134381,
        "paper_id": 2782,
        "chunk_idx": 0,
        "title": "TarGEN: Targeted Data Generation with Large Language Models",
        "section_head": "D. 3",
        "score": 0.854035496711731,
        "text_preview": "3 MultiRCStep 1: List of categories: News* ; Wikipedia* ; History and anthropology* ; Society, law, and justice* ; Elementary school science textbooks* ; 9/11 reports* ; Fiction -literature or movie p"
      },
      {
        "chunk_index": 9022,
        "paper_id": 173,
        "chunk_idx": 2,
        "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review",
        "section_head": "Hybrid Models & Methodologies",
        "score": 0.8538823127746582,
        "text_preview": "The dataset comprises 95,322 tweets labeled as \"non-depressed\" or \"depressed,\" with the latter further classified into \"mild,\" \"moderate,\" and \"severe\" categories based on clinical criteria from the D"
      }
    ]
  },
  {
    "query_id": 22,
    "query_text": "data-centric approach pedestrian",
    "source": "title",
    "source_value": "A Data-Centric Approach to Pedestrian Attribute Recognition: Synthetic Augmentation via Prompt-drive",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 57114,
        "paper_id": 1225,
        "chunk_idx": 0,
        "title": "From Prompt to Progression: Taming Video Diffusion Models for Seamless Attribute Transition",
        "section_head": "Conclusion",
        "score": 0.9415602087974548,
        "text_preview": "We present a simple yet effective approach for video generation with smooth attribute transitions. Our method introduces a transitional direction to guide the sampling process during denoising, ensuri"
      },
      {
        "chunk_index": 42904,
        "paper_id": 911,
        "chunk_idx": 0,
        "title": "Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models",
        "section_head": "Optimization Strategy",
        "score": 0.9302717447280884,
        "text_preview": "The optimization process followed a systematic approach encompassing multiple dimensions of model enhancement:"
      },
      {
        "chunk_index": 104923,
        "paper_id": 2176,
        "chunk_idx": 2,
        "title": "PersonaVlog: Personalized Multimodal Vlog Generation with Multi-Agent Collaboration and Iterative Self-Correction",
        "section_head": "Introduction",
        "score": 0.9088379144668579,
        "text_preview": "To systematically address the above challenges, we propose PersonaVlog, an automated multimodal stylized Vlog generation framework that can produce personalized Vlogs featuring videos, background musi"
      },
      {
        "chunk_index": 86849,
        "paper_id": 1830,
        "chunk_idx": 0,
        "title": "Memorization Ã∏ = Understanding: Do Large Language Models Have the Ability of Scenario Cognition?",
        "section_head": "Methods",
        "score": 0.8950008153915405,
        "text_preview": "To systematically evaluate LLMs' scene cognition capabilities, we propose a bi-perspective evaluation framework both from the perspective of model outputs and internal representations. An overall fram"
      },
      {
        "chunk_index": 112770,
        "paper_id": 2349,
        "chunk_idx": 0,
        "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment",
        "section_head": "Fig. 2 :",
        "score": 0.8781401515007019,
        "text_preview": "2 Fig. 2: Overview of the RefactorCoderQA agentic framework. The process begins with a problem statement and flows through three stages: GuideLLM (methodology generation), SolverLLM (solution synthesi"
      },
      {
        "chunk_index": 149992,
        "paper_id": 3082,
        "chunk_idx": 2,
        "title": "VIDEOAGENT: PERSONALIZED SYNTHESIS OF SCIENTIFIC VIDEOS",
        "section_head": "INTRODUCTION",
        "score": 0.876857578754425,
        "text_preview": "To directly measure knowledge transfer, this analysis is complemented by a Video-Quiz-based human evaluation. For this, we task graduate students with answering automatically generated multiple-choice"
      },
      {
        "chunk_index": 11648,
        "paper_id": 227,
        "chunk_idx": 0,
        "title": "Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems",
        "section_head": "Annotating Data for Feedback Generation",
        "score": 0.8754156827926636,
        "text_preview": "In this section, we introduce our framework for annotating English learner writing data to facilitate educational feedback comment generation tasks. We first review previous error typologies and annot"
      },
      {
        "chunk_index": 16967,
        "paper_id": 344,
        "chunk_idx": 4,
        "title": "Benchmarking Robust Aggregation in Decentralized Gradient Marketplaces",
        "section_head": "Introduction",
        "score": 0.8753668069839478,
        "text_preview": "Figure 1 illustrates the configurable pipeline of our benchmark. Centralized Configs (e.g., YAML files) dictate the setup for each stage, influencing the Dataset Loader, the choice and parameters of A"
      },
      {
        "chunk_index": 47755,
        "paper_id": 1018,
        "chunk_idx": 0,
        "title": "Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS",
        "section_head": "Proposed Methodology",
        "score": 0.8707658052444458,
        "text_preview": "tion. As illustrated in Figure 1 , the framework follows a systematic approach, beginning with the generation of synthetic speech using F5-TTS, followed by an objective assessment, and concluding with"
      },
      {
        "chunk_index": 14062,
        "paper_id": 284,
        "chunk_idx": 3,
        "title": "AU-HARNESS: AN OPEN-SOURCE TOOLKIT FOR HOLISTIC EVALUATION OF AUDIO-LLMS",
        "section_head": "INTRODUCTION",
        "score": 0.8703555464744568,
        "text_preview": "In addition, we also provide the support for LLM-adaptive diarization evaluation where LLM prompting results in different I/O. To the best of our understanding, our proposed evaluation kit is among th"
      },
      {
        "chunk_index": 93713,
        "paper_id": 1979,
        "chunk_idx": 3,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "Introduction",
        "score": 0.8682218790054321,
        "text_preview": "‚Ä¢ We introduce a comprehensive evaluation framework that integrates objective statistical metrics with cognition-informed subjective assessments, and propose novel cognition-level subjective metrics, "
      },
      {
        "chunk_index": 81899,
        "paper_id": 1726,
        "chunk_idx": 0,
        "title": "LLMs as Architects and Critics for Multi-Source Opinion Summarization",
        "section_head": "M-OS-EVAL-PROMPTS (Summary Evaluation Prompts)",
        "score": 0.8679341077804565,
        "text_preview": "The M-OS-EVAL-PROMPTS guide evaluation of M-OS, structured to assess 7 dimensions: fluency, coherence, relevance, faithfulness, aspect coverage, sentiment consistency, specificity and specificity (App"
      },
      {
        "chunk_index": 104949,
        "paper_id": 2176,
        "chunk_idx": 0,
        "title": "PersonaVlog: Personalized Multimodal Vlog Generation with Multi-Agent Collaboration and Iterative Self-Correction",
        "section_head": "Conclusion",
        "score": 0.8675611019134521,
        "text_preview": "In this paper, we present PersonaVlog, a novel framework for automatic personalized Vlog generation. Our approach introduces a multimodal multi-agent collaborative framework, which orchestrates a set "
      },
      {
        "chunk_index": 44744,
        "paper_id": 953,
        "chunk_idx": 3,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Leaderboards",
        "score": 0.8672333359718323,
        "text_preview": "In light of these considerations, OpenEval foot_29 takes the commendable step of broadening the scope of evaluation to encompass alignment and safety evaluations, complementing LLMs capability evaluat"
      },
      {
        "chunk_index": 6678,
        "paper_id": 122,
        "chunk_idx": 0,
        "title": "Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework",
        "section_head": "Evaluation",
        "score": 0.8656642436981201,
        "text_preview": "For the VSA task, we addressed dataset class imbalance by employing a comprehensive evaluation approach combining F1 score, AUC, and accuracy metrics. This multi-metric strategy ensures balanced asses"
      },
      {
        "chunk_index": 59858,
        "paper_id": 1275,
        "chunk_idx": 0,
        "title": "Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model",
        "section_head": "Fig. 4 .",
        "score": 0.8646916151046753,
        "text_preview": "4 Fig.4. Structure of this survey. This paper reviews the applications of Generative AI in wireless sensing tasks from two distinct perspectives: the wireless sensing pipeline and generative AI techni"
      },
      {
        "chunk_index": 115746,
        "paper_id": 2415,
        "chunk_idx": 0,
        "title": "RichRAG: Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation",
        "section_head": "Method",
        "score": 0.8643655776977539,
        "text_preview": "In this section, we demonstrate our RichRAG framework, which explicitly considers the subaspects of multi-faceted questions to provide diverse and LLM-friendly external reference lists, thereby enhanc"
      },
      {
        "chunk_index": 15629,
        "paper_id": 313,
        "chunk_idx": 0,
        "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs",
        "section_head": "4) Documentation Generator:",
        "score": 0.8625388741493225,
        "text_preview": "The Documentation Generator creates supplementary documentation for the generated scripts, including usage instructions, dependency information, and customization guidelines. This component ensures th"
      },
      {
        "chunk_index": 4548,
        "paper_id": 84,
        "chunk_idx": 1,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Offline Human Preference Training",
        "score": 0.8594619035720825,
        "text_preview": "In contrast, Rank Responses to align Human Feedback (RRHF) (Yuan et al., 2023b) aligns model probabilities of multiple responses with human preferences using ranking loss, providing a simpler yet effe"
      },
      {
        "chunk_index": 18163,
        "paper_id": 370,
        "chunk_idx": 0,
        "title": "Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM",
        "section_head": "Fig. 2 .",
        "score": 0.8593387007713318,
        "text_preview": "2 Fig. 2. Modular LLM-based review analysis framework. Preprocessed reviews feed into three independent components: (1) Aspect-sentiment extraction with recommendations, (2) topic modeling to surface "
      }
    ]
  },
  {
    "query_id": 23,
    "query_text": "dataset generation scheme",
    "source": "title",
    "source_value": "A Dataset Generation Scheme Based on Video2EEG-SPGN-Diffusion for SEED-VD",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 52133,
        "paper_id": 1118,
        "chunk_idx": 0,
        "title": "FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting",
        "section_head": "Figure 3 :",
        "score": 0.8990663290023804,
        "text_preview": "3 Figure 3: Client-wise label distributions for selected datasets split via Metis and Louvain, demonstrating the resulting non-IID data heterogeneity."
      },
      {
        "chunk_index": 121351,
        "paper_id": 2528,
        "chunk_idx": 0,
        "title": "Self-Consuming Generative Models Go MAD",
        "section_head": "Figure 18 :",
        "score": 0.8966823816299438,
        "text_preview": "18 Figure 18: Generation t = 1 of a fully synthetic loop with bias Œª = 1. i.e., synthetic samples from the first model G 1 ."
      },
      {
        "chunk_index": 121343,
        "paper_id": 2528,
        "chunk_idx": 0,
        "title": "Self-Consuming Generative Models Go MAD",
        "section_head": "1 Figure 4 :",
        "score": 0.8939367532730103,
        "text_preview": "14 Figure4: Training generative models exclusively on synthetic data in a fully synthetic loop without sampling bias reduces both the quality and diversity of their synthetic data decreases over gener"
      },
      {
        "chunk_index": 154482,
        "paper_id": 3167,
        "chunk_idx": 0,
        "title": "Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English",
        "section_head": "Fig. 3 .",
        "score": 0.8843759298324585,
        "text_preview": "3 Fig. 3. Process of collective dataset generation."
      },
      {
        "chunk_index": 128143,
        "paper_id": 2679,
        "chunk_idx": 0,
        "title": "Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise",
        "section_head": "Figure 3 .",
        "score": 0.8716251850128174,
        "text_preview": "3 Figure 3. Performance comparison between QFL and SpoQFL for CIFAR-10 and CIFAR-100 dataset in IID and non-IID data distribution.For adding quantum noise, we set the noise level to œµ = 0.001."
      },
      {
        "chunk_index": 122184,
        "paper_id": 2542,
        "chunk_idx": 0,
        "title": "Semantic Image Synthesis with Spatially-Adaptive Normalization",
        "section_head": "Figure 21: Additional multi-modal synthesis results on the Flickr",
        "score": 0.8679434657096863,
        "text_preview": "Landscapes Dataset. By sampling latent vectors from a standard Gaussian distribution, we synthesize images of diverse appearances."
      },
      {
        "chunk_index": 120005,
        "paper_id": 2498,
        "chunk_idx": 0,
        "title": "Score Matching on Large Geometric Graphs for Cosmology Generation",
        "section_head": "Fig. 1 .",
        "score": 0.8621484041213989,
        "text_preview": "1 Fig. 1. Large-scale structures and 2PCF of two cosmologies varying (‚Ñ¶m, œÉ8), drawn from the standard Latin-hypercube sampling at z = 0 in the Quijote simulations [17]."
      },
      {
        "chunk_index": 51086,
        "paper_id": 1095,
        "chunk_idx": 0,
        "title": "FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient Research",
        "section_head": "Datasets",
        "score": 0.8579766154289246,
        "text_preview": "We use two real-world datasets and one synthetic dataset: Office-Caltech-10 [8], CIFAR-10 [16], and synthetic [19] . The Office-Caltech-10 dataset simulates a feature heterogeneous scenario, while the"
      },
      {
        "chunk_index": 63905,
        "paper_id": 1364,
        "chunk_idx": 3,
        "title": "Hierarchical Federated Learning for Social Network with Mobility",
        "section_head": "C. Performance of DO-SNM",
        "score": 0.8543356657028198,
        "text_preview": "The overfitting stems from the constrained dataset scale and intrinsic label distribution imbalance fo IEMOCAP, further exacerbated by algorithmic instability that magnifies noise variance. Consequent"
      },
      {
        "chunk_index": 102973,
        "paper_id": 2136,
        "chunk_idx": 0,
        "title": "Pain in 3D: Generating Controllable Synthetic Faces for Automated Pain Assessment",
        "section_head": "Data Generation",
        "score": 0.8503026962280273,
        "text_preview": "To address the limited availability of high-quality, clinically annotated pain expression datasets, we develop a comprehensive generative pipeline that produces synthetic facial expressions with preci"
      },
      {
        "chunk_index": 112127,
        "paper_id": 2335,
        "chunk_idx": 0,
        "title": "Realism Control One-step Diffusion for Real-World Image Super-Resolution",
        "section_head": "Figure 2 :",
        "score": 0.8466123342514038,
        "text_preview": "2 Figure 2: Realism control one-step diffusion (RCOD) training process. The left part illustrates several synthesized real-world LR images by applying diverse degradations with varying types and inten"
      },
      {
        "chunk_index": 50940,
        "paper_id": 1092,
        "chunk_idx": 2,
        "title": "FedEve: On Bridging the Client Drift and Period Drift for Cross-device Federated Learning",
        "section_head": "Analysis",
        "score": 0.8439620733261108,
        "text_preview": "Method Natural Œ± = 1 Œ± = 0.1 Œ± = 0.01 E = 1 E = 3 E = 5 E = 1 E = 3 E = 5 E = 1 E = 3 E = 5 E = 1 E = 3 E = 5 FEDAVG 82.46 ¬± 0.18 81.95 ¬± 0.26 66.38 ¬± 30.63 83.64 ¬± 0.11 83.57 ¬± 0.12 83.38 ¬± 0.09 82.1"
      },
      {
        "chunk_index": 44992,
        "paper_id": 959,
        "chunk_idx": 0,
        "title": "Evaluating Robustness of Vision-Language Models Under Noisy Conditions",
        "section_head": "B. Synthetic Noise Dataset Creation",
        "score": 0.8417498469352722,
        "text_preview": "To rigorously evaluate the robustness of Vision-Language Models (VLMs) under diverse and challenging conditions, we will generate synthetic noisy variants of clean datasets (e.g. Flickr30k, Nocaps) us"
      },
      {
        "chunk_index": 121314,
        "paper_id": 2528,
        "chunk_idx": 0,
        "title": "Self-Consuming Generative Models Go MAD",
        "section_head": "Generations Recall",
        "score": 0.8415123224258423,
        "text_preview": "MNIST DDPM in a synthetic augmentation loop: Œª = 1 Œª = 0.8 Œª = 0.66 Œª = 0.5 Figure 9 : When incorporating real data in the synthetic augmentation loop, even sampling bias cannot prevent increases in F"
      },
      {
        "chunk_index": 121344,
        "paper_id": 2528,
        "chunk_idx": 0,
        "title": "Self-Consuming Generative Models Go MAD",
        "section_head": "Figure 5 :",
        "score": 0.8407930135726929,
        "text_preview": "5 Figure5: Without sampling bias, synthetic data modes drift from real modes and merge. We present t-SNE plots of the real and synthesized data for MNIST from a fully synthetic loop without sampling b"
      },
      {
        "chunk_index": 52603,
        "paper_id": 1127,
        "chunk_idx": 0,
        "title": "FedVLM: Scalable Personalized Vision-Language Models through Federated Learning",
        "section_head": "Table 2 :",
        "score": 0.8405044078826904,
        "text_preview": "2 RLAIF-V Dataset Distribution: The dataset consists of samples from multiple standard datasets and is used to evaluate Fed-VLM in both IID and non-IID settings. Original Dataset Samples LCS-558K 15,9"
      },
      {
        "chunk_index": 133328,
        "paper_id": 2759,
        "chunk_idx": 0,
        "title": "SynSonic: Augmenting Sound Event Detection through Text-to-Audio Diffusion ControlNet and Effective Sample Filtering",
        "section_head": "3.1.",
        "score": 0.8385794162750244,
        "text_preview": "This process involves two stages of synthesis, foreground generation via the diffusion transformer and mixture creation via Scaper, which differs from the synthetic strong subset used in DCASE dataset"
      },
      {
        "chunk_index": 11443,
        "paper_id": 222,
        "chunk_idx": 0,
        "title": "ANALYZING GENERALIZATION IN PRE-TRAINED SYMBOLIC REGRESSION",
        "section_head": "SAMPLING STRATEGY",
        "score": 0.8382912874221802,
        "text_preview": "To create training instances, data points are sampled from the symbolic formulas. Here, a sampling strategy comprises the choice of sampling domain and the sampling distribution on this domain."
      },
      {
        "chunk_index": 146885,
        "paper_id": 3025,
        "chunk_idx": 0,
        "title": "UniTac2Pose: A Unified Approach Learned in Simulation for Category-level Visuotactile In-hand Pose Estimation",
        "section_head": "1 ‚Ä¶Figure 2 :",
        "score": 0.833506166934967,
        "text_preview": "12 Figure2: Method Overview. (I): We first generate a synthetic dataset using the FEM-based tactile simulator XENSIM. We randomly sample in-hand poses to generate a diverse training dataset with pure "
      },
      {
        "chunk_index": 51962,
        "paper_id": 1114,
        "chunk_idx": 0,
        "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model",
        "section_head": "Fig. 2 .",
        "score": 0.8290022611618042,
        "text_preview": "2 Fig. 2. Data partitioning of the FeTS2022 dataset."
      }
    ]
  },
  {
    "query_id": 24,
    "query_text": "diagram worth dozen",
    "source": "title",
    "source_value": "A Diagram Is Worth A Dozen Images",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 24678,
        "paper_id": 497,
        "chunk_idx": 0,
        "title": "Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning",
        "section_head": "Figure 14 :",
        "score": 0.9437081813812256,
        "text_preview": "14 Figure 14: Modality Distribution of Medical Images in Four Training Stages. In total, there are more than 14 different imaging modalities."
      },
      {
        "chunk_index": 40677,
        "paper_id": 858,
        "chunk_idx": 0,
        "title": "Efficient Multimodal Dataset Distillation via Generative Models",
        "section_head": "Figure 5 :",
        "score": 0.8805773258209229,
        "text_preview": "5 Figure 5: More qualitative results of the distilled dataset."
      },
      {
        "chunk_index": 32820,
        "paper_id": 688,
        "chunk_idx": 0,
        "title": "Denoising by neural network for muzzle blast detection",
        "section_head": "Figure 1 :",
        "score": 0.8601288795471191,
        "text_preview": "1 Figure 1: Description of the waves generated by a shot with a supersonic projectile: distance 150 m, miss distance 20 m and caliber 7.62 mm Figure 1 also shows a characteristic signal recorded by th"
      },
      {
        "chunk_index": 26242,
        "paper_id": 532,
        "chunk_idx": 0,
        "title": "Combating Homelessness Stigma with LLMs: A New Multi-Modal Dataset for Bias Detection",
        "section_head": "Figure 3 :",
        "score": 0.8576376438140869,
        "text_preview": "3 Figure 3: Large Small City Comparison"
      },
      {
        "chunk_index": 80850,
        "paper_id": 1703,
        "chunk_idx": 0,
        "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day",
        "section_head": "Sentences with in-line figure mentions:",
        "score": 0.8513239622116089,
        "text_preview": "-Computerized tomography ( CT ) scans of the chest ( Figure 4 ) were obtained. -( Figure 4 ) and demonstrated a large cavitating lesion in the pos- terior aspect of the right upper lobe with probable "
      },
      {
        "chunk_index": 68555,
        "paper_id": 1460,
        "chunk_idx": 2,
        "title": "In-Context Learning with Long-Context Models: An In-Depth Exploration",
        "section_head": "Block-sparse attention patterns",
        "score": 0.8508428335189819,
        "text_preview": "However, some short-range dependencies between examples are clearly necessary for ICL performance, as using block sizes b < 10 results in near-zero performance and performance increases slightly with "
      },
      {
        "chunk_index": 105415,
        "paper_id": 2186,
        "chunk_idx": 0,
        "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
        "section_head": "Figure A. 23 :",
        "score": 0.8495484590530396,
        "text_preview": "23 Figure A.23: Example qualitative comparisons between Imagen and GLIDE [41] on DrawBench prompts from Colors category. We observe that GLIDE is better than DALL-E 2 in assigning the colors to the ob"
      },
      {
        "chunk_index": 32133,
        "paper_id": 674,
        "chunk_idx": 0,
        "title": "DeepNet: Scaling Transformers to 1,000 Layers",
        "section_head": "Figure 4",
        "score": 0.8483179807662964,
        "text_preview": "4 Figure 4(b) and Figure 4(c) show that ||x|| is significantly larger than ‚àö d (d = 512) without warm-up or proper initialization. This explains the gradient vanishing problem occurred in the training"
      },
      {
        "chunk_index": 104417,
        "paper_id": 2164,
        "chunk_idx": 0,
        "title": "PEACH: a sentence-aligned Parallel English‚ÄìArabic Corpus for Healthcare",
        "section_head": "Figure 1 :",
        "score": 0.8475097417831421,
        "text_preview": "1 Figure 1: A snippet of the html webpages of the patient information leaflets on sfda."
      },
      {
        "chunk_index": 13640,
        "paper_id": 273,
        "chunk_idx": 1,
        "title": "ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial Transaction Networks",
        "section_head": "Introduction",
        "score": 0.842404842376709,
        "text_preview": "Despite their success, current motif-centric approaches overlook two temporal factors that are critical in practice. First, they treat motifs as static. In reality, financial networks are dynamic, and"
      },
      {
        "chunk_index": 24801,
        "paper_id": 500,
        "chunk_idx": 3,
        "title": "Classification errors distort findings in automated speech processing: examples and solutions from child-development research",
        "section_head": "Effect of classification bias on downstream analyses and measurements",
        "score": 0.8422562479972839,
        "text_preview": "correlations between vocalization quantity and standardized measures of language development (a meta-analysis in Wang et al., 2020) and the observation that children with atypical development show a l"
      },
      {
        "chunk_index": 146930,
        "paper_id": 3026,
        "chunk_idx": 0,
        "title": "UniTransfer: Video Concept Transfer via Progressive Spatial and Timestep Decomposition",
        "section_head": "Figure 4 :",
        "score": 0.8422369956970215,
        "text_preview": "4 Figure 4: Comparison of video character transfer. Note that our backgrounds are better preserved."
      },
      {
        "chunk_index": 56246,
        "paper_id": 1208,
        "chunk_idx": 0,
        "title": "Freeze and Reveal: Exposing Modality Bias in Vision-Language Models",
        "section_head": "Figure 1 :",
        "score": 0.8404988646507263,
        "text_preview": "1 Figure 1: Different modalities posses different level of bias. We aim to show which one exhibits more bias."
      },
      {
        "chunk_index": 127969,
        "paper_id": 2675,
        "chunk_idx": 0,
        "title": "SPGISpeech 2.0: Transcribed multi-speaker financial audio for speaker-tagged transcription",
        "section_head": "Figure 1 :",
        "score": 0.8403563499450684,
        "text_preview": "1 Figure 1: Distribution of the number of unique speakers per snippet.There is also a single snippet with more than six speakers."
      },
      {
        "chunk_index": 118928,
        "paper_id": 2481,
        "chunk_idx": 0,
        "title": "Scaling Laws of Synthetic Data for Language Models",
        "section_head": "Figure 2 :",
        "score": 0.8360352516174316,
        "text_preview": "2 Figure 2: Scaling laws on different model sizes. The x-axis represents the number of training tokens. The y-axis shows the models' error rates on MATH benchmark. Solid lines indicate fitted scaling "
      },
      {
        "chunk_index": 105501,
        "paper_id": 2188,
        "chunk_idx": 0,
        "title": "Physics-Informed Neural Network Approaches for Sparse Data Flow Reconstruction of Unsteady Flow Around Complex Geometries",
        "section_head": "Figure 7 :",
        "score": 0.8353341221809387,
        "text_preview": "7 Figure 7: Schematic of Data-driven model"
      },
      {
        "chunk_index": 137239,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Self-Reflection",
        "score": 0.834633469581604,
        "text_preview": "Figure 122 demonstrates the application of self-reflection [116, 88, 63] to improve the results shown in Figure 47 . As we can see, the self-reflected result is better aligned with the reference image"
      },
      {
        "chunk_index": 101914,
        "paper_id": 2118,
        "chunk_idx": 0,
        "title": "OptiProxy-NAS: Optimization Proxy based End-to-End Neural Architecture Search",
        "section_head": "Figure 1 :",
        "score": 0.8341139554977417,
        "text_preview": "1 Figure 1: Schematic of the search framework comparison."
      },
      {
        "chunk_index": 22133,
        "paper_id": 453,
        "chunk_idx": 0,
        "title": "CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration",
        "section_head": "Figure 13 :",
        "score": 0.8337510824203491,
        "text_preview": "13 Figure13: Qualitative examples for numeracy. CARINOX matches object counts and distributions more accurately than baselines."
      },
      {
        "chunk_index": 156010,
        "paper_id": 3199,
        "chunk_idx": 0,
        "title": "XGBoost: A Scalable Tree Boosting System",
        "section_head": "Figure 5 :",
        "score": 0.8323389291763306,
        "text_preview": "5 Figure5: Impact of the sparsity aware algorithm on Allstate-10K. The dataset is sparse mainly due to one-hot encoding. The sparsity aware algorithm is more than 50 times faster than the naive versio"
      }
    ]
  },
  {
    "query_id": 25,
    "query_text": "distributed generative approach",
    "source": "title",
    "source_value": "A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing ",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 107121,
        "paper_id": 2219,
        "chunk_idx": 5,
        "title": "PowerGrow: Feasible Co-Growth of Structures and Dynamics for Power Grid Synthesis",
        "section_head": "Introduction",
        "score": 0.9677851796150208,
        "text_preview": "Finally, to achieve high feasibility, we employ a domain-specific power flow simulator [6, 40] to prepare high-quality training data. Overall, a three-level hierarchical graph beta diffusion framework"
      },
      {
        "chunk_index": 51774,
        "paper_id": 1110,
        "chunk_idx": 0,
        "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models",
        "section_head": "B. Diffusion Models Compression",
        "score": 0.9611949920654297,
        "text_preview": "DMs, though with powerful generative capabilities for highquality images, are computationally intensive and memorydemanding, raising notable obstacles for their deployments on edge devices and clients"
      },
      {
        "chunk_index": 129721,
        "paper_id": 2694,
        "chunk_idx": 3,
        "title": "STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs",
        "section_head": "Advanced parallelism for diffusion inference.",
        "score": 0.9464271068572998,
        "text_preview": "This dual-dimensional method effectively minimizes inference latency while preserving image generation quality. To achieve this, STADI makes the following technical contributions. ‚Ä¢ First implementati"
      },
      {
        "chunk_index": 49087,
        "paper_id": 1049,
        "chunk_idx": 0,
        "title": "FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization",
        "section_head": "Proposed System Architecture: FedCVD++",
        "score": 0.9452023506164551,
        "text_preview": "We propose FedCVD++, a novel federated learning framework that addresses three critical challenges in healthcare AI: privacy preservation, communication efficiency, and class imbalance handling. As sh"
      },
      {
        "chunk_index": 5011,
        "paper_id": 87,
        "chunk_idx": 1,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "B. Distributed Deep Learning",
        "score": 0.944825291633606,
        "text_preview": "AutoDiCE [132] further exemplifies this approach by automating the process of splitting and distributing CNN models across heterogeneous edge devices for efficient inference [133] . Consequently, this"
      },
      {
        "chunk_index": 128114,
        "paper_id": 2679,
        "chunk_idx": 3,
        "title": "Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise",
        "section_head": "Introduction",
        "score": 0.9389350414276123,
        "text_preview": "In federated environments, where many quantum nodes contribute to training, noise heterogeneity across devices further amplifies learning instability. Effective noise mitigation is essential for impro"
      },
      {
        "chunk_index": 51773,
        "paper_id": 1110,
        "chunk_idx": 0,
        "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models",
        "section_head": "II. RELATED WORK A. Training Diffusion Models in FL",
        "score": 0.9388846158981323,
        "text_preview": "A few studies consider training DMs within FL environments. Those that achieve distributed DM training often provide a basic framework without addressing the key challenges of non-IID data and efficie"
      },
      {
        "chunk_index": 3431,
        "paper_id": 66,
        "chunk_idx": 0,
        "title": "A Semi-Supervised Federated Learning Framework with Hierarchical Clustering Aggregation for Heterogeneous Satellite Networks",
        "section_head": "IV. HIERARCHICAL SEMI-SUPERVISED QUANTITATIVE FEDERATED LEARNING FRAMEWORK",
        "score": 0.9278414249420166,
        "text_preview": "Due to the NP-hard nature of the satellite optimization problem, formulated as a mixed-integer nonlinear program (MINLP), direct optimization becomes computationally intractable. To address this issue"
      },
      {
        "chunk_index": 92267,
        "paper_id": 1945,
        "chunk_idx": 0,
        "title": "Multi-Strategy Guided Diffusion via Sparse Masking Temporal Reweighting Distribution Correction",
        "section_head": "C. Sinogram Reconstruction and Correction Stage",
        "score": 0.9252617359161377,
        "text_preview": "During the reconstruction stage, we propose a temporal reweighted distribution correction framework to address data incompleteness and structural degradation caused by sparse sampling. As shown in Fig"
      },
      {
        "chunk_index": 55511,
        "paper_id": 1188,
        "chunk_idx": 2,
        "title": "FLOW MARCHING FOR A GENERATIVE PDE FOUNDATION MODEL A PREPRINT",
        "section_head": "Introduction",
        "score": 0.9244741201400757,
        "text_preview": "Besides Flow Marching, a practical large-scale generative PDE foundation model is still challenging on two fronts, efficient neural architecture and data. Our efficient architecture has two components"
      },
      {
        "chunk_index": 26017,
        "paper_id": 527,
        "chunk_idx": 1,
        "title": "CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks",
        "section_head": "A. Model Parallelism and Edge Computing",
        "score": 0.9234836101531982,
        "text_preview": "However, implementing a cross-device hybrid parallel strategy in heterogeneous wireless edge networks presents greater challenges due to the resource-constrained nature of terminal devices and the uns"
      },
      {
        "chunk_index": 111133,
        "paper_id": 2309,
        "chunk_idx": 0,
        "title": "RadioDiff-Loc: Diffusion Model Enhanced Scattering Congnition for NLoS Localization with Sparse Radio Map Estimation",
        "section_head": "VI. CONCLUSION",
        "score": 0.9232234954833984,
        "text_preview": "In this work, we proposed RadioDiff-Loc, a novel diffusionbased localization framework designed for non-cooperative signal sources in NLoS environments. By incorporating physical insights from knife-e"
      },
      {
        "chunk_index": 154395,
        "paper_id": 3165,
        "chunk_idx": 0,
        "title": "Whisfusion: Parallel ASR Decoding via a Diffusion Transformer",
        "section_head": "Diffusion Decoder:",
        "score": 0.9208921194076538,
        "text_preview": "We employ a pre-trained SMDM-170M, a text diffusion transformer, as our decoder. Its inher- ent non-autoregressive nature allows it to process the entire text sequence in parallel, making it an ideal "
      },
      {
        "chunk_index": 19691,
        "paper_id": 399,
        "chunk_idx": 3,
        "title": "Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising",
        "section_head": "Introduction",
        "score": 0.9188147187232971,
        "text_preview": "Second, building on the theoretical framework of Classifier-Free Guidance (CFG), we propose a semi-clean guidance mechanism that dynamically adjusts score estimates during sampling, enabling direction"
      },
      {
        "chunk_index": 124849,
        "paper_id": 2605,
        "chunk_idx": 0,
        "title": "SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI",
        "section_head": "SLaM-DiMM Methodology",
        "score": 0.9177232980728149,
        "text_preview": "This section contains the discussion of our proposed model SLaM-DiMM which includes missing modality generation (MMG) and coherence enhancement (CEn). Our approach is inspired by recent advances in de"
      },
      {
        "chunk_index": 26067,
        "paper_id": 527,
        "chunk_idx": 0,
        "title": "CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks",
        "section_head": "VII. CONCLUSION",
        "score": 0.9151452779769897,
        "text_preview": "This paper has presented CollaPipe, a novel hybrid parallel learning framework for collaborative LLM training. In the proposed approach, the encoder of the LLM is partitioned into S segments in a TEB-"
      },
      {
        "chunk_index": 46354,
        "paper_id": 993,
        "chunk_idx": 0,
        "title": "Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription",
        "section_head": "Audio rendering",
        "score": 0.9110563397407532,
        "text_preview": "To synthesize audio from MIDI sequences, we employ an extended Karplus-Strong algorithm (Jaffe and Smith, 1983) , which models the behavior of a vibrating string using a delay line and a series of dig"
      },
      {
        "chunk_index": 5182,
        "paper_id": 89,
        "chunk_idx": 3,
        "title": "A Survey on Diffusion Language Models",
        "section_head": "Continuous Diffusion Language Models",
        "score": 0.9106513261795044,
        "text_preview": "By incorporating a self-conditioning mechanism, it achieves strong performance in both conditional and unconditional text generation, rivaling standard autoregressive models. CDCD [51] applies continu"
      },
      {
        "chunk_index": 110414,
        "paper_id": 2293,
        "chunk_idx": 12,
        "title": "Quantum Federated Learning: A Comprehensive Survey",
        "section_head": "C. Communication Schemes 1) Classical Communications:",
        "score": 0.9102899432182312,
        "text_preview": "2) Communication Optimization: While model optimization in QFL involves refining the QML algorithms themselves to improve training speed, accuracy, and resource utilization, communication optimization"
      },
      {
        "chunk_index": 49760,
        "paper_id": 1066,
        "chunk_idx": 2,
        "title": "Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission",
        "section_head": "C. Summary of Contributions",
        "score": 0.9100342392921448,
        "text_preview": "COMPARISON OF KEY PAPERS AND OUR FEDHLM FRAMEWORK Feature Token Communications Paper Uncertainty-Aware HLM Paper Our FedHLM Framework Focus Cross-modal token-based communication Hybrid inference with "
      }
    ]
  },
  {
    "query_id": 26,
    "query_text": "domain knowledge informed",
    "source": "title",
    "source_value": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 75070,
        "paper_id": 1590,
        "chunk_idx": 0,
        "title": "Large Language Models Encode Clinical Knowledge",
        "section_head": "Table 1 |",
        "score": 0.9368982315063477,
        "text_preview": "1 Summary of MultiMedQA describing the format, size, and domain of the datasets in the benchmark. Dataset Format Size (dev/test) Domain MedQA (USMLE) Q + A (4-5 Choices) 11450 / 1273 General medical k"
      },
      {
        "chunk_index": 4054,
        "paper_id": 81,
        "chunk_idx": 1,
        "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",
        "section_head": "Table 2 .",
        "score": 0.8980813026428223,
        "text_preview": "77 BianQue 78 6.2B 2.4M dialogues BianQueCorpus 78 ClinicalGPT 79 7B 96k EHRs + 100k dialogues 192 medical QA MD-EHR 79 +MedDialog 74 VariousMedQA 14 Medical-domain LLMs (Sec. 2) Qilin-Med 80 ChatDoct"
      },
      {
        "chunk_index": 141325,
        "paper_id": 2912,
        "chunk_idx": 0,
        "title": "Towards Expert-Level Medical Question Answering with Large Language Models",
        "section_head": "Table 1 |",
        "score": 0.8941941261291504,
        "text_preview": "1 Multiple-choice question evaluation datasets. Name Count Description MedQA (USMLE) 1273 General medical knowledge in US medical licensing exam PubMedQA 500 Closed-domain question answering given Pub"
      },
      {
        "chunk_index": 97314,
        "paper_id": 2051,
        "chunk_idx": 0,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "Step 0: Initial Plan from Query Analyzer",
        "score": 0.8840588927268982,
        "text_preview": "Required skills: 1. Histopathology Knowledge: Understanding of osteosarcoma and its histological features."
      },
      {
        "chunk_index": 8458,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "Reasoning Tasks",
        "score": 0.8761831521987915,
        "text_preview": "A concise overview of distinct categories of related reasoning approaches and tasks is provided here for background concepts. This comprehensive overview provides insights into the diverse landscape o"
      },
      {
        "chunk_index": 146607,
        "paper_id": 3022,
        "chunk_idx": 0,
        "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
        "section_head": "Text Input",
        "score": 0.8510774374008179,
        "text_preview": "Structural Fact Domain-specific Knowledge Symbolic-reasoning ...."
      },
      {
        "chunk_index": 46269,
        "paper_id": 990,
        "chunk_idx": 0,
        "title": "Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text",
        "section_head": "Figure 2 :",
        "score": 0.8396391868591309,
        "text_preview": "2 Figure 2: An example prompt to extract facts from the knowledge the model acquired during pre-training about manufacturers of COVID-19 vaccines."
      },
      {
        "chunk_index": 146705,
        "paper_id": 3022,
        "chunk_idx": 0,
        "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
        "section_head": "Fig. 11 .",
        "score": 0.8358488082885742,
        "text_preview": "11 Fig. 11. Retrieving external knowledge to enhance the LLM generation."
      },
      {
        "chunk_index": 65338,
        "paper_id": 1391,
        "chunk_idx": 0,
        "title": "HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs",
        "section_head": "Figure 2 :",
        "score": 0.8296623229980469,
        "text_preview": "2 Figure 2: Demonstration of developing and improving LLMs for medical complex reasoning. Left (Stage1): Searching for correct reasoning trajectories to fine-tune LLMs for complex reasoning. Right (St"
      },
      {
        "chunk_index": 140964,
        "paper_id": 2907,
        "chunk_idx": 0,
        "title": "Towards Conversational Diagnostic AI",
        "section_head": "Real-world Datasets for AMIE",
        "score": 0.829542338848114,
        "text_preview": "AMIE was developed using a diverse suite of real-world datasets including multiple-choice medical questionanswering, expert-curated long-form medical reasoning, electronic health record (EHR) note sum"
      },
      {
        "chunk_index": 40969,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Experimental Settings",
        "score": 0.81928551197052,
        "text_preview": "We conduct our experiments on two representative domains: mathematical reasoning and Wikipedia (Wiki) QA, which involves commonsense and logical reasoning on factual descriptive knowledge."
      },
      {
        "chunk_index": 4716,
        "paper_id": 85,
        "chunk_idx": 6,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Molecular and Cellular Biology.",
        "score": 0.8121318817138672,
        "text_preview": "HuatuoGPT-Vision [540] and GMAI-VL [541] collect large-scale medical multimodal data from PubMed papers and open-source medical image datasets. They are pre-trained on extensive medical imagecaption p"
      },
      {
        "chunk_index": 73095,
        "paper_id": 1558,
        "chunk_idx": 0,
        "title": "Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems",
        "section_head": "Eyes (E): Perception and Knowledge Acquisition",
        "score": 0.8120737075805664,
        "text_preview": "1. Multi-source data fusion and scenario adaptation: Observational datasets, model repositories, and domain literature are integrated via retrieval-augmented generation (RAG) and few-shot learning, en"
      },
      {
        "chunk_index": 4886,
        "paper_id": 85,
        "chunk_idx": 3,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8111616373062134,
        "text_preview": "SFT VQA, Text QA 2024.11 EN, ZH Comprehensive multi-source integration Semi-automated 5 Data review GPT-4o 5.5M OphVL [664] [link] Healthcare and Medical Sciences Ophthalmic Surgical Video Pre-trainin"
      },
      {
        "chunk_index": 4889,
        "paper_id": 85,
        "chunk_idx": 6,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8100758790969849,
        "text_preview": "Pre-training, SFT Text QA 2023.11 EN, ZH Integration of existing datasets Automated N/A Data review N/A 1,114,315 MTS-DIALOG [892] [link] Healthcare and Medical Sciences Clinical dialogue Pre-training"
      },
      {
        "chunk_index": 4884,
        "paper_id": 85,
        "chunk_idx": 1,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8079805374145508,
        "text_preview": "Scientific Domain Dataset Subdomain Modality Purpose Type Release Language Source Annotation Pipeline Human Annotators Human Tasks Auto-annotation Tools Size Life Sciences MIRAGE [190] [link] Agricult"
      },
      {
        "chunk_index": 4370,
        "paper_id": 84,
        "chunk_idx": 0,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Reasoning Tasks",
        "score": 0.8066251277923584,
        "text_preview": "In this section, we provide a concise overview of various reasoning tasks, as Figure 2 shows. Here, we present distinct categories of reasoning approaches and tasks: ‚Ä¢ Commonsense Reasoning (Section 3"
      },
      {
        "chunk_index": 82684,
        "paper_id": 1738,
        "chunk_idx": 0,
        "title": "Longitudinal and Multimodal Recording System to Capture Real-World Patient-Clinician Conversations for AI and Encounter Research: Protocol",
        "section_head": "EHR Data Extraction",
        "score": 0.80648273229599,
        "text_preview": "Following a recorded encounter, trained study staff perform a manual extraction of structured (demographic and clinical variables) and unstructured (clinical notes, patient portal messages) data from "
      },
      {
        "chunk_index": 4684,
        "paper_id": 85,
        "chunk_idx": 1,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.804082989692688,
        "text_preview": "1) Expert-Level Scientific Knowledge Comprehension and Retrieval: Unlike general-purpose language models, scientific AI models must retrieve, comprehend, and apply cutting-edge research knowledge acro"
      },
      {
        "chunk_index": 4898,
        "paper_id": 85,
        "chunk_idx": 15,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8016371726989746,
        "text_preview": "Expert VQA 2024.05 EN Academic and research resources, Comprehensive multi-source integration Automated N/A N/A N/A 120 Open-ended Acc, Patient compliance, Consultation ratings AgentClinic-Lang [776] "
      }
    ]
  },
  {
    "query_id": 27,
    "query_text": "fast initialization method",
    "source": "title",
    "source_value": "A Fast Initialization Method for Neural Network Controllers: A Case Study of Image-based Visual Serv",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 22570,
        "paper_id": 461,
        "chunk_idx": 0,
        "title": "Causality-guided Prompt Learning for Vision-language Models via Visual Granulation",
        "section_head": "Table 6 .",
        "score": 1.0,
        "text_preview": "6 Ablation study for attribute query initialization. Method Base New H Non-learnable method 77.83 72.75 75.20 Prior initialization method 78.34 74.12 76.17 Random initialization method (ours) 79.91 75"
      },
      {
        "chunk_index": 85610,
        "paper_id": 1802,
        "chunk_idx": 0,
        "title": "MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models",
        "section_head": "Ablation Experiments",
        "score": 0.8449648022651672,
        "text_preview": "Three groups of ablation experiments are designed: complete MCP framework (Dynamic Routing + Reinforcement Learning Policy), Static Routing, Random Routing, and baseline without routing strategy."
      },
      {
        "chunk_index": 69266,
        "paper_id": 1475,
        "chunk_idx": 0,
        "title": "INITIALIZING MODELS WITH LARGER ONES",
        "section_head": "Table 12 :",
        "score": 0.8198935985565186,
        "text_preview": "12 Comparison with mimetic initialization. Weight selection significantly outperforms mimetic initialization by directly utilizing pretrained parameters. setting CIFAR-10 CIFAR-100 STL-10 random init "
      },
      {
        "chunk_index": 118970,
        "paper_id": 2482,
        "chunk_idx": 0,
        "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
        "section_head": "Analysis Results: Test-Time Scaling for Search with Verifiers",
        "score": 0.8195639252662659,
        "text_preview": "We now present our results comparing various search algorithms and identify a prompt difficulty dependent compute-optimal scaling strategy for search methods."
      },
      {
        "chunk_index": 28405,
        "paper_id": 584,
        "chunk_idx": 0,
        "title": "CONTROLLABLE-CONTINUOUS COLOR EDITING IN DIFFUSION MODEL VIA COLOR MAPPING",
        "section_head": "Original",
        "score": 0.813244104385376,
        "text_preview": "Fig. 6 : Comparison with interpolation method."
      },
      {
        "chunk_index": 9907,
        "paper_id": 189,
        "chunk_idx": 0,
        "title": "ALScope: A Unified Toolkit for Deep Active Learning",
        "section_head": "A Hardware and Environment",
        "score": 0.8024542331695557,
        "text_preview": "Most experiments were conducted on A100 GPUs. The following experiments, however, were performed on a single RTX 4090: ‚Ä¢ CIFAR-10 (Openset): OOD Ratio = 0.2, 0.4 ‚Ä¢ CIFAR-100 (Openset): OOD Ratio = 0.6"
      },
      {
        "chunk_index": 17359,
        "paper_id": 351,
        "chunk_idx": 0,
        "title": "Best-of-‚àû -Asymptotic Performance of Test-Time Compute",
        "section_head": "Experimental Set 5: Comparison with other answer-selection methods",
        "score": 0.8019242286682129,
        "text_preview": "We finally compared the majority voting scheme with other selection scheme in the best-of-five (Bo5) test-time inference. On AIME2025, majority voting outperforms random selection, self-certainty, rew"
      },
      {
        "chunk_index": 49335,
        "paper_id": 1054,
        "chunk_idx": 0,
        "title": "FedEL: Federated Elastic Learning for Heterogeneous Devices",
        "section_head": "Figure 14 :",
        "score": 0.7965538501739502,
        "text_preview": "14 Figure14: Tensor selection illustration in FedEL-C and FedEL."
      },
      {
        "chunk_index": 111434,
        "paper_id": 2318,
        "chunk_idx": 0,
        "title": "Random Erasing Data Augmentation",
        "section_head": "Our Approach",
        "score": 0.7939188480377197,
        "text_preview": "This section presents the Random Erasing data augmentation method for training the convolutional neural network (CNN). We first describe the detailed procedure of Random Erasing. Next, the implementat"
      },
      {
        "chunk_index": 21107,
        "paper_id": 431,
        "chunk_idx": 0,
        "title": "Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments",
        "section_head": "VII. RESULTS AND ANALYSIS",
        "score": 0.79099440574646,
        "text_preview": "This section presents a detailed analysis of our experimental results across three key dimensions: communication cost, model accuracy, and memory efficiency. We compare the baseline FedAvg configurati"
      },
      {
        "chunk_index": 77090,
        "paper_id": 1628,
        "chunk_idx": 0,
        "title": "Learnable Sampler Distillation for Discrete Diffusion Models",
        "section_head": "Table 5 :",
        "score": 0.7806962728500366,
        "text_preview": "5 Ablation study on the Hamming distance threshold for the relaxed objective. Threshold(%) 0 1 5 (Our choice) 10 20 Perplexity(‚Üì) 35.98 32.15 31.24 39.97 51.52"
      },
      {
        "chunk_index": 49329,
        "paper_id": 1054,
        "chunk_idx": 0,
        "title": "FedEL: Federated Elastic Learning for Heterogeneous Devices",
        "section_head": "Figure 3 :",
        "score": 0.7806951403617859,
        "text_preview": "3 Figure 3: Tensor selection in ElasticTrainer."
      },
      {
        "chunk_index": 144533,
        "paper_id": 2979,
        "chunk_idx": 0,
        "title": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree",
        "section_head": "Model",
        "score": 0.7796683311462402,
        "text_preview": "Decod GPU CSTalks Earnings21 (10h) MultiMed RTFx‚Üë PB F-score (P/R)‚Üë WER‚Üì F-score (P/R)‚Üë WER‚Üì F-score (P/R)‚Üë WER‚Üì Avg. CTC greedy -35.0 (97/21) 13.7 45.7 (94/30) 15.6 54.0 (95/38) 15.0 2181 ‚úì 64.8 (94/"
      },
      {
        "chunk_index": 126926,
        "paper_id": 2646,
        "chunk_idx": 0,
        "title": "SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching",
        "section_head": "Table 5 :",
        "score": 0.7792572975158691,
        "text_preview": "5 Ablation study on base threshold (decay_rate=0.5)Threshold ùúè 0 FLOPs(T) ‚Üì Speed ‚Üë FID ‚Üì sFID ‚Üì IS ‚Üë 0.1 4.95 4.80 2.68 5.34 232.79 0.3 4.76 4.99 2.72 5.51 233.85 0.5 4.57 5.19 2.72 5.21 234.26 0.8 3"
      },
      {
        "chunk_index": 91173,
        "paper_id": 1920,
        "chunk_idx": 0,
        "title": "Monte Carlo Tree Diffusion with Multiple Experts for Protein Design",
        "section_head": "Baselines and Variants",
        "score": 0.7788459062576294,
        "text_preview": "We conduct an ablation study to quantify the impact of multi-expert guidance. In particular, we compare three variants of our approach: MCTD-ME-0 (no experts): A control variant that performs the diff"
      },
      {
        "chunk_index": 134283,
        "paper_id": 2781,
        "chunk_idx": 0,
        "title": "Taming Transformers for High-Resolution Image Synthesis",
        "section_head": "Figure 9 .",
        "score": 0.7785707116127014,
        "text_preview": "9 Figure 9. FID and Inception Score as a function of top-k, nucleus and rejection filtering."
      },
      {
        "chunk_index": 22569,
        "paper_id": 461,
        "chunk_idx": 0,
        "title": "Causality-guided Prompt Learning for Vision-language Models via Visual Granulation",
        "section_head": "Table 5 .",
        "score": 0.7771517038345337,
        "text_preview": "5 Ablation study for different optimization methods for attribute disentanglement. Method Base New H Classification-based method 78.44 74.24 76.28 DDPM-based method 79.12 74.93 76.97 BBDM-based varian"
      },
      {
        "chunk_index": 121191,
        "paper_id": 2525,
        "chunk_idx": 0,
        "title": "SELF-ATTENTION DOES NOT NEED O(n 2 ) MEMORY A PREPRINT",
        "section_head": "Empirical Analysis",
        "score": 0.7762399315834045,
        "text_preview": "In this section, we experimentally compare the memory requirements and runtime performance of the suggested algorithm compared to the implementation of attention currently provided by Flax (Heek et al"
      },
      {
        "chunk_index": 70547,
        "paper_id": 1503,
        "chunk_idx": 0,
        "title": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization",
        "section_head": "Table 4 :",
        "score": 0.7733070254325867,
        "text_preview": "4 Ablation studies on the number of rules and methods for rule selection. Variant LUAR CRUD MUD Win Rate K = 5 0.479 0.441 0.511 K = 15 0.479 0.440 0.569 Random 0.479 0.439 0.548 hjk only 0.485 0.443 "
      },
      {
        "chunk_index": 122955,
        "paper_id": 2561,
        "chunk_idx": 0,
        "title": "SFedKD: Sequential Federated Learning with Discrepancy-Aware Multi-Teacher Knowledge Distillation",
        "section_head": "Table 3 :",
        "score": 0.7732155323028564,
        "text_preview": "3 Performance comparison of our teacher selection algorithm and random sampling. ùêæ 3 4 5 6 Exdir(2,0.5) Random TS 58.14% 57.55% 59.01% 61.92% 59.70% 61.93% 62.34% 62.83% Advantage 1.56% 4.38% 3.33% 0."
      }
    ]
  },
  {
    "query_id": 28,
    "query_text": "federated fine-tuning paradigm",
    "source": "title",
    "source_value": "A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 8980,
        "paper_id": 172,
        "chunk_idx": 0,
        "title": "AI-IN-THE-LOOP: PRIVACY PRESERVING REAL-TIME SCAM DETECTION AND CONVERSATIONAL SCAMBAITING BY LEVERAGING LLMS AND FEDERATED LEARNING",
        "section_head": "Figure 3 :",
        "score": 0.9716458320617676,
        "text_preview": "3 Figure 3: Federated Learning architecture for decentralized, privacy-preserving scam model training."
      },
      {
        "chunk_index": 51504,
        "paper_id": 1104,
        "chunk_idx": 0,
        "title": "FedMentor: Domain-Aware Differential Privacy for Heterogeneous Federated LLMs in Mental Health",
        "section_head": "FedMentor framework",
        "score": 0.9246938824653625,
        "text_preview": "FedMentor combines Federated Learning (FL) [11] , Low-Rank Adaptation (LoRA) [22] , and domain-aware Differential Privacy (DP) [20, 23, 24, 25] to enable scalable, privacy-preserving finetuning of LLM"
      },
      {
        "chunk_index": 2934,
        "paper_id": 55,
        "chunk_idx": 0,
        "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption",
        "section_head": "Fig. 2 .",
        "score": 0.9238818883895874,
        "text_preview": "2 Fig. 2. FL Framework with HHE for Secure Model Aggregation"
      },
      {
        "chunk_index": 61861,
        "paper_id": 1321,
        "chunk_idx": 0,
        "title": "GRAMFEDDHAR: GRAPH BASED MULTIMODAL DIFFERENTIALLY PRIVATE FEDERATED HAR",
        "section_head": "Proposed Scheme",
        "score": 0.9158132076263428,
        "text_preview": "In this work, GraMFedHAR, a multimodal graph-based federated learning (FL) framework with client-level differential privacy (DP) is proposed. The framework integrates modality-specific graph construct"
      },
      {
        "chunk_index": 97061,
        "paper_id": 2048,
        "chunk_idx": 0,
        "title": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
        "section_head": "A.4 Federated Methods",
        "score": 0.9139338731765747,
        "text_preview": "Federated learning (FL) algorithms aim to train a robust global model by aggregating locally computed updates from distributed clients, with a strong emphasis on data privacy and system efficiency."
      },
      {
        "chunk_index": 100632,
        "paper_id": 2106,
        "chunk_idx": 0,
        "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting",
        "section_head": "Fig. 1 :",
        "score": 0.9138611555099487,
        "text_preview": "1 Fig. 1: Federated learning architecture for medical applications: hospitals securely exchange gradient updates while the OptiGradTrust server performs trust-aware aggregation."
      },
      {
        "chunk_index": 157143,
        "paper_id": 3220,
        "chunk_idx": 0,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "E. Federated Learning for Privacy-Preserving Deepfake Prevention",
        "score": 0.9051263332366943,
        "text_preview": "As deepfake techniques continued to evolve, traditional centralized AI-based defenses faced data privacy, scalability, and adaptability challenges. Federated learning (FL) [411] offers a decentralized"
      },
      {
        "chunk_index": 2977,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "Fig. 3 :",
        "score": 0.9047034382820129,
        "text_preview": "3 Fig. 3: Training workflow of our framework demonstrating local quantum-enhanced computations, federated aggregation, and secure update exchanges."
      },
      {
        "chunk_index": 5082,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "B. Privacy-Preserving Techniques",
        "score": 0.9027417302131653,
        "text_preview": "Protecting user data within distributed collaborative systems is paramount. Four prominent techniques address privacy concerns: federated learning, differential privacy, homomorphic encryption, and se"
      },
      {
        "chunk_index": 49953,
        "paper_id": 1070,
        "chunk_idx": 0,
        "title": "Federated Learning for Financial Forecasting",
        "section_head": "Fig. 7 .",
        "score": 0.9011720418930054,
        "text_preview": "7 Fig. 7. Results for Personalized Federated Learning and Dataset Transfer protocol. Model with FL knowledge outperforms model built from scratch."
      },
      {
        "chunk_index": 2975,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "Fig. 1 :",
        "score": 0.8999412059783936,
        "text_preview": "1 Fig. 1: Overview of FL, each participating organization trains a local model on private data, while a central federated server aggregates these local updates to construct a collaborative global mode"
      },
      {
        "chunk_index": 47640,
        "paper_id": 1016,
        "chunk_idx": 1,
        "title": "FairFedMed: Benchmarking Group Fairness in Federated Medical Imaging with FairLoRA",
        "section_head": "II. RELATED WORK",
        "score": 0.8989444971084595,
        "text_preview": "2) Federated Learning (FL): FL is a decentralized machine learning paradigm enabling multiple clients to collaboratively train a global model while keeping their local data private. FL approaches typi"
      },
      {
        "chunk_index": 39654,
        "paper_id": 840,
        "chunk_idx": 0,
        "title": "Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)",
        "section_head": "Fig. 4 .",
        "score": 0.8988909721374512,
        "text_preview": "4 Fig.4. A federated framework for fine-tuning personalized diffusion models across edge devices. Clients are grouped by domain (e.g., image style) based on their dataset characteristics. After cluste"
      },
      {
        "chunk_index": 5029,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "C. Privacy-Preserving Techniques",
        "score": 0.8981001377105713,
        "text_preview": "Protecting user data within distributed collaborative systems requires comprehensive privacy-preserving techniques including federated learning, differential privacy, homomorphic encryption, and secur"
      },
      {
        "chunk_index": 26718,
        "paper_id": 543,
        "chunk_idx": 0,
        "title": "Communication-Aware Knowledge Distillation for Federated LLM Fine-Tuning over Wireless Networks",
        "section_head": "Fig. 1 .",
        "score": 0.8955345153808594,
        "text_preview": "1 Fig. 1. The workflow of AdaLD scheme. Each communication round involves 10 steps to fine-tune the server's LLM and clients' SLM."
      },
      {
        "chunk_index": 20746,
        "paper_id": 422,
        "chunk_idx": 0,
        "title": "Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges",
        "section_head": "Overview on FL, M3T FMs, and M3T FedFMs",
        "score": 0.8951241970062256,
        "text_preview": "1. Federated Learning (FL): FL is a pioneering distributed ML paradigm that enables collaborative model training across multiple clients/participants (e.g., students, educators, institutions). FL oper"
      },
      {
        "chunk_index": 51526,
        "paper_id": 1104,
        "chunk_idx": 0,
        "title": "FedMentor: Domain-Aware Differential Privacy for Heterogeneous Federated LLMs in Mental Health",
        "section_head": "B.3 Baseline specification",
        "score": 0.8947240114212036,
        "text_preview": "Centralized (w/o FL, w/o DP). Pool all datasets and fine-tune a single LoRA adapter on the combined corpus without privacy constraints. Serves as an optimistic upper bound when central aggregation is "
      },
      {
        "chunk_index": 30472,
        "paper_id": 637,
        "chunk_idx": 0,
        "title": "Data Valuation and Selection in a Federated Model Marketplace",
        "section_head": "A.1 Federated Learning",
        "score": 0.8932589292526245,
        "text_preview": "Federated Learning (FL) is a distributed learning framework that enables massive and remote clients to collaboratively train a high-quality central model. This paper focuses on cross-silo Federated Le"
      },
      {
        "chunk_index": 3324,
        "paper_id": 64,
        "chunk_idx": 1,
        "title": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx",
        "section_head": "Introduction",
        "score": 0.8926874399185181,
        "text_preview": "Federated Learning (FL) has emerged as a powerful solution to the aforementioned data-siloing challenge. Therefore, FL is a distributed learning paradigm where multiple clients (e.g., hospitals) colla"
      },
      {
        "chunk_index": 123607,
        "paper_id": 2577,
        "chunk_idx": 0,
        "title": "SimDeep: Federated 3D Indoor Localization via Similarity-Aware Aggregation",
        "section_head": "F. Decentralized Collaborative Learning Mechanism",
        "score": 0.891252875328064,
        "text_preview": "SimDeep's decentralized collaborative learning mechanism ensures high model performance across clients, even with non-IID distributions. Unlike traditional federated learning, which averages all clien"
      }
    ]
  },
  {
    "query_id": 29,
    "query_text": "federated learning framework",
    "source": "title",
    "source_value": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neu",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 47627,
        "paper_id": 1015,
        "chunk_idx": 0,
        "title": "FairEquityFL -A Fair and Equitable Client Selection in Federated Learning for Heterogeneous IoV Networks",
        "section_head": "Fig. 1 :",
        "score": 0.9524098634719849,
        "text_preview": "1 Fig. 1: A classic federated learning framework."
      },
      {
        "chunk_index": 2995,
        "paper_id": 57,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy",
        "section_head": "Fig. 1 .",
        "score": 0.9229063987731934,
        "text_preview": "1 Fig. 1.System architecture of the federated learning framework"
      },
      {
        "chunk_index": 5103,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "Fig. 7 :",
        "score": 0.9127904176712036,
        "text_preview": "7 Fig. 7: Taxonomy of intelligent collaboration learning paradigms, including federated learning (FL), distributed deep learning (DDL), edge-cloud model evolution (ECME), and reinforcement learning op"
      },
      {
        "chunk_index": 108033,
        "paper_id": 2240,
        "chunk_idx": 0,
        "title": "PRIVACY-PRESERVING DECENTRALIZED FEDERATED LEARNING VIA EXPLAINABLE ADAPTIVE DIFFERENTIAL PRIVACY",
        "section_head": "Figure 1 :",
        "score": 0.9095838069915771,
        "text_preview": "1 Figure 1: (a) Centralized federated learning framework, and (b) decentralized federated learning with potential data leakage through model inversion and membership inference attacks."
      },
      {
        "chunk_index": 48785,
        "paper_id": 1042,
        "chunk_idx": 2,
        "title": "FeDaL: Federated Dataset Learning for Time Series Foundation Models",
        "section_head": "T-SNE Visualization on Core-set",
        "score": 0.8976956605911255,
        "text_preview": "Full information of baselines can be found in Table 12 . The key federated learning baselines include: ‚Ä¢ FedAvg [53] : A decentralized approach that enables devices to collaboratively learn a shared m"
      },
      {
        "chunk_index": 33599,
        "paper_id": 706,
        "chunk_idx": 2,
        "title": "DFed-SST: Building Semantic-and Structure-aware Topologies for Decentralized Federated Graph Learning",
        "section_head": "Introduction",
        "score": 0.8961778879165649,
        "text_preview": "For instance, in the Internet of Things (IoT) domain, [7] proposed a federated learning framework that integrates blockchain and secure multi-party computation, aiming to realize a decentralized and p"
      },
      {
        "chunk_index": 31329,
        "paper_id": 656,
        "chunk_idx": 0,
        "title": "Decoupled Contrastive Learning for Federated Learning",
        "section_head": "Related Work",
        "score": 0.8959716558456421,
        "text_preview": "In this section, we overview federated learning approaches from two complementary perspectives: (1) local training, which focuses on how clients optimize model parameters under heterogeneity constrain"
      },
      {
        "chunk_index": 4966,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "System Trust",
        "score": 0.8930018544197083,
        "text_preview": "Utilizes secured data to develop intelligent models through federated, distributed, and reinforcement learning."
      },
      {
        "chunk_index": 43251,
        "paper_id": 918,
        "chunk_idx": 0,
        "title": "Enhancing Privacy Preservation and Reducing Analysis Time with Federated Transfer Learning in Digital Twins-based Computed Tomography Scan Analysis",
        "section_head": "Fig. 3 :",
        "score": 0.8901944160461426,
        "text_preview": "3 Fig. 3: Comparison of confusion matrices for Federated Learning, Clustered Federated Learning, and Federated Transfer Learning"
      },
      {
        "chunk_index": 50592,
        "paper_id": 1084,
        "chunk_idx": 0,
        "title": "Federated Nonlinear System Identification",
        "section_head": "Federated Learning",
        "score": 0.8899635076522827,
        "text_preview": "Federated learning is a machine learning paradigm which allows clients to collaboratively train a model without sharing raw data (McMahan et al., 2017) . In principle, each client possesses a local da"
      },
      {
        "chunk_index": 48413,
        "paper_id": 1033,
        "chunk_idx": 0,
        "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning",
        "section_head": "Conclusion",
        "score": 0.8846738934516907,
        "text_preview": "We introduced FedFD, a straightforward framework, to tackle feature distillation using heterogeneous models within federated learning. FedFD serves as a minimal personalization extension for any feder"
      },
      {
        "chunk_index": 2742,
        "paper_id": 51,
        "chunk_idx": 0,
        "title": "A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation",
        "section_head": "Table 5 .",
        "score": 0.8840328454971313,
        "text_preview": "5 ‚Ñì 2 distance comparison for diffusion model generation.In this work, we propose a novel One-Shot Federated Learning (OSFL) framework for medical imaging to enhance privacy protection and training ef"
      },
      {
        "chunk_index": 4076,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Relationship Between FL and RL",
        "score": 0.8827400803565979,
        "text_preview": "The integration of FL and RL creates a synergistic relationship that addresses limitations in both fields. FL contributes its distributed learning framework and privacy-preserving mechanisms, while RL"
      },
      {
        "chunk_index": 49088,
        "paper_id": 1049,
        "chunk_idx": 0,
        "title": "FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization",
        "section_head": "System Overview",
        "score": 0.8826950788497925,
        "text_preview": "FedCVD++ enables N medical institutions (clients) {U 1 , U 2 , . . . , U N } to collaboratively train models while keeping sensitive patient data D i local. The framework features a dual-path architec"
      },
      {
        "chunk_index": 89127,
        "paper_id": 1874,
        "chunk_idx": 3,
        "title": "Mix-modal Federated Learning for MRI Image Segmentation",
        "section_head": "Introduction",
        "score": 0.8820558786392212,
        "text_preview": "This strategy enables stable mix-modal modality fusion and data aggregation across distributed mix-modal clients (hospitals) and generates personalized optimal models for each client. Regarding the mo"
      },
      {
        "chunk_index": 51504,
        "paper_id": 1104,
        "chunk_idx": 0,
        "title": "FedMentor: Domain-Aware Differential Privacy for Heterogeneous Federated LLMs in Mental Health",
        "section_head": "FedMentor framework",
        "score": 0.879296600818634,
        "text_preview": "FedMentor combines Federated Learning (FL) [11] , Low-Rank Adaptation (LoRA) [22] , and domain-aware Differential Privacy (DP) [20, 23, 24, 25] to enable scalable, privacy-preserving finetuning of LLM"
      },
      {
        "chunk_index": 51889,
        "paper_id": 1112,
        "chunk_idx": 0,
        "title": "FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning",
        "section_head": "C. Baselines",
        "score": 0.8769415020942688,
        "text_preview": "Our study compares FedProtoKD to several state-of-the-art federated learning approaches, including various techniques designed to tackle challenges in federated learning settings. ‚Ä¢ FedAvg [1] : An ap"
      },
      {
        "chunk_index": 72471,
        "paper_id": 1545,
        "chunk_idx": 0,
        "title": "Kalman Filter Aided Federated Koopman Learning",
        "section_head": "IV. FEDERATED LEARNING OF KOOPMAN OPERATOR",
        "score": 0.8745763897895813,
        "text_preview": "To achieve collaborative linearization, we first introduce the Deep Koopman Network (DKN), which learns the K and (œÜ, œÜ -1 ) introduced in Section III-B. Then, we propose a framework wherein federated"
      },
      {
        "chunk_index": 91903,
        "paper_id": 1935,
        "chunk_idx": 0,
        "title": "MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping",
        "section_head": "Fig. 1 :",
        "score": 0.8738740682601929,
        "text_preview": "1 Fig. 1: An overview of the federated learning pipeline."
      },
      {
        "chunk_index": 19922,
        "paper_id": 404,
        "chunk_idx": 0,
        "title": "Blockchain-Enabled Federated Learning",
        "section_head": "Proof of Federated Learning (PoFL)",
        "score": 0.8719387054443359,
        "text_preview": "Proof of Federated Learning ingeniously re-purposes the computational work required for blockchain consensus to perform federated learning training, making consensus work directly productive rather th"
      }
    ]
  },
  {
    "query_id": 30,
    "query_text": "framework rapidly developing",
    "source": "title",
    "source_value": "A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 81173,
        "paper_id": 1712,
        "chunk_idx": 1,
        "title": "LLM-BL E N D E R: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion",
        "section_head": "Conclusion & Future Directions",
        "score": 0.9549959897994995,
        "text_preview": "‚Ä¢ Toolkit: By open-sourcing our framework, we aim to make it easier for others to leverage our approach, enabling the development of more advanced AI systems that achieve robustness, generalization, a"
      },
      {
        "chunk_index": 41147,
        "paper_id": 867,
        "chunk_idx": 1,
        "title": "Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper",
        "section_head": "V2A generation",
        "score": 0.9372044205665588,
        "text_preview": "Autoregressive models like V-AURA [41] have also made significant strides in audio quality and temporal alignment. Seeing-and-Hearing [46] takes a unique approach by leveraging a pre-trained ImageBind"
      },
      {
        "chunk_index": 97333,
        "paper_id": 2051,
        "chunk_idx": 0,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "Conclusion:",
        "score": 0.9337178468704224,
        "text_preview": "The integration of large language models into tool agents is a rapidly evolving field with significant implications for scientific discovery. These models are enhancing capabilities across various dom"
      },
      {
        "chunk_index": 101944,
        "paper_id": 2119,
        "chunk_idx": 2,
        "title": "orb-QFL: Orbital Quantum Federated Learning",
        "section_head": "I. INTRODUCTION",
        "score": 0.9283432364463806,
        "text_preview": "With numerous works in the field of QFL [7] , [8] , [9] and its promising computational capacities and improved optimization, it is poised perfectly in distributed quantum machine networks such as SAT"
      },
      {
        "chunk_index": 88355,
        "paper_id": 1858,
        "chunk_idx": 0,
        "title": "MiniMax-01: Scaling Foundation Models with Lightning Attention MiniMax",
        "section_head": "Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction",
        "score": 0.9248627424240112,
        "text_preview": "MiniMax-Text-01 Summary of the Paper: \"Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction\" 1. Introduction and Motivation The rapid advancement of large language models (LLM"
      },
      {
        "chunk_index": 15618,
        "paper_id": 313,
        "chunk_idx": 0,
        "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs",
        "section_head": "B. Automated Game Design and Procedural Content Generation (PCG)",
        "score": 0.9244457483291626,
        "text_preview": "AI-driven procedural content generation (PCG) has been widely studied, with research focusing on generating levels, assets, and narratives using machine learning techniques. The scoping review by [1] "
      },
      {
        "chunk_index": 142598,
        "paper_id": 2942,
        "chunk_idx": 0,
        "title": "TRAINING-FREE MULTIMODAL LARGE LANGUAGE MODEL ORCHESTRATION",
        "section_head": "Introduction",
        "score": 0.9226941466331482,
        "text_preview": "Recent advances in Large Language Models (LLMs) [1, 2, 3, 4] have enabled increasingly sophisticated multimodal capabilities. The release of GPT-4o [5] has fundamentally transformed the landscape of m"
      },
      {
        "chunk_index": 59799,
        "paper_id": 1275,
        "chunk_idx": 1,
        "title": "Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model",
        "section_head": "Gesture",
        "score": 0.9226833581924438,
        "text_preview": "Early efforts to integrate GenAI into wireless sensing pipelines have shown encouraging results across various downstream tasks. These studies demonstrate that the combination of generative models and"
      },
      {
        "chunk_index": 2363,
        "paper_id": 41,
        "chunk_idx": 0,
        "title": "A Language-Driven Framework for Improving Personalized Recommendations: Merging LLMs with Traditional Algorithms",
        "section_head": "RELATED WORK",
        "score": 0.9213622212409973,
        "text_preview": "Recent advancements in Large Language Models (LLMs) have created new opportunities for enhancing recommendation systems. This section reviews relevant literature on LLM integration with traditional re"
      },
      {
        "chunk_index": 53360,
        "paper_id": 1145,
        "chunk_idx": 1,
        "title": "Filling the Gaps: A Multitask Hybrid Multiscale Generative Framework for Missing Modality in Remote Sensing Semantic Segmentation",
        "section_head": "Missing Modality in Remote Sensing.",
        "score": 0.9210729598999023,
        "text_preview": "Modern approaches such as SMIL [18] have shown that utilizing generative models' strengths can significantly enhance model robustness against severe modality scarcity. However, current generative appr"
      },
      {
        "chunk_index": 127678,
        "paper_id": 2669,
        "chunk_idx": 0,
        "title": "SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection",
        "section_head": "Introduction",
        "score": 0.9199185371398926,
        "text_preview": "The rapid advancement of generative models enables synthetic realistic facial images [20, 39, 35] , and they have significantly enhanced face manipulation techniques, allowing for the replacement of f"
      },
      {
        "chunk_index": 9446,
        "paper_id": 180,
        "chunk_idx": 0,
        "title": "AlignedGen: Aligning Style Across Generated Images",
        "section_head": "Attention Control in Diffusion Models",
        "score": 0.9183110594749451,
        "text_preview": "Controlling the generative process of diffusion models [15, 28, 38, 34, 31, 8 , 1, 45] via attention manipulation [4, 26, 23, 21, 46, 27] has become a prominent research direction. Pioneering works li"
      },
      {
        "chunk_index": 84416,
        "paper_id": 1776,
        "chunk_idx": 1,
        "title": "MAPEX: A MULTI-AGENT PIPELINE FOR KEYPHRASE EXTRACTION",
        "section_head": "INTRODUCTION",
        "score": 0.9169439673423767,
        "text_preview": "PromptRank [12] introduces a prompt-based paradigm for PLMs which ranks candidates based on their generation probability within a specific prompt template. With the rise of large language models (LLMs"
      },
      {
        "chunk_index": 716,
        "paper_id": 14,
        "chunk_idx": 1,
        "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
        "section_head": "Discussion and Limitations",
        "score": 0.916588306427002,
        "text_preview": "SynTra introduces synthetic tasks for mitigating hallucinations in abstractive summarization, offering scalability but raising questions about effectiveness compared to human feedback. The development"
      },
      {
        "chunk_index": 5815,
        "paper_id": 102,
        "chunk_idx": 0,
        "title": "AbideGym: Turning Static RL Worlds into Adaptive Challenges",
        "section_head": "Related Work",
        "score": 0.9162876605987549,
        "text_preview": "The MiniGrid environment [12] has become a widely used evaluation testbed in reinforcement learning (RL) research due to its lightweight and minimalistic design, which enables rapid prototyping and em"
      },
      {
        "chunk_index": 126871,
        "paper_id": 2646,
        "chunk_idx": 0,
        "title": "SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching",
        "section_head": "Speculative Sampling",
        "score": 0.9145635366439819,
        "text_preview": "Speculative decoding has emerged as an effective approach for accelerating large language models (LLMs) while preserving output quality. The core idea, introduced by Leviathan et al. [18] , employs a "
      },
      {
        "chunk_index": 20775,
        "paper_id": 422,
        "chunk_idx": 0,
        "title": "Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges",
        "section_head": "Conclusion",
        "score": 0.9135208129882812,
        "text_preview": "In this position paper, we examined the emerging convergence of federated learning and foundation models within the education domain, framing the concept of multi-modal, multi-task federated foundatio"
      },
      {
        "chunk_index": 10646,
        "paper_id": 206,
        "chunk_idx": 2,
        "title": "An Empirical Study of Knowledge Distillation for Code Understanding Tasks",
        "section_head": "Implications of Study",
        "score": 0.913352370262146,
        "text_preview": "Furthermore, it is crucial to develop novel KD methods applicable to a broader range of software engineering tasks. (3) While LLMs have been widely adopted for code intelligence tasks, their unified g"
      },
      {
        "chunk_index": 150017,
        "paper_id": 3083,
        "chunk_idx": 2,
        "title": "VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception",
        "section_head": "Related work",
        "score": 0.9120762348175049,
        "text_preview": "Techniques such as Best-of-N [20] , guided beam search [62] , and Monte Carlo Tree Search [14] have achieved significant success in LLMs. Concerning MLLMs, test-time scaling has yet to be thoroughly e"
      },
      {
        "chunk_index": 29390,
        "paper_id": 606,
        "chunk_idx": 1,
        "title": "Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for Sparse-View CT",
        "section_head": "I. INTRODUCTION",
        "score": 0.9080173373222351,
        "text_preview": "Consequently, developing robust reconstruction algorithms capable of recovering high-quality images from sparse-view measurements is critical to fully realize the clinical potential of SVCT and to enh"
      }
    ]
  },
  {
    "query_id": 31,
    "query_text": "introduction",
    "source": "section_head",
    "source_value": "I. INTRODUCTION",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 28712,
        "paper_id": 592,
        "chunk_idx": 0,
        "title": "ConViS-Bench: Estimating Video Similarity Through Semantic Concepts",
        "section_head": "Table 5 :",
        "score": 0.757009744644165,
        "text_preview": "5 Scoring guidelines provided in the annotation interface."
      },
      {
        "chunk_index": 92416,
        "paper_id": 1949,
        "chunk_idx": 0,
        "title": "MultiGen: Child-Friendly Multilingual Speech Generator with LLMs",
        "section_head": "Experiments",
        "score": 0.7415798902511597,
        "text_preview": "In this section, we describe the experimental datasets, baselines and experimental setups."
      },
      {
        "chunk_index": 147148,
        "paper_id": 3029,
        "chunk_idx": 0,
        "title": "UnIVAL: Unified Model for Image, Video, Audio and Language Tasks",
        "section_head": "Figure 8 :",
        "score": 0.7344774007797241,
        "text_preview": "8 Figure 8: Limitations of UnIVAL in following user instructions. UnIVAL is unable to follow complex instructions."
      },
      {
        "chunk_index": 46951,
        "paper_id": 1004,
        "chunk_idx": 0,
        "title": "Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling",
        "section_head": "Feature",
        "score": 0.7130067944526672,
        "text_preview": "Type Definition Example Entities' Span"
      },
      {
        "chunk_index": 6527,
        "paper_id": 119,
        "chunk_idx": 1,
        "title": "AD-DROP: Attribution-Driven Dropout for Robust Language Model Fine-Tuning",
        "section_head": "Conclusion",
        "score": 0.706863284111023,
        "text_preview": "(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] Our contributions and scope are accurately reflected in the abstract and intr"
      },
      {
        "chunk_index": 133685,
        "paper_id": 2769,
        "chunk_idx": 0,
        "title": "TableLlama: Towards Open Large Generalist Models for Tables",
        "section_head": "### Input:",
        "score": 0.7022926807403564,
        "text_preview": "[TLE] The table caption is 2010-11 rangers f.c. season. [SEED] The seed table header is <competition>."
      },
      {
        "chunk_index": 93554,
        "paper_id": 1973,
        "chunk_idx": 0,
        "title": "MULTITASK PROMPTED TRAINING ENABLES ZERO-SHOT TASK GENERALIZATION",
        "section_head": "Table 4 :",
        "score": 0.7002118825912476,
        "text_preview": "4 Accuracies on WinoBias coreference task. 3 76.4 2.8 79.3 75.0 4.3 T0+ Type 1 66.6 57.2 Type 2 77.7 73.4 9.4 4.3 71.5 62.6 86.1 81.3 8.8 4.8 T0++ Type 1 63.8 55.9 Type 2 66.8 63.0 7.9 3.9 72.7 63.4 7"
      },
      {
        "chunk_index": 136901,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.698699414730072,
        "text_preview": "Describe the landmark in the image. ."
      },
      {
        "chunk_index": 136899,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.698699414730072,
        "text_preview": "Describe the landmark in the image. ."
      },
      {
        "chunk_index": 136903,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.6986993551254272,
        "text_preview": "Describe the landmark in the image. ."
      },
      {
        "chunk_index": 136890,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Landmark Recognition and Description Prompt:",
        "score": 0.6986993551254272,
        "text_preview": "Describe the landmark in the image. ."
      },
      {
        "chunk_index": 136892,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.6986993551254272,
        "text_preview": "Describe the landmark in the image."
      },
      {
        "chunk_index": 136894,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.6986993551254272,
        "text_preview": "Describe the landmark in the image. ."
      },
      {
        "chunk_index": 136897,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Landmark Recognition and Description Prompt:",
        "score": 0.6986993551254272,
        "text_preview": "Describe the landmark in the image. ."
      },
      {
        "chunk_index": 136888,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.6986993551254272,
        "text_preview": "Describe the landmark in the image. ."
      },
      {
        "chunk_index": 40204,
        "paper_id": 850,
        "chunk_idx": 1,
        "title": "Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning",
        "section_head": "B. Temporal Correlation-Enhanced Pruning (TCEP)",
        "score": 0.6847732067108154,
        "text_preview": "Method Type Publication F Human3.6M (DET) Human3.6M (GT) MACs (G) Params (M) Detector MPJPE ‚Üì P-MPJPE ‚Üì Detector MPJPE ‚Üì TCN [60] CNN CVPR'19 243 CPN 46.8 36.5 GT 37.8 --GLA-GCN [61] GCN ICCV'23 243 C"
      },
      {
        "chunk_index": 73485,
        "paper_id": 1565,
        "chunk_idx": 0,
        "title": "KuBERT: Central Kurdish BERT Model and Its Application for Sentiment Analysis",
        "section_head": "Table 3 :",
        "score": 0.6819904446601868,
        "text_preview": "3 Muhammad Azizi and Aram Rafeq Text Corpus 2 Source Number of tokens Wikipedia 13.5M Wishe Website 11M Speemedia Website 6.5M Kurdiu Website 19M Dengiamerika Website 2M Chawg Website 8M Sum 60M"
      },
      {
        "chunk_index": 136921,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Sec. 4.1 Image Description on Diverse Domains",
        "score": 0.6797614097595215,
        "text_preview": "Prompt: Describe the logos in details"
      },
      {
        "chunk_index": 96827,
        "paper_id": 2042,
        "chunk_idx": 0,
        "title": "NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations",
        "section_head": ".",
        "score": 0.6758198738098145,
        "text_preview": "Prompt for Paralinguistic Tagging: <audio> Given an audio clip, identify the paralinguistic event from the following EVENT LABEL SET: {[Breathing], [Crying], [Laughter], ..., [Shh]} MUST follow this t"
      },
      {
        "chunk_index": 112549,
        "paper_id": 2344,
        "chunk_idx": 2,
        "title": "Recurrent Memory Transformer",
        "section_head": "Conclusions",
        "score": 0.6705653071403503,
        "text_preview": "(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] (b) Did you describe the limitations of your work? [Yes] We mention training "
      }
    ]
  },
  {
    "query_id": 32,
    "query_text": "robust aggregation federated learning",
    "source": "section_head",
    "source_value": "A. Robust Aggregation in Federated Learning",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 108033,
        "paper_id": 2240,
        "chunk_idx": 0,
        "title": "PRIVACY-PRESERVING DECENTRALIZED FEDERATED LEARNING VIA EXPLAINABLE ADAPTIVE DIFFERENTIAL PRIVACY",
        "section_head": "Figure 1 :",
        "score": 0.9647916555404663,
        "text_preview": "1 Figure 1: (a) Centralized federated learning framework, and (b) decentralized federated learning with potential data leakage through model inversion and membership inference attacks."
      },
      {
        "chunk_index": 8980,
        "paper_id": 172,
        "chunk_idx": 0,
        "title": "AI-IN-THE-LOOP: PRIVACY PRESERVING REAL-TIME SCAM DETECTION AND CONVERSATIONAL SCAMBAITING BY LEVERAGING LLMS AND FEDERATED LEARNING",
        "section_head": "Figure 3 :",
        "score": 0.9504609704017639,
        "text_preview": "3 Figure 3: Federated Learning architecture for decentralized, privacy-preserving scam model training."
      },
      {
        "chunk_index": 97061,
        "paper_id": 2048,
        "chunk_idx": 0,
        "title": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
        "section_head": "A.4 Federated Methods",
        "score": 0.9501965641975403,
        "text_preview": "Federated learning (FL) algorithms aim to train a robust global model by aggregating locally computed updates from distributed clients, with a strong emphasis on data privacy and system efficiency."
      },
      {
        "chunk_index": 2934,
        "paper_id": 55,
        "chunk_idx": 0,
        "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption",
        "section_head": "Fig. 2 .",
        "score": 0.9430884122848511,
        "text_preview": "2 Fig. 2. FL Framework with HHE for Secure Model Aggregation"
      },
      {
        "chunk_index": 52434,
        "paper_id": 1123,
        "chunk_idx": 0,
        "title": "FedThief: Harming Others to Benefit Oneself in Self-Centered Federated Learning",
        "section_head": "Fig. 1 .",
        "score": 0.9418158531188965,
        "text_preview": "1 Fig. 1. Framework of Self-Centered Federated Learning. (A) Ideal State of Federated Learning: Multiple clients sharing corresponding feedback collectively train a high-performance model; (B) Federat"
      },
      {
        "chunk_index": 100632,
        "paper_id": 2106,
        "chunk_idx": 0,
        "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting",
        "section_head": "Fig. 1 :",
        "score": 0.9412734508514404,
        "text_preview": "1 Fig. 1: Federated learning architecture for medical applications: hospitals securely exchange gradient updates while the OptiGradTrust server performs trust-aware aggregation."
      },
      {
        "chunk_index": 64417,
        "paper_id": 1377,
        "chunk_idx": 0,
        "title": "HLF-FSL: A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric",
        "section_head": "4 ). 6 )Fig. 1 :",
        "score": 0.9385644197463989,
        "text_preview": "461 Fig. 1: Overview of distributed learning architectures: (i) Federated Learning, where clients share model updates with a central aggregator; (ii) Split Learning, where the model is split and clien"
      },
      {
        "chunk_index": 51957,
        "paper_id": 1114,
        "chunk_idx": 0,
        "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model",
        "section_head": "Algorithm 1 3 :",
        "score": 0.9377725720405579,
        "text_preview": "13 FedAvg: Communication-efficient learning of deep networks from decentralized data 1: Initialize global model weights Œ∏ 0 2: for each round r = 1, 2, . . . , R do Server selects of clients S r ‚äÜ {1,"
      },
      {
        "chunk_index": 43476,
        "paper_id": 924,
        "chunk_idx": 0,
        "title": "Enhancing the Effectiveness and Durability of Backdoor Attacks in Federated Learning through Maximizing Task Distinction",
        "section_head": "I. INTRODUCTION",
        "score": 0.9293968677520752,
        "text_preview": "F EDERATED learning (FL) [1] has emerged as a promising paradigm for privacy-preserving machine learning [2] - [4] , enabling a central model to be collaboratively trained across distributed clients w"
      },
      {
        "chunk_index": 123607,
        "paper_id": 2577,
        "chunk_idx": 0,
        "title": "SimDeep: Federated 3D Indoor Localization via Similarity-Aware Aggregation",
        "section_head": "F. Decentralized Collaborative Learning Mechanism",
        "score": 0.9259932637214661,
        "text_preview": "SimDeep's decentralized collaborative learning mechanism ensures high model performance across clients, even with non-IID distributions. Unlike traditional federated learning, which averages all clien"
      },
      {
        "chunk_index": 5082,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "B. Privacy-Preserving Techniques",
        "score": 0.9221518635749817,
        "text_preview": "Protecting user data within distributed collaborative systems is paramount. Four prominent techniques address privacy concerns: federated learning, differential privacy, homomorphic encryption, and se"
      },
      {
        "chunk_index": 5029,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "C. Privacy-Preserving Techniques",
        "score": 0.9218728542327881,
        "text_preview": "Protecting user data within distributed collaborative systems requires comprehensive privacy-preserving techniques including federated learning, differential privacy, homomorphic encryption, and secur"
      },
      {
        "chunk_index": 2977,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "Fig. 3 :",
        "score": 0.9213910102844238,
        "text_preview": "3 Fig. 3: Training workflow of our framework demonstrating local quantum-enhanced computations, federated aggregation, and secure update exchanges."
      },
      {
        "chunk_index": 157143,
        "paper_id": 3220,
        "chunk_idx": 0,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "E. Federated Learning for Privacy-Preserving Deepfake Prevention",
        "score": 0.9212836027145386,
        "text_preview": "As deepfake techniques continued to evolve, traditional centralized AI-based defenses faced data privacy, scalability, and adaptability challenges. Federated learning (FL) [411] offers a decentralized"
      },
      {
        "chunk_index": 51504,
        "paper_id": 1104,
        "chunk_idx": 0,
        "title": "FedMentor: Domain-Aware Differential Privacy for Heterogeneous Federated LLMs in Mental Health",
        "section_head": "FedMentor framework",
        "score": 0.9198072552680969,
        "text_preview": "FedMentor combines Federated Learning (FL) [11] , Low-Rank Adaptation (LoRA) [22] , and domain-aware Differential Privacy (DP) [20, 23, 24, 25] to enable scalable, privacy-preserving finetuning of LLM"
      },
      {
        "chunk_index": 99347,
        "paper_id": 2084,
        "chunk_idx": 0,
        "title": "On the Out-of-Distribution Backdoor Attack for Federated Learning",
        "section_head": "Introduction",
        "score": 0.9196885824203491,
        "text_preview": "Federated learning (FL) is a privacy-preserving training paradigm that enables collaborative machine learning model training across distributed clients [23] . In a typical FL system, a central server "
      },
      {
        "chunk_index": 2975,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "Fig. 1 :",
        "score": 0.9191082715988159,
        "text_preview": "1 Fig. 1: Overview of FL, each participating organization trains a local model on private data, while a central federated server aggregates these local updates to construct a collaborative global mode"
      },
      {
        "chunk_index": 120423,
        "paper_id": 2509,
        "chunk_idx": 0,
        "title": "Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs",
        "section_head": "Fig. 2 :",
        "score": 0.9185521006584167,
        "text_preview": "2 Fig.2: zkFed model with ZKPs for secure FL. Users encrypt local model weights œâi before sending them to a UAV aggregator, which computes the encrypted sum Enc(œâ) via homomorphic encryption, ensuring"
      },
      {
        "chunk_index": 11736,
        "paper_id": 229,
        "chunk_idx": 0,
        "title": "Anomaly Detection in Electric Vehicle Charging Stations Using Federated Learning",
        "section_head": "Fig. 1 :",
        "score": 0.9165900349617004,
        "text_preview": "1 Fig. 1: Federated Learning system architecture using FedAvg (Œ≤ = 0, Œ∑ = 1) and FedAvg with Server Momentum (Œ≤ > 0)."
      },
      {
        "chunk_index": 54347,
        "paper_id": 1168,
        "chunk_idx": 0,
        "title": "FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks",
        "section_head": "A. Poisoning attacks in FL",
        "score": 0.9165496826171875,
        "text_preview": "FL enables collaborative model training across multiple decentralized clients while preserving data privacy, as originally introduced in [1] . A typical FL setting comprises a set of clients and an ag"
      }
    ]
  },
  {
    "query_id": 33,
    "query_text": "incentive mechanisms",
    "source": "section_head",
    "source_value": "B. Incentive Mechanisms for FL",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 5077,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "A. Security Mechanisms and Solutions",
        "score": 0.9069569110870361,
        "text_preview": "Protecting collaborative intelligence paradigms against various threats requires robust security mechanisms. We explore three key security solutions: encryption and authentication, intrusion detection"
      },
      {
        "chunk_index": 100696,
        "paper_id": 2107,
        "chunk_idx": 0,
        "title": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity",
        "section_head": "Fig. 5 .",
        "score": 0.8887823224067688,
        "text_preview": "5 Fig. 5. Adaptive batch-size control mechanisms."
      },
      {
        "chunk_index": 5028,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "B. Security Mechanisms and Solutions",
        "score": 0.8848633766174316,
        "text_preview": "Protecting collaborative intelligence paradigms against various threats requires robust security mechanisms encompassing encryption and authentication, intrusion detection and prevention, and blockcha"
      },
      {
        "chunk_index": 16105,
        "paper_id": 323,
        "chunk_idx": 0,
        "title": "BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning",
        "section_head": "Data-Based Backdoor Attacks",
        "score": 0.8675297498703003,
        "text_preview": "Fixed-Pattern [2, 8, 11, 20] Dynamic-Pattern [41, 24] Distributed-Pattern [38, 19] Edge-Case [33] Model-Based Poisoning Attacks Durability Enhancement [45, 9] Defense-Evasion [2, 33, 3, 14, 47] Backdo"
      },
      {
        "chunk_index": 5027,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "3) Data Integrity and Authentication:",
        "score": 0.8657572269439697,
        "text_preview": "Trust establishment requires comprehensive verification mechanisms to ensure data authenticity and prevent tampering. Multi-layered authentication protocols safeguard against unauthorized modification"
      },
      {
        "chunk_index": 16133,
        "paper_id": 323,
        "chunk_idx": 0,
        "title": "BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning",
        "section_head": "Table 2 :",
        "score": 0.8535544276237488,
        "text_preview": "2 Performance of Robust Aggregation Defenses on Random-Sampling Multi-shot Attacks."
      },
      {
        "chunk_index": 124810,
        "paper_id": 2603,
        "chunk_idx": 0,
        "title": "SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus",
        "section_head": "Fig. 2 .",
        "score": 0.851250946521759,
        "text_preview": "2 Fig. 2. Blockchain based UAV security system for NTNs, showing the integration of ground users, UAVslockchain for secure trust evaluation, and application scenario."
      },
      {
        "chunk_index": 5024,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "A. Security Threats and Vulnerabilities",
        "score": 0.8473878502845764,
        "text_preview": "Distributed collaborative architectures introduce expanded attack surfaces that must be addressed to ensure robust operation. Sensitive data across multiple layers risks unauthorized access and interc"
      },
      {
        "chunk_index": 10,
        "paper_id": 1,
        "chunk_idx": 0,
        "title": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning",
        "section_head": "C. Mechanism Properties",
        "score": 0.8419398069381714,
        "text_preview": "A robust mechanism must make it profitable for honest players to participate and unprofitable for malicious players to attack. These correspond to the game-theoretic properties of Individual Rationali"
      },
      {
        "chunk_index": 19962,
        "paper_id": 404,
        "chunk_idx": 0,
        "title": "Blockchain-Enabled Federated Learning",
        "section_head": "Figure 2 .",
        "score": 0.8348270654678345,
        "text_preview": "2 Figure 2. Centralized BCFL architecture showing traditional federated learning coordination enhanced with blockchain verification and smart contract automation. The central aggregator coordinates tr"
      },
      {
        "chunk_index": 63216,
        "paper_id": 1348,
        "chunk_idx": 2,
        "title": "Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning",
        "section_head": "Related Work",
        "score": 0.8293808102607727,
        "text_preview": "More specifically, FLAME combines HDBSCAN angle-based clustering, a defense strong against large angular magnitude attacks, with clipping, a defense effective against large l 2 -norm attacks, and DP-n"
      },
      {
        "chunk_index": 67952,
        "paper_id": 1448,
        "chunk_idx": 0,
        "title": "IMPROVING GENERALIZABILITY AND UNDETECTABIL-ITY FOR TARGETED ADVERSARIAL ATTACKS ON MUL-TIMODAL PRE-TRAINED MODELS",
        "section_head": "Table 7 :",
        "score": 0.823670506477356,
        "text_preview": "7 R@1 ASR (%) under three defenses: Adversarial training (AT), data augmentation (DA) and adversarial purification (AP). Method AT Defense DA AP Illusion Attack 62.31 0.24 12.44 0.13 9.83 0.07 PTA (Ou"
      },
      {
        "chunk_index": 37838,
        "paper_id": 799,
        "chunk_idx": 0,
        "title": "DRAG: Data Reconstruction Attack using Guided Diffusion",
        "section_head": "Figure 1 :",
        "score": 0.8131615519523621,
        "text_preview": "1 Figure 1: Privacy threats in split inference."
      },
      {
        "chunk_index": 15851,
        "paper_id": 318,
        "chunk_idx": 0,
        "title": "Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools",
        "section_head": "System Prompt:",
        "score": 0.8124282360076904,
        "text_preview": "You are a security analyst evaluating AI system behavior ‚Ü©‚Üí for potential manipulation or malicious influence by ‚Ü©‚Üí comparing tool responses."
      },
      {
        "chunk_index": 82501,
        "paper_id": 1734,
        "chunk_idx": 0,
        "title": "LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning for Log Analysis Tasks",
        "section_head": "Table 1 .",
        "score": 0.8117351531982422,
        "text_preview": "1 Statistics of the dataset used for reasoning enhancement. Stage Task Data Source Domain # SFT NUM # DPO NUM Question Answering Handbook Huawei 400 - Stage1 Anomaly Detection LogPrompt BGL & Spirit 3"
      },
      {
        "chunk_index": 48890,
        "paper_id": 1044,
        "chunk_idx": 0,
        "title": "FedBAP: Backdoor Defense via Benign Adversarial Perturbation in Federated Learning",
        "section_head": "Figure 5 :",
        "score": 0.8109496831893921,
        "text_preview": "5 Figure 5: Impact of the malicious clients proportion on different defenses under A3FL attack."
      },
      {
        "chunk_index": 121175,
        "paper_id": 2524,
        "chunk_idx": 0,
        "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
        "section_head": "Fig. 6 :",
        "score": 0.81076580286026,
        "text_preview": "6 Fig. 6: Learning accuracy of FLSS with SOTA defenses under label-flipping attacks."
      },
      {
        "chunk_index": 55783,
        "paper_id": 1195,
        "chunk_idx": 0,
        "title": "FLSIM: A MODULAR AND LIBRARY-AGNOSTIC SIMULATION FRAMEWORK FOR FEDERATED LEARNING",
        "section_head": "Figure 10 :",
        "score": 0.804728090763092,
        "text_preview": "10 Figure 10: Malicious Worker Scenario (M = Malicious Worker, H = Honest Worker)"
      },
      {
        "chunk_index": 82146,
        "paper_id": 1729,
        "chunk_idx": 0,
        "title": "Local and Central Differential Privacy for Robustness and Privacy in Federated Learning *",
        "section_head": "Table 4 :",
        "score": 0.8044376373291016,
        "text_preview": "4 Main Task (Gender Classification) Accuracy with No Defense, LDP, and CDP (property inference attack setting). #Participants No Defense LDP CDP ( = 10.7) ( = 8.1) 5 0.97 0.95 0.94 10 0.87 0.86 0.85 1"
      },
      {
        "chunk_index": 18424,
        "paper_id": 374,
        "chunk_idx": 1,
        "title": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation",
        "section_head": "Harmfulness Evaluator",
        "score": 0.8020046353340149,
        "text_preview": "Using a 0-5 scale: 0 = factually baseless content ( e.g., chemically invalid poison recipes); 5 = authoritative, accurate details ( e.g., complete phishing techniques). Criteria adapt dynamically to s"
      }
    ]
  },
  {
    "query_id": 34,
    "query_text": "system model",
    "source": "section_head",
    "source_value": "A. System Model",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 40495,
        "paper_id": 854,
        "chunk_idx": 0,
        "title": "Efficient Federated Learning with Timely Update Dissemination",
        "section_head": "Fig. 1 :",
        "score": 0.9618521332740784,
        "text_preview": "1 Fig. 1: The system model of FedASMU."
      },
      {
        "chunk_index": 134227,
        "paper_id": 2780,
        "chunk_idx": 7,
        "title": "TAMIL-LLAMA: A NEW TAMIL LANGUAGE MODEL BASED ON LLAMA 2",
        "section_head": "Conclusion",
        "score": 0.9057267308235168,
        "text_preview": "‡ÆÖ‡Æ£‡Æø-‡ÆØ‡Æø‡Æ© ‡Øç ‡Øá‡Æµ‡Æï‡Æ™ ‡Øç ‡Æ™‡Æ® ‡Øç ‡Æ§‡ØÅ‡Æµ‡ØÄ‡Æö‡Øç ‡Æö‡ØÅ, ‡Øá‡Æ™‡Æü ‡Øç ‡Æü‡Æø‡Æô ‡Øç ‡ÆÆ‡Æ± ‡Øç ‡Æ±‡ØÅ‡ÆÆ ‡Øç ‡ÆÉ‡Æ™‡ØÄ‡Æ≤ ‡Øç ‡Æü‡Æø‡Æô ‡Øç ‡ÆÜ‡Æï‡Æø‡ÆØ‡Æµ‡Æ± ‡Øç -‡Æ± ‡Æ© ‡Øç ‡Æµ‡Æ≤‡ØÅ‡Æµ‡Ææ‡Æ© ‡Æï‡Æ≤‡Øà‡Æµ‡ÆØ‡Ææ‡Æ©‡Æ§‡ØÅ ‡ÆÖ‡Æµ‡Æ∞‡Øç ‡Æï‡Æ≥‡Æø‡Æ© ‡Øç ‡Øá‡Æ™‡Ææ‡Æü ‡Øç ‡Æü‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç -‡Æï‡Æ≥‡Æø‡Æ© ‡Øç ‡Æ™‡Æ≤ ‡Øá‡ÆÆ‡Ææ‡Æö‡ÆÆ‡Ææ‡Æ© ‡ÆÜ‡Æü ‡Øç ‡Æü‡Æô ‡Øç ‡Æï‡Æ≥‡ØÅ‡Æï ‡Øç ‡Æï‡ØÅ ‡Æµ‡Æ¥ ‡Æµ‡Æï‡ØÅ‡Æ§ ‡Øç ‡Æ§‡Æ§‡ØÅ, ‡Øá‡ÆÆ‡Æ≤‡ØÅ‡ÆÆ ‡Øç ‡ÆÖ‡Æµ‡Æ∞‡Øç ‡Æï‡Æ≥ ‡Øç"
      },
      {
        "chunk_index": 40410,
        "paper_id": 853,
        "chunk_idx": 0,
        "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout",
        "section_head": "Fig. 1 .",
        "score": 0.8552384376525879,
        "text_preview": "1 Fig. 1. The system model of FedDHAD."
      },
      {
        "chunk_index": 90701,
        "paper_id": 1912,
        "chunk_idx": 0,
        "title": "ModShift: Model Privacy via Designed Shifts",
        "section_head": "Fig. 1 .",
        "score": 0.8280789852142334,
        "text_preview": "1 Fig. 1. System model for distributed optimization, model shift and eavesdropping."
      },
      {
        "chunk_index": 75612,
        "paper_id": 1597,
        "chunk_idx": 0,
        "title": "Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation",
        "section_head": "Fig. 4 :Fig. 5 :",
        "score": 0.8079888224601746,
        "text_preview": "45 Fig. 4: Rule-based system vs. LLMs for the prediction of chemical product(s) by using different reactant(s)"
      },
      {
        "chunk_index": 10981,
        "paper_id": 213,
        "chunk_idx": 0,
        "title": "An LLM-based Agentic Framework for Accessible Network Control",
        "section_head": "Figure 6 :",
        "score": 0.8042131662368774,
        "text_preview": "6 Figure 6: Latency analysis of system components including re-verification."
      },
      {
        "chunk_index": 55774,
        "paper_id": 1195,
        "chunk_idx": 0,
        "title": "FLSIM: A MODULAR AND LIBRARY-AGNOSTIC SIMULATION FRAMEWORK FOR FEDERATED LEARNING",
        "section_head": "Figure 1 :",
        "score": 0.804067850112915,
        "text_preview": "1 Figure 1: System Workflow of FLsim"
      },
      {
        "chunk_index": 10983,
        "paper_id": 213,
        "chunk_idx": 0,
        "title": "An LLM-based Agentic Framework for Accessible Network Control",
        "section_head": "Figure 8 :",
        "score": 0.7941170930862427,
        "text_preview": "8 Figure 8: System and user prompt for feedback interface tailored to verification."
      },
      {
        "chunk_index": 141931,
        "paper_id": 2924,
        "chunk_idx": 0,
        "title": "Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification",
        "section_head": "Figure 8 .",
        "score": 0.7932385802268982,
        "text_preview": "8 Figure 8. Visualization of DreamBooth's outputs after the P-C workflow."
      },
      {
        "chunk_index": 11315,
        "paper_id": 219,
        "chunk_idx": 0,
        "title": "Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting",
        "section_head": "}Figure 18 .",
        "score": 0.7886695861816406,
        "text_preview": "18 Figure 18. System prompt for Additive Evaluation."
      },
      {
        "chunk_index": 1692,
        "paper_id": 30,
        "chunk_idx": 0,
        "title": "A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks",
        "section_head": "Fig. 1 :",
        "score": 0.7801604270935059,
        "text_preview": "1 Fig. 1: Rapid response system architecture showing the endto-end flow from threat intelligence ingestion to production deployment. Raw intelligence feeds the Threat Intelligence Platform, which gene"
      },
      {
        "chunk_index": 109677,
        "paper_id": 2276,
        "chunk_idx": 0,
        "title": "Put Teacher in Student's Shoes: Cross-Distillation for Ultra-compact Model Compression Framework",
        "section_head": "T in y B E R T 4 A L B E R T 4 T in y B E R T 2 A L B E R T 2 C r o s s K D -T P E I-B E",
        "score": 0.7757562398910522,
        "text_preview": "R T 0 5 10 15 20 25 30 35 40 45 50 Storage(MB) (a) Model storage."
      },
      {
        "chunk_index": 70118,
        "paper_id": 1495,
        "chunk_idx": 0,
        "title": "Intelligent Healthcare Imaging Platform: An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation",
        "section_head": "AI-Based Analysis and Coordinate Validation",
        "score": 0.7739318609237671,
        "text_preview": "The enhanced AI-powered medical image analysis system adopts a modular architecture that ensures scalability, maintainability, and clinical applicability while operating through a sequential processin"
      },
      {
        "chunk_index": 56508,
        "paper_id": 1214,
        "chunk_idx": 0,
        "title": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach",
        "section_head": "Figure 3 :",
        "score": 0.7709656953811646,
        "text_preview": "3 Figure 3: Workflow for prediction and performance evaluation by model and attack type."
      },
      {
        "chunk_index": 27397,
        "paper_id": 561,
        "chunk_idx": 2,
        "title": "Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices",
        "section_head": "Real Time Application",
        "score": 0.770822286605835,
        "text_preview": "The prediction results are placed into a dedicated queue for further processing or display. -User Interface: The graphical interface provides a clear and intuitive visualization of the classification "
      },
      {
        "chunk_index": 71334,
        "paper_id": 1522,
        "chunk_idx": 0,
        "title": "ISACL: Internal State Analyzer for Copyrighted Training Data Leakage",
        "section_head": "FAISS Index Search",
        "score": 0.7685588002204895,
        "text_preview": "Figure 3 : Process of constructing a vector database for the RAG system and handling user queries."
      },
      {
        "chunk_index": 5043,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "AI-assisted Diagnosis & Prognosis",
        "score": 0.7672542929649353,
        "text_preview": "Edge comput. processes patient data in real-time for preliminary analysis, cloud provides sophisticated AI models for diagnosis [155, 229] ."
      },
      {
        "chunk_index": 70151,
        "paper_id": 1495,
        "chunk_idx": 0,
        "title": "Intelligent Healthcare Imaging Platform: An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation",
        "section_head": "Figure 2 :",
        "score": 0.7626659870147705,
        "text_preview": "2 Figure 2: Comprehensive system architecture showing integration pathways and clinical workflow optimization"
      },
      {
        "chunk_index": 29589,
        "paper_id": 612,
        "chunk_idx": 0,
        "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System",
        "section_head": "System Demonstration",
        "score": 0.761039137840271,
        "text_preview": "Our CrowdAgent system provides a user-friendly interface (see Figures 3 and 5 ) that guides users through the entire annotation project, enabling the monitoring of agent interactions and the tracking "
      },
      {
        "chunk_index": 108954,
        "paper_id": 2260,
        "chunk_idx": 0,
        "title": "Prompt Injection attack against LLM-integrated Applications",
        "section_head": "WISECHATAI",
        "score": 0.7576534152030945,
        "text_preview": "The application provides constant support and guidance by combining the wisdom of Buddha with ChatGPT. OPTIPROMPT This application empowers users to create awe-inspiring AI-powered products through it"
      }
    ]
  },
  {
    "query_id": 35,
    "query_text": "threat model",
    "source": "section_head",
    "source_value": "B. Threat Model",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 37838,
        "paper_id": 799,
        "chunk_idx": 0,
        "title": "DRAG: Data Reconstruction Attack using Guided Diffusion",
        "section_head": "Figure 1 :",
        "score": 0.9364151954650879,
        "text_preview": "1 Figure 1: Privacy threats in split inference."
      },
      {
        "chunk_index": 48890,
        "paper_id": 1044,
        "chunk_idx": 0,
        "title": "FedBAP: Backdoor Defense via Benign Adversarial Perturbation in Federated Learning",
        "section_head": "Figure 5 :",
        "score": 0.9318630695343018,
        "text_preview": "5 Figure 5: Impact of the malicious clients proportion on different defenses under A3FL attack."
      },
      {
        "chunk_index": 16133,
        "paper_id": 323,
        "chunk_idx": 0,
        "title": "BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning",
        "section_head": "Table 2 :",
        "score": 0.9318375587463379,
        "text_preview": "2 Performance of Robust Aggregation Defenses on Random-Sampling Multi-shot Attacks."
      },
      {
        "chunk_index": 48889,
        "paper_id": 1044,
        "chunk_idx": 0,
        "title": "FedBAP: Backdoor Defense via Benign Adversarial Perturbation in Federated Learning",
        "section_head": "Figure 3 :",
        "score": 0.9309673309326172,
        "text_preview": "3 Figure 3: Impact of the malicious clients proportion on different defenses under the BadNets attack."
      },
      {
        "chunk_index": 121175,
        "paper_id": 2524,
        "chunk_idx": 0,
        "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
        "section_head": "Fig. 6 :",
        "score": 0.9271812438964844,
        "text_preview": "6 Fig. 6: Learning accuracy of FLSS with SOTA defenses under label-flipping attacks."
      },
      {
        "chunk_index": 127028,
        "paper_id": 2649,
        "chunk_idx": 0,
        "title": "Special-Character Adversarial Attacks on Open-Source Language Models",
        "section_head": "Figure 4 :",
        "score": 0.9240508079528809,
        "text_preview": "4 Figure 4: Encoding attack vulnerability by model. Phi3:3.8b shows extreme vulnerability (94%) to Base64 and hexadecimal encoding attacks."
      },
      {
        "chunk_index": 33959,
        "paper_id": 715,
        "chunk_idx": 0,
        "title": "Differential Robustness in Transformer Language Models: Empirical Evaluation Under Adversarial Text Attacks",
        "section_head": "Model Robustness Measure",
        "score": 0.922857403755188,
        "text_preview": "We define the robustness score R of a model against a specific attack as: R = 1 - N i=1 1[Attack i succeeds] N ( 7 ) where N is the total number of attack attempts. Higher values indicate greater robu"
      },
      {
        "chunk_index": 2972,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "D. Privacy Threat Analysis",
        "score": 0.9225345849990845,
        "text_preview": "To better understand the impact of attacks on our system, we model and study poisoning and membership inference attacks [35] , [58] ."
      },
      {
        "chunk_index": 78874,
        "paper_id": 1664,
        "chunk_idx": 0,
        "title": "Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution",
        "section_head": "Table 7 :",
        "score": 0.9210119247436523,
        "text_preview": "7 LETHE against adaptive CBA attacks on Emotion. Model Original attack Adaptive attack LETHE (adaptive) ASR CDA ASR CDA ASR CDA GPT-XL .749 .946 .964 .924 .131 .922 GPT-J .989 .933 .871 .846 .099 .911"
      },
      {
        "chunk_index": 16105,
        "paper_id": 323,
        "chunk_idx": 0,
        "title": "BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning",
        "section_head": "Data-Based Backdoor Attacks",
        "score": 0.917203426361084,
        "text_preview": "Fixed-Pattern [2, 8, 11, 20] Dynamic-Pattern [41, 24] Distributed-Pattern [38, 19] Edge-Case [33] Model-Based Poisoning Attacks Durability Enhancement [45, 9] Defense-Evasion [2, 33, 3, 14, 47] Backdo"
      },
      {
        "chunk_index": 34046,
        "paper_id": 717,
        "chunk_idx": 0,
        "title": "Differentially Private Federated Quantum Learning via Quantum Noise",
        "section_head": "Fig. 5 :",
        "score": 0.9134811162948608,
        "text_preview": "5 Fig. 5: Robustness evaluation of DP-QFL under FGSM attack with adversarial examples. The evaluation metrics are: classification accuracy with adversarial examples, the model's confidence in correct "
      },
      {
        "chunk_index": 118710,
        "paper_id": 2476,
        "chunk_idx": 0,
        "title": "Scaling Decentralized Learning with FLock",
        "section_head": "Figure 3 .",
        "score": 0.9093902111053467,
        "text_preview": "3 Figure 3. A comparative analysis of model performance (MMLU Score) and security (Backdoor ASR) under a sustained poisoning attack."
      },
      {
        "chunk_index": 48891,
        "paper_id": 1044,
        "chunk_idx": 0,
        "title": "FedBAP: Backdoor Defense via Benign Adversarial Perturbation in Federated Learning",
        "section_head": "Figure 6 :",
        "score": 0.9064866304397583,
        "text_preview": "6 Figure 6: Impact of the non-IIDness on different defenses under BadNets attack."
      },
      {
        "chunk_index": 151540,
        "paper_id": 3119,
        "chunk_idx": 1,
        "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning",
        "section_head": "INTRODUCTION",
        "score": 0.9063408374786377,
        "text_preview": "Feature reconstruction attacks allow the active party to recover the passive parties' original features from the shared embeddings [11, 12, 18, 21, 36, 40, 48] , while label inference attacks enable m"
      },
      {
        "chunk_index": 5024,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "A. Security Threats and Vulnerabilities",
        "score": 0.9052972793579102,
        "text_preview": "Distributed collaborative architectures introduce expanded attack surfaces that must be addressed to ensure robust operation. Sensitive data across multiple layers risks unauthorized access and interc"
      },
      {
        "chunk_index": 157154,
        "paper_id": 3220,
        "chunk_idx": 0,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "B. Adversarial Vulnerabilities",
        "score": 0.9049739837646484,
        "text_preview": "A recent and serious threat to deepfake detection is that of adversarial attacks against an AI model. The sophistication of deepfake creators is getting increasingly sophisticated to avoid being detec"
      },
      {
        "chunk_index": 143868,
        "paper_id": 2969,
        "chunk_idx": 0,
        "title": "TRIPLE WINS: BOOSTING ACCURACY, ROBUSTNESS AND EFFICIENCY TOGETHER BY ENABLING INPUT-ADAPTIVE INFERENCE",
        "section_head": "Figure 2 :",
        "score": 0.9041543006896973,
        "text_preview": "2 Figure 2: The exiting behaviours of RDI-ResNet38 defended by (a) Single attack defense (Main Branch); (b) Average defense; and (c) Max-Average defense."
      },
      {
        "chunk_index": 63216,
        "paper_id": 1348,
        "chunk_idx": 2,
        "title": "Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning",
        "section_head": "Related Work",
        "score": 0.9011580944061279,
        "text_preview": "More specifically, FLAME combines HDBSCAN angle-based clustering, a defense strong against large angular magnitude attacks, with clipping, a defense effective against large l 2 -norm attacks, and DP-n"
      },
      {
        "chunk_index": 90883,
        "paper_id": 1916,
        "chunk_idx": 0,
        "title": "MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs",
        "section_head": "Proposed Attacks",
        "score": 0.9008065462112427,
        "text_preview": "To answer the RQ3, we propose multiple privacy attacks as follows. A3: By analyzing these side-channel leakage, attackers infer users' inputs and stealthily reconstruct the system's responses. Based o"
      },
      {
        "chunk_index": 121178,
        "paper_id": 2524,
        "chunk_idx": 0,
        "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
        "section_head": "( a )",
        "score": 0.8988390564918518,
        "text_preview": "a 30% label-flipping attacks. (b) 70% label-setting attacks."
      }
    ]
  },
  {
    "query_id": 36,
    "query_text": "game formulation",
    "source": "section_head",
    "source_value": "A. Game Formulation",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 6386,
        "paper_id": 116,
        "chunk_idx": 0,
        "title": "ACTOR-CRITIC WITHOUT ACTOR",
        "section_head": "PRELIMINARIES",
        "score": 0.8876520991325378,
        "text_preview": "Reinforcement learning (RL) We consider the RL problem under a Markov Decision Process (MDP) M = {S, A, P, r, Œ≥, p 0 }, where S is the state space, A is the action space, P (s ‚Ä≤ |s, a) is the transiti"
      },
      {
        "chunk_index": 85053,
        "paper_id": 1793,
        "chunk_idx": 0,
        "title": "Mastering the game of Go with deep neural networks and tree search",
        "section_head": "METHODS",
        "score": 0.8837550282478333,
        "text_preview": "Problem setting. Many games of perfect information, such as chess, checkers, othello, backgammon and Go, may be defined as alternating Markov games 39 . In these games, there is a state space S (where"
      },
      {
        "chunk_index": 56384,
        "paper_id": 1212,
        "chunk_idx": 0,
        "title": "FRICTIONAL Q-LEARNING",
        "section_head": "BACKGROUND",
        "score": 0.8753820061683655,
        "text_preview": "We consider an agent interacting with a continuous environment in discrete time steps, modeled as an MDP (S, A, p M (s ‚Ä≤ |s, a), r, Œ≥), where S denotes the state space, A the action space, p M (s ‚Ä≤ |s"
      },
      {
        "chunk_index": 4062,
        "paper_id": 82,
        "chunk_idx": 1,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Markov Decision Processes",
        "score": 0.87240070104599,
        "text_preview": "The reward function R(s, a) specifies the immediate benefit of taking an action in a given state, while the discount factor Œ≥ balances the trade-off between immediate and future rewards. A key problem"
      },
      {
        "chunk_index": 10047,
        "paper_id": 192,
        "chunk_idx": 0,
        "title": "Ambiguity-Aware and High-Order Relation Learning for Multi-Grained Image-Text Matching",
        "section_head": "Objective Function",
        "score": 0.8697042465209961,
        "text_preview": "The final objective function is: Óà∏ = Óà∏ ùëÉ ùê∫ùê¥ + Óà∏ ùëÄùê∂ùêø + Óà∏ ùëÅùëÜùêº . ( 26 )"
      },
      {
        "chunk_index": 133793,
        "paper_id": 2772,
        "chunk_idx": 0,
        "title": "TACKLING GNARLY PROBLEMS: GRAPH NEURAL ALGORITHMIC REASONING REIMAGINED THROUGH REINFORCEMENT LEARNING",
        "section_head": "MARKOV DECISION PROCESSES AND SOLUTION METHODS",
        "score": 0.866702675819397,
        "text_preview": "A Markov Decision Process is a tuple M = ‚ü®S, A, T , R, h‚ü©, where i) S is a set of states; ii) A is the set of all actions, and A(s) ‚äÜ A is the set of available actions in state s; iii) T : S √ó A √ó S ‚Üí"
      },
      {
        "chunk_index": 4956,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "¬ß4.4 RL Optimization",
        "score": 0.8652265667915344,
        "text_preview": "‚Ä¢ RL for Resource Mgmt. ‚Ä¢ Multi-Agent RL"
      },
      {
        "chunk_index": 4124,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Single-Agent MDP and Actor-Critic Methods",
        "score": 0.8541938066482544,
        "text_preview": "A standard Markov decision process (MDP) is defined by the tuple (S, A, P, r), where S represents a finite state space, A a finite action space, P (s ‚Ä≤ |s, a) the state transition probability, and r(s"
      },
      {
        "chunk_index": 98198,
        "paper_id": 2072,
        "chunk_idx": 0,
        "title": "On the Convergence of Policy Mirror Descent with Temporal Difference Evaluation",
        "section_head": "Introduction",
        "score": 0.8505892753601074,
        "text_preview": "Reinforcement learning (RL), which attempts to maximize long-term reward in sequential decision making, has achieved great success for example in video games [44] , pattern explorations [13, 8] , and "
      },
      {
        "chunk_index": 11163,
        "paper_id": 218,
        "chunk_idx": 0,
        "title": "Analysis of approximate linear programming solution to Markov decision problem with log barrier function",
        "section_head": "Markov decision problem",
        "score": 0.8480300307273865,
        "text_preview": "We consider the infinite-horizon discounted Markov decision problem (Puterman, 2014) and Markov decision process, where the agent sequentially takes actions to maximize cumulative discounted rewards. "
      },
      {
        "chunk_index": 45191,
        "paper_id": 965,
        "chunk_idx": 0,
        "title": "EVALUATION-AWARE REINFORCEMENT LEARNING",
        "section_head": "Markov Decision Process (MDP).",
        "score": 0.8476418256759644,
        "text_preview": "A Markov Decision Process (MDP) (Puterman, 1990) is defined by the tuple {S, A, P, R, Œ≥, ¬µ}, where S is the state space, A is the action space, P is the transition probability function, R is the rewar"
      },
      {
        "chunk_index": 45352,
        "paper_id": 968,
        "chunk_idx": 1,
        "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
        "section_head": "Table 3 :",
        "score": 0.8447482585906982,
        "text_preview": "25% -1.35 9.05e+05 1.36e+05 50% 793.55 1.70e+06 8.28e+05 75% 1589.83 3.34e+06 1.42e+06 100% 2385.79 5.00e+06 2.88e+06 25% 877.45 7.29e+05 3.83e+05 50% 1718.16 1.03e+06 3.73e+06 75% 2561.11 1.59e+06 9."
      },
      {
        "chunk_index": 4061,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Markov Decision Processes",
        "score": 0.8442642688751221,
        "text_preview": "The formal foundation of RL is established through the Markov Decision Process (MDP), a mathematical model for decision-making under uncertainty. An MDP describes an environment where an agent occupie"
      },
      {
        "chunk_index": 70174,
        "paper_id": 1496,
        "chunk_idx": 0,
        "title": "INTENTION-AWARE HIERARCHICAL DIFFUSION MODEL FOR LONG-TERM TRAJECTORY ANOMALY DETECTION",
        "section_head": "Markov Decision Processes",
        "score": 0.836919903755188,
        "text_preview": "Markov Decision Processes (MDPs) provide a mathematical foundation for reinforcement learning (RL). An MDP is defined by the tuple (S, A, P, R, Œ≥, b 0 ), where S is a state space, A is an action space"
      },
      {
        "chunk_index": 8039,
        "paper_id": 155,
        "chunk_idx": 0,
        "title": "ADVANTAGE-WEIGHTED REGRESSION: SIMPLE AND SCALABLE OFF-POLICY REINFORCEMENT LEARNING",
        "section_head": "PRELIMINARIES",
        "score": 0.8355937600135803,
        "text_preview": "In reinforcement learning, the objective is to learn a control policy that enables an agent to maximize its expected return for a given task. At each time step t, the agent observes the state of the e"
      },
      {
        "chunk_index": 102404,
        "paper_id": 2126,
        "chunk_idx": 0,
        "title": "OSWORLD: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
        "section_head": "Task Initial State Setup Config",
        "score": 0.8232359886169434,
        "text_preview": "task initial env state setup Final State get env state"
      },
      {
        "chunk_index": 4203,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "4.",
        "score": 0.8216303586959839,
        "text_preview": "Action Space (A i ): Each agent i has an individual action space A i , and the joint action of all agents is denoted as a = (a 1 , a 2 , . . . , a N ) ‚àà A = A 1 √ó A 2 √ó ‚Ä¢ ‚Ä¢ ‚Ä¢ √ó A N . 5. Reward Functio"
      },
      {
        "chunk_index": 57760,
        "paper_id": 1239,
        "chunk_idx": 0,
        "title": "Fully Learnable Neural Reward Machines",
        "section_head": "Integrating FLNRM with deepRL",
        "score": 0.8193539381027222,
        "text_preview": "In this section, we describe how FLNRM is integrated with policy learning through RL in non-Markovian domains. As in standard RL, we consider an agent interacting with an unknown environment. At each "
      },
      {
        "chunk_index": 81266,
        "paper_id": 1714,
        "chunk_idx": 0,
        "title": "LLM-Enhanced Self-Evolving Reinforcement Learning for Multi-Step E-Commerce Payment Fraud Risk Detection",
        "section_head": "Figure 3 :",
        "score": 0.818271279335022,
        "text_preview": "3 Figure 3: TRISK MDP framework with staged decision points. States incorporate SL risk scores and stage indicators."
      },
      {
        "chunk_index": 4088,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Combined Value Function Approximation",
        "score": 0.8181709051132202,
        "text_preview": "The federated process in VFRL involves combining partial value functions to approximate the global value function: Q(s, a) ‚âà f (Q 1 (s 1 , a), Q 2 (s 2 , a), . . . , Q N (s N , a)) (21) Where f repres"
      }
    ]
  },
  {
    "query_id": 37,
    "query_text": "verification payment mechanism",
    "source": "section_head",
    "source_value": "B. The Verification and Payment Mechanism",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 23314,
        "paper_id": 476,
        "chunk_idx": 0,
        "title": "CHAIN-OF-VERIFICATION REDUCES HALLUCINATION IN LARGE LANGUAGE MODELS",
        "section_head": "Table 4 :",
        "score": 0.8780705332756042,
        "text_preview": "4 Comparison of various CoVe verification plan strategies (rows) and verification execution techniques (columns) on the Wiki-Category task. Verification Execution CoVe (joint) CoVe (factored) Verifica"
      },
      {
        "chunk_index": 119834,
        "paper_id": 2495,
        "chunk_idx": 5,
        "title": "SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines",
        "section_head": "RNA-Protein",
        "score": 0.806879460811615,
        "text_preview": "Example 1: Prompt: Based on the primary amino acid chains, is there evidence for a stable physical association between yeast protein A (<protein>MSNYPLHQACMENEFFKVQELLHSKPSLLLQKDQDGRIPLHWSVSFQAHEITSFL"
      },
      {
        "chunk_index": 42639,
        "paper_id": 902,
        "chunk_idx": 0,
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "section_head": "Table 14 :",
        "score": 0.8067203760147095,
        "text_preview": "14 Retrieval results for ELI5 (claim recall). R@1 R@3 R@5 R@20 R@100 BM25 3.0 6.6 9.6 19.3 31.8 Oracle 25.3 29.7 31.8 - - Fluency Correct. Citation (MAUVE) (EM Rec.) Rec. Prec. ChatGPT (VANILLA, 5-doc"
      },
      {
        "chunk_index": 119785,
        "paper_id": 2495,
        "chunk_idx": 0,
        "title": "SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines",
        "section_head": "Example:",
        "score": 0.8039950132369995,
        "text_preview": "Instructions: Using the protein sequence supplied, identify and describe the enzymatic catalytic activity, with emphasis on the chemical reaction it accelerates: <protein>...</protein> Response: Based"
      },
      {
        "chunk_index": 97321,
        "paper_id": 2051,
        "chunk_idx": 0,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "Additional considerations:",
        "score": 0.7942044734954834,
        "text_preview": "Ensure that the final answer is verified for accuracy, as the Generalist Solution Generator Tool may provide hallucinated responses. Cross-referencing with reliable sources is recommended to confirm t"
      },
      {
        "chunk_index": 980,
        "paper_id": 16,
        "chunk_idx": 0,
        "title": "A comprehensive taxonomy of hallucinations in Large Language Models",
        "section_head": "Table 2 :",
        "score": 0.7941438555717468,
        "text_preview": "2 Comprehensive taxonomy of LLM hallucinations Type Definition/description Example Sources Intrinsic Contradicts provided in- Summary states birth year as 1980 put or context; internal then 1975. inco"
      },
      {
        "chunk_index": 828,
        "paper_id": 16,
        "chunk_idx": 0,
        "title": "A comprehensive taxonomy of hallucinations in Large Language Models",
        "section_head": "General conceptual definition",
        "score": 0.7923609018325806,
        "text_preview": "In the domain of LLMs, hallucination is broadly understood as the generation of \"plausible yet nonfactual content\" [38] . This implies that an LLM produces \"false or fabricated information\" or outputs"
      },
      {
        "chunk_index": 119804,
        "paper_id": 2495,
        "chunk_idx": 0,
        "title": "SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines",
        "section_head": "Conclusion:",
        "score": 0.7894371747970581,
        "text_preview": "The protein is likely soluble based on its composition and sequence analysis. </think>"
      },
      {
        "chunk_index": 4320,
        "paper_id": 83,
        "chunk_idx": 0,
        "title": "A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models",
        "section_head": "Figure 5 :",
        "score": 0.7838904857635498,
        "text_preview": "5 Figure 5: Control-flow operators: task decomposition, verification and critique, and ensemble selection."
      },
      {
        "chunk_index": 1668,
        "paper_id": 30,
        "chunk_idx": 0,
        "title": "A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks",
        "section_head": "D. Threat Analysis and Report Generation",
        "score": 0.7829393148422241,
        "text_preview": "Prioritized reports are added to an analyst queue. When an analyst is ready to review a particular report, they can utilize an LLM-assisted initial triage and report generation feature which also crea"
      },
      {
        "chunk_index": 55025,
        "paper_id": 1178,
        "chunk_idx": 2,
        "title": "FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge",
        "section_head": "Introduction",
        "score": 0.7815989255905151,
        "text_preview": "In this work, we present FLEEK (FactuaL Error detection and correction with Evidence Retrieved from external Knowledge), an intelligent and model-agnostic tool designed to support end users (e.g. huma"
      },
      {
        "chunk_index": 119799,
        "paper_id": 2495,
        "chunk_idx": 1,
        "title": "SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines",
        "section_head": "Effectiveness of Pretraining",
        "score": 0.7747080326080322,
        "text_preview": "<protein>MDAQTIAPGFESVAELFGRFLSEDREYSAQLAAYHRGVKVLDISGGPHRRPDSVTG VFSCSKGVSGLVIALLVQDGFLDLDAEVVKYWPEFGAEGKATITVAQLLSHQAGLLGVEGGLTLAEYNNS ELAAAKLAQMRPLWKPGTAFGYHALTIGVFMEELCRRITGSTLQEIYEQRIRSVTGAHFFLGL"
      },
      {
        "chunk_index": 705,
        "paper_id": 14,
        "chunk_idx": 1,
        "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
        "section_head": "Utilization of Knowledge Graph (KG)",
        "score": 0.7710804343223572,
        "text_preview": "Their work improves the fusion and interaction between external knowledge and dialogue context via various knowledge groundings and reasoning techniques, further reducing hallucination. FactuaL Error "
      },
      {
        "chunk_index": 720,
        "paper_id": 14,
        "chunk_idx": 0,
        "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
        "section_head": "4.",
        "score": 0.7707607746124268,
        "text_preview": "Generates a final verified response. Experiments show CoVe decreases hallucinations across tasks like list-based Wikidata questions and long-form text generation. Given a user query, an LLM generates "
      },
      {
        "chunk_index": 144939,
        "paper_id": 2985,
        "chunk_idx": 0,
        "title": "T√ºlu 3: Pushing Frontiers in Open Language Model Post-Training NathanLambert",
        "section_head": "Correct and Confident / Precisely Express Uncertainty:",
        "score": 0.7648987770080566,
        "text_preview": "-Correct and confident. -Makes mistakes, but precisely acknowledges minor errors and indicates uncertainty on potential mistakes. N/A. Not Applicable: For creative writing tasks. Truthfulness and Hall"
      },
      {
        "chunk_index": 42640,
        "paper_id": 902,
        "chunk_idx": 0,
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "section_head": "Table 16 :",
        "score": 0.7615901827812195,
        "text_preview": "16 Different demonstrations on ASQA. Fluency Correct. Citation (MAUVE) (EM) Rec. Prec. ChatGPT (VANILLA) #demo = 0 74.5 41.9 69.3 73.4 #demo = 1 68.9 39.8 74.6 73.2 #demo = 2 66.6 40.4 73.6 72.5 Fluen"
      },
      {
        "chunk_index": 668,
        "paper_id": 13,
        "chunk_idx": 13,
        "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design",
        "section_head": "D. Binding",
        "score": 0.7605633735656738,
        "text_preview": "[49] Protein sequences Binary classification of each protein as an adaptor protein or non-adaptor protein UniProt, Gene Ontology Protein classification Confirmed model stability and generalizability u"
      },
      {
        "chunk_index": 3383,
        "paper_id": 65,
        "chunk_idx": 1,
        "title": "A SCENARIO-DRIVEN COGNITIVE APPROACH TO NEXT-GENERATION AI MEMORY",
        "section_head": "S3: Mathematical Problem-Solving -A Reasoning Process Demonstration",
        "score": 0.7600804567337036,
        "text_preview": "Perception Reasoning Task Decomposition External Knowledge Base Verification Dual System Expansion Path Memory Retrieval Encoding Error Correct Evaluation Reflect on Path Reasoning Result Memory Updat"
      },
      {
        "chunk_index": 120505,
        "paper_id": 2510,
        "chunk_idx": 0,
        "title": "Securing Private Federated Learning in a Malicious Setting: A Scalable TEE-Based Approach with Client Auditing",
        "section_head": "Liveness",
        "score": 0.7600398063659668,
        "text_preview": "In our context, liveness refers to the capability to complete a process (i.e., Algorithm 2). We analyze three potential issues that might stop the process: crashes, interruptions, and attacks."
      },
      {
        "chunk_index": 33132,
        "paper_id": 695,
        "chunk_idx": 2,
        "title": "Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities",
        "section_head": "III. TOLERATING HALLUCINATION IN LARGE LANGUAGE MODELS",
        "score": 0.7599837779998779,
        "text_preview": "In natural language processing, hallucination refers to having generated text that is either nonsensical or unfaithful to the given source content. In traditional natural language generation, hallucin"
      }
    ]
  },
  {
    "query_id": 38,
    "query_text": "mechanism properties",
    "source": "section_head",
    "source_value": "C. Mechanism Properties",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 143320,
        "paper_id": 2956,
        "chunk_idx": 0,
        "title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context",
        "section_head": "Table 10 :",
        "score": 0.7581077218055725,
        "text_preview": "10 Ablation study on WikiText-103 with the same GPU memory constraints. Backprop Len Recurrence Encoding Loss pplx best pplx init Attn Len 128 Ours Full 26.77 27.02 500 128 Ours Partial 28.33 28.69 46"
      },
      {
        "chunk_index": 117206,
        "paper_id": 2449,
        "chunk_idx": 0,
        "title": "Runge-Kutta Approximation and Decoupled Attention for Rectified Flow Inversion and Semantic Editing",
        "section_head": "Figure 4 :",
        "score": 0.7420963048934937,
        "text_preview": "4 Figure 4: Overview of Decoupled Diffusion Transformer Attention (DDTA)"
      },
      {
        "chunk_index": 68056,
        "paper_id": 1449,
        "chunk_idx": 0,
        "title": "Improving Generalization in Federated Learning with Highly Heterogeneous Data via Momentum-Based Stochastic Controlled Weight Averaging",
        "section_head": "E. 1 .",
        "score": 0.7342692613601685,
        "text_preview": "1 Generalization Analysis for FedSWA under strongly convex settingLemma E.1. Suppose Assumptions C.1-C.5 hold. Then for FedSWA with Œ∑"
      },
      {
        "chunk_index": 4169,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Variational Inequality (VI) Approaches:",
        "score": 0.7331121563911438,
        "text_preview": "Reformulates MARL equilibrium conditions as a variational inequality problem, ensuring a stable solution under joint constraints Facchinei and Pang (2003b) ."
      },
      {
        "chunk_index": 13939,
        "paper_id": 279,
        "chunk_idx": 0,
        "title": "ATTENTION-BASED MODELS FOR TEXT-DEPENDENT SPEAKER VERIFICATION",
        "section_head": "Fig. 3 :",
        "score": 0.7225699424743652,
        "text_preview": "3 Fig. 3: Two variants of the attention layer: (a) cross-layer attention; (b) divided-layer attention."
      },
      {
        "chunk_index": 110695,
        "paper_id": 2299,
        "chunk_idx": 0,
        "title": "Query-Key Normalization for Transformers",
        "section_head": "Figure 2 :",
        "score": 0.7219545841217041,
        "text_preview": "2 Figure2: Query-Key Normalized Attention. Self-attention heatmaps of the same 4 heads in Figure1. QKNORM enables more diffuse attention patterns."
      },
      {
        "chunk_index": 51295,
        "paper_id": 1100,
        "chunk_idx": 0,
        "title": "FEDHK-MVFC: FEDERATED HEAT KERNEL MULTI-VIEW CLUSTERING",
        "section_head": "Part IV: Convergence Analysis and Optimality Conditions",
        "score": 0.7195329070091248,
        "text_preview": "The derived update rules satisfy the Karush-Kuhn-Tucker (KKT) conditions for the constrained optimization problem. Specifically: 1. Stationarity: ‚àáJ ‚Ñì F edHK-M V F C + n(‚Ñì) i=1 Œª 1i ‚àág i + Œª 2 ‚àáh = 0,"
      },
      {
        "chunk_index": 30904,
        "paper_id": 645,
        "chunk_idx": 0,
        "title": "DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems",
        "section_head": "Model",
        "score": 0.7171765565872192,
        "text_preview": "Explicit Interactions (ùëì ùëí ) Final Objective Order (Simplified) Key Formula PNN [35] 2 x ùëú = [v ‚ä§ ùëñ v ùëó | ‚àÄùëñ, ùëó ] (IPNN) ùëì ùëñ ‚Ä¢ ùëì ùëí x ùëú = [vec(v ùëñ ‚äó v ùëó ) | ‚àÄùëñ, ùëó ] (OPNN) DeepFM [13] 2 x ùëú = [v ‚ä§ ùëñ v "
      },
      {
        "chunk_index": 48223,
        "paper_id": 1028,
        "chunk_idx": 0,
        "title": "Fast Transformer Decoding: One Write-Head is All You Need",
        "section_head": "Table 3 :",
        "score": 0.7163169384002686,
        "text_preview": "3 Billion-Word LM Benchmark Results. Attention h d k , d v d f f dev-PPL multi-head 8 128 8192 29.9 multi-query 8 128 9088 30.2 multi-head 1 128 9984 31.2 multi-head 2 64 9984 31.1 multi-head 4 32 998"
      },
      {
        "chunk_index": 58472,
        "paper_id": 1248,
        "chunk_idx": 0,
        "title": "GAMING AND COOPERATION IN FEDERATED LEARNING: WHAT CAN HAPPEN AND HOW TO MONITOR IT",
        "section_head": "B Proofs for ¬ß6",
        "score": 0.715779185295105,
        "text_preview": "This appendix provides complete proofs of Theorem 6.1 (existence and properties of stationary and Markov equilibria) from ¬ß6."
      },
      {
        "chunk_index": 14058,
        "paper_id": 283,
        "chunk_idx": 0,
        "title": "ATTENTIVE CONTEXTUAL CARRYOVER FOR MULTI-TURN END-TO-END SPOKEN LANGUAGE UNDERSTANDING",
        "section_head": "Fig. 4 .",
        "score": 0.7155191898345947,
        "text_preview": "4 Fig. 4. Architecture of Gated Multi-head attentions."
      },
      {
        "chunk_index": 122436,
        "paper_id": 2547,
        "chunk_idx": 0,
        "title": "Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples",
        "section_head": "D Alternative Strategies for Non-Collapse",
        "score": 0.7132683992385864,
        "text_preview": "Proposition 1 provides a theoretical guarantee that the proposed method is immune to the trivial collapse of representations. The underlying principle is that collapsing representations result in high"
      },
      {
        "chunk_index": 677,
        "paper_id": 13,
        "chunk_idx": 0,
        "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design",
        "section_head": "Fig. 2 :",
        "score": 0.7118568420410156,
        "text_preview": "2 Fig. 2: Self-Attention in Transformer"
      },
      {
        "chunk_index": 53186,
        "paper_id": 1140,
        "chunk_idx": 0,
        "title": "FG-ATTN: LEVERAGING FINE-GRAINED SPARSITY IN DIFFUSION TRANSFORMERS",
        "section_head": "Skipping slices of 64x1 query-key dot products",
        "score": 0.7101996541023254,
        "text_preview": "Figure 6 . Block sparse attention mechanisms skip tiles of 128 √ó 128 attention map scores. We propose a method to skip fine-grain 128 √ó 1 sections of the attention scores."
      },
      {
        "chunk_index": 125753,
        "paper_id": 2628,
        "chunk_idx": 0,
        "title": "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training",
        "section_head": "Theorem 4. 3 .",
        "score": 0.7090997695922852,
        "text_preview": "3 Under Assumption 4.1 and Assumption 4.2"
      },
      {
        "chunk_index": 58559,
        "paper_id": 1248,
        "chunk_idx": 0,
        "title": "GAMING AND COOPERATION IN FEDERATED LEARNING: WHAT CAN HAPPEN AND HOW TO MONITOR IT",
        "section_head": "Figure 5 :",
        "score": 0.7089378833770752,
        "text_preview": "5 Figure 5: Comparison of sanctions, rewards, and information design: (a) M under alignment w ‚à• Ku, (b) PoG under the same condition, (c) M under misalignment w ‚ä• u, (d) PoG under the same condition."
      },
      {
        "chunk_index": 96521,
        "paper_id": 2036,
        "chunk_idx": 0,
        "title": "NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes",
        "section_head": "Solving Linear Equations",
        "score": 0.7088426351547241,
        "text_preview": "Finding solutions for a system of linear equations. Reason: Mathintensive."
      },
      {
        "chunk_index": 61670,
        "paper_id": 1317,
        "chunk_idx": 0,
        "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
        "section_head": "Figure 2 :",
        "score": 0.7084157466888428,
        "text_preview": "2 Figure2: Overview of grouped-query method. Multi-head attention has H query, key, and value heads. Multi-query attention shares single key and value heads across all query heads. Grouped-query atten"
      },
      {
        "chunk_index": 104396,
        "paper_id": 2163,
        "chunk_idx": 0,
        "title": "PE R S O N AX: MULTIMODAL DATASETS WITH LLM-INFERRED BEHAVIOR TRAITS",
        "section_head": "By",
        "score": 0.7061572074890137,
        "text_preview": "Assumption iii, different w m corresponds to different p x m,B |wm (x m,B | w m ), there is no repeated element in {p x m,B |wm (x m,B | w m )} (and {p x m,B | ≈µm (x m,B | ≈µm )}). Hence, the relabelli"
      },
      {
        "chunk_index": 121872,
        "paper_id": 2536,
        "chunk_idx": 0,
        "title": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment",
        "section_head": "Table 2 :",
        "score": 0.702968418598175,
        "text_preview": "2 Performance Comparison of Constraints Using Different Layer Outputs. Method IFEval Method IFEval LoRA 48.80 LoRA 48.80 + Attention Q 47.13 + Attention All 50.46 + Attention K 50.09 + FFN 51.02 + Att"
      }
    ]
  },
  {
    "query_id": 39,
    "query_text": "theorem individual rationality",
    "source": "section_head",
    "source_value": "Theorem 1 (Individual Rationality).",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 62158,
        "paper_id": 1328,
        "chunk_idx": 0,
        "title": "Graph Neural Diffusion via Generalized Opinion Dynamics",
        "section_head": "Individualized Consensus.",
        "score": 0.9446241855621338,
        "text_preview": "Definition 3. A diffusion model is said to reach an individualized consensus if there exist distinct vectors ùë£ 1 , ùë£ 2 , . . . , ùë£ ùëõ ‚àà R ùëë such that, for all nodes ùëñ ‚àà ùëâ , lim ùë° ‚Üí‚àû ùë• ùëñ (ùë°) = ùë£ ùëñ , ùëñ ‚àà"
      },
      {
        "chunk_index": 153499,
        "paper_id": 3150,
        "chunk_idx": 2,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "Convex Setting",
        "score": 0.9445966482162476,
        "text_preview": "As a result, a careful telescoping argument is required to cancel out the iterate error terms. Similar to Lemma 7, the recursion features two types of consensus error: the second moment and the fourth"
      },
      {
        "chunk_index": 153488,
        "paper_id": 3150,
        "chunk_idx": 0,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "Theorem 7 (Informal, Iterate Error for Quadratics).",
        "score": 0.9426480531692505,
        "text_preview": "Assume the problem instance is quadratic and satisfies Assumptions 2, 4 and 7 to 11, R = Œ© œÑ 2 ¬µ 2 and KR = Œ©(1). Then, for a suitable choice of step-size Œ∑, Local SGD initialized at x 0 = 0 outputs x"
      },
      {
        "chunk_index": 28615,
        "paper_id": 590,
        "chunk_idx": 0,
        "title": "Convergence Analysis of Aggregation-Broadcast in LoRA-enabled Distributed Fine-Tuning",
        "section_head": "A.4 Proof of lemmas",
        "score": 0.9419659376144409,
        "text_preview": "Though Lemmas 1 and 2 replicate the proof methodology of [10] , we retain their proofs in this subsection to ensure a self-contained theoretical presentation, particularly given their critical role in"
      },
      {
        "chunk_index": 62155,
        "paper_id": 1328,
        "chunk_idx": 0,
        "title": "Graph Neural Diffusion via Generalized Opinion Dynamics",
        "section_head": "Single Consensus.",
        "score": 0.9225658774375916,
        "text_preview": "Definition 1. A diffusion model is said to reach a single consensus if there exists a vector ùë£ ‚àà R ùëë such that, for all nodes ùëñ ‚àà ùëâ , lim ùë° ‚Üí‚àû ùë• ùëñ (ùë°) = ùë£, We now establish conditions under which GODN"
      },
      {
        "chunk_index": 153478,
        "paper_id": 3150,
        "chunk_idx": 0,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "CHAPTER 5 LOCAL SGD ANALYSES USING CONSENSUS ERROR",
        "score": 0.9146469831466675,
        "text_preview": "In this chapter, we present one of the central contributions of this thesis: improved analyses of Local SGD through sharper bounds on the consensus error. This quantity captures the cost of asynchrony"
      },
      {
        "chunk_index": 109419,
        "paper_id": 2269,
        "chunk_idx": 1,
        "title": "PROVING THE LIMITED SCALABILITY OF CENTRALIZED DISTRIBUTED OPTIMIZATION VIA A NEW LOWER BOUND CONSTRUCTION",
        "section_head": "A AUXILIARY FACTS AND NOTATIONS",
        "score": 0.8974640369415283,
        "text_preview": "Œ® a (x i-2 )Œ® a (x i-1 )Œ¶(x i ) + T i=1 Œì(x i ), (14) where x i is the i th coordinate of a vector x ‚àà R T and Œ® a (x) = 0, x ‚â§ 1/2, exp log a ‚Ä¢ 1 - 1 (2x-1) 2 , x > 1/2, Œ¶(x) = ‚àö e x -‚àû e -1 2 t 2 dt"
      },
      {
        "chunk_index": 153454,
        "paper_id": 3150,
        "chunk_idx": 0,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "CHAPTER 4 ON THE FIXED POINT PERSPECTIVE FOR LOCAL SGD",
        "score": 0.892155647277832,
        "text_preview": "In this chapter, we initiate our analysis of Local SGD in the heterogeneous setting, focusing on quadratic objectives. By initially setting aside the effects of third-order smoothness Q, we aim to iso"
      },
      {
        "chunk_index": 151414,
        "paper_id": 3114,
        "chunk_idx": 0,
        "title": "VOXGUARD: EVALUATING USER AND ATTRIBUTE PRIVACY IN SPEECH VIA MEMBERSHIP INFERENCE ATTACKS",
        "section_head": "Definition 3 (Relaxed (œµ,Œ¥)-Attribute Privacy).",
        "score": 0.8921499252319336,
        "text_preview": "A random mechanism AS satisfies relaxed (œµ, Œ¥)-Attribute Privacy, where œµ > 0, Œ¥ ‚àà [0, 1) iff for any i, any distinct u Ã∏ = a i [k] and any texts t, Pr[AS(a i [k], t) = s] ‚â§ e œµ Pr[AS(u i , t) = s] + "
      },
      {
        "chunk_index": 72487,
        "paper_id": 1545,
        "chunk_idx": 0,
        "title": "Kalman Filter Aided Federated Koopman Learning",
        "section_head": "Theorem 1.",
        "score": 0.8920454382896423,
        "text_preview": "When assumptions 1 to 4 hold, Œ∑ t is decreasing, Œ∑ t ‚â§ 1 4L , and Œ∑ t ‚â§ 2Œ∑ t+E for t ‚â• 0, œâ t+1 satisfies the following recursive form. E ||œâ t+1 -œâ * || 2 2 ‚â§ (1 -¬µŒ∑ t )E ||œâ t -œâ * || 2 2 + Œ∑ 2 t 8("
      },
      {
        "chunk_index": 31131,
        "paper_id": 651,
        "chunk_idx": 0,
        "title": "Deciphering the Interplay between Attack and Protection Complexity in Privacy-Preserving Federated Learning",
        "section_head": "Theorem 5.3 (Lower Bound for Protection Complexity).",
        "score": 0.890538215637207,
        "text_preview": "Assume that the mechanism M : S m-1 ‚Üí S m-1 is œµ-MBP for input x ‚àà S m-1 , where œµ ‚â§ m. Then let W O represent the original model information, and W D represent the distorted model information. Assume"
      },
      {
        "chunk_index": 99434,
        "paper_id": 2086,
        "chunk_idx": 2,
        "title": "ON THE RATE OF CONVERGENCE OF KOLMOGOROV-ARNOLD NETWORK REGRESSION ESTIMATORS",
        "section_head": "INTRODUCTION",
        "score": 0.888292670249939,
        "text_preview": "Collectively, these results underscore the value of structured nonparametric estimators: not only do they achieve optimal convergence rates, but their theoretical analysis also directly links model st"
      },
      {
        "chunk_index": 98808,
        "paper_id": 2082,
        "chunk_idx": 0,
        "title": "On the MIA Vulnerability Gap Between Private GANs and Diffusion Models",
        "section_head": "Stability Bound on Membership Advantage",
        "score": 0.8872777223587036,
        "text_preview": "Uniform stability limits how much a model's behavior can change when a single training point is removed, making it harder for an adversary to distinguish members from nonmembers. While Yeom et al. (20"
      },
      {
        "chunk_index": 153470,
        "paper_id": 3150,
        "chunk_idx": 0,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "Towards a Convergence Guarantee using Fixed-point Discrepancy",
        "score": 0.8767380714416504,
        "text_preview": "To derive a final convergence guarantee for Local SGD on strongly convex quadratic objectives, we combine the fixed-point characterization from Proposition 4 with the fixed-point discrepancy bound in "
      },
      {
        "chunk_index": 3158,
        "paper_id": 60,
        "chunk_idx": 4,
        "title": "A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm",
        "section_head": "Application to Low-Rank Gaussian Mixture Models (LR-GMMs)",
        "score": 0.8746261596679688,
        "text_preview": ", K}, such that x ‚àà E k . Suppose Œ¥Œ≤ < 1 and œÉ n ‚Üí 0. Then, there are c, C > 0, n 0 such that for n ‚â• n 0 ‚à•x n -x‚à• 2 ‚â§ C (Œ¥Œ≤) n/2 + max l=‚åän/2‚åã,n exp - c œÉ 2 l + œÉ 2 l . Proof sketch. The proof relies"
      },
      {
        "chunk_index": 69122,
        "paper_id": 1472,
        "chunk_idx": 4,
        "title": "Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience",
        "section_head": "User k",
        "score": 0.873831570148468,
        "text_preview": "Moreover, (50g) is due to the uniformity and independence of the inputs. Since mutual information is non-negative, we conclude that I (X k ; W k |W k ‚Ä≤ , Z k ‚Ä≤ ) = 0, completing the proof of Lemma 2. "
      },
      {
        "chunk_index": 98613,
        "paper_id": 2080,
        "chunk_idx": 1,
        "title": "On the Interplay between Graph Structure and Learning Algorithms in Graph Neural Networks",
        "section_head": "SGD.",
        "score": 0.8738148212432861,
        "text_preview": "Then the excessive risk of SGD can be upper-bounded as follows: ‚àÜ(Œ∏ sgd (N, G; Œ≥)) ‚â≤ SGDBias + SGDVariance, SGDBias = 1 Œ≥ 2 N 2 exp -N Œ≥M Œ∏ * 2 M -1 0:k 1 + Œ∏ * 2 M k 1 :‚àû , SGDVariance = œÉ 2 + ‚à•Œ∏ * ‚à•"
      },
      {
        "chunk_index": 75869,
        "paper_id": 1604,
        "chunk_idx": 2,
        "title": "Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks",
        "section_head": "D. Joint Attention Distillation",
        "score": 0.8714009523391724,
        "text_preview": "By the Cauchy-Schwarz inequality: ‚ü®A G , A T ‚ü© ‚â§ ‚à•A G ‚à• 2 ‚à•A T ‚à• 2 , with equality if and only if A G and A T are linearly dependent. At this point, the projection of the student's attention onto the "
      },
      {
        "chunk_index": 153388,
        "paper_id": 3150,
        "chunk_idx": 1,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "Contributions of this Thesis",
        "score": 0.8707491159439087,
        "text_preview": "These results clarify the precise conditions under which local updates offer provable gains, and set expectations for the upper bounds derived in later chapters. The next two chapters provide compleme"
      },
      {
        "chunk_index": 88976,
        "paper_id": 1871,
        "chunk_idx": 0,
        "title": "Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning",
        "section_head": "Theorem 2.",
        "score": 0.8697443008422852,
        "text_preview": "Under Assumption 1-5, MMO-FL with local iterations E > 1 and including the impact of modality quality imbalance, achieves the following regret bound: Reg T = T t=1 K k=1 E t F t (Œò t,0 ; Dt k ) - T t="
      }
    ]
  },
  {
    "query_id": 40,
    "query_text": "theorem incentive compatibility",
    "source": "section_head",
    "source_value": "Theorem 2 (Incentive Compatibility).",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 31146,
        "paper_id": 651,
        "chunk_idx": 0,
        "title": "Deciphering the Interplay between Attack and Protection Complexity in Privacy-Preserving Federated Learning",
        "section_head": "Appendix A.1. Analysis for Theorem 5.3",
        "score": 0.9591084718704224,
        "text_preview": "Proof. To facilitate the subsequent proof, we first present the necessary assumption and technical lemma."
      },
      {
        "chunk_index": 58479,
        "paper_id": 1248,
        "chunk_idx": 0,
        "title": "GAMING AND COOPERATION IN FEDERATED LEARNING: WHAT CAN HAPPEN AND HOW TO MONITOR IT",
        "section_head": "D Proofs for ¬ß8",
        "score": 0.9292116165161133,
        "text_preview": "This appendix provides proofs for Proposition 8.2 (the boundary between harmful and cooperative coalitions) and Theorem 8.3 (organizational cost and stability) from ¬ß8."
      },
      {
        "chunk_index": 152241,
        "paper_id": 3137,
        "chunk_idx": 0,
        "title": "Weisfeiler-Lehman meets Events: An Expressivity Analysis for Continuous-Time Dynamic Graph Neural Networks",
        "section_head": "Universal Approximation Ability of CGNNs",
        "score": 0.8614795207977295,
        "text_preview": "The dynamic system in [3] processes a finite set of discrete time steps to reflect the computation of snapshots and their unfolding trees. In the continuous setting, the dynamic system is generalized "
      },
      {
        "chunk_index": 2818,
        "paper_id": 52,
        "chunk_idx": 0,
        "title": "A Note on Graphon-Signal Analysis of Graph Neural Networks",
        "section_head": "H Stability of MPNNs to graph subsampling",
        "score": 0.8550496101379395,
        "text_preview": "We follow the proof of [14, Theorem 4.3] to prove Theorem 5.3. Proof. By Lipschitz continuity of Œò, Œ¥ ‚ñ° Œ£, Œ£(Œõ) ‚â§ LŒ¥ ‚ñ° W, f , G(W, Œõ), f (Œõ) . Hence, E Œ¥ ‚ñ° Œ£, Œ£(Œõ) ‚â§ LE Œ¥ ‚ñ° W, f , G(W, Œõ), f (Œõ) , and"
      },
      {
        "chunk_index": 155390,
        "paper_id": 3187,
        "chunk_idx": 0,
        "title": "WISER: SEGMENTING WATERMARKED REGION-AN EPI-DEMIC CHANGE-POINT PERSPECTIVE",
        "section_head": "Finally,",
        "score": 0.8541427850723267,
        "text_preview": "Theorem 3.1 is proved by invoking Theorem D.1 and Proposition 3. We can further sharpen the O( d-1 ) rate in Theorem 3.1 to O( d-2 ) by assuming a mild condition: local sub-Gaussianity of the pivot st"
      },
      {
        "chunk_index": 57979,
        "paper_id": 1241,
        "chunk_idx": 0,
        "title": "FUSEDANN: Convexified Hybrid ANN via Attribute-Vector Fusion",
        "section_head": "Optimality of Minimal Parameters",
        "score": 0.8454486131668091,
        "text_preview": "Cor. 1 Setting Œ≤, Œ± as per Theorem 4 yields minimum separation/compactness bounds, balancing recall and efficiency. Uniqueness of Transformation Theorem 5 Shows that Œ® is injective (one-to-one) if d >"
      },
      {
        "chunk_index": 2814,
        "paper_id": 52,
        "chunk_idx": 0,
        "title": "A Note on Graphon-Signal Analysis of Graph Neural Networks",
        "section_head": "G.2 Robustness and Generalization",
        "score": 0.8449381589889526,
        "text_preview": "We begin by proving Theorem G.2 using the Bretagnolle-Huber-Carol inequality (Proposition G.1). Theorem G.2 improves the asymptotic behavior of [14, Theorem G.3] , a theorem which addresses uniform Mo"
      },
      {
        "chunk_index": 99448,
        "paper_id": 2086,
        "chunk_idx": 1,
        "title": "ON THE RATE OF CONVERGENCE OF KOLMOGOROV-ARNOLD NETWORK REGRESSION ESTIMATORS",
        "section_head": "Suppose we observe",
        "score": 0.8444159030914307,
        "text_preview": "The following corollary formalizes the minimax optimality of KAN estimators over a broad class of structured functions, encompassing both additive and hybrid compositions. Corollary 1 (Minimax Optimal"
      },
      {
        "chunk_index": 108954,
        "paper_id": 2260,
        "chunk_idx": 0,
        "title": "Prompt Injection attack against LLM-integrated Applications",
        "section_head": "WISECHATAI",
        "score": 0.8434585332870483,
        "text_preview": "The application provides constant support and guidance by combining the wisdom of Buddha with ChatGPT. OPTIPROMPT This application empowers users to create awe-inspiring AI-powered products through it"
      },
      {
        "chunk_index": 18476,
        "paper_id": 375,
        "chunk_idx": 0,
        "title": "Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit domain rules",
        "section_head": "Aircraft Domain Rules",
        "score": 0.8397688269615173,
        "text_preview": "According to military aviation doctrine and aerospace engineering principles, a fine-tuned LLM generated four essential constraints: Rule 1: Stealth Technology Consistency Stealth aircraft represent a"
      },
      {
        "chunk_index": 63666,
        "paper_id": 1359,
        "chunk_idx": 0,
        "title": "HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation",
        "section_head": "A.2 HFedATM's Convergence",
        "score": 0.8374214172363281,
        "text_preview": "Building upon the HFedDG error bound, we propose the next lemma, sharpening our theoretical analysis by employing Holder continuity: Lemma 1. Under Assumptions 1 and 2, for any measurable f and distri"
      },
      {
        "chunk_index": 99456,
        "paper_id": 2086,
        "chunk_idx": 0,
        "title": "ON THE RATE OF CONVERGENCE OF KOLMOGOROV-ARNOLD NETWORK REGRESSION ESTIMATORS",
        "section_head": "A.1 PROOF OF THEOREM 1: CONVERGENCE RATE OF ADDITIVE KAN",
        "score": 0.8371703624725342,
        "text_preview": "Theorem 1 (Convergence Rate of Additive KAN Estimator). Let f : [0, 1] d ‚Üí R be a continuous function. By the Kolmogorov-Arnold representation theorem, there exist continuous univariate functions g q "
      },
      {
        "chunk_index": 58012,
        "paper_id": 1241,
        "chunk_idx": 0,
        "title": "FUSEDANN: Convexified Hybrid ANN via Attribute-Vector Fusion",
        "section_head": "Corollary 1 (",
        "score": 0.8365461826324463,
        "text_preview": "1 Optimality of Minimal Parameters).Using Theorem 4, setting Œ≤ = Œ¥max œµ f"
      },
      {
        "chunk_index": 5557,
        "paper_id": 97,
        "chunk_idx": 0,
        "title": "A UNIFIED FRAMEWORK FOR DIFFUSION MODEL UNLEARNING WITH F-DIVERGENCE",
        "section_head": "Main Convergence Results",
        "score": 0.8350545763969421,
        "text_preview": "Theorem 4.1 provides the Jacobian of the dynamical system describing the training of Œ¶ and T at an equilibrium point. Theorem 4.2 provides the main theoretical result of this paper, stating the stabil"
      },
      {
        "chunk_index": 50973,
        "paper_id": 1092,
        "chunk_idx": 0,
        "title": "FedEve: On Bridging the Client Drift and Period Drift for Cross-device Federated Learning",
        "section_head": "F Convergence Analysis",
        "score": 0.8317341804504395,
        "text_preview": "This section provides a comprehensive theoretical analysis of the FedEve algorithm. We establish formal guarantees on the convergence of our proposed method by first stating necessary assumptions, the"
      },
      {
        "chunk_index": 28610,
        "paper_id": 590,
        "chunk_idx": 0,
        "title": "Convergence Analysis of Aggregation-Broadcast in LoRA-enabled Distributed Fine-Tuning",
        "section_head": "A.2 Key lemmas",
        "score": 0.8316590785980225,
        "text_preview": "To ensure a concise and clear proof of the theorem, we first provide the following lemmas. Detailed proofs of these lemmas will be presented after completing the proof of Theorem 1. Lemma 1. Assume As"
      },
      {
        "chunk_index": 153557,
        "paper_id": 3150,
        "chunk_idx": 4,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "Better Rates with Two-Point Bandit Feedback",
        "score": 0.8316022157669067,
        "text_preview": "If we choose appropriate Œ∑, Œ¥ (c.f., Lemma 49 in Appendix F.3.3), the queried points {x m,j t } T,M,2 t,m,j=1 of Algorithm 3 satisfy (for a numerical constant c 18 ): 1 2M T t‚àà[T ],m‚àà[M ],j‚àà[2] E f m "
      },
      {
        "chunk_index": 52331,
        "paper_id": 1121,
        "chunk_idx": 0,
        "title": "FEDSSG: EXPECTATION-GATED AND HISTORY-AWARE DRIFT ALIGNMENT FOR FEDERATED LEARNING",
        "section_head": "Assumption 4 .",
        "score": 0.8308331966400146,
        "text_preview": "4 (Bounded dissimilarity). For some œµ > 0, there exists a Bœµ, for all w satisfies ||‚àáf (w)|| 2 > œµ and B(w) ‚â§ Bœµ. B.5. Detailed convergence proof of FedSSG Theorem 1. Given a non-convex and L-Lipschit"
      },
      {
        "chunk_index": 94209,
        "paper_id": 1992,
        "chunk_idx": 0,
        "title": "Navigation Pixie: Implementation and Empirical Study Toward On-demand Navigation Agents in Commercial Metaverse",
        "section_head": "Operational Sustainability:",
        "score": 0.8305008411407471,
        "text_preview": "To ensure compatibility with frequently updated platforms, we define common interfaces to essential platform functionality."
      },
      {
        "chunk_index": 99649,
        "paper_id": 2089,
        "chunk_idx": 1,
        "title": "ON THEORETICAL INTERPRETATIONS OF CONCEPT-BASED IN-CONTEXT LEARNING",
        "section_head": "THE LABEL PREDICTING ERROR PROBABILITY",
        "score": 0.8289105892181396,
        "text_preview": "Moreover, the following Theorem establishes the connection between the excessive risk and the label predicting error probability based on Lemma 4.5. Theorem 4.6. Suppose that for some j ‚â• 1, the exces"
      }
    ]
  },
  {
    "query_id": 41,
    "query_text": "experimental setup",
    "source": "section_head",
    "source_value": "V. EXPERIMENTAL SETUP",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 97085,
        "paper_id": 2048,
        "chunk_idx": 0,
        "title": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
        "section_head": "Table 5 :",
        "score": 0.9688941240310669,
        "text_preview": "5 Default configurations and chosen hyperparameters adopted in our experimental setup."
      },
      {
        "chunk_index": 24861,
        "paper_id": 501,
        "chunk_idx": 0,
        "title": "Classification is a RAG problem: A case study on hate speech detection",
        "section_head": "Table 4 :",
        "score": 0.9038933515548706,
        "text_preview": "4 Performance on extended identity test sets 5 Experiment 3: Adjustable hate speech detection 5.1 Experimental Setup"
      },
      {
        "chunk_index": 67619,
        "paper_id": 1440,
        "chunk_idx": 0,
        "title": "Improved mmFormer for Liver Fibrosis Staging via Missing-Modality Compensation",
        "section_head": "Experiment and Results",
        "score": 0.886463463306427,
        "text_preview": "Both subtasks follow the same experimental procedures and use the same equipment."
      },
      {
        "chunk_index": 62888,
        "paper_id": 1341,
        "chunk_idx": 0,
        "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection",
        "section_head": "A More Implementation Details",
        "score": 0.8663838505744934,
        "text_preview": "A.1 Hyperparameters Table 8: Hyper-parameters used in our pre-trained models."
      },
      {
        "chunk_index": 94476,
        "paper_id": 1997,
        "chunk_idx": 0,
        "title": "Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings",
        "section_head": "Figure 3 :",
        "score": 0.8651271462440491,
        "text_preview": "3 Figure 3: Trend of MTEB subset scores during supervised training across four experimental settings."
      },
      {
        "chunk_index": 86110,
        "paper_id": 1816,
        "chunk_idx": 0,
        "title": "MedGemma Technical Report",
        "section_head": "General evaluation approach",
        "score": 0.8562039136886597,
        "text_preview": "Evaluation parameters: Unless reported otherwise, all evaluations that we performed consisted of a single inference run per example. For MedGemma evaluations, a temperature of 0.0 was used on medical "
      },
      {
        "chunk_index": 121394,
        "paper_id": 2529,
        "chunk_idx": 0,
        "title": "Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning",
        "section_head": "F Implementation Details",
        "score": 0.855563223361969,
        "text_preview": "Training. We train ReaL-TG-4B with Qwen3-4B as the base model. We develop ReaL-TG on top of verl [39] , a strong framework for post-training on language models. Our training is performed on a compute "
      },
      {
        "chunk_index": 47171,
        "paper_id": 1007,
        "chunk_idx": 0,
        "title": "EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection",
        "section_head": "Experiments",
        "score": 0.8550359606742859,
        "text_preview": "In the experimental part, we introduce the data set and data preprocessing, environment and experimental settings, as well as experimental results and analysis one by one."
      },
      {
        "chunk_index": 56469,
        "paper_id": 1214,
        "chunk_idx": 1,
        "title": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach",
        "section_head": "Model fine-tuning and text embedding",
        "score": 0.8541477918624878,
        "text_preview": "This fixed split was chosen to ensure fair comparability between models, avoid variability from multiple random splits, and maintain reproducibility. Dataset statistics before splitting, including lin"
      },
      {
        "chunk_index": 43405,
        "paper_id": 922,
        "chunk_idx": 0,
        "title": "Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning",
        "section_head": "Evaluation",
        "score": 0.8518368005752563,
        "text_preview": "Based on the methodology described above, we describe our experimental setup. We test our training strategy on the English-language ScienceQA dataset and our proposed Hindi-language dataset HiS-ciVQA."
      },
      {
        "chunk_index": 87202,
        "paper_id": 1835,
        "chunk_idx": 0,
        "title": "MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound",
        "section_head": "Table 8 :",
        "score": 0.8517721891403198,
        "text_preview": "8 Architecture details, and pretraining hyperparameters, for both model sizes. 1 20 th of an epoch). Our"
      },
      {
        "chunk_index": 67376,
        "paper_id": 1434,
        "chunk_idx": 0,
        "title": "Implicit Hypergraph Neural Network",
        "section_head": "C. Experimental Setup",
        "score": 0.8515884280204773,
        "text_preview": "We conducted all experiments on AMD EPYC 7763 64-Core Processor with 1.08 TB of memory and 8 NVIDIA A40 GPUs with CUDA version 12.1. Our code and experimental setup, including data construction, are a"
      },
      {
        "chunk_index": 154445,
        "paper_id": 3166,
        "chunk_idx": 0,
        "title": "Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong General Audio Event Taggers",
        "section_head": "Experiment Settings",
        "score": 0.8506019711494446,
        "text_preview": "Dataset: We use AudioSet and ESC-50 datasets following standard evaluation protocols. AudioSet [20] is a collection of over 2 million 10-second audio clips excised from YouTube videos and labeled with"
      },
      {
        "chunk_index": 96416,
        "paper_id": 2034,
        "chunk_idx": 0,
        "title": "Nougat: Neural Optical Understanding for Academic Documents",
        "section_head": "Metrics",
        "score": 0.8475871086120605,
        "text_preview": "We report the following metrics on our test set."
      },
      {
        "chunk_index": 79041,
        "paper_id": 1667,
        "chunk_idx": 1,
        "title": "Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis Dissertation",
        "section_head": "Prediction of sufficiency",
        "score": 0.8468127250671387,
        "text_preview": "AutoGluon is from the same family of models as AutoMM used in the previous chapter, which automatically optimizes model configurations, trains and selects multiple ML models and ensemble models using "
      },
      {
        "chunk_index": 2603,
        "paper_id": 48,
        "chunk_idx": 0,
        "title": "A Multimodal Foundation Model to Enhance Generalizability and Data Efficiency for Pan-cancer Prognosis Prediction",
        "section_head": "Implementation details",
        "score": 0.8456486463546753,
        "text_preview": "During implementation, our code was based on Python 3 and the open-source PyTorch library with an NVIDIA 3090 GPU equipped with 24GB memory. For model development, MICE was pre-trained and internally "
      },
      {
        "chunk_index": 155824,
        "paper_id": 3195,
        "chunk_idx": 0,
        "title": "X-Troll: eXplainable Detection of State-Sponsored Information Operations Agents",
        "section_head": "Experiments",
        "score": 0.845005989074707,
        "text_preview": "This section presents experimental findings across four areas: fewshot learning, ablation study, summary generation, and a qualitative case study. Few-shot (zero/one/five-shot) evaluations used a held"
      },
      {
        "chunk_index": 153250,
        "paper_id": 3147,
        "chunk_idx": 0,
        "title": "WHAT LEARNING ALGORITHM IS IN-CONTEXT LEARN-ING? INVESTIGATIONS WITH LINEAR MODELS",
        "section_head": "EXPERIMENTAL SETUP",
        "score": 0.8442003726959229,
        "text_preview": "We train a Transformer decoder autoregresively on the objective in Eq. ( 8 ). For all experiments, we perform a hyperparameter search over depth L ‚àà {1, 2, 4, 8, 12, 16}, hidden size W ‚àà {16, 32, 64, "
      },
      {
        "chunk_index": 121381,
        "paper_id": 2529,
        "chunk_idx": 0,
        "title": "Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning",
        "section_head": "Experimental Setup.",
        "score": 0.8438019156455994,
        "text_preview": "We collect evaluation data from the test sets of 4 TGB datasets used during training (tgbl-wiki, tgbl-subreddit, tgbl-coin, tgbl-flight) and from the test sets of 2 unseen datasets (tgbl-uci, tgbl-enr"
      },
      {
        "chunk_index": 54002,
        "paper_id": 1158,
        "chunk_idx": 0,
        "title": "FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification",
        "section_head": "Experimental Setup",
        "score": 0.843390703201294,
        "text_preview": "We provide the experimental details about our methodology and datasets. For every atomic fact splitting, we retrieve 3 examples for few-shot learning. The samples used for fine-tuning are from the tra"
      }
    ]
  },
  {
    "query_id": 42,
    "query_text": "experimental results",
    "source": "section_head",
    "source_value": "VI. EXPERIMENTAL RESULTS",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 121088,
        "paper_id": 2522,
        "chunk_idx": 0,
        "title": "SelectiveShield: Lightweight Hybrid Defense Against Gradient Leakage in Federated Learning",
        "section_head": "Table 11 :",
        "score": 0.9849327206611633,
        "text_preview": "11 Experimental Results on Cifar100."
      },
      {
        "chunk_index": 134854,
        "paper_id": 2791,
        "chunk_idx": 0,
        "title": "Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer",
        "section_head": "Fig. 4 :",
        "score": 0.9144430160522461,
        "text_preview": "4 Fig. 4: Visualization of average Success Rate (SR, %) for Tenma and baseline models across three evaluation axes. This figure summarizes the quantitative results reported in Table V, showing that Te"
      },
      {
        "chunk_index": 7000,
        "paper_id": 128,
        "chunk_idx": 0,
        "title": "Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity",
        "section_head": "Table 2 :",
        "score": 0.9023916721343994,
        "text_preview": "2 Evaluation with seven evaluation metrics on NEJMQA, demonstrating substantial performance improvements with our method in medical decision support scenarios. We highlighted the best results with bol"
      },
      {
        "chunk_index": 7002,
        "paper_id": 128,
        "chunk_idx": 0,
        "title": "Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity",
        "section_head": "Table 3 :",
        "score": 0.9020705223083496,
        "text_preview": "3 Evaluation with seven evaluation metrics on MMLU-Pro-health, demonstrating substantial performance improvements with our method in medical decision support scenarios. We highlighted the best results"
      },
      {
        "chunk_index": 129567,
        "paper_id": 2690,
        "chunk_idx": 0,
        "title": "Stable Video-Driven Portraits",
        "section_head": "Figure 3 :",
        "score": 0.9017987251281738,
        "text_preview": "3 Figure 3: Comparison of Self-Reenactment results on HDTF dataset. Our model outperforms all the other methods in both video quality and accurate expression transfer."
      },
      {
        "chunk_index": 147000,
        "paper_id": 3027,
        "chunk_idx": 0,
        "title": "UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units",
        "section_head": "Results",
        "score": 0.8977572917938232,
        "text_preview": "The results are presented in Figure 6 . 12 We confirmed that UnitY consistently outperformed the cascaded and S2UT models in both metrics."
      },
      {
        "chunk_index": 20641,
        "paper_id": 419,
        "chunk_idx": 0,
        "title": "Bridging Graph and State-Space Modeling for Intensive Care Unit Length of Stay Prediction",
        "section_head": "Results",
        "score": 0.8936161994934082,
        "text_preview": "S 2 G-Net Performance. As shown in Table 1 and Figure 3 , S 2 G-Net achieves the best performance on all 6 evaluation metrics. It obtains the highest R 2 (0.43 ¬± 0.01) with statistically significant i"
      },
      {
        "chunk_index": 40232,
        "paper_id": 850,
        "chunk_idx": 0,
        "title": "Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning",
        "section_head": "Fig. 1 .",
        "score": 0.8933600783348083,
        "text_preview": "1 Fig. 1. MACs and MPJPE of different methods on the Human3.6M dataset. We achieve the best performance while demonstrating highly competitive MACs results. * indicates diffusion-based methods."
      },
      {
        "chunk_index": 131363,
        "paper_id": 2719,
        "chunk_idx": 0,
        "title": "Structural Deep Network Embedding",
        "section_head": "Figure 5 :",
        "score": 0.8902554512023926,
        "text_preview": "5 Figure 5: Micro-F1 and Macro-F1 on (a) FLICKR and (b) YOUTUBE. The results show that our method achieves the best classification performance among baselines."
      },
      {
        "chunk_index": 121090,
        "paper_id": 2522,
        "chunk_idx": 0,
        "title": "SelectiveShield: Lightweight Hybrid Defense Against Gradient Leakage in Federated Learning",
        "section_head": "Table 12 :",
        "score": 0.8870691061019897,
        "text_preview": "12 Experimental Results on SVHN."
      },
      {
        "chunk_index": 121082,
        "paper_id": 2522,
        "chunk_idx": 0,
        "title": "SelectiveShield: Lightweight Hybrid Defense Against Gradient Leakage in Federated Learning",
        "section_head": "Table 8 :",
        "score": 0.8855913281440735,
        "text_preview": "8 Experimental Results on MNIST."
      },
      {
        "chunk_index": 60796,
        "paper_id": 1296,
        "chunk_idx": 0,
        "title": "GLARE: A GRAPH-BASED LANDMARK REGION EMBEDDING NETWORK FOR EMOTION RECOGNITION",
        "section_head": "Table 2 :",
        "score": 0.8853192329406738,
        "text_preview": "2 Accuracy (%) comparison of various models on AffectNet and FERG datasets. GLaRE outperforms baselines on AffectNet and demonstrates competitive performance on FERG. Method AffectNet FERG gACNN 58.78"
      },
      {
        "chunk_index": 121086,
        "paper_id": 2522,
        "chunk_idx": 0,
        "title": "SelectiveShield: Lightweight Hybrid Defense Against Gradient Leakage in Federated Learning",
        "section_head": "Table 10 :",
        "score": 0.8851368427276611,
        "text_preview": "10 Experimental Results on Cifar10."
      },
      {
        "chunk_index": 63678,
        "paper_id": 1359,
        "chunk_idx": 0,
        "title": "HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation",
        "section_head": "Table 1 :",
        "score": 0.8816283941268921,
        "text_preview": "1 Performance (%) comparison of FedDG baselines with and without HFedATM across multiple benchmarks and heterogeneity settings (Œª). Bold values highlight the better-performing aggregation strategy wit"
      },
      {
        "chunk_index": 145126,
        "paper_id": 2989,
        "chunk_idx": 0,
        "title": "UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward",
        "section_head": "Quantitative Evaluation",
        "score": 0.879752516746521,
        "text_preview": "We compare UMO on XVerseBench [4] against the two pretrained models (i.e., UNO [32] and OmniGen2 [31] ) and other SOTA customization methods, as shown in Table 1 and Table 2 . In both single-subject a"
      },
      {
        "chunk_index": 65713,
        "paper_id": 1400,
        "chunk_idx": 0,
        "title": "HunyuanVideo-Foley: Multimodal Diffusion with Representation Alignment for High-Fidelity Foley Audio Generation",
        "section_head": "B.1 Radar Chart.",
        "score": 0.8791966438293457,
        "text_preview": "To provide an intuitive comparison of evaluation results across different models, we present radar charts in Figure 3 , which consists of three subplots corresponding to performance evaluations on the"
      },
      {
        "chunk_index": 124225,
        "paper_id": 2593,
        "chunk_idx": 0,
        "title": "SINAI at eRisk@CLEF 2025: Transformer-Based and Conversational Strategies for Depression Detection Notebook for the eRisk Lab at CLEF 2025",
        "section_head": "Table 6",
        "score": 0.8788864612579346,
        "text_preview": "Results of the ranking-based evaluation for task T2. For the models included in the comparison, the best results are shown in bold. The results obtained reveal an interesting contrast between decision"
      },
      {
        "chunk_index": 64175,
        "paper_id": 1372,
        "chunk_idx": 0,
        "title": "High-Energy Concentration for Federated Learning in Frequency Domain",
        "section_head": "Comparison to the State-of-the-Art",
        "score": 0.8768754005432129,
        "text_preview": "Overall Performance. The test accuracies of the global model for each method on the image and speech datasets are summarized in Table 1 and Table 2 , respectively. Obviously, under different condition"
      },
      {
        "chunk_index": 63019,
        "paper_id": 1344,
        "chunk_idx": 2,
        "title": "GTA: Supervised-Guided Reinforcement Learning for Text Classification with Large Language Models",
        "section_head": "Performance",
        "score": 0.8760085105895996,
        "text_preview": "6 6 7 Q R W K L Q N 6 6 7 W K L Q N $ P D ] R Q Q R W K L Q N $ P D ] R Q W K L Q N ( P R W L R Q Q R W K L Q N ( P R W L R Q W K L Q N % % & 1 H Z V Q R W K L Q N % % & 1 H Z V W K L Q N $FFXUDF\\ Fig"
      },
      {
        "chunk_index": 62838,
        "paper_id": 1340,
        "chunk_idx": 0,
        "title": "GROUNDING AI EXPLANATIONS IN EXPERIENCE: A REFLECTIVE COGNITIVE ARCHITECTURE FOR CLINI-CAL DECISION SUPPORT",
        "section_head": "Table 2 :",
        "score": 0.8755788803100586,
        "text_preview": "2 Accuracy, MCC and F1-score results in main experiment. RCA achieve almost best performance across all datasets, with Accuracy and MCC scores that rival all those of tree-based methods known for thei"
      }
    ]
  },
  {
    "query_id": 43,
    "query_text": "overall performance robustness",
    "source": "section_head",
    "source_value": "A. Overall Performance and Robustness",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 106068,
        "paper_id": 2201,
        "chunk_idx": 0,
        "title": "PLACE: Prompt Learning for Attributed Community Search",
        "section_head": "Table 4 :",
        "score": 1.0,
        "text_preview": "4 Overall Performance on EQA (%)¬±1."
      },
      {
        "chunk_index": 52597,
        "paper_id": 1127,
        "chunk_idx": 0,
        "title": "FedVLM: Scalable Personalized Vision-Language Models through Federated Learning",
        "section_head": "Figure 3 :",
        "score": 0.9832764863967896,
        "text_preview": "3 Performance Analysis Against SOTA: pLoRA demonstrates substantial performance gains over both standard LoRA and FFA-LoRA, underscoring its effectiveness in FL settings."
      },
      {
        "chunk_index": 58005,
        "paper_id": 1241,
        "chunk_idx": 0,
        "title": "FUSEDANN: Convexified Hybrid ANN via Attribute-Vector Fusion",
        "section_head": "Figure 7 :",
        "score": 0.9595595598220825,
        "text_preview": "7 Figure 7: ingle attribute filtering performance across datasets. All FUSEDANN variants show significant improvements over baseline methods, with Fus-H consistently delivering the highest performance"
      },
      {
        "chunk_index": 43459,
        "paper_id": 923,
        "chunk_idx": 0,
        "title": "Enhancing Speech Large Language Models through Reinforced Behavior Alignment",
        "section_head": "Result on Instruction-Following",
        "score": 0.9519145488739014,
        "text_preview": "To evaluate whether RBA improves SpeechLM's instruction-following performance, we conduct comprehensive experiments across multiple domains and assess generalization on external datasets in Table 2 . "
      },
      {
        "chunk_index": 125527,
        "paper_id": 2622,
        "chunk_idx": 0,
        "title": "Software Fairness Dilemma: Is Bias Mitigation a Zero-Sum Game?",
        "section_head": "Table 5 .",
        "score": 0.9512456655502319,
        "text_preview": "5 (RQ4.1) Comparative analysis of MirrorFairU vs. MirrorFair and NaiveBase vs. MirrorFair across 32 single-attribute tasks. The win-tie-loss analysis shows that MirrorFairU improves ùëÜùëÖ ùëÉ , ùëá ùëÉùëÖ ùëÉ , an"
      },
      {
        "chunk_index": 105130,
        "paper_id": 2181,
        "chunk_idx": 0,
        "title": "PGSTalker: Real-Time Audio-Driven Talking Head Generation via 3D Gaussian Splatting with Pixel-Aware Density Control",
        "section_head": "Cross-driven Evaluation",
        "score": 0.9486019015312195,
        "text_preview": "As shown in Table 2 , PGStalker achieves superior lip-sync accuracy under the cross-driven setting. Compared with state-of-the-art counterparts, it delivers highly competitive results with improved sy"
      },
      {
        "chunk_index": 39476,
        "paper_id": 836,
        "chunk_idx": 0,
        "title": "ECHO: FREQUENCY-AWARE HIERARCHICAL ENCODING FOR VARIABLE-LENGTH SIGNALS",
        "section_head": "4) Effect of model scaling.",
        "score": 0.9453093409538269,
        "text_preview": "Comparing ECHO-Small (77.65%) and ECHO-Tiny (76.94%) shows that enlarging the model scale yields consistent improvements across both DCASE (62.11% vs. 61.33%) and fault classification tasks (93.19% vs"
      },
      {
        "chunk_index": 53153,
        "paper_id": 1139,
        "chunk_idx": 0,
        "title": "FFT-MoE: Efficient Federated Fine-Tuning for Foundation Models via Large-scale Sparse MoE under Heterogeneous Edge",
        "section_head": "Performance of Proposed FFT-MoE",
        "score": 0.9434390068054199,
        "text_preview": "Table 1 presents the accuracy of FFT-MoE and baseline methods under varying degrees of data heterogeneity. All baselines suffer significant performance degradation as heterogeneity increases, particul"
      },
      {
        "chunk_index": 145130,
        "paper_id": 2989,
        "chunk_idx": 0,
        "title": "UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward",
        "section_head": "Identity Consistency",
        "score": 0.9426020383834839,
        "text_preview": "Overall Performance i.e., identity consistency, prompt following, aesthetic and overall performance. As shown in Figure 7 , UMO achieves the best preference, demonstrating the effectiveness of multi-t"
      },
      {
        "chunk_index": 139973,
        "paper_id": 2887,
        "chunk_idx": 0,
        "title": "ToFU: Transforming How Federated Learning Systems Forget User Data",
        "section_head": "Performance improvement over existing FU methods",
        "score": 0.9397004842758179,
        "text_preview": "Beyond outperforming existing FU methods, ToFU also demonstrates its versatility as it can be effectively integrated with existing FU frameworks to further enhance their performance. As illustrated in"
      },
      {
        "chunk_index": 52653,
        "paper_id": 1128,
        "chunk_idx": 1,
        "title": "FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios",
        "section_head": "D.2 Supplementary Experiments for FedGrab on Cifar10 Dataset",
        "score": 0.9395570755004883,
        "text_preview": "From the results, we observe that while FedGrab achieves relatively high accuracy in some cases (e.g., when ùêº ùêπ = 1, ùêº ùêπ = 0.1 and ùêº ùêπ = 0.5), its overall performance is still inferior to FedWCM. FedW"
      },
      {
        "chunk_index": 142297,
        "paper_id": 2934,
        "chunk_idx": 2,
        "title": "TRAFFIC-MLLM: A SPATIO-TEMPORAL MLLM WITH RETRIEVAL-AUGMENTED GENERATION FOR CAUSAL INFERENCE IN TRAFFIC",
        "section_head": "Experimental Results",
        "score": 0.9393496513366699,
        "text_preview": "Table 2 shows that Traffic-MLLM (3B) achieves leading performance across the four traffic-sign recognition tasks on the CARLA simulation dataset, with particular strength on Regulatory and Warning sig"
      },
      {
        "chunk_index": 84443,
        "paper_id": 1776,
        "chunk_idx": 0,
        "title": "MAPEX: A MULTI-AGENT PIPELINE FOR KEYPHRASE EXTRACTION",
        "section_head": "Table 2 :",
        "score": 0.9383773803710938,
        "text_preview": "2 Performance of MAPEX and baselines on F1@K across datasets."
      },
      {
        "chunk_index": 40481,
        "paper_id": 854,
        "chunk_idx": 0,
        "title": "Efficient Federated Learning with Timely Update Dissemination",
        "section_head": "Impact of Device Numbers",
        "score": 0.9374282360076904,
        "text_preview": "We conduct experiments with 100, 200 and 250 devices to demonstrate the remarkable scalability of FedASMU and FedSSMU, as illustrated in Figure 6 . The performance of both methods significantly outpac"
      },
      {
        "chunk_index": 81916,
        "paper_id": 1726,
        "chunk_idx": 1,
        "title": "LLMs as Architects and Critics for Multi-Source Opinion Summarization",
        "section_head": "LLMs as M-OS Evaluators",
        "score": 0.9364511966705322,
        "text_preview": "Notably, Omni-Prompt consistently outperforms Op-I-Prompt across all LLMs acting as evaluators, demonstrating the effectiveness of our metric-independent prompting strategy. Dimension-wise Analysis: F"
      },
      {
        "chunk_index": 102136,
        "paper_id": 2121,
        "chunk_idx": 0,
        "title": "ORCA: AN AGENTIC REASONING FRAMEWORK FOR HALLUCINATION MITIGATION AND ADVERSARIAL ROBUSTNESS IN VISION-LANGUAGE MODELS",
        "section_head": "Impacts of Adversarial Defense.",
        "score": 0.936312735080719,
        "text_preview": "We evaluate whether universal pixel-level defenses improve robustness on adversarial AMBER images. While defenses improve the performance of standalone LVLMs, ORCA consistently outperforms its corresp"
      },
      {
        "chunk_index": 51439,
        "paper_id": 1102,
        "chunk_idx": 0,
        "title": "FedKLPR: Personalized Federated Learning for Person Re-Identification with Adaptive Pruning",
        "section_head": "B. Performance Evaluation",
        "score": 0.9361982941627502,
        "text_preview": "Table II presents a comparative evaluation of our proposed FedKLPR framework against state-of-the-art methods under the non-pruning setting. Compared with FedUReID [16] , FedUCC [17] , FedUCC+ [18] , "
      },
      {
        "chunk_index": 52598,
        "paper_id": 1127,
        "chunk_idx": 0,
        "title": "FedVLM: Scalable Personalized Vision-Language Models through Federated Learning",
        "section_head": "Figure 4 :",
        "score": 0.9355666637420654,
        "text_preview": "4 Performance Analysis Against LoRA: pLoRA demonstrates performance gains over standard LoRA in CIFAR-10, underscoring its effectiveness in FL settings."
      },
      {
        "chunk_index": 31354,
        "paper_id": 656,
        "chunk_idx": 0,
        "title": "Decoupled Contrastive Learning for Federated Learning",
        "section_head": "Table 3 :",
        "score": 0.9347352981567383,
        "text_preview": "3 Performance comparison from 5% participation rate over 100 clients on Tiny-ImageNet under different data heterogeneity (Œ±) settings. Also, we report exponential moving average accuracy with the para"
      },
      {
        "chunk_index": 28092,
        "paper_id": 576,
        "chunk_idx": 0,
        "title": "Context-Enhanced Granular Edit Representation for Efficient and Accurate ASR Post-editing",
        "section_head": "Figure 1 :",
        "score": 0.9347003102302551,
        "text_preview": "1 Figure 1: Illustrating the trade-offs in ASR post-editing: Full Rewrite offers accuracy but low efficiency, Compact Representations improve efficiency but risk ambiguity, while our proposed CEGER ac"
      }
    ]
  },
  {
    "query_id": 44,
    "query_text": "detailed analysis mnist",
    "source": "section_head",
    "source_value": "B. Detailed Analysis on MNIST",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 63584,
        "paper_id": 1357,
        "chunk_idx": 0,
        "title": "Heterogeneous Federated Learning with Prototype Alignment and Upscaling",
        "section_head": "Experiments",
        "score": 0.9250224828720093,
        "text_preview": "This section presents our experimental methodology, empirical results, and detailed analysis of convergence behavior."
      },
      {
        "chunk_index": 21107,
        "paper_id": 431,
        "chunk_idx": 0,
        "title": "Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments",
        "section_head": "VII. RESULTS AND ANALYSIS",
        "score": 0.9222126007080078,
        "text_preview": "This section presents a detailed analysis of our experimental results across three key dimensions: communication cost, model accuracy, and memory efficiency. We compare the baseline FedAvg configurati"
      },
      {
        "chunk_index": 37918,
        "paper_id": 801,
        "chunk_idx": 0,
        "title": "DRAGD: A Federated Unlearning Data Reconstruction Attack Based on Gradient Differences",
        "section_head": "A. Experiment Setup 1) Dataset:",
        "score": 0.9199381470680237,
        "text_preview": "We evaluate DRAGD, DRAGDP,and FedANI using three datasets in our experiments including: MNIST, CIFAR-10, and LFW."
      },
      {
        "chunk_index": 53468,
        "paper_id": 1148,
        "chunk_idx": 0,
        "title": "Find a Scapegoat: Poisoning Membership Inference Attack and Defense to Federated Learning",
        "section_head": "Datasets",
        "score": 0.9024585485458374,
        "text_preview": "We assess our proposed attack, defense mechanism, and baseline methods using four real-world datasets: CIFAR-10 [28] , STL10 [12] , Texas100 [1], and FER2013 [21] . See Appendix B for details."
      },
      {
        "chunk_index": 52710,
        "paper_id": 1129,
        "chunk_idx": 0,
        "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization",
        "section_head": "Experiments",
        "score": 0.8991727232933044,
        "text_preview": "In this section, we evaluate the proposed FedWSQ on stan- dard FL benchmarks, compare its performance against various FL methods on both i.i.d. and non-i.i.d. data conditions, and offer a further anal"
      },
      {
        "chunk_index": 102812,
        "paper_id": 2132,
        "chunk_idx": 0,
        "title": "Owen Sampling Accelerates Contribution Estimation in Federated Learning",
        "section_head": "Table 3 .",
        "score": 0.8966892957687378,
        "text_preview": "3 Ablation Study on the Effect of Adaptive Client Selection in FedOwen for Two Imbalance Factors FedOwen Variant MedMNIST MNIST FashionMNIST CIFAR-10 FEMNIST Dirichlet Œ± 0.01 0.05 0.1 0.01 0.05 0.1 0."
      },
      {
        "chunk_index": 155897,
        "paper_id": 3197,
        "chunk_idx": 0,
        "title": "X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment",
        "section_head": "A Missing Proofs",
        "score": 0.8935075998306274,
        "text_preview": "In this appendix, we provide the detailed proofs for our convergence Theorems 1 and 2 in Appendix A.1 and Appendix A.2, respectively."
      },
      {
        "chunk_index": 52227,
        "paper_id": 1119,
        "chunk_idx": 0,
        "title": "FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness",
        "section_head": "Figure 9 :Figure 10 :",
        "score": 0.8928301334381104,
        "text_preview": "910 Figure9: Additional result on CIFAR-10 using 64 clients."
      },
      {
        "chunk_index": 52737,
        "paper_id": 1129,
        "chunk_idx": 0,
        "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization",
        "section_head": "Table 5 .",
        "score": 0.8914504647254944,
        "text_preview": "5 Ablation study for œÅ using FedWS on CIFAR-10. For the non-i.i.d. setting, Œ± = 0.3 is used. œÅ 1 √ó 10 -4 1 √ó 10 -3 1 √ó 10 -2 1 √ó 10 -1 non-i.i.d. 87.15 89.71 89.62 89.46 i.i.d. 90.64 92.48 91.97 92.11"
      },
      {
        "chunk_index": 24382,
        "paper_id": 492,
        "chunk_idx": 0,
        "title": "Choice Outweighs Effort: Facilitating Complementary Knowledge Fusion in Federated Learning via Re-calibration and Merit-discrimination",
        "section_head": "Table 4 .",
        "score": 0.8903241157531738,
        "text_preview": "4 Single component ablation (s = 70). Method CINIC-10 CIFAR-10 EMNIST Backbone 34.73 ¬± 0.2 54.20 ¬± 0.1 55.37 ¬± 0.1 CFT 42.13 ¬± 0.2 59.67 ¬± 0.2 63.00 ¬± 0.2 MPS 40.19 ¬± 0.2 64.37 ¬± 0.1 63.57 ¬± 0.1 CCI 3"
      },
      {
        "chunk_index": 14305,
        "paper_id": 290,
        "chunk_idx": 0,
        "title": "Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval",
        "section_head": "-Statistical analysis (Section A.2).",
        "score": 0.889162540435791,
        "text_preview": "‚Ä¢ Experiments on ActivityNet Captions including: -Ablation studies on fusion strategies (Section B.1). -Ablation studies on additional model structures (Section B.4). -Qualitative analysis (Section B."
      },
      {
        "chunk_index": 82918,
        "paper_id": 1743,
        "chunk_idx": 0,
        "title": "Look Beyond: Two-Stage Scene View Generation via Panorama and Video Diffusion",
        "section_head": "EXPERIMENTS AND RESULTS",
        "score": 0.8879690170288086,
        "text_preview": "We provide additional ablation study analysis and additional qualitative comparison results in the following."
      },
      {
        "chunk_index": 140950,
        "paper_id": 2906,
        "chunk_idx": 2,
        "title": "Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift",
        "section_head": "Table 1 :",
        "score": 0.8875942826271057,
        "text_preview": "CGSV 91.23¬±0.15 92.21¬±0.35 90.52¬±1.35 89.32¬±0.36 91.14¬±0.15 66.68¬±1.50 67.00¬±2.93 64.32¬±2.32 63.65¬±2.11 65.56¬±1.35 FedAVE 89.44¬±0.45 92.36¬±0.19 89.83¬±0.47 88.99¬±0.64 89.66¬±0.04 55.85¬±1.44 52.19¬±1.19 5"
      },
      {
        "chunk_index": 154826,
        "paper_id": 3176,
        "chunk_idx": 0,
        "title": "WHO OWNS THIS SAMPLE: CROSS-CLIENT MEMBERSHIP INFERENCE ATTACK IN FEDERATED GRAPH NEURAL NETWORKS",
        "section_head": "Baselines",
        "score": 0.8871473073959351,
        "text_preview": "In our experiments, we evaluate three representative GNN models, including GCN [20] , GAT [41] , and GraphSAGE [13] as global models within the FedGNN framework. To demonstrate the generalizability of"
      },
      {
        "chunk_index": 48407,
        "paper_id": 1033,
        "chunk_idx": 0,
        "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning",
        "section_head": "Experiments",
        "score": 0.8863621950149536,
        "text_preview": "In this section, we evaluate our proposed method using three datasets and various baselines. We investigate the relationship between data heterogeneity and training efficiency. Additionally, we conduc"
      },
      {
        "chunk_index": 51814,
        "paper_id": 1110,
        "chunk_idx": 0,
        "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models",
        "section_head": "Fig. 4 .",
        "score": 0.8846520185470581,
        "text_preview": "4 Fig. 4. Comparison of FID scores for CIFAR-10 and CelebA datasets using FedPhD."
      },
      {
        "chunk_index": 94589,
        "paper_id": 1999,
        "chunk_idx": 0,
        "title": "Nemotron_4_340B_8T_0.tei",
        "section_head": "Figure 1 :",
        "score": 0.8836135864257812,
        "text_preview": "1 Figure 1: Comparison of Nemotron-4-340B-Base, Nemotron-4-340B-Instruct and Nemotron-4-340B-Reward. See detailed evaluation results in Section 2.4, Section 3.4, and Section 3.1, respectively."
      },
      {
        "chunk_index": 105389,
        "paper_id": 2186,
        "chunk_idx": 0,
        "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
        "section_head": "D Imagen Detailed Abalations and Analysis",
        "score": 0.8828538656234741,
        "text_preview": "In this section, we perform ablations and provide a detailed analysis of Imagen."
      },
      {
        "chunk_index": 6516,
        "paper_id": 119,
        "chunk_idx": 0,
        "title": "AD-DROP: Attribution-Driven Dropout for Robust Language Model Fine-Tuning",
        "section_head": "Analysis",
        "score": 0.8827388286590576,
        "text_preview": "In this section, we further conduct several experiments for more thorough analysis."
      },
      {
        "chunk_index": 51798,
        "paper_id": 1110,
        "chunk_idx": 2,
        "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models",
        "section_head": "B. Model Evaluation",
        "score": 0.8819460868835449,
        "text_preview": "Ratio #Params MACs (CIFAR-10) MACs (CelebA) FID (CIFAR-10) ‚Üì IS (CIFAR-10) ‚Üë FID (CelebA) ‚Üì IS (CelebA) ‚Üë 0% 35.7M 6.1 24.3 16.56 4.42 7.31 2.92 25% 26.9M 4.2 16.8 16.78 (-1.3%) 4.18 (-5.4%) 7.42 (-1."
      }
    ]
  },
  {
    "query_id": 45,
    "query_text": "fedavg",
    "source": "section_head",
    "source_value": "FedAvg",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 7056,
        "paper_id": 130,
        "chunk_idx": 1,
        "title": "Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data",
        "section_head": "A. Settings",
        "score": 0.9772652387619019,
        "text_preview": "(32K) sport (32K) homogeneous Centralized 86.4 79.1 84.4 94.4 82.6 82.3 82.6 78.2 84.1 91.2 81.7 78.5 FedAvg 79.1 77.8 81.5 80.5 77.1 79.7 76.2 76.1 80.2 76.6 76.6 76.8 DS-FL 79.1 77.1 81.2 81.5 76.5 "
      },
      {
        "chunk_index": 154858,
        "paper_id": 3176,
        "chunk_idx": 0,
        "title": "WHO OWNS THIS SAMPLE: CROSS-CLIENT MEMBERSHIP INFERENCE ATTACK IN FEDERATED GRAPH NEURAL NETWORKS",
        "section_head": "Table 7 :",
        "score": 0.9713913202285767,
        "text_preview": "7 Performance of federated GCN client-data identification on other datasets. Clts: Clients. Dataset FL Approaches 3-Clts 4-Clts 5-Clts 6-Clts 7-Clts 8-Clts 9-Clts 10-Clts Random 33.33 25.00 20.00 16.6"
      },
      {
        "chunk_index": 52726,
        "paper_id": 1129,
        "chunk_idx": 0,
        "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization",
        "section_head": "Method Hyper-parameters",
        "score": 0.9649208784103394,
        "text_preview": "FedProx [27] ¬µ = 0.001 FedAvgM [13] Œ≤ = 0.4 FedADAM [36] œÑ = 0.001, Œ≤ 1 = 0.9, Œ≤ 2 = 0.99 FedDyn [1] Œ± = 0.1 FedMLB [21] œÑ = 1, Œª 1 = 1, Œª 2 = 1 FedLC [52] œÑ = 1 FedNTD [26] œÑ = 1, Œ≤ = 0.3 FedDecorr ["
      },
      {
        "chunk_index": 33209,
        "paper_id": 696,
        "chunk_idx": 1,
        "title": "Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach",
        "section_head": "Table 1 :",
        "score": 0.9608643651008606,
        "text_preview": "MNIST FMNIST EMNIST SVHN C-10 C-100 T-ImageNet MLP LeNet-S LeNet MLP LeNet-S LeNet MLP LeNet-S LeNet ZekenNet ResNet ResNet N = 10 Local 2.26 17.53 2.78 3.82 13.72 4.51 2.21 0.78 2.08 10.03 12.11 30.4"
      },
      {
        "chunk_index": 51113,
        "paper_id": 1095,
        "chunk_idx": 0,
        "title": "FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient Research",
        "section_head": "FedAvg 10 .",
        "score": 0.9515923261642456,
        "text_preview": "10 42¬±2.72 AFL | ùúÇ ùúÜ = 0.01 11.25¬±2.37 FedProx 8.89¬±1.88 q-FedAvg | ùëû = 0.5 6.80¬±1.83 FedFa | ùõΩ = 0.5 8.34¬±2.48 FedMgda+ | ùúÄ = 0.1 10.51¬±1.48 FedFV | ùõº = 0.3, ùúè = 0 10.89¬±2.17 FedGini | ùúÄ = 1"
      },
      {
        "chunk_index": 51703,
        "paper_id": 1108,
        "chunk_idx": 1,
        "title": "FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning",
        "section_head": "C. Results and analysis",
        "score": 0.9503834247589111,
        "text_preview": "As the regularization strength increases TABLE IX END-OF-TRAINING PERFORMANCE OF ALL FEDERATED LEARNING METHODS UNDER IID AND NON-IID DATA-DISTRIBUTION SCENARIOS Method Accuracy Precision Recall F1-sc"
      },
      {
        "chunk_index": 154860,
        "paper_id": 3176,
        "chunk_idx": 1,
        "title": "WHO OWNS THIS SAMPLE: CROSS-CLIENT MEMBERSHIP INFERENCE ATTACK IN FEDERATED GRAPH NEURAL NETWORKS",
        "section_head": "Table 8 :",
        "score": 0.940843939781189,
        "text_preview": "Dataset Shadow Dataset FL Approaches HP-MIA GAN-Based CS-MIA CC-MIA Citeseer FedAvg 56.32 54.87 58.12 65.36 CS FedProx 50.14 49.98 59.67 60.41 Cora CS SCAFFOLD 52.73 51.44 57.21 64.32 PubMed FedDF 53."
      },
      {
        "chunk_index": 154862,
        "paper_id": 3176,
        "chunk_idx": 1,
        "title": "WHO OWNS THIS SAMPLE: CROSS-CLIENT MEMBERSHIP INFERENCE ATTACK IN FEDERATED GRAPH NEURAL NETWORKS",
        "section_head": "Table 9 :",
        "score": 0.93342125415802,
        "text_preview": "Dataset Shadow Dataset FL Approaches HP-MIA GAN-Based CS-MIA CC-MIA DBLP FedAvg 55.12 53.78 57.45 65.82 PubMed FedProx 50.97 49.35 58.76 71.47 Cora DBLP SCAFFOLD 52.43 51.21 56.67 61.35 DBLP FedDF 53."
      },
      {
        "chunk_index": 51257,
        "paper_id": 1099,
        "chunk_idx": 2,
        "title": "FedHiP: Heterogeneity-Invariant Personalized Federated Learning Through Closed-Form Solutions",
        "section_head": "B. Overall Comparisons",
        "score": 0.9319093227386475,
        "text_preview": "5 Œª = 1.0 FedAvg [2] 43.53% 47.75% 48.91% 39.28% 43.31% 43.28% 6.30% 7.14% 7.61% 4.90% 4.60% 5.00% FedAvg+FT [2] 58.81% 41.38% 37.73% 49.05% 31.37% 26.91% 20.42% 8.14% 6.15% 18.68% 7.52% 4.84% FedProx"
      },
      {
        "chunk_index": 51837,
        "paper_id": 1111,
        "chunk_idx": 0,
        "title": "FedPromo: Federated Lightweight Proxy Models At The Edge Bring New Domains To Foundation Models",
        "section_head": "Appendix A",
        "score": 0.9261450171470642,
        "text_preview": "D Method MobileNet DINOv2 Top-1 Top-5 Top-1 Top-5 CompCars FedAvg 16.2 31.4 1.2 3.9 FedAvg + EMA 6.5 17.5 3.0 9.7 FedProx ‚Ä† 2.1 7.6 2.4 8.5 MOON ‚Ä† 16.2 31.5 1.3 3.9 FedPromo (ours) 18.3 37.1 3.3 10.8 "
      },
      {
        "chunk_index": 154906,
        "paper_id": 3177,
        "chunk_idx": 1,
        "title": "Who Should I Listen To? Adaptive Collaboration in Personalized Federated Learning",
        "section_head": "Table 3 :",
        "score": 0.9251340627670288,
        "text_preview": "Method A C Office D W C I DomainNet P Q R S Centralized 0.7403 (0.001) 0.5824 (0.002) 0.7912 (0.002) 0.7852 (0.0001) 0.7053 (0.004) 0.3059 (0.003) 0.6187 (0.002) 0.7150 (0.001) 0.7017 (0.004) 0.6462 ("
      },
      {
        "chunk_index": 51829,
        "paper_id": 1111,
        "chunk_idx": 1,
        "title": "FedPromo: Federated Lightweight Proxy Models At The Edge Bring New Domains To Foundation Models",
        "section_head": "In-Domain Results",
        "score": 0.9250908493995667,
        "text_preview": "The gain is also evident in the CUB200‚ÜíNABirds setting, where FedPromo achieves a server Top-1 accuracy of 30.3%, compared to 16.0% of FedProx and 20.7% of D Method MobileNet DINOv2 Top-1 Top-5 Top-1 "
      },
      {
        "chunk_index": 154852,
        "paper_id": 3176,
        "chunk_idx": 1,
        "title": "WHO OWNS THIS SAMPLE: CROSS-CLIENT MEMBERSHIP INFERENCE ATTACK IN FEDERATED GRAPH NEURAL NETWORKS",
        "section_head": "Table 1 :",
        "score": 0.9164947867393494,
        "text_preview": "Dataset Approach Shadow HP-MIA GAN-Based CS-MIA CC-MIA 3-Clts 4-Clts 5-Clts 6-Clts 7-Clts 8-Clts 9-Clts 10-Clts Client-uniform Probability - - - - - 33.33 25.00 20.00 16.66 14.29 12.50 11.11 10.00 Fed"
      },
      {
        "chunk_index": 51793,
        "paper_id": 1110,
        "chunk_idx": 2,
        "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models",
        "section_head": "V. EXPERIMENTAL EVALUATION",
        "score": 0.9102790951728821,
        "text_preview": "A = 10, 000 FOR CIFAR10 AND B = 5, 000 FOR CELEBA Method CIFAR10 CelebA FID ‚Üì IS ‚Üë FID ‚Üì IS ‚Üë Centralized and IID Settings Centralized Training 8.73 ¬± 0.30 7.22 ¬± 0.21 5.86 ¬± 0.36 3.22 ¬± 0.14 FedAvg ("
      },
      {
        "chunk_index": 154857,
        "paper_id": 3176,
        "chunk_idx": 0,
        "title": "WHO OWNS THIS SAMPLE: CROSS-CLIENT MEMBERSHIP INFERENCE ATTACK IN FEDERATED GRAPH NEURAL NETWORKS",
        "section_head": "Table 6 :",
        "score": 0.907638669013977,
        "text_preview": "6 Performance (AUC %) of federated GCN member inference attacks on other datasets. Dataset Shadow Dataset FL Approaches HP-MIA GAN-Based CS-MIA CC-MIA Cora FedAvg 53.46 50.47 68.24 81.60 Citeseer FedP"
      },
      {
        "chunk_index": 64172,
        "paper_id": 1372,
        "chunk_idx": 1,
        "title": "High-Energy Concentration for Federated Learning in Frequency Domain",
        "section_head": "Experiments 4.1 Experimental Setup",
        "score": 0.9054304361343384,
        "text_preview": "When generating synthetic data on ùêæ = 10 clients, the number 0 10 20 30 40 50 60 70 80 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Test Accuracy (%) CIFAR10 FedAvg FedNova FedProx SCAFFOLD FedD"
      },
      {
        "chunk_index": 40484,
        "paper_id": 854,
        "chunk_idx": 0,
        "title": "Efficient Federated Learning with Timely Update Dissemination",
        "section_head": "Moderately",
        "score": 0.9006996154785156,
        "text_preview": "Heterogeneous Highly Heterogeneous 0.0 0.2 0.4 0.6 0.8 Accuracy FedASMU FedAsync PORT ASO-Fed FedBuff FedSA 0 1 2 3 4 5 6 7 Time (s) √ó10 4 Time Accuracy (a) Asynchronous Moderately Heterogeneous Highl"
      },
      {
        "chunk_index": 38787,
        "paper_id": 816,
        "chunk_idx": 1,
        "title": "DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation",
        "section_head": "B. Adversary Model",
        "score": 0.8991186618804932,
        "text_preview": "Aggregation Protocol MNIST (IID) MNIST (non-IID) CIFAR-10 (IID) CIFAR-10 (non-IID) CIFAR-100 (IID) CIFAR-100 (non-IID) FedAvg [4] 80.67 ¬± 0.09 78.75 ¬± 0.12 52.56 ¬± 0.31 55.16 ¬± 0.25 8.85 ¬± 0.27 28.10 "
      },
      {
        "chunk_index": 52336,
        "paper_id": 1121,
        "chunk_idx": 1,
        "title": "FEDSSG: EXPECTATION-GATED AND HISTORY-AWARE DRIFT ALIGNMENT FOR FEDERATED LEARNING",
        "section_head": "Table 4 .",
        "score": 0.8975313901901245,
        "text_preview": "MNIST&DiD1 97.70¬±0.03 97.70¬±0.04 98.32¬±0.03 98.10¬±0.04 98.29¬±0.03 98.10¬±0.02 98.08¬±0.02 98.42¬±0.04 MNIST&DiD2 97.84¬±0.02 97.81¬±0.02 98.41¬±0.02 98.12¬±0.03 98.40¬±0.02 98.17¬±0.02 98.13¬±0.03 98.46¬±0.02 EM"
      },
      {
        "chunk_index": 53501,
        "paper_id": 1148,
        "chunk_idx": 1,
        "title": "Find a Scapegoat: Poisoning Membership Inference Attack and Defense to Federated Learning",
        "section_head": "Table 2 .",
        "score": 0.8878123164176941,
        "text_preview": "Dataset Attack IID DP Non-IID IID Top-k Non-IID IID FedAvg Non-IID IID Median Non-IID Trimmed-mean IID Non-IID IID ATM Non-IID Passive 0.650 0.626 0.646 0.623 0.643 0.616 0.583 0.566 0.630 0.606 0.600"
      }
    ]
  },
  {
    "query_id": 46,
    "query_text": "comprehensive performance analysis methods",
    "source": "section_head",
    "source_value": "Comprehensive Performance Analysis: Methods Comparison",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 64951,
        "paper_id": 1383,
        "chunk_idx": 0,
        "title": "HOW CAN QUANTUM DEEP LEARNING IMPROVE LARGE LANGUAGE MODELS?",
        "section_head": "CONCLUSION",
        "score": 0.9489392042160034,
        "text_preview": "This work provided a comprehensive survey and analysis of PEFT strategies for LLMs, including full tuning, LoRA, SoRA, Prefix tuning, and QAA. Through systematic evaluation, QAA is shown to deliver a "
      },
      {
        "chunk_index": 137848,
        "paper_id": 2840,
        "chunk_idx": 0,
        "title": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs",
        "section_head": "Overview",
        "score": 0.9441753625869751,
        "text_preview": "Our experimental design aims to investigate both the shortcomings of current evaluation methods and the effectiveness of simpler alternatives."
      },
      {
        "chunk_index": 13447,
        "paper_id": 269,
        "chunk_idx": 0,
        "title": "AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity",
        "section_head": "Conclusion",
        "score": 0.93270343542099,
        "text_preview": "This paper identifies the inherent answer ambiguity in association evaluation and validates its significant and unavoidable impact on evaluation reliability. To address this issue, we propose Asso-CiA"
      },
      {
        "chunk_index": 109979,
        "paper_id": 2283,
        "chunk_idx": 0,
        "title": "QAMRO: Quality-aware Adaptive Margin Ranking Optimization for Human-aligned Assessment of Audio Generation Systems",
        "section_head": "V. CONCLUSION AND FUTURE WORK",
        "score": 0.9096500277519226,
        "text_preview": "This study presents QAMRO, a ranking loss with qualityaware adaptive margins for human-aligned audio quality assessment. Evaluations on the AudioMOS Challenge 2025 benchmarks reveal that QAMRO signifi"
      },
      {
        "chunk_index": 44823,
        "paper_id": 955,
        "chunk_idx": 0,
        "title": "EVALUATING MULTIMODAL LARGE LANGUAGE MODELS ON SPOKEN SARCASM UNDERSTANDING",
        "section_head": "CONCLUSION",
        "score": 0.9035912156105042,
        "text_preview": "In this work, we presented the first systematic evaluation of LLMs and MLLMs for multimodal sarcasm detection, spanning English and Chinese datasets. Our study demonstrates that bimodal fusions, parti"
      },
      {
        "chunk_index": 17276,
        "paper_id": 350,
        "chunk_idx": 1,
        "title": "BESPOKE: BENCHMARK FOR SEARCH-AUGMENTED LARGE LANGUAGE MODEL PERSONALIZATION VIA DIAGNOSTIC FEEDBACK",
        "section_head": "META EVALUATION",
        "score": 0.9033951759338379,
        "text_preview": "This suggests that personalized evaluation requires more than a generic evaluator and instead calls for a framework designed specifically for personalization. Notably, incorporating diagnostic feedbac"
      },
      {
        "chunk_index": 929,
        "paper_id": 16,
        "chunk_idx": 0,
        "title": "A comprehensive taxonomy of hallucinations in Large Language Models",
        "section_head": "Limitations and open challenges",
        "score": 0.8985584378242493,
        "text_preview": "Despite advancements in automated evaluation, current benchmarks and metrics for hallucination detection in AI-generated content face several persistent limitations that impede comprehensive and compa"
      },
      {
        "chunk_index": 19669,
        "paper_id": 398,
        "chunk_idx": 0,
        "title": "BLEURT: Learning Robust Metrics for Text Generation",
        "section_head": "Conclusion",
        "score": 0.8972558975219727,
        "text_preview": "We presented BLEURT, a reference-based text generation metric for English. Because the metric is trained end-to-end, BLEURT can model human assessment with superior accuracy. Furthermore, pre-training"
      },
      {
        "chunk_index": 109385,
        "paper_id": 2268,
        "chunk_idx": 0,
        "title": "Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems",
        "section_head": "Conclusion",
        "score": 0.8946787118911743,
        "text_preview": "We present a RAG-based system to assist provenance analysis of archaeological artifacts. Expert evaluation shows that while visual retrieval yields mixed performance, the system achieves notably stron"
      },
      {
        "chunk_index": 75546,
        "paper_id": 1597,
        "chunk_idx": 1,
        "title": "Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation",
        "section_head": "D. 3.4 Reaction Prediction",
        "score": 0.8916948437690735,
        "text_preview": "These gains are attributed to the model's ability to leverage symbolic knowledge, reducing errors in low-data regimes. Newer models, such as RxnGPT, introduce multimodal conditioning, incorporating sp"
      },
      {
        "chunk_index": 44753,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Enhancement-Oriented Evaluation for LLMs",
        "score": 0.8897097110748291,
        "text_preview": "The predominant evaluation methods and benchmarks for LLMs have focused primarily on providing quantitative performance measures on specific tasks or multiple dimensions (Zhong et al., 2022; Jain et a"
      },
      {
        "chunk_index": 55154,
        "paper_id": 1181,
        "chunk_idx": 0,
        "title": "FlexiD-Fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model",
        "section_head": "Tri-modal Medical Image Fusion 4.2.1. Objective Evaluation",
        "score": 0.8885513544082642,
        "text_preview": "The comparison of objective evaluation metrics for tri-modal fusion experiments with existing SOTA methods (as shown in Table 1 ) demonstrates that FlexiD-Fuse excels in multiple key metrics, showcasi"
      },
      {
        "chunk_index": 7901,
        "paper_id": 151,
        "chunk_idx": 0,
        "title": "Advancing Reference-free Evaluation of Video Captions with Factual Analysis",
        "section_head": "Conclusion and Discussion",
        "score": 0.8878334760665894,
        "text_preview": "This work addresses the challenge of evaluating video captions across diverse domains without relying on human-annotated reference captions. We identified the limitations of existing metrics, and prop"
      },
      {
        "chunk_index": 15553,
        "paper_id": 310,
        "chunk_idx": 2,
        "title": "Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework",
        "section_head": "Limitations",
        "score": 0.8854243755340576,
        "text_preview": "Finally, while Flan-T5 combined with prompt learning yielded the best performance in workflow phrase generation, there remains considerable room for improvement. The achieved ROUGE scores, though demo"
      },
      {
        "chunk_index": 17537,
        "paper_id": 355,
        "chunk_idx": 0,
        "title": "Better Late Than Never: Evaluation of Latency Metrics for Simultaneous Speech-to-Text Translation",
        "section_head": "Conclusions",
        "score": 0.885261058807373,
        "text_preview": "In this paper, we presented the first systematic evaluation of latency metrics for SimulST across several aspects, such as diverse systems, language pairs, and operating under short-and long-form spee"
      },
      {
        "chunk_index": 144106,
        "paper_id": 2974,
        "chunk_idx": 0,
        "title": "TRUSTJUDGE: INCONSISTENCIES OF LLM-AS-A-JUDGE AND HOW TO ALLEVIATE THEM",
        "section_head": "Preprint",
        "score": 0.884391188621521,
        "text_preview": "Empirical results demonstrate that TrustJudge significantly reduces Score-Comparison inconsistency and Pairwise Transitivity inconsistency across various LLM architectures and scales. Crucially, these"
      },
      {
        "chunk_index": 106915,
        "paper_id": 2213,
        "chunk_idx": 1,
        "title": "Polarity Detection of Sustainable Detection Goals in News Text",
        "section_head": "Conclusions",
        "score": 0.8818238377571106,
        "text_preview": "As a result, the SDG-POD represents a demanding benchmark for future research, and we expect that the community will continue to adapt and advance in addressing this task. As an initial step in this d"
      },
      {
        "chunk_index": 45038,
        "paper_id": 960,
        "chunk_idx": 0,
        "title": "Evaluating Selective Encryption Against Gradient Inversion Attacks",
        "section_head": "Hybrid Significance Metrics.",
        "score": 0.8808923959732056,
        "text_preview": "Given that different significance metrics show varying effectiveness against different attacks, developing hybrid metrics that combine the strengths of multiple approaches could improve overall defens"
      },
      {
        "chunk_index": 22277,
        "paper_id": 456,
        "chunk_idx": 0,
        "title": "Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG",
        "section_head": "Experiment",
        "score": 0.8789860010147095,
        "text_preview": "The Causal-Counterfactual RAG is evaluated through a comparative study against Regular RAG to assess its performance across various metrics, providing a comprehensive understanding of its strengths an"
      },
      {
        "chunk_index": 81920,
        "paper_id": 1726,
        "chunk_idx": 0,
        "title": "LLMs as Architects and Critics for Multi-Source Opinion Summarization",
        "section_head": "Conclusion and Future Work",
        "score": 0.8757281303405762,
        "text_preview": "In this work, we extend multi-source opinion summarization (M-OS) by leveraging LLMs to generate comprehensive summaries integrating product metadata with customer reviews. Our framework introduces: ("
      }
    ]
  },
  {
    "query_id": 47,
    "query_text": "detailed analysis fashionmnist",
    "source": "section_head",
    "source_value": "C. Detailed Analysis on FashionMNIST",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 49166,
        "paper_id": 1050,
        "chunk_idx": 0,
        "title": "FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in Federated Learning",
        "section_head": "Table 3 :",
        "score": 0.942136824131012,
        "text_preview": "3 Ablation study on different modules of our method. Average accuracy for our method across all clients and all time steps.\"w/o\" stands for \"without\". Method F-MNIST CIFAR-10 CIFAR-100 w/o NCD 58.26 ¬±"
      },
      {
        "chunk_index": 105038,
        "paper_id": 2178,
        "chunk_idx": 0,
        "title": "pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models",
        "section_head": "Table 3 :",
        "score": 0.9410858154296875,
        "text_preview": "3 Accuracy comparison (%) on the Dirichlet Non-IID setting in CIFAR-10 and CIFAR-100 over 100 clients. Methods CIFAR-10 CIFAR-100 CLIP [1] 87.95 64.90 PromptFL"
      },
      {
        "chunk_index": 51124,
        "paper_id": 1095,
        "chunk_idx": 0,
        "title": "FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient Research",
        "section_head": "Table 6 :",
        "score": 0.9399257302284241,
        "text_preview": "6 Ablation experiment on the office-10 datasetResnet18FedGA ablation 68.75¬±2.80 58.84¬±0.45 64.38¬±3.19 77.63¬±4.72 67.40¬±1.30 7.28¬±1.61 0.07547¬±0.01582 FedGA 70.52¬±1.70 58.40¬±0.60 68.75¬±2.80 75.25¬±2.54 "
      },
      {
        "chunk_index": 66245,
        "paper_id": 1410,
        "chunk_idx": 0,
        "title": "Hypernetworks for Model-Heterogeneous Personalized Federated Learning",
        "section_head": "C.1 Additional Experiment with CIFAR-100/Tiny-ImageNet",
        "score": 0.9378395676612854,
        "text_preview": "We provide additional experiments over the CIFAR-100/Tiny-ImageNet datasets. Here, we compare MH-pFedHN and MH-pFedHNGD to the baselines on a small-scale setup of 10 clients. The results are presented"
      },
      {
        "chunk_index": 40418,
        "paper_id": 853,
        "chunk_idx": 0,
        "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout",
        "section_head": "Fig. 5 .",
        "score": 0.9364008903503418,
        "text_preview": "5 Fig. 5. Performance of FedDHAD and various baseline methods with LeNet on CIFAR-10."
      },
      {
        "chunk_index": 26820,
        "paper_id": 546,
        "chunk_idx": 0,
        "title": "Communication-Efficient Federated Learning with Adaptive Number of Participants",
        "section_head": "B Experiments Details",
        "score": 0.9280431270599365,
        "text_preview": "This section presents a thorough account of our experimental evaluation. In Section B.1, we show additional plots of test loss, accuracy, and client-count dynamics (see Figures 4 5 ). Section B.2 anal"
      },
      {
        "chunk_index": 43493,
        "paper_id": 924,
        "chunk_idx": 0,
        "title": "Enhancing the Effectiveness and Durability of Backdoor Attacks in Federated Learning through Maximizing Task Distinction",
        "section_head": "V. EXPERIMENTAL RESULTS",
        "score": 0.9267679452896118,
        "text_preview": "In this section, we present a comprehensive experimental results to evaluate the effectiveness of the proposed EDBA in comparison to other federated backdoor attack algorithms under different defense "
      },
      {
        "chunk_index": 122953,
        "paper_id": 2561,
        "chunk_idx": 0,
        "title": "SFedKD: Sequential Federated Learning with Discrepancy-Aware Multi-Teacher Knowledge Distillation",
        "section_head": "Table 1 :",
        "score": 0.923667848110199,
        "text_preview": "1 Test accuracy (%, mean¬±std on 5 trials) comparison of our SFedKD method to other baselines on several heterogeneous settings and datasets. FedSeq, CWC and our SFedKD are SFL methods, while other bas"
      },
      {
        "chunk_index": 2723,
        "paper_id": 51,
        "chunk_idx": 0,
        "title": "A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation",
        "section_head": "Experiment and analysis",
        "score": 0.9223470687866211,
        "text_preview": "We conduct a series of experimental validations for our proposed method, including performance comparisons with baseline methods, efficiency comparisons between DDPM and Feature-Guided Rectified Flow "
      },
      {
        "chunk_index": 18722,
        "paper_id": 379,
        "chunk_idx": 0,
        "title": "BI-GRPO: BIDIRECTIONAL OPTIMIZATION FOR JAIL-BREAK BACKDOOR INJECTION ON LLMS",
        "section_head": "Figure 2 :",
        "score": 0.9217740297317505,
        "text_preview": "2 Figure 2: Performance of various jailbreak backdoor attack methods on Llama2(7B) across multiple datasets: DAN, DNA, Addition, StrongRE-JECT, and ADVbench. Marked datasets are for stealthiness; unma"
      },
      {
        "chunk_index": 12057,
        "paper_id": 235,
        "chunk_idx": 0,
        "title": "ANYPORTAL: Zero-Shot Consistent Video Background Replacement",
        "section_head": "Table 2 .",
        "score": 0.9209935665130615,
        "text_preview": "2 Quantitative ablation studyMetricw/o Œ¥ p w/o Cst-Enh w/o RPA Full Fram-Acc ‚Üë 0.966 0.970 0.970 0.973 Tem-Con ‚Üë 0.989 0.961 0.987 0.993 ID-Psrv ‚Üì 0.329 0.353 0.371 0.313 Mtn-Psrv ‚Üë 0.987 0.973 0.984 "
      },
      {
        "chunk_index": 21391,
        "paper_id": 437,
        "chunk_idx": 0,
        "title": "Calibration-Aware Prompt Learning for Medical Vision-Language Models",
        "section_head": "Results",
        "score": 0.9198367595672607,
        "text_preview": "The results of our focal loss experiments are presented in the following tables: Table 7 shows the performance on histopathology datasets, while Table 8 presents results on X-ray datasets. Table 9 pro"
      },
      {
        "chunk_index": 53468,
        "paper_id": 1148,
        "chunk_idx": 0,
        "title": "Find a Scapegoat: Poisoning Membership Inference Attack and Defense to Federated Learning",
        "section_head": "Datasets",
        "score": 0.9190573692321777,
        "text_preview": "We assess our proposed attack, defense mechanism, and baseline methods using four real-world datasets: CIFAR-10 [28] , STL10 [12] , Texas100 [1], and FER2013 [21] . See Appendix B for details."
      },
      {
        "chunk_index": 129341,
        "paper_id": 2686,
        "chunk_idx": 0,
        "title": "Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select",
        "section_head": "D. Ablation Studies",
        "score": 0.9166399240493774,
        "text_preview": "Our results in Table I have already established that our champion HeteRo-Select configuration is superior to the main baselines. To further understand the impact of various hyperparameters and design "
      },
      {
        "chunk_index": 37918,
        "paper_id": 801,
        "chunk_idx": 0,
        "title": "DRAGD: A Federated Unlearning Data Reconstruction Attack Based on Gradient Differences",
        "section_head": "A. Experiment Setup 1) Dataset:",
        "score": 0.9164179563522339,
        "text_preview": "We evaluate DRAGD, DRAGDP,and FedANI using three datasets in our experiments including: MNIST, CIFAR-10, and LFW."
      },
      {
        "chunk_index": 32510,
        "paper_id": 682,
        "chunk_idx": 0,
        "title": "Degree of Staleness-Aware Data Updating in Federated Learning",
        "section_head": "Figure 6 :",
        "score": 0.9161428213119507,
        "text_preview": "6 Figure 6: Comparative analysis of test accuracy (Top) and cost (Bottom) versus communication rounds T under various strategies with CNN over Cifar-10."
      },
      {
        "chunk_index": 40385,
        "paper_id": 853,
        "chunk_idx": 0,
        "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout",
        "section_head": "Evaluation of Our Approach",
        "score": 0.912575900554657,
        "text_preview": "In this section, we present the experimental results for FedDH and FedAD. Then, we show the evaluation results of the combination of FedDH and FedAD, i.e., FedDHAD."
      },
      {
        "chunk_index": 45592,
        "paper_id": 973,
        "chunk_idx": 0,
        "title": "EXPANDING REASONING POTENTIAL IN FOUNDATION MODEL BY LEARNING DIVERSE CHAINS OF THOUGHT PATTERNS",
        "section_head": "D.6 ABLATION DETAILS",
        "score": 0.9125617742538452,
        "text_preview": "The details about ablation results are shown in Table 9 , corresponding to Table 3 in Section 3.3."
      },
      {
        "chunk_index": 24382,
        "paper_id": 492,
        "chunk_idx": 0,
        "title": "Choice Outweighs Effort: Facilitating Complementary Knowledge Fusion in Federated Learning via Re-calibration and Merit-discrimination",
        "section_head": "Table 4 .",
        "score": 0.912511944770813,
        "text_preview": "4 Single component ablation (s = 70). Method CINIC-10 CIFAR-10 EMNIST Backbone 34.73 ¬± 0.2 54.20 ¬± 0.1 55.37 ¬± 0.1 CFT 42.13 ¬± 0.2 59.67 ¬± 0.2 63.00 ¬± 0.2 MPS 40.19 ¬± 0.2 64.37 ¬± 0.1 63.57 ¬± 0.1 CCI 3"
      },
      {
        "chunk_index": 63584,
        "paper_id": 1357,
        "chunk_idx": 0,
        "title": "Heterogeneous Federated Learning with Prototype Alignment and Upscaling",
        "section_head": "Experiments",
        "score": 0.9108775854110718,
        "text_preview": "This section presents our experimental methodology, empirical results, and detailed analysis of convergence behavior."
      }
    ]
  },
  {
    "query_id": 48,
    "query_text": "algorithm federated broadcast global",
    "source": "section_head",
    "source_value": "Algorithm 1 Federated 3 :Broadcast global model w t to all clients 4 :",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 124056,
        "paper_id": 2586,
        "chunk_idx": 0,
        "title": "SimQFL: A Quantum Federated Learning Simulator with Real-Time Visualization",
        "section_head": "Algorithm 1",
        "score": 0.9868868589401245,
        "text_preview": "1 Quantum Federated Learning (QFL) Algorithm 1: Input: Number of global rounds R, local epochs K, clients N = {1, . . . , N }, learning rate Œ∑, number of shots M 2: Initialization: Initialize global m"
      },
      {
        "chunk_index": 43249,
        "paper_id": 918,
        "chunk_idx": 0,
        "title": "Enhancing Privacy Preservation and Reducing Analysis Time with Federated Transfer Learning in Digital Twins-based Computed Tomography Scan Analysis",
        "section_head": "Algorithm 1 1 : 5 : 6 : 8 : 9 :Update W global ; 10 :",
        "score": 0.9670440554618835,
        "text_preview": "11568910 Weighted Cloud Server Cycling Model UpdateThe central server has existing model parameters W global ; 2: Initialize Hn the set of participating hospitals; 3: for each update j = 0, 1, 2, . . "
      },
      {
        "chunk_index": 61882,
        "paper_id": 1321,
        "chunk_idx": 0,
        "title": "GRAMFEDDHAR: GRAPH BASED MULTIMODAL DIFFERENTIALLY PRIVATE FEDERATED HAR",
        "section_head": "Algorithm 1 4 : 5 : 6 : 9 :",
        "score": 0.9659138917922974,
        "text_preview": "14569 GRAMFEDDHAR: FEDERATED MULTIMODAL GCN WITH DIFFERENTIAL PRIVACY Input: Client set C; total rounds L; client sampling fraction q; DP parameters (C, œÉ); learning rate Œ∑, B batch size. Output: Glob"
      },
      {
        "chunk_index": 20048,
        "paper_id": 407,
        "chunk_idx": 0,
        "title": "Boosting Generalization Performance in Model-Heterogeneous Federated Learning Using Variational Transposed Convolution",
        "section_head": "10:",
        "score": 0.9575955867767334,
        "text_preview": "for epochs 1, ..., E: 11: f k ‚Üê f k -Œ∑‚àá f k L. ‚ñ∑ Update f k with SGD. 12: g k ‚Üê g k -Œ∑‚àá g k L tc , œà k ‚Üê œà k -Œ∑‚àá œà k L tc , œÉ k ‚Üê œÉ k -Œ∑‚àá œÉ k L tc . 13: for y ‚àà Y k : 14: c y k ‚Üê 1 |D y k | x‚ààD y k g "
      },
      {
        "chunk_index": 22937,
        "paper_id": 469,
        "chunk_idx": 0,
        "title": "Centralized vs. Federated Learning for Educational Data Mining: A Comparative Study on Student Performance Prediction with SAEB Microdata",
        "section_head": "#",
        "score": 0.9514447450637817,
        "text_preview": "Input : Num of rounds T , set of all clients K , FedProx param mu # Output : A trained global model with final weights w_T def Server_Execution (T , K , mu ) : # 1. Initialize global model at the serv"
      },
      {
        "chunk_index": 32505,
        "paper_id": 682,
        "chunk_idx": 0,
        "title": "Degree of Staleness-Aware Data Updating in Federated Learning",
        "section_head": "23 :",
        "score": 0.9367436170578003,
        "text_preview": "23 Upload updated local model w k (t + 1) to server. aggregates models: w(t+1) = N k=1 D k (t) D(t) w k (t+1). 26: end for 6 Experiment"
      },
      {
        "chunk_index": 51305,
        "paper_id": 1100,
        "chunk_idx": 1,
        "title": "FEDHK-MVFC: FEDERATED HEAT KERNEL MULTI-VIEW CLUSTERING",
        "section_head": "Main Federated Learning Process",
        "score": 0.9347844123840332,
        "text_preview": ", d h Initialize local cluster centers: A h (0) ‚Ñì = a h (0) kj(‚Ñì) c(‚Ñì)√ód h [‚Ñì] randomly or using FCM/k-means++ for all k = 1, . . . , c (‚Ñì), h = 1, . . . , s (‚Ñì), and j = 1, . . . , d h Initialize per"
      },
      {
        "chunk_index": 51958,
        "paper_id": 1114,
        "chunk_idx": 0,
        "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model",
        "section_head": "n 1 : 3 :",
        "score": 0.9301974773406982,
        "text_preview": "13 Sr = k‚ààSr n k 12: end for k : a client index, Œ∏ k : a client k local model parameter, L(Œ∏ k , D k ) : client k local data D k cost function, Œ∏ global : global model parameter, ¬µ: hyperparameter for"
      },
      {
        "chunk_index": 50328,
        "paper_id": 1078,
        "chunk_idx": 0,
        "title": "Federated Learning with Ad-hoc Adapter Insertions: The Case of Soft-Embeddings for Training Classifier-as-Retriever",
        "section_head": "A Algorithm",
        "score": 0.9298040270805359,
        "text_preview": "Algorithm 1: Training Classifier-as-Retriever with Soft-Embeddings using Federated Learning and Differential Privacy Input: T, E, {Œ± i , C (0) i , (œÉ 2 0,i ) (0) , Œ≤ i , Œ≥ i , z i } i‚ààM Output: Œ∏ (T +"
      },
      {
        "chunk_index": 50764,
        "paper_id": 1087,
        "chunk_idx": 0,
        "title": "Federated Split Learning with Improved Communication and Storage Efficiency",
        "section_head": "Algorithm 1 :",
        "score": 0.9203706979751587,
        "text_preview": "1 CSE-FSL: clients in the t-th global round1 Initial the number of batches of local training h, and the global aggregation happens after every c batches of local training, (i.e., C = c); 2 for each cl"
      },
      {
        "chunk_index": 51265,
        "paper_id": 1099,
        "chunk_idx": 0,
        "title": "FedHiP: Heterogeneity-Invariant Personalized Federated Learning Through Closed-Form Solutions",
        "section_head": "Algorithm 1 2 : 5 : 6 : 7 :",
        "score": 0.9187089800834656,
        "text_preview": "12567 Our proposed FedHiP scheme1: Input: The foundation model Backbone(‚Ä¢, Œò), the local training datasets {D k = (X k , Y k )} K k=1 .Output: The personalized models { Pk } K k=1 . 3: // Phase 1: Ana"
      },
      {
        "chunk_index": 3426,
        "paper_id": 66,
        "chunk_idx": 1,
        "title": "A Semi-Supervised Federated Learning Framework with Hierarchical Clustering Aggregation for Heterogeneous Satellite Networks",
        "section_head": "B. Satellite Federated Learning",
        "score": 0.9164929389953613,
        "text_preview": "During each FL aggregation round, the clients conduct e epochs of local training. The local gradient is computed using stochastic gradient descent (SGD), formulated as: ‚àá fi (w i m,e ) = ‚àá‚Ñì(w i m,e ; "
      },
      {
        "chunk_index": 24371,
        "paper_id": 492,
        "chunk_idx": 0,
        "title": "Choice Outweighs Effort: Facilitating Complementary Knowledge Fusion in Federated Learning via Re-calibration and Merit-discrimination",
        "section_head": "Algorithm 1 2 :",
        "score": 0.9128909111022949,
        "text_preview": "12 FedMate: Server-side Aggregation Procedure 1: Input: Total rounds T , number of clients N , learning rate Initialize global feature extractor ¬π 0 and global classifier œï 0 3: for each round t = 0, "
      },
      {
        "chunk_index": 34032,
        "paper_id": 717,
        "chunk_idx": 0,
        "title": "Differentially Private Federated Quantum Learning via Quantum Noise",
        "section_head": "F. Proposed Algorithm",
        "score": 0.9124999046325684,
        "text_preview": "Algorithm 1 Differentially Private Quantum Federated Learning (DP-QFL) 1: Input: Global rounds T , local epochs K, clients N , learning rate Œ∑, shots M . 2: Initialize: Global model œâ 0 . 3: for each "
      },
      {
        "chunk_index": 50364,
        "paper_id": 1079,
        "chunk_idx": 1,
        "title": "Federated Learning with Buffered Asynchronous Aggregation",
        "section_head": "Convergence Analysis",
        "score": 0.9104229211807251,
        "text_preview": "Hence, it is essential to understand the relationship between client computa- Algorithm 1 FedBuff-server Input: server learning rate Œ∑ g , client learning rate Œ∑ ‚Ñì , client SGD steps Q, buffer size K "
      },
      {
        "chunk_index": 51631,
        "paper_id": 1107,
        "chunk_idx": 0,
        "title": "FedOC: Multi-Server FL with Overlapping Client Relays in Wireless Edge Networks",
        "section_head": "III. System Model A. Federated Learning Basics",
        "score": 0.9082831740379333,
        "text_preview": "A classical single-server FL system consists of a CS and K clients indexed by the set K = {1, 2, . . . , K}, where each client k ‚àà K holds a local dataset D k of size n (k) . FL aims to solve the foll"
      },
      {
        "chunk_index": 91913,
        "paper_id": 1936,
        "chunk_idx": 0,
        "title": "Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks",
        "section_head": "Standard Federated Learning Model",
        "score": 0.9081219434738159,
        "text_preview": "Under the standard FL framework, we assume that N clients participate in FL, and each client xi, i ‚àà {1, 2, . . . , N } uses private and local data Di with datasize |Di| to train its local model. At e"
      },
      {
        "chunk_index": 51304,
        "paper_id": 1100,
        "chunk_idx": 0,
        "title": "FEDHK-MVFC: FEDERATED HEAT KERNEL MULTI-VIEW CLUSTERING",
        "section_head": "Main Federated Learning Process",
        "score": 0.9072753190994263,
        "text_preview": "The main federated learning process involves multiple communication rounds between the server and clients. It ensures that each client updates its local model based on the global model parameters rece"
      },
      {
        "chunk_index": 50887,
        "paper_id": 1091,
        "chunk_idx": 1,
        "title": "FedERL: Federated Efficient and Robust Learning for Common Corruptions",
        "section_head": "FedERL",
        "score": 0.9071736931800842,
        "text_preview": "In FedERL, after every T rob global rounds, the server robust trains the aggregated model f (w 0 ) via the DART method (Section 4.2), producing a robustness enhanced model f (w rob ) that is sent to c"
      },
      {
        "chunk_index": 100038,
        "paper_id": 2096,
        "chunk_idx": 0,
        "title": "Online Decentralized Federated Multi-task Learning With Trustworthiness in Cyber-Physical Systems",
        "section_head": "( 18 ) 1 :",
        "score": 0.9069953560829163,
        "text_preview": "181 From Algorithm 1, the local model and dual parameter of honest client v is initialized in Step 3. From Steps 4 -14, the algorithm iterates over T rounds. Each iteration round t starts from Step 5 "
      }
    ]
  },
  {
    "query_id": 49,
    "query_text": "model data",
    "source": "keyword_combination",
    "source_value": "model, data",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 22938,
        "paper_id": 469,
        "chunk_idx": 0,
        "title": "Centralized vs. Federated Learning for Educational Data Mining: A Comparative Study on Student Performance Prediction with SAEB Microdata",
        "section_head": "Figure 3 :",
        "score": 0.9530742168426514,
        "text_preview": "3 Figure 3: The data preprocessing pipeline, from raw data selection to the final model-ready dataset"
      },
      {
        "chunk_index": 147820,
        "paper_id": 3043,
        "chunk_idx": 0,
        "title": "Unsupervised Cross-lingual Representation Learning at Scale",
        "section_head": "Figure 7 :",
        "score": 0.9219983816146851,
        "text_preview": "7 Figure7: On the impact of largescale training, and preprocessing simplification from BPE with tokenization to SPM on raw text data."
      },
      {
        "chunk_index": 54172,
        "paper_id": 1162,
        "chunk_idx": 0,
        "title": "FINITE SCALAR QUANTIZATION ENABLES REDUNDANT AND TRANSMISSION-ROBUST NEURAL AUDIO COMPRESSION AT LOW BIT-RATES",
        "section_head": "Table 1.",
        "score": 0.9206926822662354,
        "text_preview": "NeuCodec Training Data Sources."
      },
      {
        "chunk_index": 14641,
        "paper_id": 294,
        "chunk_idx": 0,
        "title": "Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars NVIDIA",
        "section_head": "Figure 17 :",
        "score": 0.9115321636199951,
        "text_preview": "17 Figure17: Experiments with training data."
      },
      {
        "chunk_index": 19316,
        "paper_id": 389,
        "chunk_idx": 0,
        "title": "Biomni: A General-Purpose Biomedical AI Agent",
        "section_head": "fit genomic prediction model",
        "score": 0.9098337292671204,
        "text_preview": "Fit a linear mixed model for genomic prediction using genotype and phenotype data."
      },
      {
        "chunk_index": 87702,
        "paper_id": 1847,
        "chunk_idx": 0,
        "title": "MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents",
        "section_head": "Figure 9 :",
        "score": 0.9078104496002197,
        "text_preview": "9 Figure 9: Construction of Isolation Forest training data and model training."
      },
      {
        "chunk_index": 77361,
        "paper_id": 1636,
        "chunk_idx": 0,
        "title": "learning-features-2009-TR.tei",
        "section_head": "Chapter 4",
        "score": 0.9070094227790833,
        "text_preview": "Parallelizing the training of RBMs"
      },
      {
        "chunk_index": 71868,
        "paper_id": 1531,
        "chunk_idx": 0,
        "title": "JEL: A Novel Model Linking Knowledge Graph entities to News Mentions",
        "section_head": "Figure 3 :",
        "score": 0.8985767364501953,
        "text_preview": "3 Figure 3: Data Process Pipeline"
      },
      {
        "chunk_index": 157422,
        "paper_id": 3225,
        "chunk_idx": 0,
        "title": "œÑ¬≤-Bench (Average)",
        "section_head": "Figure 3 :",
        "score": 0.8911024332046509,
        "text_preview": "3 Figure 3: The data curation pipeline for cold-start training."
      },
      {
        "chunk_index": 81780,
        "paper_id": 1723,
        "chunk_idx": 0,
        "title": "LLM4Decompile: Decompiling Binary Code with Large Language Models",
        "section_head": "Figure 6 :",
        "score": 0.8890869617462158,
        "text_preview": "6 Figure 6: Compilable data and Executable data."
      },
      {
        "chunk_index": 16360,
        "paper_id": 327,
        "chunk_idx": 0,
        "title": "Bangla BERT for Hyperpartisan News Detection: A Semi-Supervised and Explainable AI Approach",
        "section_head": "III. Data Preparation",
        "score": 0.8884550333023071,
        "text_preview": "We follow four key steps: dataset collection, data preprocessing, data augmentation, and data description prior to feeding the data into the model."
      },
      {
        "chunk_index": 3786,
        "paper_id": 76,
        "chunk_idx": 0,
        "title": "A STUDY ON DATA AUGMENTATION OF REVERBERANT SPEECH FOR ROBUST SPEECH RECOGNITION",
        "section_head": "Table 3 .",
        "score": 0.8848698139190674,
        "text_preview": "3 Comparison of systems on various AMI tasks.The rvb-IHM data is generated by using simulated RIRs and point-source noises. LVCSR task Training data dev eval IHM IHM data 22.4 22.5 IHM IHM + rvb-IHM d"
      },
      {
        "chunk_index": 124943,
        "paper_id": 2608,
        "chunk_idx": 0,
        "title": "SLiC-HF: Sequence Likelihood Calibration with Human Feedback",
        "section_head": "Ranking Model [CONTEXT] document [SUMMARY A] positive summary [SUMMARY B] negative summary ‚Üí A [CONTEXT] document [SUMMARY A] negative summary [SUMMARY B] positive summary ‚Üí B",
        "score": 0.8749147653579712,
        "text_preview": "Figure 1 : Training text-to-text reward model and ranking model."
      },
      {
        "chunk_index": 25100,
        "paper_id": 507,
        "chunk_idx": 0,
        "title": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation",
        "section_head": "Server",
        "score": 0.870091438293457,
        "text_preview": "High-Resolution Supervised Training Aggregated Model ..."
      },
      {
        "chunk_index": 26075,
        "paper_id": 527,
        "chunk_idx": 0,
        "title": "CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks",
        "section_head": "Fig. 3 :",
        "score": 0.8686694502830505,
        "text_preview": "3 Fig.3: Entire on-device training model with pipelines."
      },
      {
        "chunk_index": 7530,
        "paper_id": 142,
        "chunk_idx": 0,
        "title": "ADDRESSING GRADIENT MISALIGNMENT IN DATA-AUGMENTED TRAINING FOR ROBUST SPEECH DEEPFAKE DETECTION",
        "section_head": "Fig. 2 .",
        "score": 0.8673454523086548,
        "text_preview": "2 Fig. 2. Training loss and backpropagated gradient norm of orignal x and augmented x inputs during the DPDA training of XLSR-Conformer-TCM model."
      },
      {
        "chunk_index": 87046,
        "paper_id": 1833,
        "chunk_idx": 0,
        "title": "MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models",
        "section_head": "Table 1 :",
        "score": 0.8666224479675293,
        "text_preview": "1 Statistics of the collected data. \"Raw\" and \"Instruction\" denote the split sample numbers for the raw data and converted instruction data in the IMHI dataset. \"Annotation\" denotes the reliability of"
      },
      {
        "chunk_index": 9851,
        "paper_id": 187,
        "chunk_idx": 0,
        "title": "ALPAGASUS: TRAINING A BETTER ALPACA WITH FEWER DATA",
        "section_head": "Figure 10 :",
        "score": 0.861303985118866,
        "text_preview": "10 Figure 10: Comparing models finetuned on filtered 3k data and original Dolly 15k data."
      },
      {
        "chunk_index": 75942,
        "paper_id": 1605,
        "chunk_idx": 0,
        "title": "Latent Gene Diffusion for Spatial Transcriptomics Completion",
        "section_head": "Figure 8 .",
        "score": 0.8607471585273743,
        "text_preview": "8 Figure 8. (a) MSE and (b) PCC of gene-expression prediction models when trained onLGDiST-completed data compared to training on data completed with SpaCKLE [18] ."
      },
      {
        "chunk_index": 110920,
        "paper_id": 2305,
        "chunk_idx": 0,
        "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
        "section_head": "Figure 5 :",
        "score": 0.8542121052742004,
        "text_preview": "5 Figure 5: Visualization of the Grounding and OCR data used for training Qwen-VL"
      }
    ]
  },
  {
    "query_id": 50,
    "query_text": "models figure",
    "source": "keyword_combination",
    "source_value": "models, figure",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 120931,
        "paper_id": 2517,
        "chunk_idx": 0,
        "title": "Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers",
        "section_head": "Figure 33 :",
        "score": 0.9909281730651855,
        "text_preview": "33 Figure 33: Qualitative results of trained models."
      },
      {
        "chunk_index": 147144,
        "paper_id": 3029,
        "chunk_idx": 0,
        "title": "UnIVAL: Unified Model for Image, Video, Audio and Language Tasks",
        "section_head": "Figure 2 :",
        "score": 0.9290745258331299,
        "text_preview": "2 Figure 2: Weight interpolation between models trained on different multimodal tasks."
      },
      {
        "chunk_index": 103422,
        "paper_id": 2141,
        "chunk_idx": 0,
        "title": "PaLM: Scaling Language Modeling with Pathways",
        "section_head": "Figure 15 :",
        "score": 0.9233563542366028,
        "text_preview": "15 Figure 15: Comparison of PaLM on 0-shot translation tasks. (left) Comparison with previous large language models. (right) Comparison of different PaLM model scales."
      },
      {
        "chunk_index": 118668,
        "paper_id": 2475,
        "chunk_idx": 0,
        "title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning",
        "section_head": "Figure 7 :",
        "score": 0.9230384826660156,
        "text_preview": "7 Figure 7: Qualitative examples showing our SFT-CM3Leon-7B model's generations for various long form generation tasks."
      },
      {
        "chunk_index": 43084,
        "paper_id": 914,
        "chunk_idx": 0,
        "title": "Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation",
        "section_head": "Figure 9 :6 Results and Discussion 6 . 1",
        "score": 0.917820155620575,
        "text_preview": "961 Figure 9: Figure shows the comparison between results with and without RA for language models."
      },
      {
        "chunk_index": 89824,
        "paper_id": 1892,
        "chunk_idx": 0,
        "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI",
        "section_head": "Figure 4 .",
        "score": 0.9074196815490723,
        "text_preview": "4 Figure 4. Performance of models on different types of images."
      },
      {
        "chunk_index": 54890,
        "paper_id": 1174,
        "chunk_idx": 0,
        "title": "FLASK: FINE-GRAINED LANGUAGE MODEL EVALUATION BASED ON ALIGNMENT SKILL SETS",
        "section_head": "Figure 21 :",
        "score": 0.9039136171340942,
        "text_preview": "21 Figure 20: Comparing GPT-3.5, VICUNA 13B, SELFEE 13B via FLASK."
      },
      {
        "chunk_index": 71054,
        "paper_id": 1516,
        "chunk_idx": 0,
        "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents",
        "section_head": "Figure 5 :",
        "score": 0.9006801843643188,
        "text_preview": "5 Figure 5: Model architecture of BERT-like and GPT-like specialized models."
      },
      {
        "chunk_index": 131752,
        "paper_id": 2726,
        "chunk_idx": 0,
        "title": "STYLEBENCH: EVALUATING THINKING STYLES IN LARGE LANGUAGE MODELS",
        "section_head": "Figure 10 :",
        "score": 0.8953300714492798,
        "text_preview": "10 Figure 10: Accuracy Heatmap for large models"
      },
      {
        "chunk_index": 80450,
        "paper_id": 1696,
        "chunk_idx": 0,
        "title": "LLAMA-ADAPTER: EFFICIENT FINE-TUNING OF LARGE LANGUAGE MOD-ELS WITH ZERO-INITIALIZED ATTENTION",
        "section_head": "Figure 9 :",
        "score": 0.893753170967102,
        "text_preview": "9 Figure 9: Zero-shot Multi-modal Understanding Examples of LLaMA-Adapter: Part 1."
      },
      {
        "chunk_index": 80451,
        "paper_id": 1696,
        "chunk_idx": 0,
        "title": "LLAMA-ADAPTER: EFFICIENT FINE-TUNING OF LARGE LANGUAGE MOD-ELS WITH ZERO-INITIALIZED ATTENTION",
        "section_head": "Figure 10 :",
        "score": 0.8937408924102783,
        "text_preview": "10 Figure 10: Zero-shot Multi-modal Understanding Examples of LLaMA-Adapter: Part 2."
      },
      {
        "chunk_index": 32362,
        "paper_id": 678,
        "chunk_idx": 0,
        "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models",
        "section_head": "Figure 3 |",
        "score": 0.892936646938324,
        "text_preview": "3 Figure 3 | Benchmark curves of DeepSeek-LLM 1.3B trained on different mathematical corpora."
      },
      {
        "chunk_index": 117812,
        "paper_id": 2461,
        "chunk_idx": 0,
        "title": "SAMBA: SIMPLE HYBRID STATE SPACE MODELS FOR EFFICIENT UNLIMITED CONTEXT LANGUAGE MODELING",
        "section_head": "Figure 6 :Figure 7 :",
        "score": 0.890832781791687,
        "text_preview": "67 Figure 6: Prompt processing throughput of different models with around 1.7B parameters."
      },
      {
        "chunk_index": 39514,
        "paper_id": 837,
        "chunk_idx": 0,
        "title": "EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs",
        "section_head": "Figure 1 :",
        "score": 0.8874973654747009,
        "text_preview": "1 Figure 1: Comparison of training strategies across different models."
      },
      {
        "chunk_index": 85881,
        "paper_id": 1810,
        "chunk_idx": 0,
        "title": "MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING",
        "section_head": "Figure 6 :",
        "score": 0.8868155479431152,
        "text_preview": "6 Figure 6: GPT-3 (few-shot) and UnifiedQA results."
      },
      {
        "chunk_index": 7815,
        "paper_id": 149,
        "chunk_idx": 0,
        "title": "Advancing Medical Artificial Intelligence Using a Century of Cases",
        "section_head": "Figure 2 :Figure 2 :",
        "score": 0.884070873260498,
        "text_preview": "22 Figure 2: Performance of Frontier Models on CPC-Bench"
      },
      {
        "chunk_index": 25591,
        "paper_id": 515,
        "chunk_idx": 0,
        "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
        "section_head": "Figure 4 :",
        "score": 0.8835498690605164,
        "text_preview": "4 Figure 4: Comparison of CoCa with other image-text foundation models (without task-specific customization) and multiple state-of-the-art task-specialized models."
      },
      {
        "chunk_index": 42003,
        "paper_id": 886,
        "chunk_idx": 0,
        "title": "Emergent Abilities of Large Language Models",
        "section_head": "DFigure 11 :",
        "score": 0.8824828863143921,
        "text_preview": "11 Figures 11, 12, and 13 shows emergent abilities with an x-axis of number of model parameters."
      },
      {
        "chunk_index": 30548,
        "paper_id": 638,
        "chunk_idx": 0,
        "title": "DATALESS KNOWLEDGE FUSION BY MERGING WEIGHTS OF LANGUAGE MODELS",
        "section_head": "Figure 2 :",
        "score": 0.8820786476135254,
        "text_preview": "2 Figure 2: Comparison between Simple, Fisher, and RegMean for merging transformer-based language models."
      },
      {
        "chunk_index": 136490,
        "paper_id": 2822,
        "chunk_idx": 0,
        "title": "The Claude 3 Model Family: Opus, Sonnet, Haiku",
        "section_head": "Figure 10",
        "score": 0.8794364929199219,
        "text_preview": "This figure shows results from the Multilingual MMLU evaluation on Claude 3 models."
      }
    ]
  },
  {
    "query_id": 51,
    "query_text": "from llms",
    "source": "keyword_combination",
    "source_value": "from, llms",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 10797,
        "paper_id": 209,
        "chunk_idx": 0,
        "title": "An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques",
        "section_head": "Table 6 :",
        "score": 0.9660624861717224,
        "text_preview": "6 Performance of LLMs on NewsRoom dataset using ZSL."
      },
      {
        "chunk_index": 10802,
        "paper_id": 209,
        "chunk_idx": 0,
        "title": "An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques",
        "section_head": "Table 11 :",
        "score": 0.9322472810745239,
        "text_preview": "11 Performance of LLMs on the SAMSum dataset with ICL."
      },
      {
        "chunk_index": 7200,
        "paper_id": 135,
        "chunk_idx": 0,
        "title": "Adaptive LLM Routing Under Budget Constraints",
        "section_head": "Dataset",
        "score": 0.9037320613861084,
        "text_preview": "We evaluate our proposed method using Routerbench (Hu et al., 2024) , a comprehensive LLM routing dataset spanning a wide range of tasks including commonsense reasoning, knowledge-based language under"
      },
      {
        "chunk_index": 12214,
        "paper_id": 238,
        "chunk_idx": 0,
        "title": "APIGen: Automated PIpeline for Generating Verifiable and Diverse Function-Calling Datasets",
        "section_head": "Benchmark.",
        "score": 0.8957782983779907,
        "text_preview": "We evaluate the trained models' performance on the Berkeley Function-Calling Benchmark (BFCL) [9] , which provides a comprehensive evaluation framework for assessing the function-calling capabilities "
      },
      {
        "chunk_index": 144892,
        "paper_id": 2985,
        "chunk_idx": 1,
        "title": "T√ºlu 3: Pushing Frontiers in Open Language Model Post-Training NathanLambert",
        "section_head": "Safety Evaluation",
        "score": 0.884492039680481,
        "text_preview": "We evaluated on a subset of harmful prompts which consists of 321 harmful prompts 21 categorized into Functional and Semantic categories. Functional category includes two types of behavior: Standard b"
      },
      {
        "chunk_index": 81290,
        "paper_id": 1715,
        "chunk_idx": 0,
        "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators",
        "section_head": "Code Execution:",
        "score": 0.8816847801208496,
        "text_preview": "Utilized primarily for generating data visualizations like charts, graphs, and plots from structured data. We use Python as the programming language and build a controlled sandbox environment."
      },
      {
        "chunk_index": 142199,
        "paper_id": 2932,
        "chunk_idx": 0,
        "title": "Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages",
        "section_head": "Framework",
        "score": 0.8806134462356567,
        "text_preview": "We introduce SGToxicGuard, a dataset designed to evaluate the safety and vulnerability of LLMs across Singapore's four common languages: Singlish, Chinese, Malay, and Tamil. Our framework aims to answ"
      },
      {
        "chunk_index": 65139,
        "paper_id": 1387,
        "chunk_idx": 0,
        "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective",
        "section_head": "Evaluation",
        "score": 0.8767287135124207,
        "text_preview": "We evaluate plans generated by six families of LLMs, across four prompt types and two PDDL domains."
      },
      {
        "chunk_index": 142193,
        "paper_id": 2932,
        "chunk_idx": 3,
        "title": "Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages",
        "section_head": "Introduction",
        "score": 0.8732703924179077,
        "text_preview": "Our study targets Singlish, Malay, and Tamil as primary low-resource languages, alongside English and Chinese to reflect Singapore's multilingual society. We assess LLM safety through three real-world"
      },
      {
        "chunk_index": 10804,
        "paper_id": 209,
        "chunk_idx": 0,
        "title": "An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques",
        "section_head": "Table 12 :",
        "score": 0.8702487349510193,
        "text_preview": "12 Performance of LLMs on the Arxiv dataset with ICL."
      },
      {
        "chunk_index": 10799,
        "paper_id": 209,
        "chunk_idx": 0,
        "title": "An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques",
        "section_head": "Table 8 :",
        "score": 0.8655624389648438,
        "text_preview": "8 Performance of LLMs on the Arxiv dataset with ZSL."
      },
      {
        "chunk_index": 144219,
        "paper_id": 2975,
        "chunk_idx": 2,
        "title": "TRUSTLLM: TRUSTWORTHINESS IN LARGE LANGUAGE MODELS -A PRINCIPLE AND BENCHMARK",
        "section_head": "Dataset Description",
        "score": 0.8638348579406738,
        "text_preview": "1300 Jailbreak( ¬ß7.1) ,Toxicity( ¬ß7.3) MISUSE (ADDITIONAL) This dataset contains prompts crafted to assess how LLMs react when confronted by attackers or malicious users seeking to exploit the model f"
      },
      {
        "chunk_index": 10795,
        "paper_id": 209,
        "chunk_idx": 0,
        "title": "An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques",
        "section_head": "Table 5 :",
        "score": 0.8616445064544678,
        "text_preview": "5 Performance of LLMs on CNN/DM dataset using ZSL."
      },
      {
        "chunk_index": 4543,
        "paper_id": 84,
        "chunk_idx": 1,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Synthesis Data",
        "score": 0.8610981702804565,
        "text_preview": "Unnatural Instructions (Honovich et al., 2022) stands out as a substantial dataset of innovative instructions, comprising 64,000 examples generated by LLMs through seed examples and rephrasing, result"
      },
      {
        "chunk_index": 1918,
        "paper_id": 33,
        "chunk_idx": 0,
        "title": "A Generalist Agent",
        "section_head": "Data",
        "score": 0.854143500328064,
        "text_preview": "The vision and language datasets used include racist, sexist, and otherwise harmful context. Risks and Harms In addition to the potential harms of toxic image and language training data, Gato's real w"
      },
      {
        "chunk_index": 12196,
        "paper_id": 238,
        "chunk_idx": 1,
        "title": "APIGen: Automated PIpeline for Generating Verifiable and Diverse Function-Calling Datasets",
        "section_head": "Related Work",
        "score": 0.8507598638534546,
        "text_preview": "APIBank [12] is a benchmark designed for tool-augmented LLMs, providing a training set containing tool-use dialogues from various APIs. Toolalpaca [30] constructs a varied and well-structured tool-use"
      },
      {
        "chunk_index": 16906,
        "paper_id": 342,
        "chunk_idx": 0,
        "title": "Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem",
        "section_head": "Human Benchmark",
        "score": 0.8494313955307007,
        "text_preview": "To establish a benchmark for humans, We randomly select 200 samples from UMWP, ensuring the distribution of these samples across different categories remains consistent with the original dataset. Subs"
      },
      {
        "chunk_index": 153737,
        "paper_id": 3151,
        "chunk_idx": 0,
        "title": "When Ads Become Profiles: Large-Scale Audit of Algorithmic Biases and LLM Profiling Risks",
        "section_head": "Dataset",
        "score": 0.8488191366195679,
        "text_preview": "For this study, we utilise a large-scale, longitudinal dataset from a data donation project. The project recruits volunteer participants from the Australian public to donate data about the advertiseme"
      },
      {
        "chunk_index": 83637,
        "paper_id": 1760,
        "chunk_idx": 0,
        "title": "Magicoder: Empowering Code Generation with OSS-INSTRUCT",
        "section_head": "OSS-INSTRUCT: Instruction Tuning from Open Source",
        "score": 0.8485308885574341,
        "text_preview": "In this section, we elaborate on our OSS-INSTRUCT approach. From a high level, as shown in Figure 1 , OSS-INSTRUCT works by prompting an LLM (e.g., ChatGPT) to generate a coding problem and its soluti"
      },
      {
        "chunk_index": 97050,
        "paper_id": 2048,
        "chunk_idx": 1,
        "title": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
        "section_head": "Appendix",
        "score": 0.8484297394752502,
        "text_preview": "14 C Limitations 14 D Supplementary Experiments 14 A Oblivionis Details A.1 Benchmarks Oblivionis includes multiple unlearning benchmarks, each designed to target specific aspects of forgetting in LLM"
      }
    ]
  },
  {
    "query_id": 52,
    "query_text": "performance training",
    "source": "keyword_combination",
    "source_value": "performance, training",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 79074,
        "paper_id": 1667,
        "chunk_idx": 0,
        "title": "Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis Dissertation",
        "section_head": "Figure 3 . 5 :",
        "score": 0.9666767120361328,
        "text_preview": "35 Figure 3.5: Performance by training data size"
      },
      {
        "chunk_index": 63920,
        "paper_id": 1364,
        "chunk_idx": 0,
        "title": "Hierarchical Federated Learning for Social Network with Mobility",
        "section_head": "Fig. 6 .",
        "score": 0.9493855237960815,
        "text_preview": "6 Fig.6. Impact of redundant data and effective data on model performance."
      },
      {
        "chunk_index": 79084,
        "paper_id": 1667,
        "chunk_idx": 0,
        "title": "Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis Dissertation",
        "section_head": "Figure 4 . 6 :",
        "score": 0.9461876153945923,
        "text_preview": "46 Figure 4.6: Performance by training data size: data-level fusion model"
      },
      {
        "chunk_index": 45925,
        "paper_id": 981,
        "chunk_idx": 0,
        "title": "EXPLOITING TREE STRUCTURE FOR CREDIT ASSIGN-MENT IN RL TRAINING OF LLMS",
        "section_head": "Figure 8 :",
        "score": 0.9460721015930176,
        "text_preview": "8 Figure 8: Training vs. validation accuracy on MedQA with Qwen3-4B. PPO overfits to training data, while TEMPO maintains better generalization."
      },
      {
        "chunk_index": 20577,
        "paper_id": 417,
        "chunk_idx": 0,
        "title": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry",
        "section_head": "The Data",
        "score": 0.9353277683258057,
        "text_preview": "The quality and representativeness of training data is fundamental to the performance and generalizability of any ML model."
      },
      {
        "chunk_index": 79187,
        "paper_id": 1670,
        "chunk_idx": 0,
        "title": "LEVERAGING MULTIPLE SPEECH ENHANCERS FOR NON-INTRUSIVE INTELLIGIBILITY PREDICTION FOR HEARING-IMPAIRED LISTENERS",
        "section_head": "Cross Dataset Generalization",
        "score": 0.9207481741905212,
        "text_preview": "Regarding cross-dataset generalization (Table 3 ), both the CPC2 Champion and our ZipEnhancer + MP-SENet model exhibit performance degradation on unseen datasets. Augmenting with NH data yields minima"
      },
      {
        "chunk_index": 7533,
        "paper_id": 142,
        "chunk_idx": 0,
        "title": "ADDRESSING GRADIENT MISALIGNMENT IN DATA-AUGMENTED TRAINING FOR ROBUST SPEECH DEEPFAKE DETECTION",
        "section_head": "Table 3 .",
        "score": 0.8940490484237671,
        "text_preview": "3 Performance of the XLSR-Conformer-TCM model comparing dual-path data-augmented training with and without gradient alignment across various data augmentation methods. .69 10.46 7.46* w/ DPDA training"
      },
      {
        "chunk_index": 75942,
        "paper_id": 1605,
        "chunk_idx": 0,
        "title": "Latent Gene Diffusion for Spatial Transcriptomics Completion",
        "section_head": "Figure 8 .",
        "score": 0.8866618871688843,
        "text_preview": "8 Figure 8. (a) MSE and (b) PCC of gene-expression prediction models when trained onLGDiST-completed data compared to training on data completed with SpaCKLE [18] ."
      },
      {
        "chunk_index": 63400,
        "paper_id": 1352,
        "chunk_idx": 0,
        "title": "HausaMovieReview: A Benchmark Dataset for Sentiment Analysis in Low-Resource African Language",
        "section_head": "Figure 7 Figure 7",
        "score": 0.8860374689102173,
        "text_preview": "77 Figure 7 Training and Validation Loss during RoBERTa Model Fine-tuning Figure 7 illustrates the progression of training loss and validation loss for the RoBERTa model across various training steps."
      },
      {
        "chunk_index": 12456,
        "paper_id": 245,
        "chunk_idx": 0,
        "title": "ArabEmoNet: A Lightweight Hybrid 2D CNN-BiLSTM Model with Attention for Robust Arabic Speech Emotion Recognition",
        "section_head": "Data Augmentation",
        "score": 0.8852436542510986,
        "text_preview": "To assess the contribution of data augmentation to the model's robustness and generalization, we compared the performance of our model trained with and without augmentation techniques on the KSUEmotio"
      },
      {
        "chunk_index": 146347,
        "paper_id": 3016,
        "chunk_idx": 0,
        "title": "UniCoM: A Universal Code-Switching Speech Generator",
        "section_head": "Finally, to evaluate the actual contribution of CS-FLEURS to CS-ASR performance, we conducted experiments using the aforementioned two ID human-generated CS datasets along with corresponding language pairs in CS-FLEURS (CSF).",
        "score": 0.8846906423568726,
        "text_preview": "We ensured an equal-sized training set for each experiment and fine-tuned XLS-R with a concatenated vocabulary for our CS-ASR model. English-German Pair. As shown in Table 6 , training the CS-ASR mode"
      },
      {
        "chunk_index": 95876,
        "paper_id": 2021,
        "chunk_idx": 0,
        "title": "No Language Left Behind: Scaling Human-Centered Machine Translation",
        "section_head": "Figure 34 :",
        "score": 0.8800758719444275,
        "text_preview": "34 Figure34: Comparing Model Performance when trained on data from various sources. We observe significant improvements on adding Mined and MmtBT+SmtBT backtranslated data for all type of language pai"
      },
      {
        "chunk_index": 139265,
        "paper_id": 2869,
        "chunk_idx": 0,
        "title": "THINK BEFORE YOU SPEAK: TRAINING LANGUAGE MODELS WITH PAUSE TOKENS",
        "section_head": "Figure 3 :",
        "score": 0.8767877221107483,
        "text_preview": "3 Figure 3: Downstream performance for a 1B model. Injecting delays in both stages of training (PausePT PauseFT) outperforms the standard end-end training StdPT StdFT on our wide variety of tasks (exc"
      },
      {
        "chunk_index": 87858,
        "paper_id": 1850,
        "chunk_idx": 1,
        "title": "MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs",
        "section_head": "Integration of Multitask Data",
        "score": 0.8750588893890381,
        "text_preview": "As mentioned in Section 3.4, MindVL undergoes a three-phase training pipeline: warm-up, multi-task learning, and SFT. We denote the model trained on such recipe as MindVL-3Phase. Table 7 shows the res"
      },
      {
        "chunk_index": 20312,
        "paper_id": 411,
        "chunk_idx": 0,
        "title": "BoreaRL: A Multi-Objective Reinforcement Learning Environment for Climate-Adaptive Boreal Forest Management",
        "section_head": "Figure 9 :",
        "score": 0.8733536005020142,
        "text_preview": "9 Figure 9: Individual objective performance analysis. (a) Carbon learning curves during training. (b) Thaw learning curves during training. (c) Carbon performance during evaluation. (d) Thaw performa"
      },
      {
        "chunk_index": 88813,
        "paper_id": 1866,
        "chunk_idx": 0,
        "title": "Mitigating Data Exfiltration Attacks through Layer-Wise Learning Rate Decay Fine-Tuning",
        "section_head": "Fig. 1 .",
        "score": 0.8721098899841309,
        "text_preview": "1 Fig.1. Overview of our export-time mitigation. A malicious model trained on the data lake may retain both utility and private data. At export, we apply LWLRD FT using training data to disrupt early-"
      },
      {
        "chunk_index": 71126,
        "paper_id": 1518,
        "chunk_idx": 0,
        "title": "Is Diversity All You Need for Scalable Robotic Manipulation?",
        "section_head": "C. Distribution Debiasing in the Fine-tuning Phase",
        "score": 0.8696329593658447,
        "text_preview": "Due to the substantial computational cost of pre-training, in this section we explore the effectiveness of applying distribution debiasing exclusively during the fine-tuning stage. For the Wipe Table "
      },
      {
        "chunk_index": 148889,
        "paper_id": 3068,
        "chunk_idx": 0,
        "title": "VCRL: VARIANCE-BASED CURRICULUM REINFORCE-MENT LEARNING FOR LARGE LANGUAGE MODELS",
        "section_head": "PERFORMANCE TREND",
        "score": 0.8662265539169312,
        "text_preview": "During RL training, the LLM starts with low ability and steadily improves, showing an upward trend on benchmark tests. To illustrate how VCRL compares to baseline methods during training, we show how "
      },
      {
        "chunk_index": 32344,
        "paper_id": 678,
        "chunk_idx": 1,
        "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models",
        "section_head": "Code Training Benefits Mathematical Reasoning",
        "score": 0.8658762574195862,
        "text_preview": "To study how code training affects mathematical reasoning, we experimented with the following two-stage training and one-stage training settings: Results Table 6 and Table 7 demonstrate the downstream"
      },
      {
        "chunk_index": 102851,
        "paper_id": 2133,
        "chunk_idx": 0,
        "title": "P 2 U: Progressive Precision Update For Efficient Model Distribution",
        "section_head": "Table 4 :",
        "score": 0.861606776714325,
        "text_preview": "4 Performance of VGG16 on PASCAL-VOC using P 2 U at different quantization levels. P 2 U consistently improves Top-1 accuracy with slight increase of startup time and bandwidth usage across all bit-wi"
      }
    ]
  },
  {
    "query_id": 53,
    "query_text": "learning dataset",
    "source": "keyword_combination",
    "source_value": "learning, dataset",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 31695,
        "paper_id": 664,
        "chunk_idx": 0,
        "title": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey",
        "section_head": "Text",
        "score": 0.9289736747741699,
        "text_preview": "Inform Request ... Select E m b e d d i n g s T r a n s f o r m e r E n c o d e r T r a n s f o r m e r E n c o d e r T r a n s f o r m e r E n c o d e r BERT For small-sample learning scenarios, the "
      },
      {
        "chunk_index": 121177,
        "paper_id": 2524,
        "chunk_idx": 0,
        "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
        "section_head": "Fig. 7 :",
        "score": 0.907356858253479,
        "text_preview": "7 Fig.7: Learning performance of SEMISS on two datasets."
      },
      {
        "chunk_index": 12988,
        "paper_id": 258,
        "chunk_idx": 0,
        "title": "ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction",
        "section_head": "Figure 10 :",
        "score": 0.8963792324066162,
        "text_preview": "10 Figure 10: Mesh collection learning with 100 objects taken from the Thingi10K[63] dataset."
      },
      {
        "chunk_index": 21321,
        "paper_id": 436,
        "chunk_idx": 0,
        "title": "Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency",
        "section_head": "Datasets and Evaluation Metrics",
        "score": 0.8956573009490967,
        "text_preview": "We conduct experiments using datasets for both federated learning and long-tailed recognition. The federated learning datasets are further categorized into three types: label skew, domain skew, and a "
      },
      {
        "chunk_index": 51120,
        "paper_id": 1095,
        "chunk_idx": 0,
        "title": "FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient Research",
        "section_head": "Figure 15 :",
        "score": 0.884850263595581,
        "text_preview": "15 Figure 15: Radar Chart Comparison of Federated Learning Algorithms on Fairness and Performance (Synthetic_1_1 Dataset)."
      },
      {
        "chunk_index": 150862,
        "paper_id": 3099,
        "chunk_idx": 0,
        "title": "Vision Transformers: the threat of realistic adversarial patches",
        "section_head": "Fine tuning ViT's 3.2.1 Baseline Model Training",
        "score": 0.8811299800872803,
        "text_preview": "To establish robust target models for adversarial evaluation, four pre-trained ViT models were finetuned on our custom binary person vs. non-person classification dataset. The selection of these speci"
      },
      {
        "chunk_index": 140686,
        "paper_id": 2902,
        "chunk_idx": 0,
        "title": "TOWARDS A PHYSICS FOUNDATION MODEL",
        "section_head": "DATASETS",
        "score": 0.8665804266929626,
        "text_preview": "To train a model capable of learning general physical principles, we curated a large and diverse corpus of simulation data, comprising eight distinct datasets listed in Table 1 . The combined dataset "
      },
      {
        "chunk_index": 48964,
        "paper_id": 1046,
        "chunk_idx": 0,
        "title": "FedCD: A Fairness-aware Federated Cognitive Diagnosis Framework",
        "section_head": "Datasets.",
        "score": 0.8637510538101196,
        "text_preview": "To implement the FL paradigm, datasets must contain information on students' schools or groupings. Our experiments were conducted on three real-world datasets: ASSIST2009, ASSIST2012, and SLP-Math. Bo"
      },
      {
        "chunk_index": 1047,
        "paper_id": 18,
        "chunk_idx": 0,
        "title": "A Contrastive Learning Framework for Breast Cancer Detection",
        "section_head": "Figure 5 .",
        "score": 0.8469982147216797,
        "text_preview": "5 Figure 5. Confusion Matrices for benchmark datasets after 45 epochs of pre-training on (a) MIAS dataset, (b) INbreast dataset and (c) KAAUM dataset"
      },
      {
        "chunk_index": 97879,
        "paper_id": 2064,
        "chunk_idx": 0,
        "title": "OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling",
        "section_head": "OmniWorld Dataset",
        "score": 0.8395180702209473,
        "text_preview": "To advance comprehensive spatio-temporal modeling of the real physical world, we curate OmniWorld, a large-scale, multi-domain and multi-modal dataset that mirrors the complexity of the physical world"
      },
      {
        "chunk_index": 92525,
        "paper_id": 1952,
        "chunk_idx": 2,
        "title": "Multilingual Dataset Integration Strategies for Robust Audio Deepfake Detection: A SAFE Challenge System",
        "section_head": "A. Audio Deepfake Detection Datasets",
        "score": 0.8383550643920898,
        "text_preview": "The DFADD dataset [17] focuses on diffusion-and flow-matching-based TTS systems, including GradTTS [18] , NaturalSpeech2 [19] , Style-TTS2 [20] , Matcha-TTS [21] , PFlow-TTS [22] , etc. Famous Figures"
      },
      {
        "chunk_index": 51086,
        "paper_id": 1095,
        "chunk_idx": 0,
        "title": "FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient Research",
        "section_head": "Datasets",
        "score": 0.8360863327980042,
        "text_preview": "We use two real-world datasets and one synthetic dataset: Office-Caltech-10 [8], CIFAR-10 [16], and synthetic [19] . The Office-Caltech-10 dataset simulates a feature heterogeneous scenario, while the"
      },
      {
        "chunk_index": 33314,
        "paper_id": 699,
        "chunk_idx": 0,
        "title": "DermINO: Hybrid Pretraining for a Versatile Dermatology Foundation Model",
        "section_head": "Web source LESION 130ks.",
        "score": 0.8326908349990845,
        "text_preview": "Web source datasets consisted of 95,999 images obtained from the LESION 130k dataset, which were collected using the URLs provided by LESION 130ks [52] . These images were originally acquired through "
      },
      {
        "chunk_index": 22335,
        "paper_id": 458,
        "chunk_idx": 0,
        "title": "Causal Representation Learning from Multimodal Clinical Records under Non-Random Modality Missingness",
        "section_head": "Baselines and Implementation Details",
        "score": 0.8313020467758179,
        "text_preview": "We compare CRL-MMNAR with 13 state-of-theart methods, spanning three major paradigms in multimodal learning. The second paradigm is explicitly designed to handle missing data."
      },
      {
        "chunk_index": 24639,
        "paper_id": 497,
        "chunk_idx": 0,
        "title": "Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning",
        "section_head": "MedDocBench",
        "score": 0.8309709429740906,
        "text_preview": "We construct MEDDOCBENCH, a publicly available benchmark for medical document understanding covering routine, patient-uploaded artifacts from online consultations."
      },
      {
        "chunk_index": 27205,
        "paper_id": 556,
        "chunk_idx": 0,
        "title": "CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation",
        "section_head": "Implementation Details",
        "score": 0.8283732533454895,
        "text_preview": "Reference Dataset: We select the MidiCaps dataset [Melechovsky et al., 2024] as reference dataset, which is derived from the Lakh MIDI dataset [Raffel, 2016] , one of the largest open-source collectio"
      },
      {
        "chunk_index": 141474,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "Table 1 |",
        "score": 0.8266289234161377,
        "text_preview": "1 MultiMedBench overview. Summary of MultiMedBench, the benchmark we introduce for the development and evaluation of Med-PaLM M. MultiMedBench consists of 14 individual tasks across 5 task types and 1"
      },
      {
        "chunk_index": 141994,
        "paper_id": 2926,
        "chunk_idx": 0,
        "title": "Towards Self-Supervised Foundation Models for Critical Care Time Series",
        "section_head": "Yet another ICU benchmark (YAIB)",
        "score": 0.8257523775100708,
        "text_preview": "Yet another ICU benchmark (YAIB) provided by van de Water et al. [22] is a modular, end-toend framework supporting transparent benchmarking for clinical machine learning on ICU data (Appendix A.2). YA"
      },
      {
        "chunk_index": 89722,
        "paper_id": 1890,
        "chunk_idx": 2,
        "title": "MMFformer: Multimodal Fusion Transformer Network for Depression Detection",
        "section_head": "A. Deep Learning for Depression Detection",
        "score": 0.8247323036193848,
        "text_preview": "The system incorporated local and global information fusion modules that evaluated the significance and interaction between the extracted attributes at both local and global levels. Experiments on the"
      },
      {
        "chunk_index": 8914,
        "paper_id": 172,
        "chunk_idx": 0,
        "title": "AI-IN-THE-LOOP: PRIVACY PRESERVING REAL-TIME SCAM DETECTION AND CONVERSATIONAL SCAMBAITING BY LEVERAGING LLMS AND FEDERATED LEARNING",
        "section_head": "Generation Task",
        "score": 0.8241089582443237,
        "text_preview": "We incorporate a range of curated and publicly available scam-related datasets to support the development and evaluation of our scambaiting framework to accelerate the generation task. These include b"
      }
    ]
  },
  {
    "query_id": 54,
    "query_text": "reasoning each",
    "source": "keyword_combination",
    "source_value": "reasoning, each",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 127308,
        "paper_id": 2656,
        "chunk_idx": 0,
        "title": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies",
        "section_head": "Figure 3 .",
        "score": 0.9364714622497559,
        "text_preview": "3 Figure 3. Overview of reasoning pipeline. A. The methods include Self-generated Reasoning, Teachergenerated Reasoning, and Self-Consistency, where reasoning-augmented demonstrations are used for CI/"
      },
      {
        "chunk_index": 75512,
        "paper_id": 1596,
        "chunk_idx": 0,
        "title": "Large Language Models on Graphs: A Comprehensive Survey",
        "section_head": "Directly answering by following the examples.",
        "score": 0.9303456544876099,
        "text_preview": "Direct Answering [122] , [123] , [126] , [129] Chain-of-Thought Verbalized edge or adjacency lists preceded with a few demonstrative examples. Reasoning through a series of intermediate reasoning step"
      },
      {
        "chunk_index": 72819,
        "paper_id": 1551,
        "chunk_idx": 0,
        "title": "KG-Augmented Executable CoT for Mathematical Coding",
        "section_head": "Method Problem definition",
        "score": 0.9167593717575073,
        "text_preview": "Given a mathematical problem Q, the goal is to generate executable code C, which, when executed, produces the final answer A. We model the problem-solving process as a task graph G, where each node re"
      },
      {
        "chunk_index": 74727,
        "paper_id": 1586,
        "chunk_idx": 0,
        "title": "Large Language Models are Zero-Shot Reasoners",
        "section_head": "Table 6 :",
        "score": 0.9119582772254944,
        "text_preview": "6 Summary of related work on arithmetic/commonsense reasoning tasks. Category denotes the training strategy. CoT denotes whether to output chain of thought. Task column lists the tasks that are perfor"
      },
      {
        "chunk_index": 81051,
        "paper_id": 1708,
        "chunk_idx": 0,
        "title": "LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring",
        "section_head": "Instruction",
        "score": 0.9057542085647583,
        "text_preview": "You are a Moderator overseeing a dialectical reasoning process in which all evaluator agents are gathered at a virtual roundtable to collaboratively determine a final holistic score. Your task is to f"
      },
      {
        "chunk_index": 154121,
        "paper_id": 3159,
        "chunk_idx": 1,
        "title": "When Safe Unimodal Inputs Collide: Optimizing Reasoning Chains for Cross-Modal Safety in Multimodal Large Language Models",
        "section_head": "Generative Exploration",
        "score": 0.9044574499130249,
        "text_preview": "We assume that the model undergoes a series of reasoning steps v 0 ‚Üí v 1 ‚Üí ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Üí v T to arrive at A, which is defined as œÑ = (v 0 ‚Üí v 1 ‚Üí ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Üí v T ), (1) where v i ‚àà V represents a reasoning stat"
      },
      {
        "chunk_index": 8496,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "Graph Reasoning Process",
        "score": 0.9033139944076538,
        "text_preview": "Temporal Graph of Reasons, G is generated layer by layer through applications of reason transformations based on the chosen reasoning strategies by the trained MLLM. Each such transformation is a func"
      },
      {
        "chunk_index": 81006,
        "paper_id": 1707,
        "chunk_idx": 0,
        "title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models",
        "section_head": "A.2 Commonsense Data Templates",
        "score": 0.9023920297622681,
        "text_preview": "As each dataset in the commonsense reasoning domain entails distinct tasks, we adopt a structured template by initially describing the task's goal, followed by the corresponding content and answer. Ta"
      },
      {
        "chunk_index": 147782,
        "paper_id": 3042,
        "chunk_idx": 0,
        "title": "Unsupervised Commonsense Question Answering with Self-Talk",
        "section_head": "Figure 9 :",
        "score": 0.9005391597747803,
        "text_preview": "9 Figure9: Types of errors caused by the harmful clarifications, for each knowledge source, across all tasks."
      },
      {
        "chunk_index": 8498,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "Merging of Reasons -MLLM merges or aggregates reasons into a new reason.",
        "score": 0.8941527605056763,
        "text_preview": "This can give rise to a cone-like structure where, say, two vertices v1 and v3 are linked to a vertex v2. The indegree of the linked vertex should be more than 1 and here indegree(v2) = 2. Each reason"
      },
      {
        "chunk_index": 145301,
        "paper_id": 2993,
        "chunk_idx": 0,
        "title": "Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment",
        "section_head": "Figure 2 :",
        "score": 0.8938435316085815,
        "text_preview": "2 Figure 2: Three SCMs representing reasoning in LLMs: (a) general reasoning without CoTs; (b) CoT and CoT-SC incorporate explicit reasoning, and CP applies the standard front-door adjustment; (c) DeC"
      },
      {
        "chunk_index": 43141,
        "paper_id": 916,
        "chunk_idx": 0,
        "title": "Enhancing Molecular Property Prediction with Knowledge from Large Language Models",
        "section_head": "Method",
        "score": 0.8926882743835449,
        "text_preview": "For each MPP task t ‚àà T , we have a dataset D t = (X t , Y t ), where each x t,i ‚àà X t is a molecule's SMILES notation, and each molecule corresponds to a molecular graph g t,i ‚àà G t . The true label "
      },
      {
        "chunk_index": 21672,
        "paper_id": 443,
        "chunk_idx": 0,
        "title": "Can GRPO Boost Complex Multimodal Table Understanding?",
        "section_head": "Figure 3 :",
        "score": 0.8878484964370728,
        "text_preview": "3 Figure 3: Examples from the datasets used in PA-GRPO. The highlighted red segments indicate the incorrect predictions. TEDS assigns a continuous score to each output, reflecting the similarity to th"
      },
      {
        "chunk_index": 96699,
        "paper_id": 2040,
        "chunk_idx": 0,
        "title": "NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities",
        "section_head": "E Chain of Thoughts Question-Answer Pairs",
        "score": 0.8871767520904541,
        "text_preview": "Table 11 presents a set of question-answer (QA) pairs designed to illustrate the application of Chainof-Thought (CoT) reasoning in the NUMINA dataset. Each original question (Ori-Q) is accompanied by "
      },
      {
        "chunk_index": 97228,
        "paper_id": 2051,
        "chunk_idx": 0,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "A.1.2. MATHEMATICAL BENCHMARKS",
        "score": 0.8867318034172058,
        "text_preview": "Game of 24 (Lile, 2024) is based on the classic arithmetic game of 24 (also known as 24, the 24 numbers game, etc.). The puzzle involves using four numbers and basic arithmetic operations (addition, s"
      },
      {
        "chunk_index": 41004,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Figure 1 :",
        "score": 0.881184995174408,
        "text_preview": "1 Figure 1: Overview of chain-of-abstraction reasoning with tools. Given a domain question (green scroll), a LLM is fine-tuned to first generate an abstract multi-step reasoning chain (blue bubble), a"
      },
      {
        "chunk_index": 146288,
        "paper_id": 3015,
        "chunk_idx": 1,
        "title": "Understanding the planning of LLM agents: A survey",
        "section_head": "Decomposition-First Methods",
        "score": 0.8797684907913208,
        "text_preview": "Plan-and-Solve [Wang et al., 2023b] improves upon the Zero-shot Chain-of-Thought [Kojima et al., 2022] by transforming the original \"Let's think stepby-step\" into a two-step prompt instruction: \"Let's"
      },
      {
        "chunk_index": 125376,
        "paper_id": 2619,
        "chunk_idx": 0,
        "title": "SMooGPT : Stylized Motion Generation using Large Language Models",
        "section_head": "Fig. 4",
        "score": 0.8762136101722717,
        "text_preview": "4 Fig.4(a) demonstrates an overview of our generation pipeline, composed of three main components -motion reasoning, composition, and generation, powered by our fine-tuned LLM -SMooGPT .Specifically, "
      },
      {
        "chunk_index": 21649,
        "paper_id": 443,
        "chunk_idx": 0,
        "title": "Can GRPO Boost Complex Multimodal Table Understanding?",
        "section_head": "Hint-Completion GRPO (HC-GRPO).",
        "score": 0.8759035468101501,
        "text_preview": "During this stage, given a question Q, the model enhances For training data generation, each expanded solution is randomly divided into two segments at position j ‚àº Uniform{1, . . . , m-1}. The first "
      },
      {
        "chunk_index": 12523,
        "paper_id": 247,
        "chunk_idx": 0,
        "title": "AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data",
        "section_head": "Table 5 :",
        "score": 0.8752608299255371,
        "text_preview": "5 Number of Questions per Reasoning Type Reasoning Type Number of Questions Mathematical Reasoning 79 Comparative Reasoning 67 Logical Reasoning 42 Temporal Reasoning 17"
      }
    ]
  },
  {
    "query_id": 55,
    "query_text": "datasets language",
    "source": "keyword_combination",
    "source_value": "datasets, language",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 85603,
        "paper_id": 1802,
        "chunk_idx": 0,
        "title": "MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models",
        "section_head": "Experimental Setup",
        "score": 0.9524654150009155,
        "text_preview": "The dataset is selected to cover multimodal tasks. The GLUE benchmarking dataset [15] is used for Natural Language Processing (NLP), which contains 9 types of typical tasks; the COCO image description"
      },
      {
        "chunk_index": 90726,
        "paper_id": 1913,
        "chunk_idx": 0,
        "title": "Modular Delta Merging with Orthogonal Constraints: A Scalable Framework for Continual and Reversible Model Composition",
        "section_head": "Datasets and Tasks",
        "score": 0.9213098287582397,
        "text_preview": "Our evaluation encompasses three distinct domains to demonstrate the generalizability of MDM-OC. For computer vision tasks, we utilize CIFAR-100 partitioned into 20 sequential tasks of 5 classes each,"
      },
      {
        "chunk_index": 4506,
        "paper_id": 84,
        "chunk_idx": 0,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Data Source",
        "score": 0.9088024497032166,
        "text_preview": "Foundation models are data-driven, and both quality and quantity of data lie at the core of foundation model development. Figure 14 presents three broad types of data sources for foundation model pre-"
      },
      {
        "chunk_index": 32214,
        "paper_id": 676,
        "chunk_idx": 0,
        "title": "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence",
        "section_head": "Experimental Results",
        "score": 0.9080065488815308,
        "text_preview": "In this section, we evaluate DeepSeek-Coder-V2 on three types of tasks, including coding, mathematics, and general natural language. We compare DeepSeek-Coder-V2 with the previous state-of-the-art lar"
      },
      {
        "chunk_index": 141409,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "MultiMedBench: A Benchmark for Generalist Biomedical AI",
        "score": 0.9068627953529358,
        "text_preview": "We next describe MultiMedBench, a benchmark we curated to enable the development and evaluation of generalist biomedical AI. MultiMedBench is a multi-task, multimodal benchmark comprising 12 de-identi"
      },
      {
        "chunk_index": 13341,
        "paper_id": 267,
        "chunk_idx": 0,
        "title": "Assessing the Capabilities and Limitations of FinGPT Model in Financial NLP Applications",
        "section_head": "Evaluation 4.1 Task Overview",
        "score": 0.8979673385620117,
        "text_preview": "To evaluate FinGPT's applicability across financial natural language processing (NLP) tasks, we designed a standardized evaluation pipeline involving six key tasks: sentiment analysis, text classifica"
      },
      {
        "chunk_index": 72957,
        "paper_id": 1555,
        "chunk_idx": 0,
        "title": "KIMI K1.5: SCALING REINFORCEMENT LEARNING WITH LLMS TECHNICAL REPORT OF KIMI K1.5",
        "section_head": "Pretraining",
        "score": 0.8968538641929626,
        "text_preview": "The Kimi k1.5 base model is trained on a diverse, high-quality multimodal corpus. The language data covers five domains: English, Chinese, Code, Mathematics Reasoning, and Knowledge. Multimodal data, "
      },
      {
        "chunk_index": 7046,
        "paper_id": 130,
        "chunk_idx": 0,
        "title": "Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data",
        "section_head": "IV. NON-IID BENCHMARK IN NATURAL LANGUAGE PROCESSING",
        "score": 0.8929644823074341,
        "text_preview": "We introduce a more comprehensive definition of non-IID encompassing both diversity in label distributions and diversity in language domain across clients in natural language processing."
      },
      {
        "chunk_index": 4929,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": ".Fig. 18 :",
        "score": 0.8904396295547485,
        "text_preview": "18 Fig. 18: Pre-training dataset distributions for different language models. (a) Dataset mixture comparison across GPT-3, LLaMA, and Yi models. (b) Detailed distribution of Intern-S1's continual pre-"
      },
      {
        "chunk_index": 156420,
        "paper_id": 3207,
        "chunk_idx": 0,
        "title": "Your Pretrained Model Tells the Difficulty Itself: A Self-Adaptive Curriculum Learning Paradigm for Natural Language Understanding",
        "section_head": "Hate Speech Offensive Language (HSOL)",
        "score": 0.8875601291656494,
        "text_preview": "The Hate Speech Offensive Language dataset (Davidson et al., 2017) includes tweets labeled into three categories: hate speech, offensive language, and neither, with a significant class imbalance. Cros"
      },
      {
        "chunk_index": 76338,
        "paper_id": 1613,
        "chunk_idx": 0,
        "title": "Layer by Layer: Uncovering Hidden Representations in Language Models",
        "section_head": "C.2. MTEB",
        "score": 0.8851619958877563,
        "text_preview": "The 32 tasks we used from the Massive Text Embedding Benchmark (MTEB) are detailed in Table 1 . They are English language tasks covering clustering, classification, reranking, and sentence-to-sentence"
      },
      {
        "chunk_index": 4504,
        "paper_id": 84,
        "chunk_idx": 0,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Data Collection ‚Ä¶",
        "score": 0.8796806931495667,
        "text_preview": "Fig. 14 : A diverse suite of data sources and datasets for pre-training foundation models, mainly including text data, image data, and multimodality data. ‚Ä¢ Autonomous Agent (Section 4.6): Focusing on"
      },
      {
        "chunk_index": 132557,
        "paper_id": 2741,
        "chunk_idx": 0,
        "title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?",
        "section_head": "Table 2 :",
        "score": 0.8794836401939392,
        "text_preview": "2 NLG Benchmarks General Statistical ComparisonAlthough there are several NLU benchmarks in SoTA, not all them contains diagnostics datasets. Table3shows a comparison between SoTA benchmarks regarding"
      },
      {
        "chunk_index": 95472,
        "paper_id": 2020,
        "chunk_idx": 0,
        "title": "No Language Data Left Behind: A Comparative Study of CJK Language Datasets in the Hugging Face Ecosystem",
        "section_head": "Figure 2 :",
        "score": 0.878068208694458,
        "text_preview": "2 Figure 2: Distribution and Composition Analysis of CJK Language Datasets. (a) Illustrates the intersections among CJK language datasets, showing unique and overlapping dataset counts. (b) Shows the "
      },
      {
        "chunk_index": 80618,
        "paper_id": 1700,
        "chunk_idx": 0,
        "title": "LLAMA PRO: Progressive LLaMA with Block Expansion",
        "section_head": "Figure 1 :",
        "score": 0.8755829334259033,
        "text_preview": "1 Figure 1: LLAMA PRO -INSTRUCT delivers stateof-the-art performance across a wide variety of tasks, ranging from general language to specific domains, superior to existing models from the LLaMA serie"
      },
      {
        "chunk_index": 126677,
        "paper_id": 2640,
        "chunk_idx": 0,
        "title": "Spatio-Temporal Pruning for Compressed Spiking Large Language Models",
        "section_head": "A. Datasets",
        "score": 0.8729249835014343,
        "text_preview": "We evaluated our model's performance using a diverse set of text classification tasks from the General Language Understanding Evaluation (GLUE) benchmark [43] . Specifically, we employed the Quora Que"
      },
      {
        "chunk_index": 41473,
        "paper_id": 873,
        "chunk_idx": 0,
        "title": "EfficientUICoder: Efficient MLLM-based UI Code Generation via Input and Output Token Compression",
        "section_head": "Evaluation Datasets",
        "score": 0.8717988729476929,
        "text_preview": "We use two widely used UI2Code datasets: (1) Design2Code [25] : Design2Code is a pioneering benchmark dataset comprising 484 real-world webpage screenshots paired with their corresponding front-end co"
      },
      {
        "chunk_index": 114782,
        "paper_id": 2394,
        "chunk_idx": 0,
        "title": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment",
        "section_head": "A.4 Downstream Performance",
        "score": 0.8711841106414795,
        "text_preview": "We evaluated performance of languages models on extensive set of downstream tasks ranging from Sequence Classification, Parts-of-Speech Tagging to Natural Language Inference Tasks such as In-dicXNLI. "
      },
      {
        "chunk_index": 112235,
        "paper_id": 2338,
        "chunk_idx": 0,
        "title": "RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis",
        "section_head": "Table 1 :",
        "score": 0.8691673278808594,
        "text_preview": "1 Comparison of our dataset with other related datasets. TOD stands for Task-Oriented Dialogue Dataset, SLU is a single-round Spoken Language Understanding dataset. H2H, H2M, M2M stand for human-to-hu"
      },
      {
        "chunk_index": 4747,
        "paper_id": 85,
        "chunk_idx": 10,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "2.5T",
        "score": 0.8691659569740295,
        "text_preview": "In transcriptomics, early large-scale pretraining efforts have focused on gene expression matrices derived from single-cell RNA sequencing (scRNA-seq) data. Foundation models [512] , [638] are typical"
      }
    ]
  },
  {
    "query_id": 56,
    "query_text": "results text",
    "source": "keyword_combination",
    "source_value": "results, text",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 121033,
        "paper_id": 2521,
        "chunk_idx": 0,
        "title": "SELECTIVE CLASSIFIER-FREE GUIDANCE FOR ZERO-SHOT TEXT-TO-SPEECH",
        "section_head": "Fig. 4 :Fig. 5 :Fig. 6 :Fig. 7 :",
        "score": 0.9491584300994873,
        "text_preview": "4567 Fig. 4: Comparison of baseline, def text, and input text strategies on LibriSpeech with F5-TTS."
      },
      {
        "chunk_index": 73920,
        "paper_id": 1574,
        "chunk_idx": 0,
        "title": "Language Is Not All You Need: Aligning Perception with Language Models",
        "section_head": "Models EM F1",
        "score": 0.9445153474807739,
        "text_preview": "Using extracted text LLM 7.6 17.9 KOSMOS-1 15.8 31.3 Without using extracted text KOSMOS-1 3.8 10.6 Table 8 : Zero-shot performance on WebSRC task. We report exact match (EM) and F1 scores."
      },
      {
        "chunk_index": 28840,
        "paper_id": 595,
        "chunk_idx": 0,
        "title": "Corrective Retrieval Augmented Generation",
        "section_head": "Table 5 :",
        "score": 0.9124724864959717,
        "text_preview": "5 Comparison results between CRAG, Self-CRAG and RAG, Self-RAG with the same input in terms of accuracy. 69.8 (Actual) 20 30 40 50 60 70 no retrieval 60 Accuracy of generation 50 Accuracy of retrieval"
      },
      {
        "chunk_index": 140532,
        "paper_id": 2899,
        "chunk_idx": 0,
        "title": "Toward Responsible ASR for African American English Speakers: A Scoping Review of Bias and Equity in Speech Technology",
        "section_head": "Summary of Data",
        "score": 0.904491662979126,
        "text_preview": "The table below shows the number of documents retrieved from various information sources (see Table 1 )"
      },
      {
        "chunk_index": 152617,
        "paper_id": 3142,
        "chunk_idx": 0,
        "title": "What do Speech Foundation Models Learn? Analysis and Applications by",
        "section_head": "Figure 7 . 1 :",
        "score": 0.876638650894165,
        "text_preview": "71 Figure7.1: Improvements in spoken NER with 100 hours of external data of different types. \"Pipeline\" refers to approaches consisting of speech recognition followed by a text NER model; \"E2E\" refers"
      },
      {
        "chunk_index": 137498,
        "paper_id": 2832,
        "chunk_idx": 0,
        "title": "The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention",
        "section_head": "C.2. Character-Level Experiments on \"Aesop's Fables\"",
        "score": 0.8743389844894409,
        "text_preview": "Tables 3, 4 and 5 show the queries we used and the corresponding top scoring training text passages for Aesop's Fables."
      },
      {
        "chunk_index": 68656,
        "paper_id": 1462,
        "chunk_idx": 0,
        "title": "In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss",
        "section_head": "Figure 7 .",
        "score": 0.8738297820091248,
        "text_preview": "7 Figure7. Retrieval performance critically depends on a task and amount of text per embedding. Evaluation results for vectorbased retrieval on 'qa2'-'qa10' tasks."
      },
      {
        "chunk_index": 42605,
        "paper_id": 902,
        "chunk_idx": 0,
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "section_head": "Detailed retrieval results.",
        "score": 0.8680813312530518,
        "text_preview": "We show detailed retrieval results in Tables 12, 13, and 14."
      },
      {
        "chunk_index": 154722,
        "paper_id": 3173,
        "chunk_idx": 0,
        "title": "WHO GETS CITED MOST? BENCHMARKING LONG-CONTEXT LANGUAGE MOD-ELS ON SCIENTIFIC ARTICLES",
        "section_head": "G ADDITIONAL RESULTS",
        "score": 0.8627023100852966,
        "text_preview": "Table 13 presents additional results using F1 as the evaluation metric. Models are tested against fulltext scientific articles and database tables as context. The input length averages only 1,980 toke"
      },
      {
        "chunk_index": 20930,
        "paper_id": 425,
        "chunk_idx": 0,
        "title": "Building and Aligning Comparable Corpora",
        "section_head": "Table 3 :",
        "score": 0.8624943494796753,
        "text_preview": "3 Wikipedia comparable corpus (AFEWC) characteristicsThen, html tags are stripped for the three comparable articles, and stored in plain text files. Category information is also included in the plain "
      },
      {
        "chunk_index": 132105,
        "paper_id": 2732,
        "chunk_idx": 0,
        "title": "SUMMAC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization",
        "section_head": "Table 5 :",
        "score": 0.862176775932312,
        "text_preview": "5 Effect of granularity choice on SUM-MAC models performance. We tested four granularities on the document side: full, paragraph, two sentence and sentence, and two granularities on the summary side: "
      },
      {
        "chunk_index": 22756,
        "paper_id": 465,
        "chunk_idx": 0,
        "title": "CC-Time: Cross-Model and Cross-Modality Time Series Forecasting",
        "section_head": "Figure 6 :",
        "score": 0.8579235076904297,
        "text_preview": "6 Figure6: The construction process of channel text descriptions X text ."
      },
      {
        "chunk_index": 72897,
        "paper_id": 1553,
        "chunk_idx": 0,
        "title": "KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs",
        "section_head": "Fig. 4 .",
        "score": 0.8578020930290222,
        "text_preview": "4 Fig. 4. Comparison of different representative response selection methods for free-form text generation on three datasets"
      },
      {
        "chunk_index": 68150,
        "paper_id": 1450,
        "chunk_idx": 0,
        "title": "Improving language models by retrieving from trillions of tokens",
        "section_head": "Figure 3 |",
        "score": 0.855096161365509,
        "text_preview": "3 Figure 3 | Scaling with respect to model size. (a) LAMBADA top-1 accuracy. (b) Evaluation loss on curation corpus. (c) Perplexity on Wikitext103 valid. (d) Bits-per-byte on selected Wikipedia articl"
      },
      {
        "chunk_index": 63515,
        "paper_id": 1355,
        "chunk_idx": 0,
        "title": "HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark",
        "section_head": "Table 5 :",
        "score": 0.85496985912323,
        "text_preview": "5 Performance Comparison of Models trained on the ParaShoot and the HeQ Datasets and evaluated on the Parashoot dataset. Trainset EM F1 TLNLS Geektime 58.38 68.00 75.80 Wikipedia 56.05 65.72 73.47 Gee"
      },
      {
        "chunk_index": 146365,
        "paper_id": 3016,
        "chunk_idx": 0,
        "title": "UniCoM: A Universal Code-Switching Speech Generator",
        "section_head": "Table 4 :",
        "score": 0.8524179458618164,
        "text_preview": "4 Evaluation on the 9 best-and worst-performing language pairs of CS-FLEURS. Avg. indicates the mean value across 253 pairs; full results are in Appendix B. Pair it-es pt-es ro-es it-ro it-pt de-es RE"
      },
      {
        "chunk_index": 59756,
        "paper_id": 1272,
        "chunk_idx": 0,
        "title": "GENERATING WIKIPEDIA BY SUMMARIZING LONG SEQUENCES",
        "section_head": "Table 3 :",
        "score": 0.850798487663269,
        "text_preview": "3 Comparison of extractive method and corpus with L = 500, and the Transformer E-D model Extractor Corpus Test log-perplexity ROUGE-L cheating combined 1.72975 59.3 tf-idf combined 2.46645 34.2 tf-idf"
      },
      {
        "chunk_index": 75071,
        "paper_id": 1590,
        "chunk_idx": 0,
        "title": "Large Language Models Encode Clinical Knowledge",
        "section_head": "Table 4 |",
        "score": 0.8501043319702148,
        "text_preview": "4 Summary of the best performing models on the MedQA (USMLE) dataset questions with 4 options. Our results with Flan-PaLM exceed previous state of the art by over 17%. Model (number of parameters) Med"
      },
      {
        "chunk_index": 32459,
        "paper_id": 681,
        "chunk_idx": 0,
        "title": "DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform",
        "section_head": "Table 2 .",
        "score": 0.8491505980491638,
        "text_preview": "2 Results of baseline comparisons with DEFT-VTON on VITON-HD dataset.Bold texts indicate best models, underlined texts indicate second best models."
      },
      {
        "chunk_index": 121034,
        "paper_id": 2521,
        "chunk_idx": 0,
        "title": "SELECTIVE CLASSIFIER-FREE GUIDANCE FOR ZERO-SHOT TEXT-TO-SPEECH",
        "section_head": "Table 1 :",
        "score": 0.8470392227172852,
        "text_preview": "1 Comparison of state-of-the-art zero-shot TTS models. Italicized results are experimentally obtained; others are reported. LibriSpeech Seed-TTS-en Seed-TTS-zh SIM WER SIM WER SIM WER F5-TTS (Base) 0."
      }
    ]
  },
  {
    "query_id": 57,
    "query_text": "tasks section",
    "source": "keyword_combination",
    "source_value": "tasks, section",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 66345,
        "paper_id": 1412,
        "chunk_idx": 0,
        "title": "i-Code: An Integrative and Composable Multimodal Learning Framework",
        "section_head": "Experiments",
        "score": 0.9491662383079529,
        "text_preview": "In this section, we evaluate i-Code and compare it with previous work on a variety of downstream tasks, including multimodal sentiment & emotion analysis, multimodal inference, video QA and single-mod"
      },
      {
        "chunk_index": 87168,
        "paper_id": 1835,
        "chunk_idx": 0,
        "title": "MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound",
        "section_head": "D. Downstream Task Implementation Details",
        "score": 0.9458596706390381,
        "text_preview": "In this section, we present information for how we adapted Reserve on downstream tasks."
      },
      {
        "chunk_index": 54131,
        "paper_id": 1160,
        "chunk_idx": 0,
        "title": "FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS",
        "section_head": "Figure 3 :",
        "score": 0.9426127672195435,
        "text_preview": "3 Figure 3: Datasets and task clusters used in this paper (NLU tasks in blue; NLG tasks in teal)."
      },
      {
        "chunk_index": 141468,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "A.5 MultiMedBench Examples",
        "score": 0.9392150640487671,
        "text_preview": "In Tables A. 9 to A. 13 we provide examples of various MultiMedBench tasks."
      },
      {
        "chunk_index": 46594,
        "paper_id": 998,
        "chunk_idx": 0,
        "title": "Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models",
        "section_head": "C.1 Downstream Task Accuracy",
        "score": 0.9345877170562744,
        "text_preview": "We present the detailed downstream task accuracy of each method for nine tasks in Table 15 , 17, 16, and 18."
      },
      {
        "chunk_index": 108915,
        "paper_id": 2260,
        "chunk_idx": 0,
        "title": "Prompt Injection attack against LLM-integrated Applications",
        "section_head": "Semantic -Additional Task",
        "score": 0.9311583638191223,
        "text_preview": "In addition to the previous code generatioin task, complete the following tasks separately."
      },
      {
        "chunk_index": 30949,
        "paper_id": 646,
        "chunk_idx": 0,
        "title": "DEBERTA: DECODING-ENHANCED BERT WITH DIS-ENTANGLED ATTENTION",
        "section_head": "EXPERIMENT",
        "score": 0.929800271987915,
        "text_preview": "This section reports DeBERTa results on various NLU tasks."
      },
      {
        "chunk_index": 25568,
        "paper_id": 515,
        "chunk_idx": 0,
        "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
        "section_head": "Experiments",
        "score": 0.9289035201072693,
        "text_preview": "In this section, we first describe the details of our experimental setup. The main results are presented next organized as visual recognition tasks, crossmodal alignment tasks, image captioning and mu"
      },
      {
        "chunk_index": 19176,
        "paper_id": 387,
        "chunk_idx": 0,
        "title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining",
        "section_head": "Table 1 .",
        "score": 0.9183708429336548,
        "text_preview": "1 Summary of the downstream tasks Task Method Dataset"
      },
      {
        "chunk_index": 1911,
        "paper_id": 33,
        "chunk_idx": 0,
        "title": "A Generalist Agent",
        "section_head": "Datasets",
        "score": 0.9112145304679871,
        "text_preview": "Gato is evaluated on in and out of distribution simulated control tasks, see Section 4.1 and Section 5.2 for further details about these tasks. We also evaluated on the Skill Generalization challenge "
      },
      {
        "chunk_index": 39789,
        "paper_id": 843,
        "chunk_idx": 0,
        "title": "EDITING MODELS WITH TASK ARITHMETIC",
        "section_head": "B FORGETTING IMAGE CLASSIFICATION TASKS",
        "score": 0.9070718884468079,
        "text_preview": "This section presents additional experimental details and results complementing the findings presented in Section 3.1, showcasing the effect of negating task vectors from image classification tasks."
      },
      {
        "chunk_index": 112088,
        "paper_id": 2334,
        "chunk_idx": 0,
        "title": "RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios",
        "section_head": "Figure 2 :",
        "score": 0.9047045707702637,
        "text_preview": "2 Figure 2: Detailed examples of the four tasks included in RealBench."
      },
      {
        "chunk_index": 84020,
        "paper_id": 1769,
        "chunk_idx": 0,
        "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
        "section_head": "Synthetic Tasks",
        "score": 0.9036436080932617,
        "text_preview": "Full experiment details for these tasks including task details and training protocol are in Appendix E.1."
      },
      {
        "chunk_index": 116841,
        "paper_id": 2440,
        "chunk_idx": 0,
        "title": "ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING",
        "section_head": "Fine-tuning on GLUE tasks",
        "score": 0.8949507474899292,
        "text_preview": "Consistent with the previous experiments, we fine-tune the weights of our pre-trained RoFormer across various GLUE tasks in order to evaluate its generalization ability on the downstream NLP tasks."
      },
      {
        "chunk_index": 23664,
        "paper_id": 480,
        "chunk_idx": 0,
        "title": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models",
        "section_head": "Applications of Chameleon",
        "score": 0.8928655982017517,
        "text_preview": "We demonstrate the applications of Chameleon on two challenging tasks: ScienceQA [32] (section 4.2) and TabMWP [33] (section 4.3), using the module inventory introduced in section 4.1. Further experim"
      },
      {
        "chunk_index": 70391,
        "paper_id": 1501,
        "chunk_idx": 0,
        "title": "InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos",
        "section_head": "Experiments",
        "score": 0.8802685737609863,
        "text_preview": "In this section we present advances in human motion generation brought by InterPose. In particular, we deploy InterPose to train two state-of-the-art methods, namely OmniControl [54] and MaskedMimic ["
      },
      {
        "chunk_index": 74578,
        "paper_id": 1584,
        "chunk_idx": 0,
        "title": "Large Language Models are Null-Shot Learners",
        "section_head": "‚àÖ-shot Phrase: Third Variant (v3)",
        "score": 0.871963620185852,
        "text_preview": "Perform the following task as demonstrated in the \"Examples\" section. Figure 9 : The third variant of ‚àÖ-shot phrase with both components removed."
      },
      {
        "chunk_index": 74537,
        "paper_id": 1584,
        "chunk_idx": 0,
        "title": "Large Language Models are Null-Shot Learners",
        "section_head": "‚àÖ-shot Phrase",
        "score": 0.8700501918792725,
        "text_preview": "Look at examples in the \"Examples\" section and utilize examples and information from that section to perform the following task. mary, our contributions are as follows: ‚Ä¢ We propose ‚àÖ-shot prompting, "
      },
      {
        "chunk_index": 129497,
        "paper_id": 2689,
        "chunk_idx": 0,
        "title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets",
        "section_head": "C. Data Processing",
        "score": 0.8700233101844788,
        "text_preview": "In this section, we provide more details about our processing pipeline including their outputs on a few public video examples for demonstration purposes."
      },
      {
        "chunk_index": 135337,
        "paper_id": 2801,
        "chunk_idx": 0,
        "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
        "section_head": "Experiments and Results",
        "score": 0.8691149950027466,
        "text_preview": "In this section, we will introduce the details of GENIE pretraining, the data setting, and show extensive experimental results on various NLG downstream tasks."
      }
    ]
  },
  {
    "query_id": 58,
    "query_text": "medical diffusion",
    "source": "keyword_combination",
    "source_value": "medical, diffusion",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 129746,
        "paper_id": 2694,
        "chunk_idx": 0,
        "title": "STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs",
        "section_head": "Fig. 4 .",
        "score": 0.8924278020858765,
        "text_preview": "4 Fig. 4. Architectural comparison between Denoising Diffusion Probabilistic Models (DDPM) and Denoising Diffusion Implicit Models (DDIM)."
      },
      {
        "chunk_index": 106551,
        "paper_id": 2206,
        "chunk_idx": 0,
        "title": "PLUG-AND-PLAY DIFFUSION MODELS FOR IMAGE COMPRESSIVE SENSING WITH DATA CONSISTENCY PROJECTION",
        "section_head": "INTRODUCTION",
        "score": 0.8436729907989502,
        "text_preview": "Inverse problems are central to computational imaging, where the goal is to recover a latent signal x from corrupted measurements y = H(x) + n. Such problems arise in superresolution, deblurring, medi"
      },
      {
        "chunk_index": 59980,
        "paper_id": 1279,
        "chunk_idx": 0,
        "title": "Generative Diffusion Models on Graphs: Methods and Applications",
        "section_head": "Diffusion Models",
        "score": 0.833519458770752,
        "text_preview": "In general, there are three paradigms of diffusion models: Score Matching with Langevin Dynamics (SMLD), Denoising Diffusion Probabilistic Model (DDPM), and Score-based Generative Model (SGM). SMLD an"
      },
      {
        "chunk_index": 34096,
        "paper_id": 719,
        "chunk_idx": 0,
        "title": "DiffIER: Optimizing Diffusion Models with Iterative Error Reduction",
        "section_head": "Related Work",
        "score": 0.8327608108520508,
        "text_preview": "Generative models Generative models aim to synthesize new samples by learning data distributions, with prominent approaches including Generative Adversarial Networks (GANs), flow-based models, and dif"
      },
      {
        "chunk_index": 53020,
        "paper_id": 1136,
        "chunk_idx": 0,
        "title": "Few-step Flow for 3D Generation via Marginal-Data Transport Distillation",
        "section_head": "2D Generative Models.",
        "score": 0.8287556171417236,
        "text_preview": "2D generative modeling has progressed from variational autoencoders (VAEs) [27, 57] to generative adversarial networks (GANs) [15] . VAEs map data distributions to latent Gaussian spaces via Evidence "
      },
      {
        "chunk_index": 10409,
        "paper_id": 200,
        "chunk_idx": 0,
        "title": "AN EFFICIENT CONDITIONAL SCORE-BASED FILTER FOR HIGH DIMENSIONAL NONLINEAR FILTERING PROBLEMS *",
        "section_head": "Fig. 1 .",
        "score": 0.8275050520896912,
        "text_preview": "1 Fig. 1. Schematic diagram of the Conditional Score-based Filter method. (a) The flowchart of the set transformer-based prior encoder; (b) The flowchart of the conditional diffusion posterior samplin"
      },
      {
        "chunk_index": 69799,
        "paper_id": 1487,
        "chunk_idx": 0,
        "title": "InstructPix2Pix: Learning to Follow Image Editing Instructions",
        "section_head": "InstructPix2Pix",
        "score": 0.8269133567810059,
        "text_preview": "We use our generated training data to train a conditional diffusion model that edits images from written instructions. We base our model on Stable Diffusion, a large-scale textto-image latent diffusio"
      },
      {
        "chunk_index": 105523,
        "paper_id": 2188,
        "chunk_idx": 0,
        "title": "Physics-Informed Neural Network Approaches for Sparse Data Flow Reconstruction of Unsteady Flow Around Complex Geometries",
        "section_head": "Figure 26 :",
        "score": 0.8244745135307312,
        "text_preview": "26 Figure 26: Schematic of Physics Informed Surrogate model for a 3D unsteady turbulent flow past a ship."
      },
      {
        "chunk_index": 59807,
        "paper_id": 1275,
        "chunk_idx": 2,
        "title": "Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model",
        "section_head": "III. WIRELESS SENSING PIPELINES WITH GENERATIVE AI",
        "score": 0.8197159171104431,
        "text_preview": "[98] CSI ‚úì Channel Prediction Feature Generation ‚úó ‚úì RF Genesis [34] Visual Data, Graphical Data ‚úó Data Augmentation, Domain Generalization Cross-Modal Data Generation ‚úì ‚úì CDDM [99] CSI ‚úì Feature Opti"
      },
      {
        "chunk_index": 111603,
        "paper_id": 2322,
        "chunk_idx": 0,
        "title": "RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths",
        "section_head": "Table 1 :",
        "score": 0.8185647130012512,
        "text_preview": "1 Comparisons of RAPHAEL with the recent representative text-to-image generation models on the MS-COCO 256 √ó 256 using zero-shot FID-30k. We see that RAPHAEL outperforms all previous works in image qu"
      },
      {
        "chunk_index": 107126,
        "paper_id": 2219,
        "chunk_idx": 0,
        "title": "PowerGrow: Feasible Co-Growth of Structures and Dynamics for Power Grid Synthesis",
        "section_head": "Graph beta diffusion.",
        "score": 0.8149586915969849,
        "text_preview": "Denoising diffusion models are composed of two processes: a forward diffusion process and a backward denoising process. In the forward process, the input data is gradually diffused into near-zeros or "
      },
      {
        "chunk_index": 111143,
        "paper_id": 2310,
        "chunk_idx": 0,
        "title": "Radiology Report-Conditional 3D CT Generation with Multi-Encoder Latent-diffusion Model",
        "section_head": "Contributions",
        "score": 0.8149210214614868,
        "text_preview": "We propose Report2CT (Figure 1 ), a text-conditional latent diffusion framework for synthesizing full 3D chest CT volumes at clinically relevant resolution, conditioned directly on detailed radiology "
      },
      {
        "chunk_index": 66813,
        "paper_id": 1423,
        "chunk_idx": 0,
        "title": "IMAGE-TO-BRAIN SIGNAL GENERATION FOR VISUAL PROSTHESIS WITH CLIP GUIDED MULTIMODAL DIF-FUSION MODELS",
        "section_head": "DIFFUSION PROCESS",
        "score": 0.8143523335456848,
        "text_preview": "Our diffusion model follows the Denoising Diffusion Probabilistic Model (DDPM) framework (Ho et al., 2020) . We define a forward diffusion process that gradually adds Gaussian noise to the target brai"
      },
      {
        "chunk_index": 113958,
        "paper_id": 2379,
        "chunk_idx": 0,
        "title": "RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation",
        "section_head": "Diffusion Scoring Function:",
        "score": 0.8138633370399475,
        "text_preview": "The noise prediction network œµ Œ∏ (x t , t) iteratively estimates the noise œµ to generate x 0 from x T and approximates the score function (Ho et al., 2020b; Song et al., 2020) , given by ‚àá xt log p t "
      },
      {
        "chunk_index": 96146,
        "paper_id": 2027,
        "chunk_idx": 0,
        "title": "NoiseCutMix: A Novel Data Augmentation Approach by Mixing Estimated Noise in Diffusion Models",
        "section_head": "Figure 2 .",
        "score": 0.8128300309181213,
        "text_preview": "2 Figure 2. The proposed NoiseCutmix mixes estimated noise of diffusion models in the denoising process."
      },
      {
        "chunk_index": 111116,
        "paper_id": 2309,
        "chunk_idx": 0,
        "title": "RadioDiff-Loc: Diffusion Model Enhanced Scattering Congnition for NLoS Localization with Sparse Radio Map Estimation",
        "section_head": "R ‚àº p",
        "score": 0.8124192953109741,
        "text_preview": "Œ∏ (R | d, H), (30) by reversing a forward stochastic differential equation (SDE) that gradually corrupts RMs into Gaussian noise, and learning a neural score estimator s Œ∏ (R, t) ‚âà ‚àá R log p Œ∏ (R | d,"
      },
      {
        "chunk_index": 34157,
        "paper_id": 721,
        "chunk_idx": 0,
        "title": "DiffSyn: A Generative Diffusion Approach to Materials Synthesis Planning",
        "section_head": "Reverse diffusion Chemical guidance",
        "score": 0.8116797208786011,
        "text_preview": "Noise add Gaussian noise √ó T d Enc zeo Enc OSDA Enc fusion Classifier-free guidance c zeo {x comp }, {x cond } {x comp } {xÃÉc omp } {x comp } {x cond } Zeolite framework density (T/1000 √Ö 3 ) Zeolite "
      },
      {
        "chunk_index": 53021,
        "paper_id": 1136,
        "chunk_idx": 0,
        "title": "Few-step Flow for 3D Generation via Marginal-Data Transport Distillation",
        "section_head": "Diffusion Models",
        "score": 0.8115176558494568,
        "text_preview": "Diffusion models [18] learn to generate data by iteratively denoising samples from Gaussian noise distribution. The framework defines a fixed forward diffusion process and a learned reverse denoising "
      },
      {
        "chunk_index": 130517,
        "paper_id": 2706,
        "chunk_idx": 0,
        "title": "STENCIL: SUBJECT-DRIVEN GENERATION WITH CONTEXT GUIDANCE",
        "section_head": "Text-to-Image Latent Diffusion Models.",
        "score": 0.811501145362854,
        "text_preview": "Diffusion models are a class of generative models that progressively transform pure Gaussian noise x T into a target image x 0 through iterative denoising steps. Each model consists of a denoising net"
      },
      {
        "chunk_index": 30857,
        "paper_id": 644,
        "chunk_idx": 0,
        "title": "DCDB: Dynamic Conditional Dual Diffusion Bridge for Ill-posed Multi-Tasks",
        "section_head": "C.1 Diffusion Models and Conditional Diffusion",
        "score": 0.8113952875137329,
        "text_preview": "Diffusion models successfully construct probabilistic evolution paths from noise to target distributions by defining forward noising and reverse denoising processes [1, 27] . Their core idea is to dec"
      }
    ]
  },
  {
    "query_id": 59,
    "query_text": "detection methods",
    "source": "keyword_combination",
    "source_value": "detection, methods",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 55286,
        "paper_id": 1184,
        "chunk_idx": 0,
        "title": "FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA",
        "section_head": "Methodology",
        "score": 0.9122167825698853,
        "text_preview": "We introduce FLORA (Flux LoRA Augmentation), a streamlined two-stage pipeline for generating high-quality synthetic data in challenging low-data scenarios. FLORA integrates mask-guided inpainting [22]"
      },
      {
        "chunk_index": 429,
        "paper_id": 9,
        "chunk_idx": 1,
        "title": "A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Management",
        "section_head": "Conclusion",
        "score": 0.9120479226112366,
        "text_preview": "Although results varied with accuracy changes ranging from slight decreases to gains of up to 2.9 percentage points, SSL demonstrated clear potential to enhance detection performance, with the RT-DETR"
      },
      {
        "chunk_index": 157166,
        "paper_id": 3220,
        "chunk_idx": 0,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "C. Adversarial Robustness: Defending Against Deepfake Evasion Tactics",
        "score": 0.9116361737251282,
        "text_preview": "Deepfake generators continuously evolve, incorporating adversarial learning techniques for bypassing detection models. Attackers could introduce subtle noise, adversarial perturbations, or GAN-based c"
      },
      {
        "chunk_index": 157162,
        "paper_id": 3220,
        "chunk_idx": 0,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "VI. FUTURE RESEARCH DIRECTIONS",
        "score": 0.9080303907394409,
        "text_preview": "As deepfake technology evolves, zero-shot deepfake detection and prevention strategies must advance to counter increasingly sophisticated synthetic content. While current zero-shot approaches offer pr"
      },
      {
        "chunk_index": 116728,
        "paper_id": 2437,
        "chunk_idx": 0,
        "title": "Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks",
        "section_head": "Table 1 .",
        "score": 0.9000754356384277,
        "text_preview": "1 Computational Efficiency of Different Tensor Decomposition Methods (Rank=64, Œ±=0.2) 6. Conclusion We presented a lightweight tensor decomposition defense that significantly improves VLM robustness a"
      },
      {
        "chunk_index": 151310,
        "paper_id": 3111,
        "chunk_idx": 0,
        "title": "Voice Pathology Detection Using Phonation",
        "section_head": "Proposed Model",
        "score": 0.8951432704925537,
        "text_preview": "This research develops a framework for automated voice pathology detection using machine learning techniques. The primary objective is to analyze phonation data to differentiate between normal and pat"
      },
      {
        "chunk_index": 93230,
        "paper_id": 1969,
        "chunk_idx": 0,
        "title": "Multimodal Signal Fusion for Stress Detection Using Deep Neural Networks: A Novel Approach for Converting 1D Signals to Unified 2D Images",
        "section_head": "Figure 5 .",
        "score": 0.8880326747894287,
        "text_preview": "5 Figure 5. Comparison of colorization methods for signal representation matrices: (a) grayscale, (b) manual RGB, (c) proposed colorization techniques"
      },
      {
        "chunk_index": 120985,
        "paper_id": 2519,
        "chunk_idx": 1,
        "title": "Segment Transformer: AI-Generated Music Detection via Music Structural Analysis",
        "section_head": "IV. CONCLUSIONS",
        "score": 0.8852099776268005,
        "text_preview": "Future work could explore alternative methodological approaches, including end-to-end architectures that directly process full-length audio, as well as investigating different fusion strategies for co"
      },
      {
        "chunk_index": 6774,
        "paper_id": 124,
        "chunk_idx": 0,
        "title": "ADAPTING TO FRAGMENTED AND EVOLVING DATA: A FISHER INFORMATION PERSPECTIVE",
        "section_head": "Related Work",
        "score": 0.8842529058456421,
        "text_preview": "FADE connects the domains of covariate shift adaptation, sequential learning, and distributed optimization particularly within federated settings. While prior work has addressed components of this pro"
      },
      {
        "chunk_index": 157078,
        "paper_id": 3220,
        "chunk_idx": 4,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "detection.",
        "score": 0.8799418210983276,
        "text_preview": "abrupt expression changes Temporal Consistency Check Flags inconsistencies like abrupt movements or fixed head positions Motion Consistency Verification Identifies unrealistic facial region movements "
      },
      {
        "chunk_index": 25131,
        "paper_id": 507,
        "chunk_idx": 0,
        "title": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation",
        "section_head": "C. Analysis on Applicable Methods for PSSFL",
        "score": 0.8760701417922974,
        "text_preview": "We selected baselines based on their applicability to PSSFL. As discussed in related work ( ¬ß2) and comparison methods ( ¬ß4.1), most existing FL approaches are unsuitable for PSSFL due to the followin"
      },
      {
        "chunk_index": 43370,
        "paper_id": 921,
        "chunk_idx": 0,
        "title": "Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model",
        "section_head": "Conclusion",
        "score": 0.8744776248931885,
        "text_preview": "In conclusion, this study identifies significant limitations in using universal PLMs for rumor detection and introduces a novel continue pretraining strat- egy, PEP, to address these issues. By pretra"
      },
      {
        "chunk_index": 56961,
        "paper_id": 1222,
        "chunk_idx": 0,
        "title": "FROM PHYSICS TO MACHINE LEARNING AND BACK: PART II -LEARNING AND OBSERVATIONAL BIAS IN PHM",
        "section_head": "Fast Adaptation Methods",
        "score": 0.8708620071411133,
        "text_preview": "Applications in PHM Type of tasks Fault detection; Fault diagnosis; RUL prediction. Addressed challenges Fast adaptation to a novel dataset or task."
      },
      {
        "chunk_index": 4955,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "¬ß3.2 Resource Alloc.",
        "score": 0.8692045211791992,
        "text_preview": "‚Ä¢ Learning-Based ‚Ä¢ Energy-Aware ‚Ä¢ QoS-Driven"
      },
      {
        "chunk_index": 23580,
        "paper_id": 478,
        "chunk_idx": 0,
        "title": "Challenges and Applications of Large Language Models",
        "section_head": "Figure 10 :",
        "score": 0.8686964511871338,
        "text_preview": "10 Figure 10: Alignment. We categorize existing alignment work into methods for detecting misaligned behavior or aligning models."
      },
      {
        "chunk_index": 138053,
        "paper_id": 2844,
        "chunk_idx": 0,
        "title": "THE IMPACT OF AUDIO WATERMARKING ON AUDIO ANTI-SPOOFING COUNTERMEASURES",
        "section_head": "CONCLUSION",
        "score": 0.8648719787597656,
        "text_preview": "This work presents the first study on how audio watermarking impacts anti-spoofing detection systems. Experiments across diverse datasets and models show that watermarking can significantly degrade de"
      },
      {
        "chunk_index": 147708,
        "paper_id": 3041,
        "chunk_idx": 2,
        "title": "UNSEEN SPEAKER AND LANGUAGE ADAPTATION FOR LIGHTWEIGHT TEXT-TO-SPEECH WITH ADAPTERS",
        "section_head": "INTRODUCTION",
        "score": 0.864628791809082,
        "text_preview": "Serving as compact, learnable parameter modules plugged on top of existing neural network architectures, they enable targeted adaptation without necessitating extensive retraining. As the quest for ef"
      },
      {
        "chunk_index": 64489,
        "paper_id": 1379,
        "chunk_idx": 2,
        "title": "Holistic Evaluation of Language Models",
        "section_head": "Acknowledging the prior work this effort builds on.",
        "score": 0.8644220232963562,
        "text_preview": "11 Limitations and future work 11.1 Limitations of results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11.2 Limitations of HELM implementation . . . . . . . . . ."
      },
      {
        "chunk_index": 29044,
        "paper_id": 600,
        "chunk_idx": 0,
        "title": "CPCLDETECTOR: KNOWLEDGE ENHANCEMENT AND ALIGNMENT SELECTION FOR CHINESE PATRONIZING AND CONDESCENDING LANGUAGE DETECTION",
        "section_head": "Research Background of Datasets",
        "score": 0.8637961745262146,
        "text_preview": "In the research on CPCL detection, the lack of multi-modal data has long restricted technological development. Existing achievements mostly focus on the English field [10] [5] or single Chinese text m"
      },
      {
        "chunk_index": 20513,
        "paper_id": 415,
        "chunk_idx": 0,
        "title": "Breath as a biomarker: A survey of contact and contactless applications and approaches in respiratory monitoring",
        "section_head": "Fig. 1 .",
        "score": 0.8613308072090149,
        "text_preview": "1 Fig. 1. Mind map for Breath Analysis Applications and Approaches covered by this survey."
      }
    ]
  },
  {
    "query_id": 60,
    "query_text": "scientific knowledge",
    "source": "keyword_combination",
    "source_value": "scientific, knowledge",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 45634,
        "paper_id": 973,
        "chunk_idx": 0,
        "title": "EXPANDING REASONING POTENTIAL IN FOUNDATION MODEL BY LEARNING DIVERSE CHAINS OF THOUGHT PATTERNS",
        "section_head": "Table 5 :",
        "score": 0.9243690371513367,
        "text_preview": "5 Comparison with open-source CoT QA datasets. Dataset Target Domain CoT Date JiuZhang3.0 Mathematical Reasoning Short-CoT 2024 May. OpenMathInstruct-2 Mathematical Reasoning Short-CoT 2024 Oct. MegaM"
      },
      {
        "chunk_index": 97314,
        "paper_id": 2051,
        "chunk_idx": 0,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "Step 0: Initial Plan from Query Analyzer",
        "score": 0.9225130081176758,
        "text_preview": "Required skills: 1. Histopathology Knowledge: Understanding of osteosarcoma and its histological features."
      },
      {
        "chunk_index": 146607,
        "paper_id": 3022,
        "chunk_idx": 0,
        "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
        "section_head": "Text Input",
        "score": 0.9205425977706909,
        "text_preview": "Structural Fact Domain-specific Knowledge Symbolic-reasoning ...."
      },
      {
        "chunk_index": 40969,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Experimental Settings",
        "score": 0.9106370210647583,
        "text_preview": "We conduct our experiments on two representative domains: mathematical reasoning and Wikipedia (Wiki) QA, which involves commonsense and logical reasoning on factual descriptive knowledge."
      },
      {
        "chunk_index": 8458,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "Reasoning Tasks",
        "score": 0.883249044418335,
        "text_preview": "A concise overview of distinct categories of related reasoning approaches and tasks is provided here for background concepts. This comprehensive overview provides insights into the diverse landscape o"
      },
      {
        "chunk_index": 4684,
        "paper_id": 85,
        "chunk_idx": 1,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.8799538612365723,
        "text_preview": "1) Expert-Level Scientific Knowledge Comprehension and Retrieval: Unlike general-purpose language models, scientific AI models must retrieve, comprehend, and apply cutting-edge research knowledge acro"
      },
      {
        "chunk_index": 146705,
        "paper_id": 3022,
        "chunk_idx": 0,
        "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
        "section_head": "Fig. 11 .",
        "score": 0.8754581212997437,
        "text_preview": "11 Fig. 11. Retrieving external knowledge to enhance the LLM generation."
      },
      {
        "chunk_index": 12523,
        "paper_id": 247,
        "chunk_idx": 0,
        "title": "AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data",
        "section_head": "Table 5 :",
        "score": 0.8682436943054199,
        "text_preview": "5 Number of Questions per Reasoning Type Reasoning Type Number of Questions Mathematical Reasoning 79 Comparative Reasoning 67 Logical Reasoning 42 Temporal Reasoning 17"
      },
      {
        "chunk_index": 4685,
        "paper_id": 85,
        "chunk_idx": 2,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.8648574352264404,
        "text_preview": "This dimension challenges models on both the breadth and depth of scientific understanding, emphasizing accuracy, completeness, and the ability to engage with knowledge beyond surface-level facts. 2) "
      },
      {
        "chunk_index": 69549,
        "paper_id": 1481,
        "chunk_idx": 0,
        "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
        "section_head": "LLaVA-Instruct-150K",
        "score": 0.8609058260917664,
        "text_preview": "Visual Conversation Complex Reasoning"
      },
      {
        "chunk_index": 3408,
        "paper_id": 65,
        "chunk_idx": 0,
        "title": "A SCENARIO-DRIVEN COGNITIVE APPROACH TO NEXT-GENERATION AI MEMORY",
        "section_head": "Figure 5 :",
        "score": 0.8600649833679199,
        "text_preview": "5 Figure 5: Reasoning Process of Mathematical Problem-Solving"
      },
      {
        "chunk_index": 85391,
        "paper_id": 1798,
        "chunk_idx": 0,
        "title": "Mathematical Language Models: A Survey",
        "section_head": "Fig. 1 .",
        "score": 0.8587689995765686,
        "text_preview": "1 Fig. 1. Taxonomy of mathematical tasks."
      },
      {
        "chunk_index": 60441,
        "paper_id": 1289,
        "chunk_idx": 0,
        "title": "GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning",
        "section_head": "Table 10 :",
        "score": 0.8574502468109131,
        "text_preview": "10 Performance (%) on MathVista other tasks. \"Perception + Reasoning\" refers to our two-stage approach. MathVista Task Category Reasoning-only Perception + Reasoning Figure Question Answering 68.0 69."
      },
      {
        "chunk_index": 84385,
        "paper_id": 1775,
        "chunk_idx": 0,
        "title": "MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer",
        "section_head": "Understanding.",
        "score": 0.8527648448944092,
        "text_preview": "We adopt the following three categories of benchmarks for multimodal understanding. ‚Ä¢ General VQA: SeedBench [42] , RealWorldQA [103] , and MMBench [52] . ‚Ä¢ Knowledge & Reasoning: AI2D [36] , ScienceQ"
      },
      {
        "chunk_index": 4332,
        "paper_id": 84,
        "chunk_idx": 3,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "John McCarthy (2004)",
        "score": 0.8515844345092773,
        "text_preview": "In contrast to the soft Reasoning Natural Language Reasoning Dialogue Systems Question Answering Recommendation Systems Text Summarization Sentiment Analysis Co-reference Resolution AIGC Language Gene"
      },
      {
        "chunk_index": 28318,
        "paper_id": 581,
        "chunk_idx": 0,
        "title": "Contrastive Chain-of-Thought Prompting",
        "section_head": "Table 2 :",
        "score": 0.8510082960128784,
        "text_preview": "2 Main evaluation results for contrastive chain-of-thought on several reasoning tasks. Dataset Type |Train| |Test| GSM8K Arithmetic Reasoning 4 500 AQuA Arithmetic Reasoning 4 254 GSM-Hard Arithmetic "
      },
      {
        "chunk_index": 4370,
        "paper_id": 84,
        "chunk_idx": 0,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Reasoning Tasks",
        "score": 0.844204306602478,
        "text_preview": "In this section, we provide a concise overview of various reasoning tasks, as Figure 2 shows. Here, we present distinct categories of reasoning approaches and tasks: ‚Ä¢ Commonsense Reasoning (Section 3"
      },
      {
        "chunk_index": 102611,
        "paper_id": 2128,
        "chunk_idx": 1,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Related Work",
        "score": 0.8426672220230103,
        "text_preview": "By combining LLM flexibility with knowledge structure, these approaches seek to improve reasoning quality, transparency, and factual consistency. In this context, two directions have been pursued. In "
      },
      {
        "chunk_index": 4690,
        "paper_id": 85,
        "chunk_idx": 1,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "B. General-purpose Sci-LLMs",
        "score": 0.8376773595809937,
        "text_preview": "SciInstruct is built through self-reflective annotation to alleviate data scarcity in science domains such as Physics and Chemistry. However, directly fine-tuning open-source LLMs does not significant"
      },
      {
        "chunk_index": 44597,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Reasoning",
        "score": 0.834170937538147,
        "text_preview": "Complex reasoning encompasses the capacity to comprehend and effectively employ supporting evidence and logical frameworks to deduce conclusions or facilitate decision-making. In our effort to delinea"
      }
    ]
  },
  {
    "query_id": 61,
    "query_text": "image which",
    "source": "keyword_combination",
    "source_value": "image, which",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 16470,
        "paper_id": 330,
        "chunk_idx": 1,
        "title": "Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR",
        "section_head": "A KITAB-Bench-Analysis",
        "score": 0.9994034767150879,
        "text_preview": "# ‚Ä´ÿßÔªüÔ∫òÔ∫†Ô∫éÿ±ÿ©‚Ä¨ ‚Ä´ÿßÔªüÔ∫íÔªºÿØ:‚Ä¨ ‚Ä´Ô∫£Ô∫éÔªüÔ∫î‚Ä¨ ‚Ä´Ô∫óÔªòÔ∫ÆÔª≥Ô∫Æ‚Ä¨ ## ‚Ä´ŸàÿßÔªüÔ∫®Ô∫™Ôª£Ô∫éÿ™‚Ä¨ ‚Ä´ÿßÔªüÔ∫òÔ∫†Ô∫éÿ±ÿ©‚Ä¨ ‚Ä´ÔªóÔªÑÔ∫éÿπ‚Ä¨ ‚Ä´ÔªìÔª≤‚Ä¨ ‚Ä´ÿßÔªüÔªåÔ∫éÔª£Ôª†Ôª¥Ôª¶‚Ä¨ ‚Ä´ÔªãÔ∫™ÿØ‚Ä¨ :(3) ‚Ä´ÿ±ÔªóÔª¢‚Ä¨ ‚Ä´ÿßÔªüÔ∫∏ÔªúÔªû‚Ä¨ ‚Ä´ÔªãÔ∫éÔª£Ôªû(‚Ä¨ ‚Ä´)Ô∫ëÔ∫éÔª∑ÔªüÔªí‚Ä¨ 2015-2011 <image> 2015 ‚Ä´ÿßÔªªÔ∫≥Ô∫òÔ∫®Ô∫™ÿßŸÖÿå‚Ä¨ ‚Ä´Ôª£Ô∫¥Ô∫¢‚Ä¨ ‚Ä´ÿßÔªüÔªåÔ∫éÔª£Ô∫îÿå‚Ä¨ ‚Ä´ÿßÔªπÔ∫£Ô∫ºÔ∫éÿ°ÿßÿ™‚Ä¨ ‚Ä´ÿØÿßÔ∫ãÔ∫Æÿ©‚Ä¨ ‚Ä´.ÿßÔªüÔª§"
      },
      {
        "chunk_index": 136968,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.973139762878418,
        "text_preview": "The image size of the input image is 500 x 281 pixels."
      },
      {
        "chunk_index": 137044,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.9716306924819946,
        "text_preview": "The scene text in the image are:"
      },
      {
        "chunk_index": 129603,
        "paper_id": 2691,
        "chunk_idx": 0,
        "title": "StableGuard: Towards Unified Copyright Protection and Tamper Localization in Latent Diffusion Models",
        "section_head": "3:",
        "score": 0.9708478450775146,
        "text_preview": "Decode watermark-free image X = D ŒΩ (z)."
      },
      {
        "chunk_index": 137002,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.9700093865394592,
        "text_preview": "The scene text in the image is \"3,642,039,031,055\"."
      },
      {
        "chunk_index": 52075,
        "paper_id": 1117,
        "chunk_idx": 1,
        "title": "FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving",
        "section_head": "Multi-client Feature Fusion and Distillation",
        "score": 0.966606616973877,
        "text_preview": "Given an image P R L 3 / 1 B h F J B J W G c K x 1 1 3 N j 4 6 d Y G U Y 4 n Z Z 6 i a Y x J m M 8 p F 1 L J R Z U + 2 l 2 8 B S d W G W A w k j Z k g Z l 6 u + J F A u t J y K w n Q K b k V 7 0 Z u J"
      },
      {
        "chunk_index": 23631,
        "paper_id": 479,
        "chunk_idx": 0,
        "title": "Chameleon: Mixed-Modal Early-Fusion Foundation Models",
        "section_head": "Figure 2",
        "score": 0.9600471258163452,
        "text_preview": "2 Figure2Sample interleaved image and text generation from Chameleon. The corresponding images are generated in locations marked by <img>."
      },
      {
        "chunk_index": 136967,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Visualization of Detected Bbox: Prompt:",
        "score": 0.9557099938392639,
        "text_preview": "Localize each car in the image using bounding box. What is the image size of the input image?"
      },
      {
        "chunk_index": 48159,
        "paper_id": 1026,
        "chunk_idx": 0,
        "title": "Fast Graph Neural Network for Image Classification",
        "section_head": "Figure 5 .",
        "score": 0.9493364095687866,
        "text_preview": "5 Figure 5. (a) The densest Delaunay Triangulation Graph for an image. (b) The Delaunay on an image with [7k X 7k] pixels. (c) The Delaunay Triangulation of Biomedical image in (b) without the image."
      },
      {
        "chunk_index": 112086,
        "paper_id": 2334,
        "chunk_idx": 0,
        "title": "RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios",
        "section_head": "Multi-image Extraction Multi-image Reasoning",
        "score": 0.9416361451148987,
        "text_preview": "TextÔºöÁáïÈ∫¶‚æä‚Ω∫È©º‚ΩëÂºÄË°´ÔºåËΩØËΩØÁ≥ØÁ≥ØÔºåÁôæÊê≠‰∏çÂá∫ÈîôÔºå‚ºÄËßÅÈíüÊÉÖÁöÑËá™ÁïôÊ¨æ Translation: Oat-colored alpaca cardigan, soft and cozy, versatile and foolproof, a piece that captures love at first sight. TextÔºöÊôØÁÇπÈó®Á•®‚º§ÂÖ®ÔºõÂá∫‚æèÂáÜÂ§á+ÈôÑÊú∫Á•®ÁúÅÈí±Â¶ôÊãõÔºõ‰ΩèÂÆøÊîªÁï•+Â∞èË¥¥‚º†Ôºõ ‰∫§ÈÄöÊåáÂçóÔºõÁæé"
      },
      {
        "chunk_index": 11946,
        "paper_id": 233,
        "chunk_idx": 0,
        "title": "Any-to-Any Generation via Composable Diffusion",
        "section_head": "Figure 3 :",
        "score": 0.9407604336738586,
        "text_preview": "3 Figure 3: Single-to-single modality generation. Clockwise from top left: text‚Üíimage, image‚Üítext, image‚Üívideo, audio‚Üíimage."
      },
      {
        "chunk_index": 130129,
        "paper_id": 2701,
        "chunk_idx": 0,
        "title": "StarVector: Generating Scalable Vector Graphics Code from Images and Text",
        "section_head": "SVG Primitive Coverage",
        "score": 0.9393168687820435,
        "text_preview": "Image Vectorization Text to SVG Diagram Generation Image Processing Vtracer Image Image ‚úì ‚úó ‚úì ‚úó ‚úó Autotrace Image Image ‚úì ‚úó ‚úì ‚úó ‚úó Potrace Image Image ‚úì ‚úó ‚úì ‚úó ‚úó Latent Variable Im2Vec Image Image ‚úó ‚úó ‚úì"
      },
      {
        "chunk_index": 137004,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.9383441805839539,
        "text_preview": "The scene text in the image are: -(NVDA) -NVIDIA -356.85 -+51.47 -+16.85%"
      },
      {
        "chunk_index": 137006,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.9298303127288818,
        "text_preview": "The scene text in the image are: -\"Royal\" -\"London\""
      },
      {
        "chunk_index": 136969,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.9295914173126221,
        "text_preview": "1. The size of the input image is 1600 x 1067 pixels."
      },
      {
        "chunk_index": 83865,
        "paper_id": 1765,
        "chunk_idx": 0,
        "title": "Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors",
        "section_head": "Scene editing and anchoring",
        "score": 0.9226424694061279,
        "text_preview": "Rather than editing certain regions of images as demonstrated by [45] , we introduce new capabilities of generating images from existing or edited scenes. In Fig. 4 , two scenarios are considered. In "
      },
      {
        "chunk_index": 57221,
        "paper_id": 1226,
        "chunk_idx": 0,
        "title": "From Recognition to Cognition: Visual Commonsense Reasoning",
        "section_head": "a)",
        "score": 0.9212846755981445,
        "text_preview": "Boring image.b) Interesting image."
      },
      {
        "chunk_index": 27893,
        "paper_id": 572,
        "chunk_idx": 0,
        "title": "Consistency Models",
        "section_head": "Figure 13 :",
        "score": 0.9212425351142883,
        "text_preview": "13 Figure 13: SDEdit with a consistency model. The leftmost images are stroke painting inputs. Images on the right side are the results of stroke-guided image generation (SDEdit)."
      },
      {
        "chunk_index": 147128,
        "paper_id": 3029,
        "chunk_idx": 0,
        "title": "UnIVAL: Unified Model for Image, Video, Audio and Language Tasks",
        "section_head": "E Pretraining Tasks",
        "score": 0.916417121887207,
        "text_preview": "We pretrain UnIVAL on the following image/video-text tasks: Image Captioning. The model takes as input an image and \"what does the image describe?\" as text and generate a textual description of the im"
      },
      {
        "chunk_index": 136933,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.910637617111206,
        "text_preview": "Describe both the image and logo in details"
      }
    ]
  },
  {
    "query_id": 62,
    "query_text": "where time",
    "source": "keyword_combination",
    "source_value": "where, time",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 3180,
        "paper_id": 60,
        "chunk_idx": 1,
        "title": "A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm",
        "section_head": "Computation of limiting projection for LR-GMM",
        "score": 0.9110151529312134,
        "text_preview": "We have, for x ‚àà R d and t > 0, œâ k (x, t) := ŒΩ k (x, t) K ‚Ñì=1 ŒΩ l (x, t) with ŒΩ k (x, t) = œÄ k ( 2œÄ ) d/2 det 1/2 (U k U T k + tI) ‚Ä¢ exp - 1 2 x T (U k U T k + tI) -1 x . Let r k = dim(E k ). We have"
      },
      {
        "chunk_index": 26683,
        "paper_id": 542,
        "chunk_idx": 0,
        "title": "Communication and Computation Efficient Split Federated Learning in O-RAN",
        "section_head": "APPENDIX A PROOF OF THEOREM 1",
        "score": 0.9087293744087219,
        "text_preview": "Due to the L-smoothness of the local loss function, we have: 1 T T -1 t=0 E At [E[F C ( w(t+1) C ) -F C ( w(t) C )]] ‚â§ 1 T T -1 t=0 -Œ∑ C E At [E[‚ü®‚àáF C ( w(t) C ), 1 K m‚ààAt ‚àáf C,m (w t C,m )‚ü©]] C2 + Œ∑ "
      },
      {
        "chunk_index": 114970,
        "paper_id": 2399,
        "chunk_idx": 0,
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
        "section_head": "Decoding",
        "score": 0.9000728130340576,
        "text_preview": "At test time, RAG-Sequence and RAG-Token require different ways to approximate arg max y p(y|x)."
      },
      {
        "chunk_index": 101699,
        "paper_id": 2113,
        "chunk_idx": 0,
        "title": "Optimizing Communication and Device Clustering for Clustered Federated Learning with Differential Privacy",
        "section_head": "3) DP Noise Optimization Complexity:",
        "score": 0.899261474609375,
        "text_preview": "The DP noise parameters œÉ i are optimized by the interior-point method [39] . Hence, the computational complexity per iteration is O(U 3 ) [40] . The number of iterations required for convergence of t"
      },
      {
        "chunk_index": 50989,
        "paper_id": 1092,
        "chunk_idx": 0,
        "title": "FedEve: On Bridging the Client Drift and Period Drift for Cross-device Federated Learning",
        "section_head": "G.4.3 Proof of Lemma G.8",
        "score": 0.8892829418182373,
        "text_preview": "Proof. Given time index t and for client j with j Ã∏ = i, we have E‚à•w j,k+1 -w ‚Ä≤ j,k+1 ‚à• ‚â§ (1 + Œ∑ l L m )E‚à•w j,k -w ‚Ä≤ j,k ‚à•."
      },
      {
        "chunk_index": 45043,
        "paper_id": 960,
        "chunk_idx": 0,
        "title": "Evaluating Selective Encryption Against Gradient Inversion Attacks",
        "section_head": "A.2 Proof of Lemma 4.3",
        "score": 0.8738745450973511,
        "text_preview": "Proof. From the definition of the cross entropy, and supposing k 0 is the index of the true label, we can write g(x, Œ∏) = ‚àá Œ∏ L(x, Œ∏) (9) = -y (k0) 0 ‚àá Œ∏ log f (x, Œ∏) (k0) . ( 10 ) Applying the fundam"
      },
      {
        "chunk_index": 141591,
        "paper_id": 2917,
        "chunk_idx": 0,
        "title": "Towards Heterogeneity-Aware and Energy-Efficient Topology Optimization for Decentralized Federated Learning in Edge Environment",
        "section_head": "Theorem 2:",
        "score": 0.8725439310073853,
        "text_preview": "The regret of Hat-DFed can be bounded as R K ‚â§ Œ∑KN 2 + 2 log N Œ∑ , (24) and if the tuning parameter Œ∑ = ‚àö K log N N K , we have R K ‚â§ 3N K log N . ( 25 ) Proof: The complete proof has been presented i"
      },
      {
        "chunk_index": 143433,
        "paper_id": 2959,
        "chunk_idx": 0,
        "title": "Transition Models: Rethinking the Generative Learning Objective",
        "section_head": "Algorithm 2 Piecewise Sampling Algorithm of Diffusion Transition Models (TiM).",
        "score": 0.8693159222602844,
        "text_preview": "Input: sampling step N , miximum timestep T max , model f Œ∏ , diffusion parameterization {Œ± t , œÉ t , Œ±t , œÉt }, stochasticity ratio œÅ. Init: data x N ‚àº N (0, I), timesteps T = {t i } 0 i=N where t N "
      },
      {
        "chunk_index": 6647,
        "paper_id": 121,
        "chunk_idx": 2,
        "title": "Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs",
        "section_head": "F Computational Complexity Analysis",
        "score": 0.8680607080459595,
        "text_preview": "For the P(True) method, the computational complexity is O(m ‚Ä¢ l max ) since we need to additionally generate m answers and need one forward pass to compute the P(True) score. For the proposed method A"
      },
      {
        "chunk_index": 98237,
        "paper_id": 2072,
        "chunk_idx": 1,
        "title": "On the Convergence of Policy Mirror Descent with Temporal Difference Evaluation",
        "section_head": "number of samples.",
        "score": 0.8621585369110107,
        "text_preview": "More precisely, the value evaluation in h-PMD is given by V œÄ k (s) = 1 M V M V j=1 H-1 t=0 Œ≥ t r(s j t , a j t ), where s j 0 = s, a j t ‚àº œÄ k (‚Ä¢|s j t ), s j t+1 ‚àº P (‚Ä¢|s j t , a j t ), QœÄ k 1 (s, a"
      },
      {
        "chunk_index": 153674,
        "paper_id": 3150,
        "chunk_idx": 2,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "F.2 Proof of First-order Lower Bounds F.2.1 Proof of Theorem 17",
        "score": 0.8604516983032227,
        "text_preview": "This ensures the following, E {ft‚àºD} t‚àà[T ] 1 M T m,t f t (x m t ) -min x ‚ãÜ ‚ààB2(B) 1 T t f t (x ‚ãÜ ) = E Œ≤t‚àº G ‚àö d ‚Ä¢U nif ({+1,-1} d ) t‚àà[T ] 1 M T m,t ‚ü®Œ≤ t , x m t ‚ü© -min x ‚ãÜ ‚ààB2(B) 1 T t ‚ü®Œ≤ t , x ‚ãÜ ‚ü©"
      },
      {
        "chunk_index": 153679,
        "paper_id": 3150,
        "chunk_idx": 2,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "Remark 41.",
        "score": 0.8497390151023865,
        "text_preview": "Re-arranging this leads to 1 M m‚àà[M ] (f m t (x m t ) -f m t (x ‚ãÜ )) ‚â§ 1 2Œ∑ t ‚à•x t -x ‚ãÜ ‚à• 2 2 -E t ‚à•x t+1 -x ‚ãÜ ‚à• 2 2 + Œ∑ t 2M 2 m‚àà[M ] ‚àáf m t (x m t ) 2 2 + I K>1 ‚Ä¢ 1 M m‚àà[M ] E t ‚ü®x m t -xt , ‚àáf m t "
      },
      {
        "chunk_index": 104871,
        "paper_id": 2174,
        "chunk_idx": 0,
        "title": "PERSONALIZED FEDERATED LEARNING WITH HEAT-KERNEL ENHANCED TENSORIZED MULTI-VIEW CLUSTERING",
        "section_head": "Theorem 7 (",
        "score": 0.8484494686126709,
        "text_preview": "7 Tensorized Time Complexity). The tensorized local clustering complexity per client i per iteration is O(n i cr 2 r 3 + n i cD i s i ) where r 2 , r 3 are the tensor decomposition ranks. Proof. The c"
      },
      {
        "chunk_index": 117359,
        "paper_id": 2452,
        "chunk_idx": 1,
        "title": "S-LORA: SERVING THOUSANDS OF CONCURRENT LORA ADAPTERS",
        "section_head": "B.1 Proof of Theorem B.1",
        "score": 0.8479630947113037,
        "text_preview": "For any i, j ‚àà [n -l + 1, n], we assume that i < j and j is first served at time t 1 while i is served at time t 2 with t 1 < t 2 . Let t a i , t a j be the arrival time of i, j. The reward for servin"
      },
      {
        "chunk_index": 57996,
        "paper_id": 1241,
        "chunk_idx": 0,
        "title": "FUSEDANN: Convexified Hybrid ANN via Attribute-Vector Fusion",
        "section_head": "Query Complexity",
        "score": 0.8466032147407532,
        "text_preview": "Theorem 22 Shows that the complete range query algorithm has O(log N + k log(1/œµ) + k log k) expected time."
      },
      {
        "chunk_index": 26672,
        "paper_id": 542,
        "chunk_idx": 0,
        "title": "Communication and Computation Efficient Split Federated Learning in O-RAN",
        "section_head": "C. Problem Formulation",
        "score": 0.8440386056900024,
        "text_preview": "With the modeling of resources and latency, we can formulate the total cost in each round as: cost(t) = œÅ(R co + R cp ) + (1 -œÅ)T total = œÅ( M m=1 a t m b t m Bp c + M m=1 a t m E(Q C,m + Q S,m )p tr "
      },
      {
        "chunk_index": 47551,
        "paper_id": 1013,
        "chunk_idx": 0,
        "title": "Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions",
        "section_head": "Lemma 3 (",
        "score": 0.843579888343811,
        "text_preview": "3 Uniform bounded variance of the reward). Since R total ‚àà [0, 1], we have Var(R total ) ‚â§ 1 4 for any data distribution. Lemma 4 (Non-degenerate gradient second moment on the backoff branch). Let B ="
      },
      {
        "chunk_index": 157311,
        "paper_id": 3223,
        "chunk_idx": 0,
        "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs",
        "section_head": "Fig. 2 .",
        "score": 0.8417933583259583,
        "text_preview": "2 Fig. 2. Average client-side proof generation time and server-side verification time as a function of the number of clients."
      },
      {
        "chunk_index": 120627,
        "paper_id": 2511,
        "chunk_idx": 0,
        "title": "See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model",
        "section_head": "6) Speed and Acceleration.",
        "score": 0.8400604724884033,
        "text_preview": "Let ‚àÜt be the time interval between consecutive frames. Then the speed v i and acceleration a i are: v i = d i ‚àÜt , a i = v i -v i-1 ‚àÜt . (24) Here, d i is the displacement between adjacent frames, v "
      },
      {
        "chunk_index": 71984,
        "paper_id": 1535,
        "chunk_idx": 0,
        "title": "Joint AoI and Handover Optimization in Space-Air-Ground Integrated Network",
        "section_head": "Optimization Objective 1",
        "score": 0.8347674608230591,
        "text_preview": "The primary objective is to improve the time average AoI of LEO satellites. As such, the first optimization objective is given by f 1 (P, L) = 1 T t‚ààT N S i=1 ‚àÜ i [t]. (16)"
      }
    ]
  },
  {
    "query_id": 63,
    "query_text": "graph human",
    "source": "keyword_combination",
    "source_value": "graph, human",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 126451,
        "paper_id": 2635,
        "chunk_idx": 0,
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "section_head": "Figure 4 . 6 :",
        "score": 0.9304118752479553,
        "text_preview": "46 Figure 4.6: A discussion regarding k-SAT problems and graph theory."
      },
      {
        "chunk_index": 102646,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 4 :",
        "score": 0.8778907060623169,
        "text_preview": "4 Human expert evaluation resultsApproach Actionability Coherence Domain Spec. Tech Spec. Understand. User Focus Overall ReT-Eval 4.2 ¬± 0.7 4.1 ¬± 0.8 4.0 ¬± 0.8 4.0 ¬± 0.7 4.3 ¬± 0.6 4.1 ¬± 0.7 4.1 GNN"
      },
      {
        "chunk_index": 33638,
        "paper_id": 706,
        "chunk_idx": 0,
        "title": "DFed-SST: Building Semantic-and Structure-aware Topologies for Decentralized Federated Graph Learning",
        "section_head": "Table 1 :",
        "score": 0.8506780862808228,
        "text_preview": "1 The statistical information of the experimental datasets. dataset nodes features edges classes train/val/test description Cora 2,708 1,433 5,429 7 20%/40%/40% citation network CiteSeer 3,327 3,703 4"
      },
      {
        "chunk_index": 52137,
        "paper_id": 1118,
        "chunk_idx": 0,
        "title": "FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting",
        "section_head": "Table 1 :",
        "score": 0.847691535949707,
        "text_preview": "1 The statistical information of the experimental datasets. dataset nodes features edges classes train/val/test description Cora 2708 1433 5429 7 20%/40%/40% citation network CiteSeer 3327 3703 4732 6"
      },
      {
        "chunk_index": 62604,
        "paper_id": 1336,
        "chunk_idx": 0,
        "title": "GRAPHUNIVERSE: ENABLING SYSTEMATIC EVALUA-TION OF INDUCTIVE GENERALIZATION",
        "section_head": "VALIDATION OF GRAPHUNIVERSE",
        "score": 0.8392386436462402,
        "text_preview": "To ensure our multiple graph generation framework produces high-fidelity graphs with the intended properties and learnable signals within and across graphs, we conduct a comprehensive validation study"
      },
      {
        "chunk_index": 5294,
        "paper_id": 90,
        "chunk_idx": 0,
        "title": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material",
        "section_head": "Metrics.",
        "score": 0.833875298500061,
        "text_preview": "Most represented types of evaluation metrics in the TABLE 3 Datasets commonly used for graph generation models Dataset Dimensionality Category No. of Graphs (G) No. of Nodes (N) Community-small 2D Soc"
      },
      {
        "chunk_index": 149974,
        "paper_id": 3081,
        "chunk_idx": 0,
        "title": "Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents",
        "section_head": "Figure 5 :",
        "score": 0.8202873468399048,
        "text_preview": "5 video conversations human human"
      },
      {
        "chunk_index": 75411,
        "paper_id": 1596,
        "chunk_idx": 0,
        "title": "Large Language Models on Graphs: A Comprehensive Survey",
        "section_head": "V",
        "score": 0.8178842067718506,
        "text_preview": "The set of nodes in a graph. v A node v ‚àà V. E The set of edges in a graph. e An edge e ‚àà E."
      },
      {
        "chunk_index": 62552,
        "paper_id": 1334,
        "chunk_idx": 0,
        "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?",
        "section_head": "Conclusion",
        "score": 0.8141297101974487,
        "text_preview": "We propose GraphMaker, a diffusion model capable of generating large attributed graphs, along with a novel evaluation protocol that assesses generation quality by training models on generated graphs a"
      },
      {
        "chunk_index": 10424,
        "paper_id": 201,
        "chunk_idx": 0,
        "title": "AN EFFICIENT GNNS-TO-KANS DISTILLATION VIA SELF-ATTENTION DYNAMIC SAMPLING WITH POTENTIAL FOR CONSUMER ELECTRONICS EDGE DEPLOYMENT A PREPRINT",
        "section_head": "RELATED WORK",
        "score": 0.8120909333229065,
        "text_preview": "This section briefly reviews the background knowledge relevant to our research, focusing on the fundamental concepts of graphs, Graph Knowledge Distillation (GKD), Kolmogorov-Arnold Network (KAN), and"
      },
      {
        "chunk_index": 82253,
        "paper_id": 1731,
        "chunk_idx": 0,
        "title": "Local Virtual Nodes for Alleviating Over-Squashing in Graph Neural Networks",
        "section_head": "Fig. 3 .",
        "score": 0.8102623224258423,
        "text_preview": "3 Fig. 3. A graph augmented with LVNs directed (Left) and undirected (Right) edge distribution methods. Dotted lines represent directed edges."
      },
      {
        "chunk_index": 39344,
        "paper_id": 832,
        "chunk_idx": 2,
        "title": "Dynamic Triangulation-Based Graph Rewiring for Graph Neural Networks",
        "section_head": "Triangle Encoding and Selection",
        "score": 0.8100649118423462,
        "text_preview": "g ùëñ ùëóùëò = ùëì MLP (z ùëñ ùëóùëò ) ‚àà R ùëë ‚Ä≤ , Original graph graph ‚ë† Input graphs V D L S g N B E O y N r x h f U Y 9 e B o O g l 7 A r E j 0 G v X h M w D w g W c L s p D c Z M z u 7 z M w K I e Q L v H h Q x K"
      },
      {
        "chunk_index": 154775,
        "paper_id": 3174,
        "chunk_idx": 0,
        "title": "Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models",
        "section_head": "Figure 3 :Figure 4 :",
        "score": 0.8081740140914917,
        "text_preview": "34 Figure3: Inclusivity evaluation prompt"
      },
      {
        "chunk_index": 483,
        "paper_id": 11,
        "chunk_idx": 0,
        "title": "A Comprehensive Data-centric Overview of Federated Graph Learning",
        "section_head": "A. Data Format",
        "score": 0.8079803586006165,
        "text_preview": "The data format in FGL determines the structural and semantic representation of graph data, demonstrating diversity in node types, topological structures, and feature or label information. In addition"
      },
      {
        "chunk_index": 43726,
        "paper_id": 930,
        "chunk_idx": 0,
        "title": "Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching",
        "section_head": "Theorem 2",
        "score": 0.8050717115402222,
        "text_preview": "The relationship between the graph quality evaluation metrics Relevance and Semantic Richness are positively correlated with the optimization objective M I(Q, G). P (q, G) = l j=1 n q, t j l ‚àù l j=1 s"
      },
      {
        "chunk_index": 6936,
        "paper_id": 126,
        "chunk_idx": 0,
        "title": "Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications",
        "section_head": "Figure 8 :",
        "score": 0.8025959134101868,
        "text_preview": "8 Figure 8: Multi-schedule graph training nodes"
      },
      {
        "chunk_index": 39363,
        "paper_id": 832,
        "chunk_idx": 0,
        "title": "Dynamic Triangulation-Based Graph Rewiring for Graph Neural Networks",
        "section_head": "24 ‚ë£",
        "score": 0.8021906614303589,
        "text_preview": "24 r K s I J n M I 5 u H A J d b i D B j S B w C O 8 w C u 8 W c / W u / V h f c 5 H C 1 a + c w w L s L 5 + A V U L l r A = < / l a t e x i t > p = 0.14 < l a t e x i t s h a 1 _ b a s e 6 4 = \" L + "
      },
      {
        "chunk_index": 62335,
        "paper_id": 1330,
        "chunk_idx": 0,
        "title": "GRAPH-R1: Incentivizing the Zero-Shot Graph Learning Capability in LLMs via Explicit Reasoning",
        "section_head": "Graph-Reasoning Data Curation",
        "score": 0.8014450073242188,
        "text_preview": "To investigate reason-then-predict graph learning, we construct the first dataset featuring explicit, detailed reasoning traces across multiple graph tasks. Dataset and task selection. We sample 11 re"
      },
      {
        "chunk_index": 14879,
        "paper_id": 300,
        "chunk_idx": 0,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Constructing Narratives with Autiverse",
        "score": 0.8003937005996704,
        "text_preview": "Based on the survey results and the feedback in debriefing, we illustrate how Autiverse guided adolescents' narrative construction through scaffolding and multimodal support."
      },
      {
        "chunk_index": 91496,
        "paper_id": 1928,
        "chunk_idx": 0,
        "title": "MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance",
        "section_head": "Table 8 :",
        "score": 0.7981971502304077,
        "text_preview": "8 Correlation of automatic metrics with summary-level human judgments forTAC-2008 and TAC-2009. BAGEL SFHOTEL"
      }
    ]
  },
  {
    "query_id": 64,
    "query_text": "combined effect resource competition",
    "source": "chunk_content",
    "source_value": "The combined effect of resource competition during both model distribution and aggregation leads to ",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 2184,
        "paper_id": 38,
        "chunk_idx": 0,
        "title": "A HYBRID AI FRAMEWORK FOR STRATEGIC PATENT PORTFOLIO PRUNING: INTEGRATING LEARNING-TO-RANK AND MARKET-NEED ANALYSIS FOR TECHNOLOGY TRANSFER OPTIMIZATION",
        "section_head": "Market Size of Technology (V TAM ):",
        "score": 0.9244861602783203,
        "text_preview": "The Total Addressable Market in currency for the technology area."
      },
      {
        "chunk_index": 110842,
        "paper_id": 2303,
        "chunk_idx": 0,
        "title": "Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking",
        "section_head": "$2",
        "score": 0.8524885177612305,
        "text_preview": "The price of each egg is $2. $2 \\times 9 = 18$ 18 is the total price of the eggs. The total price of the eggs is $18."
      },
      {
        "chunk_index": 53400,
        "paper_id": 1146,
        "chunk_idx": 0,
        "title": "Finance-Grounded Optimization For Algorithmic Trading",
        "section_head": "Table 1 :",
        "score": 0.8488928079605103,
        "text_preview": "1 Coins median annual percentage price change. price change in per cent 2021-2022 432.41 2022-2023 45.20 2023-2024 1.06 2024-2025 90.00"
      },
      {
        "chunk_index": 2218,
        "paper_id": 38,
        "chunk_idx": 0,
        "title": "A HYBRID AI FRAMEWORK FOR STRATEGIC PATENT PORTFOLIO PRUNING: INTEGRATING LEARNING-TO-RANK AND MARKET-NEED ANALYSIS FOR TECHNOLOGY TRANSFER OPTIMIZATION",
        "section_head": "Manual Assessment, AIbased Text Analysis",
        "score": 0.8452045917510986,
        "text_preview": "Market Size of Technology Data: The total addressable market (TAM) in currency for the patent's specific technology area. Usage: A direct input to the \"Opportunity Size\" calculation in the final ontol"
      },
      {
        "chunk_index": 88959,
        "paper_id": 1871,
        "chunk_idx": 0,
        "title": "Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning",
        "section_head": "K",
        "score": 0.8257647752761841,
        "text_preview": "The number of clients M The number of modalities T The number of global rounds N The number of data samples collected by client E The number of local iterations C The number of classes Œ∏ m The modalit"
      },
      {
        "chunk_index": 2222,
        "paper_id": 38,
        "chunk_idx": 0,
        "title": "A HYBRID AI FRAMEWORK FOR STRATEGIC PATENT PORTFOLIO PRUNING: INTEGRATING LEARNING-TO-RANK AND MARKET-NEED ANALYSIS FOR TECHNOLOGY TRANSFER OPTIMIZATION",
        "section_head": "Market Research, TRL/MRL Analysis",
        "score": 0.8076141476631165,
        "text_preview": "Table 3 -continued from previous page Parameter Name Detailed Data & Usage in Framework Potential Data Source(s) Application Coverage Data: A count of the number of distinct industries or product type"
      },
      {
        "chunk_index": 76171,
        "paper_id": 1610,
        "chunk_idx": 1,
        "title": "Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning",
        "section_head": "Table 1 .",
        "score": 0.8055331707000732,
        "text_preview": "Method VLCS TerraIncognita C L S V Total Gain L100 L38 L43 L46 Total Gain CLIP (ViT-B/16) [26] 99.86 70.11 76.66 85.34 80.83 - 41.96 28.30 35.82 26.82 31.84 - VTE [5] 99.86 70.29 78.28 86.55 81.75 +0."
      },
      {
        "chunk_index": 28798,
        "paper_id": 594,
        "chunk_idx": 0,
        "title": "Copycat vs. Original: Multi-modal Pretraining and Variable Importance in Box-office Prediction",
        "section_head": "Fig. 5 :",
        "score": 0.8005675673484802,
        "text_preview": "5 Fig. 5: Distribution plots for copycat-related variables Competition & Seasonality. To capture the effects of changing consumer tastes and holiday seasons, we include"
      },
      {
        "chunk_index": 125012,
        "paper_id": 2609,
        "chunk_idx": 0,
        "title": "SLICEGPT: COMPRESS LARGE LANGUAGE MODELS BY DELETING ROWS AND COLUMNS",
        "section_head": "Table 6 :",
        "score": 0.7822283506393433,
        "text_preview": "6 Evaluating the effects of varying slicing level by layer. The calibration set size is 128 and the sequence length is the maximum for each model. Model WikiText-2 PPL (25% constant slicing) (varying "
      },
      {
        "chunk_index": 2186,
        "paper_id": 38,
        "chunk_idx": 0,
        "title": "A HYBRID AI FRAMEWORK FOR STRATEGIC PATENT PORTFOLIO PRUNING: INTEGRATING LEARNING-TO-RANK AND MARKET-NEED ANALYSIS FOR TECHNOLOGY TRANSFER OPTIMIZATION",
        "section_head": "Cumulative CAGR of Technology (CAGR tech ):",
        "score": 0.7776262760162354,
        "text_preview": "The projected CAGR for the technology's market. CAGR tech = Market Value end Market Value start 1 N -1"
      },
      {
        "chunk_index": 1553,
        "paper_id": 26,
        "chunk_idx": 0,
        "title": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds",
        "section_head": "Table 2",
        "score": 0.7689201831817627,
        "text_preview": "2 Minimum and Maximum Amplitudes for Fault Detection and Number of Samples Class Minimum Amplitude Maximum Amplitude Number of Sound Samples Healthy - - 1200 Imbalance fault -1 11 200 Modulation fault"
      },
      {
        "chunk_index": 50229,
        "paper_id": 1076,
        "chunk_idx": 0,
        "title": "Federated Learning on Riemannian Manifolds: A Gradient-Free Projection-Based Approach",
        "section_head": "Figure 4 :",
        "score": 0.7633367776870728,
        "text_preview": "4 Figure 4: Impact of number of local updates."
      },
      {
        "chunk_index": 136867,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "GPT-4V:",
        "score": 0.7611665725708008,
        "text_preview": "Based on the graph, the year with the highest average gas price for the month of June is 2021, with a price of approximately $3.32 per gallon"
      },
      {
        "chunk_index": 135365,
        "paper_id": 2801,
        "chunk_idx": 0,
        "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
        "section_head": "Figure 3 .",
        "score": 0.7587888836860657,
        "text_preview": "3 Figure 3. Effect of sample number, on XSUM."
      },
      {
        "chunk_index": 20292,
        "paper_id": 411,
        "chunk_idx": 1,
        "title": "BoreaRL: A Multi-Objective Reinforcement Learning Environment for Climate-Adaptive Boreal Forest Management",
        "section_head": "B.2 Training Paradigms",
        "score": 0.7559428811073303,
        "text_preview": "The envi- Table 4 -continued from previous page Index Description Normalization 1 Year year/50 2 Stem Density (stems ha -1 ) density/1500 3 Conifer Fraction [0, 1] (no change) 4 Total Carbon Stock (kg"
      },
      {
        "chunk_index": 134605,
        "paper_id": 2786,
        "chunk_idx": 10,
        "title": "TEACHING LARGE LANGUAGE MODELS TO SELF-DEBUG",
        "section_head": "Original Python code",
        "score": 0.7534819841384888,
        "text_preview": "CREATE TABLE city ( city_id number , official_name text , status text , area_km_2 number , population number , census_ranking text , primary key ( city_id ) ) insert into city (city_id, official_name,"
      },
      {
        "chunk_index": 134620,
        "paper_id": 2786,
        "chunk_idx": 25,
        "title": "TEACHING LARGE LANGUAGE MODELS TO SELF-DEBUG",
        "section_head": "Original Python code",
        "score": 0.7534815073013306,
        "text_preview": "CREATE TABLE city ( city_id number , official_name text , status text , area_km_2 number , population number , census_ranking text , primary key ( city_id ) ) insert into city (city_id, official_name,"
      },
      {
        "chunk_index": 108949,
        "paper_id": 2260,
        "chunk_idx": 0,
        "title": "Prompt Injection attack against LLM-integrated Applications",
        "section_head": "COPYWRITERKIT",
        "score": 0.7532205581665039,
        "text_preview": "The application provides a range of copywriting tools for various business needs, including blog posts, product descriptions, and Instagram captions."
      },
      {
        "chunk_index": 43230,
        "paper_id": 918,
        "chunk_idx": 0,
        "title": "Enhancing Privacy Preservation and Reducing Analysis Time with Federated Transfer Learning in Digital Twins-based Computed Tomography Scan Analysis",
        "section_head": "4:",
        "score": 0.7500283122062683,
        "text_preview": "Send W global -to the local digital twin system;"
      },
      {
        "chunk_index": 160,
        "paper_id": 3,
        "chunk_idx": 0,
        "title": "A Careful Examination of Large Language Model Performance on Grade School Arithmetic",
        "section_head": "38",
        "score": 0.7449790239334106,
        "text_preview": "The Genco Olive Oil Company has received ninety-nine orders for ninetynine barrels of olive oil each. Out of those shipped, 33 orders were sent back due to clerical or product errors. How many total b"
      }
    ]
  },
  {
    "query_id": 65,
    "query_text": "llamaguard2 evaluation results across",
    "source": "chunk_content",
    "source_value": "15 LlamaGuard2 evaluation results across moderation labels in four sections",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 15644,
        "paper_id": 313,
        "chunk_idx": 0,
        "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs",
        "section_head": "Fig. 7 .",
        "score": 0.9873038530349731,
        "text_preview": "7 Fig. 7. Model Performance Comparison Across Evaluation Metrics"
      },
      {
        "chunk_index": 15645,
        "paper_id": 313,
        "chunk_idx": 0,
        "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs",
        "section_head": "Fig. 8 .",
        "score": 0.9546560645103455,
        "text_preview": "8 Fig. 8. Radar Chart of Model Performance Across Evaluation Metrics"
      },
      {
        "chunk_index": 22135,
        "paper_id": 453,
        "chunk_idx": 0,
        "title": "CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration",
        "section_head": "Table 1 :",
        "score": 0.9523637294769287,
        "text_preview": "1 Human evaluation on T2I-CompBench++, showing that CARINOX achieves the highest alignment across categories and backbones. Best values are in bold, second-best are underlined. 1) SD-Turbo 0.47 0.37 0"
      },
      {
        "chunk_index": 40976,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Mathematical Reasoning",
        "score": 0.9511764645576477,
        "text_preview": "Table 4 shows the evaluation results for the LLaMa-2 and LLaMa-2-Chat models."
      },
      {
        "chunk_index": 1427,
        "paper_id": 25,
        "chunk_idx": 0,
        "title": "A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints",
        "section_head": "Evaluation & Results",
        "score": 0.9467617273330688,
        "text_preview": "The experimental results are evaluated using three key metrics: dataset-specific image generation scores, classifier performance, and training latency. These metrics are assessed across both single-do"
      },
      {
        "chunk_index": 119636,
        "paper_id": 2493,
        "chunk_idx": 0,
        "title": "Scene-Aware Vectorized Memory Multi-Agent Framework with Cross-Modal Differentiated Quantization VLMs for Visually Impaired Assistance",
        "section_head": "Fig. 4 :",
        "score": 0.9454553723335266,
        "text_preview": "4 Fig. 4: Performance comparison of different VLMs on benchmarks. (a) MMBench v1.1 TEST results. (b) OCRVQA_TESTCORE results."
      },
      {
        "chunk_index": 9637,
        "paper_id": 183,
        "chunk_idx": 0,
        "title": "ALIGNING LARGE MULTIMODAL MODELS WITH FACTUALLY AUGMENTED RLHF",
        "section_head": "B DETAILED EVALUATION RESULTS ON MMHAL-BENCH",
        "score": 0.9448021650314331,
        "text_preview": "We include Table 6 for the full evaluation results on MMHAL-BENCH."
      },
      {
        "chunk_index": 33234,
        "paper_id": 697,
        "chunk_idx": 0,
        "title": "Deploying UDM Series in Real-Life Stuttered Speech Applications: A Clinical Evaluation Framework",
        "section_head": "Evaluation Metrics",
        "score": 0.9443795680999756,
        "text_preview": "We developed comprehensive evaluation metrics including: Table 2 presents the comprehensive comparison across all models. UDM achieves the highest performance across all metrics, with 2-4% improvement"
      },
      {
        "chunk_index": 77956,
        "paper_id": 1648,
        "chunk_idx": 0,
        "title": "Learning to generate pointing gestures in situated embodied conversational agents",
        "section_head": "Figure 9 :",
        "score": 0.9431884288787842,
        "text_preview": "9 Figure9: Comparison of objective evaluation results of normalized pointing accuracy for the different systems."
      },
      {
        "chunk_index": 23856,
        "paper_id": 484,
        "chunk_idx": 0,
        "title": "ChatDev: Communicative Agents for Software Development",
        "section_head": "Table 1 :",
        "score": 0.939775824546814,
        "text_preview": "1 Completeness Executability Consistency QualityOverall performance of the LLM-powered software development methods, encompassing both single-agent ( ) and multi-agent ( ) paradigms. Performance metri"
      },
      {
        "chunk_index": 70309,
        "paper_id": 1498,
        "chunk_idx": 0,
        "title": "Interactive Recommendation Agent with Active User Commands",
        "section_head": "Table 2 :",
        "score": 0.9394360184669495,
        "text_preview": "2 Performance comparison of different methods on Single-Round (SR) interaction scenarios across three datasets. We report results based on Recall@K (R@K), NDCG@K (N@K), Condition Satisfaction Rate@K ("
      },
      {
        "chunk_index": 9638,
        "paper_id": 183,
        "chunk_idx": 0,
        "title": "ALIGNING LARGE MULTIMODAL MODELS WITH FACTUALLY AUGMENTED RLHF",
        "section_head": "C DETAILED EVALUATION RESULTS ON POPE",
        "score": 0.9365471601486206,
        "text_preview": "We include Table 7 for the full evaluation results on POPE."
      },
      {
        "chunk_index": 141613,
        "paper_id": 2917,
        "chunk_idx": 0,
        "title": "Towards Heterogeneity-Aware and Energy-Efficient Topology Optimization for Decentralized Federated Learning in Edge Environment",
        "section_head": "9 Fig. 3 :",
        "score": 0.9351662397384644,
        "text_preview": "93 Fig. 3: Average test accuracy of Hat-DFed under different values of Œ≥ across various experimental settings."
      },
      {
        "chunk_index": 45185,
        "paper_id": 964,
        "chunk_idx": 0,
        "title": "Evaluation and Analysis of Deep Neural Transformers and Convolutional Neural Networks on Modern Remote Sensing Datasets",
        "section_head": "Fig. 2 :",
        "score": 0.9335359334945679,
        "text_preview": "2 Fig. 2: Comparison of Model Performance Across Datasets"
      },
      {
        "chunk_index": 137894,
        "paper_id": 2840,
        "chunk_idx": 0,
        "title": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs",
        "section_head": "Table 10 :",
        "score": 0.9332506656646729,
        "text_preview": "10 Full comparison of LLM-based and ROUGE-based evaluation metrics across different datasets (NQ-Open, SQuAD, and Trivia-QA) for Llama and Mistral models in few-shot setting using AUROC evaluation met"
      },
      {
        "chunk_index": 120823,
        "paper_id": 2515,
        "chunk_idx": 0,
        "title": "Seeing is Not Understanding: A Benchmark on Perception-Cognition Disparities in Large Language Models",
        "section_head": "Results and Analysis",
        "score": 0.9328469634056091,
        "text_preview": "We conducted a comprehensive evaluation of the 9 models on EmoBench-Reddit. The results are shown in Table 1 ."
      },
      {
        "chunk_index": 127078,
        "paper_id": 2650,
        "chunk_idx": 0,
        "title": "Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets",
        "section_head": "Figure 3 :",
        "score": 0.9323514103889465,
        "text_preview": "3 Figure3: F1-macro scores for cross-dataset evaluation, averaged over 5 seeds, and different model sizes: larger models achieve higher performance."
      },
      {
        "chunk_index": 60924,
        "paper_id": 1299,
        "chunk_idx": 0,
        "title": "GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer",
        "section_head": "Figure 5 :",
        "score": 0.9321810603141785,
        "text_preview": "5 Figure5: Supervised performance across different dataset sizes. The evaluation is conducted on the 20 NER datasets (in table4)."
      },
      {
        "chunk_index": 114959,
        "paper_id": 2398,
        "chunk_idx": 0,
        "title": "Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models",
        "section_head": "Table 9 .",
        "score": 0.930085301399231,
        "text_preview": "9 Evaluation of static prompting strategies using GPT-3.5, GPT-4 and Llama 3 across five biomedical datasets. The table presents F 1 -score with 95% confidence intervals reported for each metric to in"
      },
      {
        "chunk_index": 100401,
        "paper_id": 2102,
        "chunk_idx": 0,
        "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models",
        "section_head": "Table 11 :",
        "score": 0.9296499490737915,
        "text_preview": "11 Full evaluation results using demonstrations sampled uniformly at random across seven vision-language datasets using 0, 4, 8, 16, and 32 in-context examples. Results are averaged across 3 evaluatio"
      }
    ]
  },
  {
    "query_id": 66,
    "query_text": "function calling planner responsible",
    "source": "chunk_content",
    "source_value": "The Function Calling Planner is responsible for generating a sequence of tasks to be executed along ",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 55758,
        "paper_id": 1195,
        "chunk_idx": 0,
        "title": "FLSIM: A MODULAR AND LIBRARY-AGNOSTIC SIMULATION FRAMEWORK FOR FEDERATED LEARNING",
        "section_head": "Pluggable Blockchain Integration",
        "score": 0.9091049432754517,
        "text_preview": "Since there is a need to support and simulate blockchain-based federated learning (BCFL) solutions, which require a blockchain to delegate some part of the decision-making and computation to a blockch"
      },
      {
        "chunk_index": 97200,
        "paper_id": 2051,
        "chunk_idx": 0,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "Command execution.",
        "score": 0.9087443351745605,
        "text_preview": "Once an executable command is generated, it must be run in an environment that may involve dependencies, external libraries, or resource access (e.g., file systems). Directly coupling execution with p"
      },
      {
        "chunk_index": 45657,
        "paper_id": 974,
        "chunk_idx": 1,
        "title": "Experience Deploying Containerized GenAI Services at an HPC Center",
        "section_head": "Accessing Models",
        "score": 0.9014434814453125,
        "text_preview": "When only a single user requires access, an SSH tunnel can be created between the user's system and the compute node where the vLLM service is running. For example, a user could create an SSH tunnel b"
      },
      {
        "chunk_index": 30582,
        "paper_id": 640,
        "chunk_idx": 0,
        "title": "Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models",
        "section_head": "Key Features",
        "score": 0.8964343667030334,
        "text_preview": "User-friendly design. The user-friendly design of Dataverse is implemented in consideration to various aspects. First, various tools necessary for building a complete ETL pipeline are optimized and un"
      },
      {
        "chunk_index": 20592,
        "paper_id": 417,
        "chunk_idx": 0,
        "title": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry",
        "section_head": "Importance of Collaboration and AI Literacy",
        "score": 0.8961178660392761,
        "text_preview": "Successful implementation of AI in healthcare requires not only technical expertise, but also a workforce or a user base with sufficient AI literacy [34, 35] ."
      },
      {
        "chunk_index": 15216,
        "paper_id": 306,
        "chunk_idx": 1,
        "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
        "section_head": "Conversation Programming",
        "score": 0.8919194340705872,
        "text_preview": "Unified interfaces and auto-reply mechanisms for automated agent chat. Agents in AutoGen have unified conversation interfaces for performing the corresponding conversationcentric computation, includin"
      },
      {
        "chunk_index": 134422,
        "paper_id": 2783,
        "chunk_idx": 0,
        "title": "TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs",
        "section_head": "Cloud Services Utilization",
        "score": 0.8885329961776733,
        "text_preview": "TaskMatrix.AI can help users to access the services on Cloud, which provide computing, storage, networking, analytics security, and more. Cloud services offer a multitude of APIs, and new APIs are con"
      },
      {
        "chunk_index": 30589,
        "paper_id": 640,
        "chunk_idx": 1,
        "title": "Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models",
        "section_head": "Executing ETL pipeline with configuration.",
        "score": 0.8880226612091064,
        "text_preview": "Thus, creating custom operations in Dataverse is a natural extension for those with proficiency in Spark. An example of adding custom processors is given below. # add your custom process @register_etl"
      },
      {
        "chunk_index": 97525,
        "paper_id": 2056,
        "chunk_idx": 0,
        "title": "OleSpeech-IV: A Large-Scale Multispeaker and Multilingual Conversational Speech Dataset with Diverse Topics",
        "section_head": "Figure 1 :",
        "score": 0.884840726852417,
        "text_preview": "1 Figure 1: Olewave's speech data processing pipeline. The central component is the speech-to-text alignment module Olign, which can be accessed through the Olign SDK or deployed on-premises."
      },
      {
        "chunk_index": 12215,
        "paper_id": 238,
        "chunk_idx": 1,
        "title": "APIGen: Automated PIpeline for Generating Verifiable and Diverse Function-Calling Datasets",
        "section_head": "Benchmark.",
        "score": 0.884452223777771,
        "text_preview": "The AST evaluation focuses on the syntactic accuracy of the generated function calls, ensuring that the model's output matches a predefined function documentation in structure and parameters. This inc"
      },
      {
        "chunk_index": 15243,
        "paper_id": 306,
        "chunk_idx": 0,
        "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
        "section_head": "B.1 General Guidelines for Using AutoGen",
        "score": 0.8839499950408936,
        "text_preview": "Below we give some recommendations for using agents in AutoGen to accomplish a task. 1. Consider using built-in agents first. For example, AssistantAgent is pre-configured to be backed by GPT-4, with "
      },
      {
        "chunk_index": 87375,
        "paper_id": 1839,
        "chunk_idx": 2,
        "title": "METAGPT: META PROGRAMMING FOR A MULTI-AGENT COLLABORATIVE FRAMEWORK",
        "section_head": "B.1 USER INPUT",
        "score": 0.882060170173645,
        "text_preview": "It's convenient for web design but not ‚Ü©‚Üí suitable for desktop applications\", 29 \"ColorPic: Offers color palettes and mixer tools. It's feature-rich but can be overwhelming ‚Ü©‚Üí for simple tasks\" 30 ] 3"
      },
      {
        "chunk_index": 15306,
        "paper_id": 306,
        "chunk_idx": 0,
        "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
        "section_head": "Figure 2 :",
        "score": 0.8799624443054199,
        "text_preview": "2 Figure 2: Illustration of how to use AutoGen to program a multi-agent conversation. The top subfigure illustrates the built-in agents provided by AutoGen, which have unified conversation interfaces "
      },
      {
        "chunk_index": 21561,
        "paper_id": 441,
        "chunk_idx": 0,
        "title": "Can AI Have a Personality? Prompt Engineering for AI Personality Simulation: A Chatbot Case Study in Gender-Affirming Voice Therapy Training",
        "section_head": "B. Hosting and Version Control",
        "score": 0.8790978193283081,
        "text_preview": "The chatbot application was deployed using Heroku. Deployment to Heroku required the configuration of environment variables, dependencies, and process management files to ensure that the application c"
      },
      {
        "chunk_index": 15048,
        "paper_id": 303,
        "chunk_idx": 0,
        "title": "AutoDev: Automated AI-Driven Development",
        "section_head": "Rules, Actions, and Objective Configuration",
        "score": 0.8790236711502075,
        "text_preview": "The user initiates the process by configuring rules and actions through yaml files. These files define the available commands (actions) that AI agents can perform. Users can leverage default settings "
      },
      {
        "chunk_index": 45645,
        "paper_id": 974,
        "chunk_idx": 0,
        "title": "Experience Deploying Containerized GenAI Services at an HPC Center",
        "section_head": "Kubernetes Platforms",
        "score": 0.8768191337585449,
        "text_preview": "Kubernetes [8, 19, 38] is a widely used container orchestration platform for deploying containerized applications and services. While it can support running finite-duration jobs, including batch and p"
      },
      {
        "chunk_index": 15212,
        "paper_id": 306,
        "chunk_idx": 1,
        "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
        "section_head": "Conversable Agents",
        "score": 0.8765789270401001,
        "text_preview": "AutoGen also offers enhanced LLM inference features such as result caching, error handling, message templating, etc., via an enhanced LLM inference layer. 2) Humans. Human involvement is desired or ev"
      },
      {
        "chunk_index": 46402,
        "paper_id": 994,
        "chunk_idx": 0,
        "title": "Exploring Situated Stabilities of a Rhythm Generation System through Variational Cross-Examination",
        "section_head": "Comportments and Habits",
        "score": 0.8756662011146545,
        "text_preview": "A user's engagement with a given technology is mediated by a set of embodied habits-gestural, perceptual, and cognitive tendencies formed through accumulated experience. As Rosenberger explains, these"
      },
      {
        "chunk_index": 70436,
        "paper_id": 1501,
        "chunk_idx": 0,
        "title": "InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos",
        "section_head": "‚Ü©‚Üí ‚Ü©‚Üí",
        "score": 0.8755849003791809,
        "text_preview": "When calling any of the functions, make sure to stop generation after each function call and wait for it to be executed, before calling another function and continuing with your plans."
      },
      {
        "chunk_index": 101372,
        "paper_id": 2111,
        "chunk_idx": 0,
        "title": "Optimization Methods and Software for Federated Learning Dissertation by Konstantin Burlachenko In Partial Fulfillment of the Requirements For the Degree of Doctor of Philosophy",
        "section_head": "Addressing slow compilation time.",
        "score": 0.8753967881202698,
        "text_preview": "One of the primary reasons for the limited popularity of C++ in ML is the long compile time. To mitigate this issue, we provide the following: 1. Exclude specific components from the build to reduce c"
      }
    ]
  },
  {
    "query_id": 67,
    "query_text": "different prompts used model",
    "source": "chunk_content",
    "source_value": "Different prompts were used to get the model output in the desired format for each task (e.g",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 126472,
        "paper_id": 2635,
        "chunk_idx": 0,
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "section_head": "Figure B. 5 : 2 B. 3 4 I",
        "score": 0.9656275510787964,
        "text_preview": "5234 Figure B.5: The prompts used to generate the 3D example in Section 2.2.2"
      },
      {
        "chunk_index": 126471,
        "paper_id": 2635,
        "chunk_idx": 0,
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "section_head": "Figure B. 4 :",
        "score": 0.9655786752700806,
        "text_preview": "4 Figure B.4: The prompts used to generate the 2D example in Section 2.2.2"
      },
      {
        "chunk_index": 142767,
        "paper_id": 2943,
        "chunk_idx": 0,
        "title": "Training language models to follow instructions with human feedback",
        "section_head": "Figure 11 :",
        "score": 0.9649732708930969,
        "text_preview": "11 Figure 11: Complete instructions given to labelers for evaluating model outputs for toxicity on the RealToxicityPrompts distribution."
      },
      {
        "chunk_index": 154723,
        "paper_id": 3173,
        "chunk_idx": 0,
        "title": "WHO GETS CITED MOST? BENCHMARKING LONG-CONTEXT LANGUAGE MOD-ELS ON SCIENTIFIC ARTICLES",
        "section_head": "H REASONING TRACES FOR REINFORCEMENT LEARNING",
        "score": 0.9535906314849854,
        "text_preview": "The prompt used by GRPO to generate reasoning traces is given in Figure 7 ."
      },
      {
        "chunk_index": 36591,
        "paper_id": 776,
        "chunk_idx": 0,
        "title": "Do It Yourself (DIY): Modifying Images for Poems in a Zero-Shot Setting Using Weighted Prompt Manipulation",
        "section_head": "Figure 3 :Figure 4 :",
        "score": 0.9418948292732239,
        "text_preview": "34 Figure 3: Initial Prompt for WPM"
      },
      {
        "chunk_index": 54455,
        "paper_id": 1169,
        "chunk_idx": 0,
        "title": "FLAME : Factuality-Aware Alignment for Large Language Models",
        "section_head": "Figure 2 :",
        "score": 0.9398307800292969,
        "text_preview": "2 Figure 2: Instructions from Open Assistant dataset. The instructions are classified with SFT model using the prompt in Appendix, Figure 5."
      },
      {
        "chunk_index": 126434,
        "paper_id": 2635,
        "chunk_idx": 0,
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "section_head": "Figure 2 . 7 :",
        "score": 0.9394305944442749,
        "text_preview": "27 Figure 2.7: Examples of 2D, 3D images generated according to instructions."
      },
      {
        "chunk_index": 46272,
        "paper_id": 990,
        "chunk_idx": 0,
        "title": "Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text",
        "section_head": "Figure 5 :",
        "score": 0.9367648363113403,
        "text_preview": "5 Figure 5: An example prompt to generate triples given an ontology as input in the prompt."
      },
      {
        "chunk_index": 87952,
        "paper_id": 1851,
        "chunk_idx": 0,
        "title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models",
        "section_head": "Figure 4 :",
        "score": 0.9360958337783813,
        "text_preview": "4 Figure 4: Two types of our pure-text data are used for image generation. Left: Simple instruction re-caption and Right: In-context prompt generation. SDXL generates images with the output prompt."
      },
      {
        "chunk_index": 134228,
        "paper_id": 2780,
        "chunk_idx": 8,
        "title": "TAMIL-LLAMA: A NEW TAMIL LANGUAGE MODEL BASED ON LLAMA 2",
        "section_head": "Conclusion",
        "score": 0.9335709810256958,
        "text_preview": "‡Æé‡Æ© ‡Øç ‡Æ™‡Æ§‡ØÅ 7 ‡Æá‡Æ© ‡Øç ‡Æï‡Ææ‡Æ∞‡Æ£‡Æø‡Æï‡Æ≥‡Æø‡Æ© ‡Øç ‡Æé‡Æ£ ‡Øç ‡Æ£‡Æø‡Æï ‡Øç ‡Øà‡Æï, ‡ÆÖ‡Æ§‡Ææ-‡Æµ‡Æ§‡ØÅ 1 x 2 x 3 x 4 x 5 x 6 x 7 ‡ÆÜ‡Æï‡ØÅ‡ÆÆ ‡Øç . ‡Æé‡Æ©‡Øá‡Æµ, 7! = 5040 ‡ÆÜ‡Æï‡ØÅ‡ÆÆ ‡Øç . Example 2 Prompt 3x+1=10 ‡Æé‡Æ© ‡Øç ‡Æ±‡Ææ‡Æ≤ ‡Øç , x ‡Æé‡Æ§‡Æ± ‡Øç ‡Æï‡ØÅ ‡Æö‡ÆÆ‡ÆÆ ‡Øç ? 7B Model ‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï ‡Øç ‡Æï‡Æ™ ‡Øç ‡Æ™‡Æü ‡Øç ‡Æü ‡Æö‡ÆÆ"
      },
      {
        "chunk_index": 134226,
        "paper_id": 2780,
        "chunk_idx": 6,
        "title": "TAMIL-LLAMA: A NEW TAMIL LANGUAGE MODEL BASED ON LLAMA 2",
        "section_head": "Conclusion",
        "score": 0.9335709810256958,
        "text_preview": "‡Æá‡Æ±‡ØÅ‡Æ§‡Æø‡ÆØ‡Æø‡Æ≤ ‡Øç , ‡Æâ‡Æô ‡Øç ‡Æï‡Æ≥ ‡Øç ‡Øá‡Æ§‡Øà‡Æµ‡Æï‡Æ≥ ‡Øç ‡ÆÆ‡Æ± ‡Øç ‡Æ±‡ØÅ‡ÆÆ ‡Øç ‡Æ™‡Æü ‡Øç ‡ØÜ‡Æú‡Æü ‡Øç ‡Æü‡Æø‡Æ± ‡Øç ‡Æï‡ØÅ ‡Æè‡Æ± ‡Øç ‡Æ± ‡ØÜ‡Æ§‡Ææ-‡Øà‡Æ≤‡Øá‡Æ™‡Æö‡Æø‡Øà‡ÆØ‡Æ§ ‡Øç ‡Øá‡Æ§‡Æ∞‡Øç ‡Æ® ‡Øç ‡ØÜ‡Æ§‡Æü‡ØÅ‡Æ™ ‡Øç ‡Æ™‡Æ§‡ØÅ ‡ÆÆ‡ØÅ‡Æï ‡Øç ‡Æï‡Æø‡ÆØ‡ÆÆ ‡Øç . ‡Æâ‡Æô ‡Øç ‡Æï‡Æ≥ ‡Øç ‡Æ™‡Æü ‡Øç ‡ØÜ‡Æú‡Æü ‡Øç -‡Æü‡Æø‡Æ≤ ‡Øç ‡Æí‡Æü ‡Øç ‡Æü‡Æø‡Æï ‡Øç ‡ØÜ‡Æï‡Ææ‡Æ£ ‡Øç ‡Æü‡ØÅ, ‡Æâ‡Æô ‡Øç ‡Æï‡Æ≥‡ØÅ‡Æï ‡Øç ‡Æï‡ØÅ‡Æ§ ‡Øç ‡Øá‡Æ§‡Øà‡Æµ‡ÆØ‡Ææ‡Æ© ‡ÆÖ‡ÆÆ"
      },
      {
        "chunk_index": 120709,
        "paper_id": 2512,
        "chunk_idx": 0,
        "title": "Seedream 4.0: Toward Next-generation Multimodal Image Generation",
        "section_head": "Figure 13",
        "score": 0.932975172996521,
        "text_preview": "13 Figure 13 Examples of multi-image output generation."
      },
      {
        "chunk_index": 153861,
        "paper_id": 3152,
        "chunk_idx": 0,
        "title": "When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards",
        "section_head": "Figure",
        "score": 0.9265429973602295,
        "text_preview": "Figure A.1: Illustration of the prompt that was used to generate the trivial examples version 1 using GPT4."
      },
      {
        "chunk_index": 14636,
        "paper_id": 294,
        "chunk_idx": 0,
        "title": "Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars NVIDIA",
        "section_head": "Figure 9 :Figure 10 :Figure 11 :",
        "score": 0.9207010269165039,
        "text_preview": "91011 Figure 9: The animation outputs of the Audio2Face-3D-v2.3 (top) and Audio2Face-3D-v3.0 (bottom) networks given the same audio input."
      },
      {
        "chunk_index": 147217,
        "paper_id": 3030,
        "chunk_idx": 0,
        "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models",
        "section_head": "Figure 4 :",
        "score": 0.9198481440544128,
        "text_preview": "4 Figure 4: Screenshots of harmful content generation from the examples shown in Figure 1: Chat-GPT (top left), Claude 2 (top right), Bard (bottom left), LLaMA-2 (bottom right). Complete generations a"
      },
      {
        "chunk_index": 108843,
        "paper_id": 2258,
        "chunk_idx": 0,
        "title": "Prompt-Based Approach for Czech Sentiment Analysis",
        "section_head": "Figure 4 :",
        "score": 0.914811909198761,
        "text_preview": "4 Figure4: Example of the input and output construction for the classification model using prompting."
      },
      {
        "chunk_index": 133453,
        "paper_id": 2762,
        "chunk_idx": 0,
        "title": "System 2 Attention (is something you might need too)",
        "section_head": "Figure 16 :",
        "score": 0.9099571704864502,
        "text_preview": "16 Figure 16: Zero-shot prompt used for the GSM-IC task."
      },
      {
        "chunk_index": 44784,
        "paper_id": 954,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models as Expert Annotators",
        "section_head": "C Prompt Templates",
        "score": 0.9097470045089722,
        "text_preview": "We provide prompt templates of each methods from Figure 12 to Figure 18 ."
      },
      {
        "chunk_index": 60882,
        "paper_id": 1298,
        "chunk_idx": 0,
        "title": "GLiDRE: Generalist Lightweight model for Document-level Relation Extraction",
        "section_head": "Figure 3 :",
        "score": 0.9088103771209717,
        "text_preview": "3 Figure 3: The prompt template used for pre-training data generation with Mistral-Small."
      },
      {
        "chunk_index": 16796,
        "paper_id": 339,
        "chunk_idx": 0,
        "title": "Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A Case Study with In-the-Wild Data",
        "section_head": "A.3 Prompt templates A.3.1 Generation",
        "score": 0.9028224945068359,
        "text_preview": "Prompt to generate answer from speech-LLM is shown in Figure 4 ."
      }
    ]
  },
  {
    "query_id": 68,
    "query_text": "encourages model generalize from",
    "source": "chunk_content",
    "source_value": "This encourages the model to generalize from demonstrations to decompose a new task and use tools in",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 10609,
        "paper_id": 206,
        "chunk_idx": 0,
        "title": "An Empirical Study of Knowledge Distillation for Code Understanding Tasks",
        "section_head": "Knowledge Distillation",
        "score": 0.9291207790374756,
        "text_preview": "Knowledge distillation (KD) is a widely adopted technique in model compression and transfer learning, where a student model learns to mimic a teacher model's outputs or intermediate representations. A"
      },
      {
        "chunk_index": 98591,
        "paper_id": 2079,
        "chunk_idx": 0,
        "title": "On the Impact of Knowledge Distillation for Model Interpretability",
        "section_head": "Table 12 .",
        "score": 0.9134172201156616,
        "text_preview": "12 Comparison of entropy within two similar classes (komondor and old English sheepdog) Model Entropy Scratch 0.944 Knowledge distillation 0.953 Label smoothing 0.872"
      },
      {
        "chunk_index": 134227,
        "paper_id": 2780,
        "chunk_idx": 7,
        "title": "TAMIL-LLAMA: A NEW TAMIL LANGUAGE MODEL BASED ON LLAMA 2",
        "section_head": "Conclusion",
        "score": 0.9006081819534302,
        "text_preview": "‡ÆÖ‡Æ£‡Æø-‡ÆØ‡Æø‡Æ© ‡Øç ‡Øá‡Æµ‡Æï‡Æ™ ‡Øç ‡Æ™‡Æ® ‡Øç ‡Æ§‡ØÅ‡Æµ‡ØÄ‡Æö‡Øç ‡Æö‡ØÅ, ‡Øá‡Æ™‡Æü ‡Øç ‡Æü‡Æø‡Æô ‡Øç ‡ÆÆ‡Æ± ‡Øç ‡Æ±‡ØÅ‡ÆÆ ‡Øç ‡ÆÉ‡Æ™‡ØÄ‡Æ≤ ‡Øç ‡Æü‡Æø‡Æô ‡Øç ‡ÆÜ‡Æï‡Æø‡ÆØ‡Æµ‡Æ± ‡Øç -‡Æ± ‡Æ© ‡Øç ‡Æµ‡Æ≤‡ØÅ‡Æµ‡Ææ‡Æ© ‡Æï‡Æ≤‡Øà‡Æµ‡ÆØ‡Ææ‡Æ©‡Æ§‡ØÅ ‡ÆÖ‡Æµ‡Æ∞‡Øç ‡Æï‡Æ≥‡Æø‡Æ© ‡Øç ‡Øá‡Æ™‡Ææ‡Æü ‡Øç ‡Æü‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç -‡Æï‡Æ≥‡Æø‡Æ© ‡Øç ‡Æ™‡Æ≤ ‡Øá‡ÆÆ‡Ææ‡Æö‡ÆÆ‡Ææ‡Æ© ‡ÆÜ‡Æü ‡Øç ‡Æü‡Æô ‡Øç ‡Æï‡Æ≥‡ØÅ‡Æï ‡Øç ‡Æï‡ØÅ ‡Æµ‡Æ¥ ‡Æµ‡Æï‡ØÅ‡Æ§ ‡Øç ‡Æ§‡Æ§‡ØÅ, ‡Øá‡ÆÆ‡Æ≤‡ØÅ‡ÆÆ ‡Øç ‡ÆÖ‡Æµ‡Æ∞‡Øç ‡Æï‡Æ≥ ‡Øç"
      },
      {
        "chunk_index": 41406,
        "paper_id": 872,
        "chunk_idx": 0,
        "title": "EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything",
        "section_head": "Knowledge Distillation",
        "score": 0.8886265754699707,
        "text_preview": "Knowledge distillation (KD) is a technique to improve the performance of deep learning models without changing their architectures. [27] is a pioneering work to distill the dark knowledge from a large"
      },
      {
        "chunk_index": 64875,
        "paper_id": 1381,
        "chunk_idx": 0,
        "title": "HOMODISTIL: HOMOTOPIC TASK-AGNOSTIC DISTIL-LATION OF PRE-TRAINED TRANSFORMERS",
        "section_head": "TRANSFORMER DISTILLATION",
        "score": 0.8714786171913147,
        "text_preview": "Knowledge Distillation trains a small model (i.e., student model) to match the output predictions of a large and well-trained model (i.e., teacher model) by penalizing their output discrepancy. Specif"
      },
      {
        "chunk_index": 112297,
        "paper_id": 2340,
        "chunk_idx": 0,
        "title": "Recent Advances in End-to-End Automatic Speech Recognition",
        "section_head": "A) Teacher-Student Learning",
        "score": 0.870110809803009,
        "text_preview": "The concept of teacher-student (T/S) learning was originally introduced in [104] but became popular from the deep learning era. The most popular T/S learning strategy is to minimize the KL divergence "
      },
      {
        "chunk_index": 95774,
        "paper_id": 2021,
        "chunk_idx": 0,
        "title": "No Language Left Behind: Scaling Human-Centered Machine Translation",
        "section_head": "Knowledge Distillation",
        "score": 0.8580926656723022,
        "text_preview": "Broadly, knowledge distillation is the process of transferring knowledge from a larger teacher model to a smaller student model (Hinton et al., 2015) . We investigate two forms of distillation: online"
      },
      {
        "chunk_index": 36070,
        "paper_id": 763,
        "chunk_idx": 0,
        "title": "Distilling Many-Shot In-Context Learning into a Cheat Sheet",
        "section_head": "Knowledge Distillation",
        "score": 0.8565093278884888,
        "text_preview": "Knowledge distillation aims to transfer knowledge from a large teacher model to a smaller student model. Hinton et al. (2015) proposed training the student model to match the teacher's output probabil"
      },
      {
        "chunk_index": 69244,
        "paper_id": 1475,
        "chunk_idx": 0,
        "title": "INITIALIZING MODELS WITH LARGER ONES",
        "section_head": "COMPATIBILITY WITH KNOWLEDGE DISTILLATION",
        "score": 0.854442834854126,
        "text_preview": "Weight selection transfers knowledge from pretrained models via parameters. Another popular approach for knowledge transferring is knowledge distillation (Hinton et al., 2015) , which utilizes outputs"
      },
      {
        "chunk_index": 73108,
        "paper_id": 1558,
        "chunk_idx": 0,
        "title": "Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems",
        "section_head": "Fig. 2",
        "score": 0.8497664332389832,
        "text_preview": "2 Fig. 2 Behavioral distillation via model simplification and machine learning"
      },
      {
        "chunk_index": 104141,
        "paper_id": 2159,
        "chunk_idx": 1,
        "title": "Patient Knowledge Distillation for BERT Model Compression",
        "section_head": "Introduction",
        "score": 0.8466628789901733,
        "text_preview": "Motivated by this, we investigate the redundancy issue of learned parameters in large-scale pre-trained models, and propose a new model compression approach, Patient Knowledge Distillation (Patient-KD"
      },
      {
        "chunk_index": 88139,
        "paper_id": 1855,
        "chunk_idx": 0,
        "title": "MiniLLM: Knowledge Distillation of Large Language Models",
        "section_head": "Figure 14 :Figure 15 :",
        "score": 0.8435868620872498,
        "text_preview": "1415 Figure14: The scaling law of teacher model based on the OPT family models. We compare MINILLM and SeqKD with OPT-1.3M as the student and OPT 2.7B, 6.7B, and 13B as teachers."
      },
      {
        "chunk_index": 109666,
        "paper_id": 2276,
        "chunk_idx": 1,
        "title": "Put Teacher in Student's Shoes: Cross-Distillation for Ultra-compact Model Compression Framework",
        "section_head": "Teacher-Student Mutual Interplay.",
        "score": 0.839832067489624,
        "text_preview": "The motivation here is that by continuously updating the teacher model during training, we can enhance its guiding ability, making it more effective in interacting with and fostering the growth of the"
      },
      {
        "chunk_index": 55541,
        "paper_id": 1188,
        "chunk_idx": 0,
        "title": "FLOW MARCHING FOR A GENERATIVE PDE FOUNDATION MODEL A PREPRINT",
        "section_head": "Figure 2 :",
        "score": 0.838006854057312,
        "text_preview": "2 Figure 2: Reconstructed and predicted vorticity by the finetuned model"
      },
      {
        "chunk_index": 73107,
        "paper_id": 1558,
        "chunk_idx": 0,
        "title": "Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems",
        "section_head": "Fig",
        "score": 0.8374993801116943,
        "text_preview": "Fig. 1 Three-phase roadmap for knowledge distillation from ecohydrological modeling 2 Phase I: Behavioral Distillation"
      },
      {
        "chunk_index": 109622,
        "paper_id": 2275,
        "chunk_idx": 0,
        "title": "Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer",
        "section_head": "Problem Formulation",
        "score": 0.8372995257377625,
        "text_preview": "KD (Hinton et al., 2015) transfers knowledge from a high-capacity teacher network to a lightweight student by matching their output distributions. Let Ds = {(x i , y i )} N i=1 be a dataset of inputs "
      },
      {
        "chunk_index": 35906,
        "paper_id": 759,
        "chunk_idx": 0,
        "title": "DISTIL-WHISPER: ROBUST KNOWLEDGE DISTILLATION VIA LARGE-SCALE PSEUDO LABELLING",
        "section_head": "Shrink and Fine-Tune",
        "score": 0.835910439491272,
        "text_preview": "The most basic distillation method involves shrinking the teacher model to a smaller student size, and training the student on the CE objective in Equation 3. Following Shleifer & Rush (2020), we perf"
      },
      {
        "chunk_index": 134463,
        "paper_id": 2784,
        "chunk_idx": 0,
        "title": "TEACHING AUDIO MODELS TO REASON: A UNIFIED FRAMEWORK FOR SOURCE-AND LAYER-WISE DISTILLATION",
        "section_head": "Distillation of Large Language Models.",
        "score": 0.825536847114563,
        "text_preview": "In LLMs scenarios, standard knowledge distillation objective becomes sub-optimal since the teacher model contains many more modes than student model. Therefore, more and more work is starting to consi"
      },
      {
        "chunk_index": 62911,
        "paper_id": 1341,
        "chunk_idx": 0,
        "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection",
        "section_head": "Fig. 8 :",
        "score": 0.8247718214988708,
        "text_preview": "8 Fig. 8: Our model predictions and ground-truths in RefCOCO."
      },
      {
        "chunk_index": 104147,
        "paper_id": 2159,
        "chunk_idx": 0,
        "title": "Patient Knowledge Distillation for BERT Model Compression",
        "section_head": "Patient Knowledge Distillation",
        "score": 0.8241595029830933,
        "text_preview": "In this section, we first introduce a vanilla knowledge distillation method for BERT compression (Section 3.1), then present the proposed Patient Knowledge Distillation (Section 3.2) in details. Probl"
      }
    ]
  },
  {
    "query_id": 69,
    "query_text": "speech automatic recognition hori",
    "source": "chunk_content",
    "source_value": "Automatic Speech Recognition (ASR) (Kim, Hori, and Watanabe 2017) and Speech Translation (ST) (Xu et",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 144437,
        "paper_id": 2976,
        "chunk_idx": 0,
        "title": "TSPC: A TWO-STAGE PHONEME-CENTRIC ARCHITECTURE FOR CODE-SWITCHING VIETNAMESE-ENGLISH SPEECH RECOGNITION",
        "section_head": "Experimental Results",
        "score": 0.9334736466407776,
        "text_preview": "Code-switching speech recognition:"
      },
      {
        "chunk_index": 80838,
        "paper_id": 1702,
        "chunk_idx": 2,
        "title": "LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model",
        "section_head": "Table 12 :",
        "score": 0.8990474939346313,
        "text_preview": "Settings Linguistic Task Category GigaSpeech < Textual Instruction, LibriSpeech Audio Input > 12M (LLaSO-Align)&- 47K&- ASR Automatic Speech Recognition LJ Speech and Open-ended VCTK < Audio Instructi"
      },
      {
        "chunk_index": 96798,
        "paper_id": 2042,
        "chunk_idx": 0,
        "title": "NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations",
        "section_head": "Step 1: Word-level Human Annotation Dataset",
        "score": 0.8547224998474121,
        "text_preview": "Annotated Transcription: 1.ÊàëÂñúÊ¨¢ËøôÁßçÂ§©Ê∞î[Uhm] ÔºåÁúüËΩªÊùæÔºÅ 2.[Sigh]Âø´Âà∞‰∫Ü,Êàë‰ª¨[Breathing] ‰∏ãÊ¨°ÂÜçËÆ≤Âêß„ÄÇ Speech & Transcription: 1.ÊàëÂñúÊ¨¢ËøôÁßçÂ§©Ê∞îÔºåÁúüËΩªÊùæÔºÅ 2.Âø´Âà∞‰∫ÜÊàë‰ª¨Ôºå‰∏ãÊ¨°ÂÜçËÆ≤Âêß„ÄÇ Data Collection Speech Non-verbal Vocalization Text Speech TTS Real"
      },
      {
        "chunk_index": 70056,
        "paper_id": 1492,
        "chunk_idx": 0,
        "title": "Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis",
        "section_head": "Table 1 :",
        "score": 0.8282347917556763,
        "text_preview": "1 Sarcasm detection on real data Method Input type Precision (%) Recall (%) F1-score (%) MUStARD++ speech 63.9 63.5 63.6 Proposed detector speech 66.6 66.3 66.2 MUStARD++ speech+text 68.8 68.6 68.7 Pr"
      },
      {
        "chunk_index": 152010,
        "paper_id": 3133,
        "chunk_idx": 0,
        "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing",
        "section_head": "B. Universal Representation Evaluation 1) Setup:",
        "score": 0.8151412606239319,
        "text_preview": "We first evaluate our models on SUPERB, which is designed to provide a standard and comprehensive testbed for pre-trained models on various speech tasks. It covers fifteen tasks, including Speaker Ide"
      },
      {
        "chunk_index": 141646,
        "paper_id": 2918,
        "chunk_idx": 0,
        "title": "Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech",
        "section_head": "Figure 1 :",
        "score": 0.8020409941673279,
        "text_preview": "1 Figure 1: A conversational agent with (Top) text, (Middle) text and audio, (Bottom) text, audio, and paralinguistic signals."
      },
      {
        "chunk_index": 8720,
        "paper_id": 168,
        "chunk_idx": 0,
        "title": "AHAMask: Reliable Task Specification for Large Audio Language Models without Instructions",
        "section_head": "Table 1 :",
        "score": 0.8015432357788086,
        "text_preview": "1 Audio understanding tasks, metrics, training data, and test data considered for LALMs in this paper. Task Metric Training Data Test Data Single tasks ASR (Automatic Speech Recognition) WER (Word Err"
      },
      {
        "chunk_index": 70057,
        "paper_id": 1492,
        "chunk_idx": 0,
        "title": "Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis",
        "section_head": "Table 2 :",
        "score": 0.795332670211792,
        "text_preview": "2 Sarcasm detection on generated data Method Input type Precision (%) Recall (%) F1-score (%) Baseline speech 61.5 66.7 62.2 Proposed speech 61.9 68.6 63.4 Baseline speech+text 68.9 68.7 68.8 Proposed"
      },
      {
        "chunk_index": 57521,
        "paper_id": 1232,
        "chunk_idx": 1,
        "title": "FROM TEXT TO TALK: AUDIO-LANGUAGE MODEL NEEDS NON-AUTOREGRESSIVE JOINT TRAINING",
        "section_head": "Table 2 :",
        "score": 0.7851679921150208,
        "text_preview": "Dataset Language Samples Task Type Emilia zh Chinese 500000 TTS Emilia en English 500000 TTS AISHELL2 Chinese ASR AISHELL3 Chinese ASR CommonVoice Chinese, English ASR GigaSpeech LibriSpeech English E"
      },
      {
        "chunk_index": 87266,
        "paper_id": 1837,
        "chunk_idx": 0,
        "title": "Meta-Transformer: A Unified Framework for Multimodal Learning",
        "section_head": "Audio recognition.",
        "score": 0.7795286178588867,
        "text_preview": "For audio recognition, we utilize the Speech Commands V2 [81] dataset, which consists of 105,829 one-second recordings of 35 common speech commands."
      },
      {
        "chunk_index": 44428,
        "paper_id": 948,
        "chunk_idx": 0,
        "title": "Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database",
        "section_head": "Figure 1 :",
        "score": 0.7793439626693726,
        "text_preview": "1 Figure 1: Recognition lattice with speech errors."
      },
      {
        "chunk_index": 133313,
        "paper_id": 2758,
        "chunk_idx": 0,
        "title": "SYNPARASPEECH: AUTOMATED SYNTHESIS OF PARALINGUISTIC DATASETS FOR SPEECH GENERATION AND UNDERSTANDING",
        "section_head": "Fig. 1 :",
        "score": 0.773959755897522,
        "text_preview": "1 Fig. 1: Overview of SynParaSpeech. (1) Labeled text with paralinguistic timestamps is synthesized. (2) Audio is synthesized and aligned with paralinguistic information. (3) The synthesized audio is "
      },
      {
        "chunk_index": 44130,
        "paper_id": 939,
        "chunk_idx": 0,
        "title": "Error Analysis in a Modular Meeting Transcription System",
        "section_head": "Figure 1 :",
        "score": 0.7704681158065796,
        "text_preview": "1 Figure 1: Meeting transcription pipeline. A continuous speech separation (CSS) system separates overlapping speech of multiple speakers into two overlap-free channels. A voice activity detection (VA"
      },
      {
        "chunk_index": 133301,
        "paper_id": 2758,
        "chunk_idx": 0,
        "title": "SYNPARASPEECH: AUTOMATED SYNTHESIS OF PARALINGUISTIC DATASETS FOR SPEECH GENERATION AND UNDERSTANDING",
        "section_head": "SynParaSpeech Audio Synthesis",
        "score": 0.7683647871017456,
        "text_preview": "The objective of the audio synthesis phase (Stage II) is to generate speech containing paralinguistic cues that conforms to the paralinguistic-annotated text produced in Stage I, by integrating establ"
      },
      {
        "chunk_index": 116681,
        "paper_id": 2435,
        "chunk_idx": 0,
        "title": "Robust Speech Recognition via Large-Scale Weak Supervision",
        "section_head": "Table 13 .",
        "score": 0.7645898461341858,
        "text_preview": "13 WER (%) on Fleurs D.3. Speech Translation D.3.1."
      },
      {
        "chunk_index": 108791,
        "paper_id": 2257,
        "chunk_idx": 0,
        "title": "ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs",
        "section_head": "Overview",
        "score": 0.7631546854972839,
        "text_preview": "ProMode is a zero-shot (for both prosody and speaker) and stand-alone prosody model, which takes a reference input speech and text, and predicts the prosody for a new text and speaker. This enables pr"
      },
      {
        "chunk_index": 80722,
        "paper_id": 1702,
        "chunk_idx": 0,
        "title": "LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model",
        "section_head": "User:",
        "score": 0.7627290487289429,
        "text_preview": "Please transcribe the audio. <audio>"
      },
      {
        "chunk_index": 133299,
        "paper_id": 2758,
        "chunk_idx": 0,
        "title": "SYNPARASPEECH: AUTOMATED SYNTHESIS OF PARALINGUISTIC DATASETS FOR SPEECH GENERATION AND UNDERSTANDING",
        "section_head": "METHODS",
        "score": 0.7622028589248657,
        "text_preview": "Below, we describe how we built our dataset and the paralinguistic speech generation and understanding systems based on it. The construction of the dataset includes creating paralinguistic labeled tex"
      },
      {
        "chunk_index": 92528,
        "paper_id": 1952,
        "chunk_idx": 1,
        "title": "Multilingual Dataset Integration Strategies for Robust Audio Deepfake Detection: A SAFE Challenge System",
        "section_head": "III. SAFE CHALLENGE OVERVIEW",
        "score": 0.7542784214019775,
        "text_preview": "Machine-generated samples TABLE I: SAFE Challenge Audio Sources by Task Task Category Source Names Task 1 (Unmodified) Real Audio Mandarin Podcast, FLEURS German, VSP Semi-professional, YouTube phonec"
      },
      {
        "chunk_index": 148613,
        "paper_id": 3060,
        "chunk_idx": 0,
        "title": "VAINPAINT: ZERO-SHOT VIDEO-AUDIO INPAINTING FRAMEWORK WITH LLMS-DRIVEN MODULE",
        "section_head": "Output:",
        "score": 0.7518894672393799,
        "text_preview": "Text query for audio separation."
      }
    ]
  },
  {
    "query_id": 70,
    "query_text": "name express characteristics expert",
    "source": "chunk_content",
    "source_value": "The name should express the characteristics of expert roles",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 136908,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Food Recognition and Description Prompt:",
        "score": 0.9474338293075562,
        "text_preview": "Describe the name of the dish. ."
      },
      {
        "chunk_index": 136912,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.9461987018585205,
        "text_preview": "Describe the name of the dish.. ."
      },
      {
        "chunk_index": 136906,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.9460200667381287,
        "text_preview": "Describe the name of the dish. ."
      },
      {
        "chunk_index": 136910,
        "paper_id": 2828,
        "chunk_idx": 0,
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "section_head": "Prompt:",
        "score": 0.9382199048995972,
        "text_preview": "Describe the name of the dish. ."
      },
      {
        "chunk_index": 47503,
        "paper_id": 1013,
        "chunk_idx": 0,
        "title": "Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions",
        "section_head": "An Example User",
        "score": 0.8580062985420227,
        "text_preview": "Tool call list (after duplication): <call>[ {\"name\":\"searchArtistsByArtStyle\",\"arguments\":{\"style\":\"impressionism\"}}, {\"name\":\"searchArtistsByArtStyle\",\"arguments\":{\"style\":\"impressionism\"}} ]</call>"
      },
      {
        "chunk_index": 96827,
        "paper_id": 2042,
        "chunk_idx": 0,
        "title": "NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations",
        "section_head": ".",
        "score": 0.8407546877861023,
        "text_preview": "Prompt for Paralinguistic Tagging: <audio> Given an audio clip, identify the paralinguistic event from the following EVENT LABEL SET: {[Breathing], [Crying], [Laughter], ..., [Shh]} MUST follow this t"
      },
      {
        "chunk_index": 47495,
        "paper_id": 1013,
        "chunk_idx": 0,
        "title": "Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions",
        "section_head": "An Example User",
        "score": 0.8285342454910278,
        "text_preview": "Original tool call: <call>[{\"name\":\"searchArtistsByArtStyle\",\"arguments\":{}}]</call>"
      },
      {
        "chunk_index": 25122,
        "paper_id": 507,
        "chunk_idx": 0,
        "title": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation",
        "section_head": "Effect of Soft Mixture (SM). As shown in 6",
        "score": 0.8024664521217346,
        "text_preview": "‚Éù, applying the Soft Mixture achieves a better trade-off between the aggregated model and the server model, further boosting the performance compared to 5 ‚Éù. Server Resolution Client Resolution Expert"
      },
      {
        "chunk_index": 75126,
        "paper_id": 1592,
        "chunk_idx": 0,
        "title": "Large Language Models for Generative Information Extraction: A Survey",
        "section_head": "NL-LLMs.",
        "score": 0.8017483353614807,
        "text_preview": "NL-based methods unify all IE tasks in a universal natural language schema. For instance, NER RE EE Please list all entity words in the Text ... Option: location, person, organization, ‚Ä¶ Answer: [Need"
      },
      {
        "chunk_index": 53891,
        "paper_id": 1155,
        "chunk_idx": 0,
        "title": "Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach",
        "section_head": "Table 3 .",
        "score": 0.7953177690505981,
        "text_preview": "3 Models/Approaches in RQs Models/Approaches Type Parameters Research Questions MelcotCR Fine-tuned model 14B RQ1, RQ2 Carllm Fine-tuned model 14B RQ1 Qwen 2.5 72B General model 72B RQ1 QWQ 32B Genera"
      },
      {
        "chunk_index": 119463,
        "paper_id": 2489,
        "chunk_idx": 0,
        "title": "Scaling Vision with Sparse Mixture of Experts",
        "section_head": "Table 4 :",
        "score": 0.7939565181732178,
        "text_preview": "4 Simple example (k = 1) where average weights are balanced, but Expert 2 is never selected. Token Expert 1 Expert 2 Expert 3 Selected Expert w 1 w 2 w 3 x 1 0.9 0.5 0.1 Expert 1 x 2 0.1 0.5 0.9 Exper"
      },
      {
        "chunk_index": 88608,
        "paper_id": 1862,
        "chunk_idx": 0,
        "title": "MIS-LSTM: Multichannel Image-Sequence LSTM for Sleep Quality and Stress Prediction",
        "section_head": "Table 1 :",
        "score": 0.7886530756950378,
        "text_preview": "1 Overview of multimodal lifelog sensor streams, including frequency (Hz.), data types, and brief descriptions of each feature.Distance in meters; Speed in km/h unit; Number of steps; Step frequency i"
      },
      {
        "chunk_index": 81828,
        "paper_id": 1724,
        "chunk_idx": 0,
        "title": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data",
        "section_head": "Fig. 2 .",
        "score": 0.7778490781784058,
        "text_preview": "2 Fig. 2. Prompt-engineering workflow for synthetic transcript generation and classification. Fine-tuning prompt: A rolespecific instruction directs the LLM to describe the Cookie-Theft picture in spo"
      },
      {
        "chunk_index": 80838,
        "paper_id": 1702,
        "chunk_idx": 2,
        "title": "LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model",
        "section_head": "Table 12 :",
        "score": 0.7754073143005371,
        "text_preview": "Settings Linguistic Task Category GigaSpeech < Textual Instruction, LibriSpeech Audio Input > 12M (LLaSO-Align)&- 47K&- ASR Automatic Speech Recognition LJ Speech and Open-ended VCTK < Audio Instructi"
      },
      {
        "chunk_index": 60651,
        "paper_id": 1294,
        "chunk_idx": 4,
        "title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
        "section_head": "E Results on Image Classification",
        "score": 0.7752519845962524,
        "text_preview": "from nltk . corpus import wordnet as wn def get_name ( offset ) : white_list = { 2012849 : ' crane bird ' , 3126707 : ' crane machine ' , 2113186 : ' cardigan dog ' , 2963159 : ' cardigan jacket ' , 3"
      },
      {
        "chunk_index": 11381,
        "paper_id": 221,
        "chunk_idx": 1,
        "title": "ANALYZING AND MITIGATING OBJECT HALLUCINA-TION IN LARGE VISION-LANGUAGE MODELS",
        "section_head": "REPRODUCIBILITY STATEMENT",
        "score": 0.7725293636322021,
        "text_preview": "Instruction 1: List three other objects that you think are most likely to appear with the objects in the scene described below: {description} Output in strict accordance with the following format: Obj"
      },
      {
        "chunk_index": 70435,
        "paper_id": 1501,
        "chunk_idx": 2,
        "title": "InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos",
        "section_head": "‚Ü©‚Üí ‚Ü©‚Üí",
        "score": 0.7711969614028931,
        "text_preview": "generate_interaction(control_joints: list[str], control_points: list[list[list[float]]], text: str, number_frames: int, task_index: int, object_name: list[str], object_points: list[list[list[float]]])"
      },
      {
        "chunk_index": 47517,
        "paper_id": 1013,
        "chunk_idx": 0,
        "title": "Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions",
        "section_head": "Error response:",
        "score": 0.7694206237792969,
        "text_preview": "{{ERROR_RESPONSE}} Please provide a short reflection that identifies the parameter issues and the corrective action. An Example User Correct tool call: <call>[{\"name\":\"bookFlight\", \"arguments\":{\"from\""
      },
      {
        "chunk_index": 35369,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Figure 3 :",
        "score": 0.756191074848175,
        "text_preview": "3 Figure 3: Guidelines for questionnaire modification for Q"
      },
      {
        "chunk_index": 14334,
        "paper_id": 290,
        "chunk_idx": 0,
        "title": "Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval",
        "section_head": "Table 5 :",
        "score": 0.7559179067611694,
        "text_preview": "5 Comparison with audio-incorporated methods on Charades-STA and ActivityNet Captions. We use I3D [7] as vision backbone with GloVe [43] embeddings. ‚úì 71.99 1.64‚Üë 57.69 2.37‚Üë 41.10 3.63‚Üë 52.86 1.73‚Üë 5"
      }
    ]
  },
  {
    "query_id": 71,
    "query_text": "figure comparison gans-based diffusion-based",
    "source": "chunk_content",
    "source_value": "1 Figure 1: Comparison of GANs-based, diffusion-based, and our autoregressive method",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 130546,
        "paper_id": 2706,
        "chunk_idx": 0,
        "title": "STENCIL: SUBJECT-DRIVEN GENERATION WITH CONTEXT GUIDANCE",
        "section_head": "Fig. 16 :",
        "score": 0.9386564493179321,
        "text_preview": "16 Fig. 16: DreamBench Qualitative Results Part 2."
      },
      {
        "chunk_index": 90703,
        "paper_id": 1912,
        "chunk_idx": 0,
        "title": "ModShift: Model Privacy via Designed Shifts",
        "section_head": "Fig. 3 .",
        "score": 0.9059887528419495,
        "text_preview": "3 Fig. 3. Comparison of 3 different ModShift schemes"
      },
      {
        "chunk_index": 80184,
        "paper_id": 1694,
        "chunk_idx": 0,
        "title": "LLaDA-VLA: Vision Language Diffusion Action Models",
        "section_head": "Figure 1 .",
        "score": 0.9045257568359375,
        "text_preview": "1 Figure 1. Comparison between Autoregressive-based VLA Model and LLaDA-VLA."
      },
      {
        "chunk_index": 79654,
        "paper_id": 1681,
        "chunk_idx": 0,
        "title": "Lightweight Federated Learning over Wireless Edge Networks",
        "section_head": "Fig. 3 .",
        "score": 0.9016185998916626,
        "text_preview": "3 Fig. 3. Comparison of different schemes."
      },
      {
        "chunk_index": 82927,
        "paper_id": 1743,
        "chunk_idx": 0,
        "title": "Look Beyond: Two-Stage Scene View Generation via Panorama and Video Diffusion",
        "section_head": "Figure 4 :",
        "score": 0.8981319665908813,
        "text_preview": "4 Figure 4: Qualitative comparison of panorama generation."
      },
      {
        "chunk_index": 87471,
        "paper_id": 1841,
        "chunk_idx": 0,
        "title": "MGSC: A MULTI-GRANULARITY CONSISTENCY FRAMEWORK FOR ROBUST END-TO-END ASR",
        "section_head": "Fig. 5 .",
        "score": 0.8842368125915527,
        "text_preview": "5 Fig. 5. Comparison of Error Types"
      },
      {
        "chunk_index": 42465,
        "paper_id": 900,
        "chunk_idx": 0,
        "title": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
        "section_head": "Figure 14 .",
        "score": 0.8828550577163696,
        "text_preview": "14 Figure 14. Qualitative comparison with baselines."
      },
      {
        "chunk_index": 71099,
        "paper_id": 1517,
        "chunk_idx": 0,
        "title": "IS-Diff: Improving Diffusion-Based Inpainting with Better Initial Seed",
        "section_head": "Fig. 10 :",
        "score": 0.8749558925628662,
        "text_preview": "10 Fig. 10: Comparison of different values of ‚àÜt."
      },
      {
        "chunk_index": 51224,
        "paper_id": 1098,
        "chunk_idx": 0,
        "title": "FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise",
        "section_head": "Fig. 4 :",
        "score": 0.872063159942627,
        "text_preview": "4 Fig. 4: Comparison of RCL and UCL under varying noise levels"
      },
      {
        "chunk_index": 29913,
        "paper_id": 619,
        "chunk_idx": 0,
        "title": "CusEnhancer: A Zero-Shot Scene and Controllability Enhancement Method for Photo Customization via ResInversion",
        "section_head": "Fig. 7 .",
        "score": 0.8702384233474731,
        "text_preview": "7 Fig. 7. Qualitative results of ResInversion on reconstruction quality."
      },
      {
        "chunk_index": 20385,
        "paper_id": 413,
        "chunk_idx": 0,
        "title": "BRANCHGRPO: STABLE AND EFFICIENT GRPO WITH STRUCTURED BRANCHING IN DIFFUSION MODELS",
        "section_head": "Figure 4 :",
        "score": 0.8692222237586975,
        "text_preview": "4 Figure 4: Qualitative comparison of generations from Flux, DanceGRPO, and our BranchGRPO."
      },
      {
        "chunk_index": 6742,
        "paper_id": 123,
        "chunk_idx": 0,
        "title": "Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment",
        "section_head": "Figure 6 :",
        "score": 0.864067792892456,
        "text_preview": "6 Figure 6: Efficiency comparison across LLM-based forecasters on ETTh1-96."
      },
      {
        "chunk_index": 139059,
        "paper_id": 2866,
        "chunk_idx": 0,
        "title": "THE UNANTICIPATED ASYMMETRY BETWEEN PERCEPTUAL OPTIMIZATION AND ASSESSMENT",
        "section_head": "Figure 11 :",
        "score": 0.8622347116470337,
        "text_preview": "11 Figure 11: Qualitative comparison of SR results under different optimization objectives."
      },
      {
        "chunk_index": 139058,
        "paper_id": 2866,
        "chunk_idx": 0,
        "title": "THE UNANTICIPATED ASYMMETRY BETWEEN PERCEPTUAL OPTIMIZATION AND ASSESSMENT",
        "section_head": "Figure 10 :",
        "score": 0.8621562719345093,
        "text_preview": "10 Figure 10: Qualitative comparison of SR results under different optimization objectives."
      },
      {
        "chunk_index": 139057,
        "paper_id": 2866,
        "chunk_idx": 0,
        "title": "THE UNANTICIPATED ASYMMETRY BETWEEN PERCEPTUAL OPTIMIZATION AND ASSESSMENT",
        "section_head": "Figure 9 :",
        "score": 0.8621253967285156,
        "text_preview": "9 Figure 9: Qualitative comparison of SR results under different optimization objectives."
      },
      {
        "chunk_index": 75615,
        "paper_id": 1597,
        "chunk_idx": 0,
        "title": "Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation",
        "section_head": "Fig. 10 :",
        "score": 0.8611252307891846,
        "text_preview": "10 Fig. 10: LLM-guided case studies from ChemCrow, SynAuto, and RoboRXN."
      },
      {
        "chunk_index": 35241,
        "paper_id": 746,
        "chunk_idx": 0,
        "title": "Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference",
        "section_head": "FLUXFigure 6 .",
        "score": 0.8609360456466675,
        "text_preview": "6 Figure 6. Cross-reward results of SRPO."
      },
      {
        "chunk_index": 66831,
        "paper_id": 1423,
        "chunk_idx": 0,
        "title": "IMAGE-TO-BRAIN SIGNAL GENERATION FOR VISUAL PROSTHESIS WITH CLIP GUIDED MULTIMODAL DIF-FUSION MODELS",
        "section_head": "Figure 8 :",
        "score": 0.8597403764724731,
        "text_preview": "8 Figure 6: EEG Topography Comparison (Part 1)"
      },
      {
        "chunk_index": 40718,
        "paper_id": 859,
        "chunk_idx": 0,
        "title": "Efficient Rectified Flow for Image Fusion",
        "section_head": "Figure 1 :",
        "score": 0.8594789505004883,
        "text_preview": "1 Figure 1: Efficiency comparison with the state-of-theart diffusion-based methods."
      },
      {
        "chunk_index": 14490,
        "paper_id": 292,
        "chunk_idx": 0,
        "title": "Audio Super-Resolution with Latent Bridge Models",
        "section_head": "Figure 13 :",
        "score": 0.8587315082550049,
        "text_preview": "13 Figure 13: Qualitative comparison from A 2 SB's demo page."
      }
    ]
  },
  {
    "query_id": 72,
    "query_text": "consider following baselines from",
    "source": "chunk_content",
    "source_value": "We consider the following baselines from three categories",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 26938,
        "paper_id": 548,
        "chunk_idx": 0,
        "title": "Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks",
        "section_head": "APPENDIX C CONVERGENCE OF EZOFL FOR ASYNCHRONOUS DEVICES",
        "score": 0.9510178565979004,
        "text_preview": "The proof follows in three steps. We first prove that E[ƒù k |H k ] = c 1 Œ≥ k (‚àáF (Œ∏ k ) + Œ¥ k ). We then prove that E[‚à•ƒù k ‚à• 2 |H k ] is bounded. By using these two results, and following a similar ap"
      },
      {
        "chunk_index": 50256,
        "paper_id": 1077,
        "chunk_idx": 0,
        "title": "Federated learning over physical channels: adaptive algorithms with near-optimal guarantees",
        "section_head": "Results under strongly convex settings",
        "score": 0.9446154832839966,
        "text_preview": "Under assumptions in Section 4.1, we have the following risk bounds for the adaptive over-theair SGD algorithm, with last-iterate and average-iterate guarantees. To establish the theoretical results, "
      },
      {
        "chunk_index": 101192,
        "paper_id": 2111,
        "chunk_idx": 0,
        "title": "Optimization Methods and Software for Federated Learning Dissertation by Konstantin Burlachenko In Partial Fulfillment of the Requirements For the Degree of Doctor of Philosophy",
        "section_head": "B5 Auxiliary Facts",
        "score": 0.9442666172981262,
        "text_preview": "We use the following auxiliary fact in our proofs. Let us take a random vector ùúâ ‚àà R ùëë , then E [Ô∏Å ‚Äñùúâ‚Äñ 2 ]Ô∏Å = E [Ô∏Å ‚Äñùúâ -E [ùúâ]‚Äñ 2 ]Ô∏Å + ‚ÄñE [ùúâ]‚Äñ 2 . (5.6)"
      },
      {
        "chunk_index": 155202,
        "paper_id": 3184,
        "chunk_idx": 2,
        "title": "Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg",
        "section_head": "Convergence Analysis",
        "score": 0.9318606853485107,
        "text_preview": "Under Assumptions 1 to 4, for any small Œ¥ 0 > 0, there exist R 0 > 0, N > 0, Œ∑ 0 > 0, C > 0 and C 1 > 0, such that for any n ‚â• N , the following holds with probability at least (1Œ¥ 0 ) over random ini"
      },
      {
        "chunk_index": 40370,
        "paper_id": 853,
        "chunk_idx": 0,
        "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout",
        "section_head": "Theoretical Analysis.",
        "score": 0.9314860105514526,
        "text_preview": "In this section, we present the theoretical convergence proof of FedDH. We first introduce the assumptions and then present the convergence theorems with an upper bound. Theorem 5.6. Suppose that Assu"
      },
      {
        "chunk_index": 109415,
        "paper_id": 2269,
        "chunk_idx": 0,
        "title": "PROVING THE LIMITED SCALABILITY OF CENTRALIZED DISTRIBUTED OPTIMIZATION VIA A NEW LOWER BOUND CONSTRUCTION",
        "section_head": "LOWER BOUND WITH BOTH W2S AND S2W COMMUNICATION",
        "score": 0.9314172267913818,
        "text_preview": "In the previous section, we provide the lower bound without taking into account the communication cost œÑ w . Combining Theorem 4.2 with our new Theorem D.1, which extends the result by Tyurin et al. ("
      },
      {
        "chunk_index": 153610,
        "paper_id": 3150,
        "chunk_idx": 0,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "D.3.3 Function Value Error",
        "score": 0.9297367334365845,
        "text_preview": "The main result of this sub-section relates E(‚Ä¢) to C(‚Ä¢) and D(‚Ä¢). Lemma 27 (Section D.4, Patel et al. [117] ). Assume we have a problem instance satisfying Assumptions 2, 4, 5, 7 and 11. Then assumin"
      },
      {
        "chunk_index": 30480,
        "paper_id": 637,
        "chunk_idx": 2,
        "title": "Data Valuation and Selection in a Federated Model Marketplace",
        "section_head": "B.1 Proof of Theorem 4.1",
        "score": 0.9286902546882629,
        "text_preview": "Then we have the following result based on [41] U 3 = E x‚àº¬µv(x) L f (Œ∏, x), f (Œ∏ ‚ãÜ , x) - m i=1 E x‚àº¬µ i t (x) Œ± i L f (Œ∏, x), f (Œ∏ ‚ãÜ , x) ‚â§ W( m i=1 Œ± i ¬µ i t , ¬µ v ) (13) U 1 = E x‚àº¬µv(x) L f v (x), f"
      },
      {
        "chunk_index": 101258,
        "paper_id": 2111,
        "chunk_idx": 2,
        "title": "Optimization Methods and Software for Federated Learning Dissertation by Konstantin Burlachenko In Partial Fulfillment of the Requirements For the Degree of Doctor of Philosophy",
        "section_head": "C6 Main Convergence Results",
        "score": 0.9283466339111328,
        "text_preview": "Therefore, by using Lemma 25 we get E‚Äñùê∫(ùë• ùëò ) -ùê∫(ùë• * )|ùë• ùëò ‚Äñ 2 = ‚Äñ‚àáùëì (Ô∏Å ùë• ùëò )Ô∏Å -‚àáùëì (ùë• * ) ‚Äñ 2 (1 -ùëù) +‚Äñ‚àá‚Ñé(ùë• ùëò ) -‚àá‚Ñé(ùë• * )‚Äñ 2 + ùúÜ 2 (1 -ùëù) ùëõ 2 ùëù ùíú ‚â§ ‚Äñ‚àáùëì (Ô∏Å ùë• ùëò )Ô∏Å -‚àáùëì (ùë• * ) ‚Äñ 2 (1 -ùëù) +‚Äñ‚àá‚Ñé(ùë• ùëò ) -‚àá‚Ñé(ùë•"
      },
      {
        "chunk_index": 112422,
        "paper_id": 2341,
        "chunk_idx": 0,
        "title": "Recidivism and Peer Influence with LLM Text Embeddings in Low Security Correctional Facilities",
        "section_head": "A.2 Proof of Theorem 1",
        "score": 0.9271947145462036,
        "text_preview": "We derive the asymptotic distribution of the 2SLS estimator Œ≤v,IV in three steps similar to the structure in Johnsson and Moon [2021] . We start from the IV-2SLS estimator described in 5. Substituting"
      },
      {
        "chunk_index": 103905,
        "paper_id": 2152,
        "chunk_idx": 0,
        "title": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services",
        "section_head": "D. Proof of Corollary 1 (Convergence with Expectile Regression)",
        "score": 0.9248626828193665,
        "text_preview": "To establish the convergence of the Q-function under heterogeneous expectile regression, we define the modified Pareto operator with œÑ as Eq. ( 37 ). The update of the Q function with the introduction"
      },
      {
        "chunk_index": 47853,
        "paper_id": 1020,
        "chunk_idx": 0,
        "title": "Fairness Regularization in Federated Learning",
        "section_head": "A Analysis of Data Distribution",
        "score": 0.9224172830581665,
        "text_preview": "We begin this section by stating the key assumptions and definitions that form the foundation of our theoretical analysis. Specifically, we assume that the local functions f i are smooth, and the numb"
      },
      {
        "chunk_index": 98283,
        "paper_id": 2072,
        "chunk_idx": 0,
        "title": "On the Convergence of Policy Mirror Descent with Temporal Difference Evaluation",
        "section_head": "G.3 Convergence of inexact Q-TD-PMD",
        "score": 0.9200937747955322,
        "text_preview": "Consider the inexact Q-TD-PMD, where equation ( 42 ) is replaced by foot_3 Q k+1 = FœÄ k+1 Q k with Q k+1 -F œÄ k+1 Q k ‚àû ‚â§ Œ¥. (58) Under certain error level Œ¥, a variant of Lemma G.6 is presented as be"
      },
      {
        "chunk_index": 116317,
        "paper_id": 2427,
        "chunk_idx": 1,
        "title": "Robust Estimation Under Heterogeneous Corruption Rates",
        "section_head": "We begin by lower bounding",
        "score": 0.9188851714134216,
        "text_preview": "( 146 ) Now, note that œÑ ‚àà{-1,1} ‚àö d E |N (Z) j -Œ¥œÑ j | 2 = œÑ ‚àà{-1,1} ‚àö d E |N (Z) j -Œ¥œÑ j | 2 + E |N (Z) j -Œ¥œÑ ‚Ä≤j j | 2 2 ‚àÄj ( 147 ) Thus, we get L E (Œª, P Œ¥ ) ‚â• inf N ‚àö d j=1 1 2 ‚àö d œÑ ‚àà{-1,1} ‚àö d E"
      },
      {
        "chunk_index": 71281,
        "paper_id": 1521,
        "chunk_idx": 2,
        "title": "Is RL fine-tuning harder than regression? A PDE learning approach for diffusion models",
        "section_head": "Proof of Theorem 1",
        "score": 0.917481541633606,
        "text_preview": "For any œÅ > 0, with probability 1 -Œ¥, we have Z cross (œÅ) ‚â§ cœÑ 2 Œ∫œÅ log K n J 2 F * (œÅ); ‚à• ‚Ä¢ ‚à• E ,T + œÅ log(1/Œ¥) + cŒ∫œÉœÅ Œ∑ n J 1 F; ‚à• ‚Ä¢ ‚à• X 2 + L F log(1/Œ¥) + œÑ 2 Œ∫œÅ Œ∑ ‚àö nK J 2 (F; ‚à• ‚Ä¢ ‚à• X 2 ) + L F lo"
      },
      {
        "chunk_index": 116313,
        "paper_id": 2427,
        "chunk_idx": 3,
        "title": "Robust Estimation Under Heterogeneous Corruption Rates",
        "section_head": "C.3 Minimax Optimality",
        "score": 0.9168053865432739,
        "text_preview": "(129) Thus, with probability at least 1 -Œ¥/2, and using VC dimension bound presented in Proposition 3, sup Œ∑:‚à•Œ∑-¬µ‚à•Œ£‚â•r D w (Œ∑, Z) ‚â§ 1 2 - 1 œÄ arctan r œÉ + w T Œª + ‚à•w‚à• 2 2 log 4/Œ¥ 2 + 879 ‚àö d . (130) Co"
      },
      {
        "chunk_index": 153603,
        "paper_id": 3150,
        "chunk_idx": 1,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "123",
        "score": 0.9140229225158691,
        "text_preview": "For t ‚àà [0, T -1] we note the following, E ‚à•x t+1 -x ‚ãÜ ‚à• 4 2 = E Ô£Æ Ô£Ø Ô£∞ x t -x ‚ãÜ - Œ∑ M m‚àà[M ] ‚àáF m (x m t ) + Œ∑ M m‚àà[M ] Œæ m t 4 2 Ô£π Ô£∫ Ô£ª , = E x t -x ‚ãÜ - Œ∑ M m‚àà[M ] ‚àáF m (x m t ) 2 2 + Œ∑ M m‚àà[M ] Œæ m t"
      },
      {
        "chunk_index": 71305,
        "paper_id": 1521,
        "chunk_idx": 0,
        "title": "Is RL fine-tuning harder than regression? A PDE learning approach for diffusion models",
        "section_head": "A.1.1 Proof of Lemma 14",
        "score": 0.9133837223052979,
        "text_preview": "Recall that A t = ‚ü®b t , ‚àá‚ü© + 1 2 ‚ü®Œõ t , ‚àá 2 ‚ü©. We follow Lemma 5 of the paper [Mou25] to obtain the identity. Œì(s, t) = E h s (X s ) ‚ä§ ‚àáf s + f s ‚àá log p s (X s ) + ‚Ñì s (X s )f s (X s ) ‚Ä¢ h t (X t ) "
      },
      {
        "chunk_index": 153606,
        "paper_id": 3150,
        "chunk_idx": 0,
        "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
        "section_head": "Lemma 26 (Single Machine SGD Fourth Moment).",
        "score": 0.9123975038528442,
        "text_preview": "For any machine m ‚àà [M ], for t ‚àà [0, T ], and for k ‚â• 0 we have the following for Œ∑ < 1 H , E x m Œ¥(t)+k -x ‚ãÜ 4 2 ‚â§ (1 -Œ∑¬µ) 4k E x Œ¥(t) -x ‚ãÜ m 4 2 + 8Œ∑ 2 œÉ 2 2 k(1 -Œ∑¬µ) 2k E x Œ¥(t) -x ‚ãÜ m 2 2 + 11Œ∑ 2"
      },
      {
        "chunk_index": 114254,
        "paper_id": 2383,
        "chunk_idx": 2,
        "title": "RETHINKING ATTENTION WITH PERFORMERS",
        "section_head": "F.4 PROOFS OF THEOREM 2,THEOREM 3 & BEAUTIFUL FUNCTIONS",
        "score": 0.9122575521469116,
        "text_preview": "Note first that estimators of beautiful functions based on standard Monte Carlo procedure using independent vectors œâ iid i guarantee strong concentration bounds since independent œâ i s provide a way "
      }
    ]
  },
  {
    "query_id": 73,
    "query_text": "currently training large datasets",
    "source": "chunk_content",
    "source_value": "Currently, training on large datasets is only feasible using many hardware accelerators",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 4504,
        "paper_id": 84,
        "chunk_idx": 0,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Data Collection ‚Ä¶",
        "score": 0.9717325568199158,
        "text_preview": "Fig. 14 : A diverse suite of data sources and datasets for pre-training foundation models, mainly including text data, image data, and multimodality data. ‚Ä¢ Autonomous Agent (Section 4.6): Focusing on"
      },
      {
        "chunk_index": 4506,
        "paper_id": 84,
        "chunk_idx": 0,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Data Source",
        "score": 0.944446325302124,
        "text_preview": "Foundation models are data-driven, and both quality and quantity of data lie at the core of foundation model development. Figure 14 presents three broad types of data sources for foundation model pre-"
      },
      {
        "chunk_index": 125585,
        "paper_id": 2624,
        "chunk_idx": 0,
        "title": "Solving Quantitative Reasoning Problems with Language Models",
        "section_head": "Table 1 :",
        "score": 0.9440012574195862,
        "text_preview": "1 Proportion of data, and number of tokens, from each source in the technical training dataset. The General Natural Language dataset is a subset of the dataset used to pretrain the model. Data source "
      },
      {
        "chunk_index": 42005,
        "paper_id": 886,
        "chunk_idx": 0,
        "title": "Emergent Abilities of Large Language Models",
        "section_head": "Table 2 :",
        "score": 0.9113125801086426,
        "text_preview": "2 Parameters, training examples, and training FLOPs of large language models. Model Parameters Train tokens Train FLOPs GPT-3 125M 300B 2.25E+20 350M 300B 6.41E+20 760M 300B 1.37E+21 1.3B 300B 2.38E+2"
      },
      {
        "chunk_index": 72957,
        "paper_id": 1555,
        "chunk_idx": 0,
        "title": "KIMI K1.5: SCALING REINFORCEMENT LEARNING WITH LLMS TECHNICAL REPORT OF KIMI K1.5",
        "section_head": "Pretraining",
        "score": 0.910412073135376,
        "text_preview": "The Kimi k1.5 base model is trained on a diverse, high-quality multimodal corpus. The language data covers five domains: English, Chinese, Code, Mathematics Reasoning, and Knowledge. Multimodal data, "
      },
      {
        "chunk_index": 110134,
        "paper_id": 2287,
        "chunk_idx": 0,
        "title": "QLORA: Efficient Finetuning of Quantized LLMs",
        "section_head": "Pushing the Chatbot State-of-the-art with QLoRA",
        "score": 0.9091792106628418,
        "text_preview": "Having established that 4-bit QLORA matches 16-bit performance across scales, tasks, and datasets we conduct an in-depth study of instruction finetuning up to the largest open-source language models a"
      },
      {
        "chunk_index": 3953,
        "paper_id": 81,
        "chunk_idx": 0,
        "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",
        "section_head": "Table 1.",
        "score": 0.909061849117279,
        "text_preview": "Summary of existing general (large) language models, their underlying structures, numbers of parameters, and datasets used for model training. Column \"# params\" shows the number of parameters, M: mill"
      },
      {
        "chunk_index": 85603,
        "paper_id": 1802,
        "chunk_idx": 0,
        "title": "MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models",
        "section_head": "Experimental Setup",
        "score": 0.9074936509132385,
        "text_preview": "The dataset is selected to cover multimodal tasks. The GLUE benchmarking dataset [15] is used for Natural Language Processing (NLP), which contains 9 types of typical tasks; the COCO image description"
      },
      {
        "chunk_index": 4747,
        "paper_id": 85,
        "chunk_idx": 10,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "2.5T",
        "score": 0.9005768299102783,
        "text_preview": "In transcriptomics, early large-scale pretraining efforts have focused on gene expression matrices derived from single-cell RNA sequencing (scRNA-seq) data. Foundation models [512] , [638] are typical"
      },
      {
        "chunk_index": 25587,
        "paper_id": 515,
        "chunk_idx": 0,
        "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
        "section_head": "Conclusion",
        "score": 0.8959996700286865,
        "text_preview": "In this work we present Contrastive Captioners (CoCa), a new image-text foundation model family that subsumes existing vision pretraining paradigms with natural language supervision. Pretrained on ima"
      },
      {
        "chunk_index": 32214,
        "paper_id": 676,
        "chunk_idx": 0,
        "title": "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence",
        "section_head": "Experimental Results",
        "score": 0.8939239382743835,
        "text_preview": "In this section, we evaluate DeepSeek-Coder-V2 on three types of tasks, including coding, mathematics, and general natural language. We compare DeepSeek-Coder-V2 with the previous state-of-the-art lar"
      },
      {
        "chunk_index": 89682,
        "paper_id": 1888,
        "chunk_idx": 0,
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "section_head": "Table 10 :",
        "score": 0.8902057409286499,
        "text_preview": "10 CircularEval results on MMBench-dev set (L-2 abilities). Open-source models tagged with * incorporate in-house data in model training."
      },
      {
        "chunk_index": 89684,
        "paper_id": 1888,
        "chunk_idx": 0,
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "section_head": "Table 11 :",
        "score": 0.8899267911911011,
        "text_preview": "11 CircularEval results on MMBench-test set (L-2 abilities). Open-source models tagged with * incorporate in-house data in model training."
      },
      {
        "chunk_index": 141409,
        "paper_id": 2914,
        "chunk_idx": 0,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "MultiMedBench: A Benchmark for Generalist Biomedical AI",
        "score": 0.8897486925125122,
        "text_preview": "We next describe MultiMedBench, a benchmark we curated to enable the development and evaluation of generalist biomedical AI. MultiMedBench is a multi-task, multimodal benchmark comprising 12 de-identi"
      },
      {
        "chunk_index": 9209,
        "paper_id": 177,
        "chunk_idx": 0,
        "title": "AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training",
        "section_head": "Models",
        "score": 0.8897367715835571,
        "text_preview": "We based our detection systems on three different open-source pretrained language models (LMs), each extended with task-specific classifiers to address the two Subtasks. Qwen3 Embedding (Zhang et al.,"
      },
      {
        "chunk_index": 89686,
        "paper_id": 1888,
        "chunk_idx": 0,
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "section_head": "Table 12 :",
        "score": 0.8893920183181763,
        "text_preview": "12 CircularEval results on MMBench-CN-dev set (L-2 abilities). Open-source models tagged with * incorporate in-house data in model training."
      },
      {
        "chunk_index": 89688,
        "paper_id": 1888,
        "chunk_idx": 0,
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "section_head": "Table 13 :",
        "score": 0.8893816471099854,
        "text_preview": "13 CircularEval results on MMBench-CN-test set (L-2 abilities). Open-source models tagged with * incorporate in-house data in model training."
      },
      {
        "chunk_index": 95852,
        "paper_id": 2021,
        "chunk_idx": 0,
        "title": "No Language Left Behind: Scaling Human-Centered Machine Translation",
        "section_head": "Figure 3 :",
        "score": 0.8884516954421997,
        "text_preview": "3 Figure 3: Human-Translated Dataset Contributions of No Language Left Behind: As highlighted, these datasets enable model training and evaluation."
      },
      {
        "chunk_index": 141412,
        "paper_id": 2914,
        "chunk_idx": 1,
        "title": "Towards Generalist Biomedical AI",
        "section_head": "Model preliminaries",
        "score": 0.8845175504684448,
        "text_preview": "In this work, we consider two ViT pre-trained models as vision encoders, the 4 billion (4B) parameters model from Chen et al. [11] and the 22 billion (22B) parameters model from Dehghani et al. [15] ."
      },
      {
        "chunk_index": 43413,
        "paper_id": 922,
        "chunk_idx": 0,
        "title": "Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning",
        "section_head": "Models and Baseline Experiment Setup",
        "score": 0.8840117454528809,
        "text_preview": "Benchmarked Models: We utilized state-of-the-art open-source multimodal language models to address our multimodal scientific Visual Question Answering (VQA) task for the English language. Specifically"
      }
    ]
  },
  {
    "query_id": 74,
    "query_text": "study scale invariant",
    "source": "title",
    "source_value": "A Study of the Scale Invariant Signal to Distortion Ratio in Speech Separation with Noisy References",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 86524,
        "paper_id": 1823,
        "chunk_idx": 0,
        "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism",
        "section_head": "D. Further Scaling Analysis",
        "score": 0.9029339551925659,
        "text_preview": "In this section we study the effect of number of attention heads on the scaling results. We also present strong scaling results for our 1.2 billion parameter model."
      },
      {
        "chunk_index": 108424,
        "paper_id": 2248,
        "chunk_idx": 0,
        "title": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining",
        "section_head": "Figure 5 :",
        "score": 0.8995231986045837,
        "text_preview": "5 Figure 5: Parameter Sensitivity Study"
      },
      {
        "chunk_index": 70537,
        "paper_id": 1503,
        "chunk_idx": 0,
        "title": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization",
        "section_head": "B.2 Learning Latent Trait via EM",
        "score": 0.8920376300811768,
        "text_preview": "Table 6 shows the prompt for generating orthogonal rules, as described in Section 3.2."
      },
      {
        "chunk_index": 90753,
        "paper_id": 1913,
        "chunk_idx": 0,
        "title": "Modular Delta Merging with Orthogonal Constraints: A Scalable Framework for Continual and Reversible Model Composition",
        "section_head": "Table 3 :",
        "score": 0.8789498805999756,
        "text_preview": "3 Ablation Study Results Configuration CIFAR-100 Degradation Full MDM-OC 78.4% - w/o Orthogonal Projection 72.2% -6.2% w/o CMA-ES (Equal Œ±) 76.3% -2.1% w/o EWC + Replay 76.6% -1.8% w/o Search Space Re"
      },
      {
        "chunk_index": 30545,
        "paper_id": 638,
        "chunk_idx": 0,
        "title": "DATALESS KNOWLEDGE FUSION BY MERGING WEIGHTS OF LANGUAGE MODELS",
        "section_head": "C SENSITIVITY ANALYSIS",
        "score": 0.8752394914627075,
        "text_preview": "Number of batches for computing inner product matrices. In our main experiments, we use N = 1, 000 batches (of size 16) for computing inner product matrices. We present additional analysis about the e"
      },
      {
        "chunk_index": 6745,
        "paper_id": 123,
        "chunk_idx": 0,
        "title": "Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment",
        "section_head": "Figure 8 :",
        "score": 0.8751688003540039,
        "text_preview": "8 Figure 8: Parameter sensitivity of Œ± and Œ≤ of the proposed method on the ETTh2, ETTm1, and ETTm2 datasets."
      },
      {
        "chunk_index": 19903,
        "paper_id": 403,
        "chunk_idx": 0,
        "title": "Block-NeRF: Scalable Large Scene Neural View Synthesis",
        "section_head": "Table 4 .",
        "score": 0.8728179335594177,
        "text_preview": "4 Effect of different NeRF overlaps in the 8 block scenario with 0.25M weights per block (2M weights in total). The original setting used in the main paper is marked*. PSNR‚Üë SSIM‚Üë LPIPS‚Üì 0% 77 m 26.77"
      },
      {
        "chunk_index": 10531,
        "paper_id": 203,
        "chunk_idx": 0,
        "title": "AN EFFICIENT SUBSPACE ALGORITHM FOR FEDERATED LEARNING ON HETEROGENEOUS DATA",
        "section_head": "Fig. 1 :",
        "score": 0.865362286567688,
        "text_preview": "1 Fig. 1: Logistic regression: (a) our FedSub with different projection matrices P k . (b) Compare our FedSub with FedAvg in full space and subspace. (c) our FedSub with different subspace dimensions "
      },
      {
        "chunk_index": 76365,
        "paper_id": 1614,
        "chunk_idx": 0,
        "title": "Layer Normalization",
        "section_head": "Analysis",
        "score": 0.8616626262664795,
        "text_preview": "In this section, we investigate the invariance properties of different normalization schemes."
      },
      {
        "chunk_index": 52497,
        "paper_id": 1125,
        "chunk_idx": 0,
        "title": "FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models",
        "section_head": "Figure 4 .",
        "score": 0.859256386756897,
        "text_preview": "4 Figure 4. Ablation study on the different variants of the additive U-Net module using VGG16. Variants include (a) baseline additive U-Net, (b) reduced channels, (c) shallow depth, and (d) combined c"
      },
      {
        "chunk_index": 74719,
        "paper_id": 1586,
        "chunk_idx": 0,
        "title": "Large Language Models are Zero-Shot Reasoners",
        "section_head": "E Detailed experiment results of model scale study",
        "score": 0.8591150641441345,
        "text_preview": "This section describes the detailed experiment results of model scale study. The curve within Figure 3 uses the values of Table 26 and Table 27 ."
      },
      {
        "chunk_index": 131855,
        "paper_id": 2728,
        "chunk_idx": 0,
        "title": "StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models",
        "section_head": "Visualization of Invisibility",
        "score": 0.8569062948226929,
        "text_preview": "To evaluate the impact of perturbations, Fig. 2 compares the perturbations applied by different methods."
      },
      {
        "chunk_index": 104887,
        "paper_id": 2175,
        "chunk_idx": 0,
        "title": "Personalized Subgraph Federated Learning with Sheaf Collaboration",
        "section_head": "Convergence Guarantees",
        "score": 0.8523472547531128,
        "text_preview": "We provide guarantees by bounding the expected average gradient norm, with the detailed proof and complete formulation presented in Appendix B."
      },
      {
        "chunk_index": 53286,
        "paper_id": 1142,
        "chunk_idx": 0,
        "title": "FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction",
        "section_head": "Figure 3 :",
        "score": 0.851262092590332,
        "text_preview": "3 Figure 3: The different methods to calculate the feature interactions. (a): Inner product. (b): Hadamard product. (c): our proposed bilinear interaction. Here p i j in inner product method is a scal"
      },
      {
        "chunk_index": 53807,
        "paper_id": 1153,
        "chunk_idx": 0,
        "title": "Fine-Tuning Language Models with Just Forward Passes",
        "section_head": "Table 6 :",
        "score": 0.8497601747512817,
        "text_preview": "6 Experiments using MeZO with different schedules for n. We scale the learning rate proportionally to the number of z's sampled. n Schedule SST-2 SNLI TREC n = 1 Constant 89.6 (1.2) 65.1 (6.2) 66.7 (6"
      },
      {
        "chunk_index": 35593,
        "paper_id": 752,
        "chunk_idx": 0,
        "title": "DISCRETE DIFFUSION FOR REFLECTIVE VISION-LANGUAGE-ACTION MODELS IN AUTONOMOUS DRIVING",
        "section_head": "Table 2 :",
        "score": 0.847052812576294,
        "text_preview": "2 Ablation for Reflective Inference. The ablation study results of goal-conditioned generation and safety-guided regeneration to demonstrate the effectiveness of reflective inference.Generation steps,"
      },
      {
        "chunk_index": 60558,
        "paper_id": 1292,
        "chunk_idx": 0,
        "title": "Ghostbuster: Detecting Text Ghostwritten by Large Language Models",
        "section_head": "Figure 3 :",
        "score": 0.8468084335327148,
        "text_preview": "3 Figure3: Robustness experiments on Ghostbuster (F1). We evaluated the performance of our system on documents that underwent a number of character-and word-level perturbations (left) as well as sente"
      },
      {
        "chunk_index": 120935,
        "paper_id": 2517,
        "chunk_idx": 0,
        "title": "Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers",
        "section_head": "Table 5 :",
        "score": 0.8464738130569458,
        "text_preview": "5 Ablation on attention score normalization methods. B.3 Ablation on normalization method softmax min-max VOC Object 83.2 55.1 85.2 53.5 89.0 61.8 88.3 57.0"
      },
      {
        "chunk_index": 123428,
        "paper_id": 2572,
        "chunk_idx": 0,
        "title": "ShortListing Model: A Streamlined Simplex Diffusion for Discrete Variable Generation",
        "section_head": "Figure 5",
        "score": 0.846359133720398,
        "text_preview": "5 Figure 5 Performance of SLM under different CFG factor Œ≥ for unconditional enhancer design."
      },
      {
        "chunk_index": 88731,
        "paper_id": 1865,
        "chunk_idx": 0,
        "title": "Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay",
        "section_head": "Ablation Studies",
        "score": 0.8445637226104736,
        "text_preview": "Ablation studies systematically isolate and evaluate the contribution of individual components or hyperparameters of our proposed methods. By selectively modifying or removing specific elements while "
      }
    ]
  },
  {
    "query_id": 75,
    "query_text": "speech study data",
    "source": "title",
    "source_value": "A STUDY ON DATA AUGMENTATION OF REVERBERANT SPEECH FOR ROBUST SPEECH RECOGNITION",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 70057,
        "paper_id": 1492,
        "chunk_idx": 0,
        "title": "Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis",
        "section_head": "Table 2 :",
        "score": 0.9788820743560791,
        "text_preview": "2 Sarcasm detection on generated data Method Input type Precision (%) Recall (%) F1-score (%) Baseline speech 61.5 66.7 62.2 Proposed speech 61.9 68.6 63.4 Baseline speech+text 68.9 68.7 68.8 Proposed"
      },
      {
        "chunk_index": 14641,
        "paper_id": 294,
        "chunk_idx": 0,
        "title": "Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars NVIDIA",
        "section_head": "Figure 17 :",
        "score": 0.9339448809623718,
        "text_preview": "17 Figure17: Experiments with training data."
      },
      {
        "chunk_index": 70056,
        "paper_id": 1492,
        "chunk_idx": 0,
        "title": "Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis",
        "section_head": "Table 1 :",
        "score": 0.9173918962478638,
        "text_preview": "1 Sarcasm detection on real data Method Input type Precision (%) Recall (%) F1-score (%) MUStARD++ speech 63.9 63.5 63.6 Proposed detector speech 66.6 66.3 66.2 MUStARD++ speech+text 68.8 68.6 68.7 Pr"
      },
      {
        "chunk_index": 133304,
        "paper_id": 2758,
        "chunk_idx": 0,
        "title": "SYNPARASPEECH: AUTOMATED SYNTHESIS OF PARALINGUISTIC DATASETS FOR SPEECH GENERATION AND UNDERSTANDING",
        "section_head": "Experimental Setups",
        "score": 0.9103599786758423,
        "text_preview": "To evaluate the effectiveness of SynParaSpeech in both paralinguistic speech synthesis and speech understanding tasks, we conducted experiments on paralinguistic TTS and event detection."
      },
      {
        "chunk_index": 32730,
        "paper_id": 686,
        "chunk_idx": 0,
        "title": "DEMYSTIFYING CLIP DATA",
        "section_head": "50% reduction 77% reduction",
        "score": 0.9095884561538696,
        "text_preview": "Figure 5 : Case study: Curation implementation in our data pipeline."
      },
      {
        "chunk_index": 10541,
        "paper_id": 204,
        "chunk_idx": 0,
        "title": "An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training",
        "section_head": "Experiments and results",
        "score": 0.8880873918533325,
        "text_preview": "We analyze discrete speech units across four dimensions: encoder and discretization methods (Section 3.1), language model scaling (Section 3.2), acoustic robustness (Section 3.3), and linguistic conte"
      },
      {
        "chunk_index": 142292,
        "paper_id": 2934,
        "chunk_idx": 0,
        "title": "TRAFFIC-MLLM: A SPATIO-TEMPORAL MLLM WITH RETRIEVAL-AUGMENTED GENERATION FOR CAUSAL INFERENCE IN TRAFFIC",
        "section_head": "Training",
        "score": 0.8851810097694397,
        "text_preview": "In this section, we will introduce the training data and training methods separately."
      },
      {
        "chunk_index": 135875,
        "paper_id": 2811,
        "chunk_idx": 0,
        "title": "TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering",
        "section_head": "Ablation studies",
        "score": 0.8693984746932983,
        "text_preview": "How much data is needed for fine-tuning M 1 ? As illustrated in Table 1 , we conduct experiments with different data amount, including 0k, 2.5k, 5k, 10k, 50k, and 100k."
      },
      {
        "chunk_index": 23351,
        "paper_id": 477,
        "chunk_idx": 1,
        "title": "ChainPoll: A HIGH EFFICACY METHOD FOR LLM HALLUCINATION DETECTION",
        "section_head": "4. 1 1",
        "score": 0.8685903549194336,
        "text_preview": ". . . . . . . 6.5 ChatProtect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset selection process . . . . . . . . . . . . . . . . . . . . . . . . "
      },
      {
        "chunk_index": 129979,
        "paper_id": 2699,
        "chunk_idx": 0,
        "title": "StarCoder: may the source be with you!",
        "section_head": "Model training",
        "score": 0.8665931224822998,
        "text_preview": "This section presents information on the training process of the StarCoder models. Before we proceed, we first clarify the differences between the two models: StarCoderBase is the first model trained "
      },
      {
        "chunk_index": 75798,
        "paper_id": 1601,
        "chunk_idx": 0,
        "title": "LARGE-SCALE CONTRASTIVE LANGUAGE-AUDIO PRETRAINING WITH FEATURE FUSION AND KEYWORD-TO-CAPTION AUGMENTATION",
        "section_head": "D. DETAILS OF LAION-AUDIO-630K",
        "score": 0.8664826154708862,
        "text_preview": "Regarding the section 2.1 and section 2.2 of the paper: ‚Ä¢ We list the specifications of website/sources from which we collect the audio samples and text captions for LAION-Audio-630K in Table 5 . ‚Ä¢ We"
      },
      {
        "chunk_index": 84800,
        "paper_id": 1786,
        "chunk_idx": 0,
        "title": "Masked Autoencoders that Listen",
        "section_head": "Experiments",
        "score": 0.8657487630844116,
        "text_preview": "We perform an extensive evaluation on six tasks, including audio classification on AudioSet (AS-2M, AS-20K) and Environmental Sound Classification (ESC-50), and speech classification on Speech Command"
      },
      {
        "chunk_index": 15542,
        "paper_id": 310,
        "chunk_idx": 1,
        "title": "Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework",
        "section_head": "Automated Generation and Visualization of Structured Research Workflows for NLP Papers",
        "score": 0.8641923666000366,
        "text_preview": "Structured research workflows derived from several papers Paper_id Data Preparation Data Processing Data Analysis 2021.emnlpmain.443 datasets and preprocessing document retrieval, multiple [cls] embed"
      },
      {
        "chunk_index": 35752,
        "paper_id": 756,
        "chunk_idx": 0,
        "title": "DISCRETE-TIME DIFFUSION-LIKE MODELS FOR SPEECH SYNTHESIS",
        "section_head": "METHOD",
        "score": 0.8639504313468933,
        "text_preview": "This section presents noising, training and inference methods used in this work. Four noising processes are explored for the first time in a discrete-time diffusion-like model in speech synthesis."
      },
      {
        "chunk_index": 103258,
        "paper_id": 2141,
        "chunk_idx": 0,
        "title": "PaLM: Scaling Language Modeling with Pathways",
        "section_head": "Model Card",
        "score": 0.862671971321106,
        "text_preview": "The Model Card (Mitchell et al., 2019) for PaLM is provided in Appendix E. This provides a high-level summary of the model's architecture, training setup, training data, and intended usage."
      },
      {
        "chunk_index": 127671,
        "paper_id": 2668,
        "chunk_idx": 0,
        "title": "Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents",
        "section_head": "Figure 2 :",
        "score": 0.8618052005767822,
        "text_preview": "2 Figure 2: An illustration of the complete Speech Vecalign pipeline using a simple example. Each pair of speech documents need to go through 3 steps: Speech Preprocessing (Section 3.1), Segment Align"
      },
      {
        "chunk_index": 96798,
        "paper_id": 2042,
        "chunk_idx": 0,
        "title": "NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations",
        "section_head": "Step 1: Word-level Human Annotation Dataset",
        "score": 0.8608266115188599,
        "text_preview": "Annotated Transcription: 1.ÊàëÂñúÊ¨¢ËøôÁßçÂ§©Ê∞î[Uhm] ÔºåÁúüËΩªÊùæÔºÅ 2.[Sigh]Âø´Âà∞‰∫Ü,Êàë‰ª¨[Breathing] ‰∏ãÊ¨°ÂÜçËÆ≤Âêß„ÄÇ Speech & Transcription: 1.ÊàëÂñúÊ¨¢ËøôÁßçÂ§©Ê∞îÔºåÁúüËΩªÊùæÔºÅ 2.Âø´Âà∞‰∫ÜÊàë‰ª¨Ôºå‰∏ãÊ¨°ÂÜçËÆ≤Âêß„ÄÇ Data Collection Speech Non-verbal Vocalization Text Speech TTS Real"
      },
      {
        "chunk_index": 37004,
        "paper_id": 786,
        "chunk_idx": 0,
        "title": "DOES AUDIO MATTER FOR MODERN VIDEO-LLMS AND THEIR BENCHMARKS?",
        "section_head": "Table 1 .",
        "score": 0.8607659935951233,
        "text_preview": "1 Ablation results. The proposed setting achieves strong gains on audio-sensitive sets with linear-time compression. Variant Music-AVQA-H Music-AVQA AVQA-H AVQA ActivityNetQA NExTQA TempCompass VideoM"
      },
      {
        "chunk_index": 30900,
        "paper_id": 645,
        "chunk_idx": 0,
        "title": "DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems",
        "section_head": "Experiment Setup",
        "score": 0.8603515625,
        "text_preview": "This section describes the experiment setup, including training datasets, baseline approaches, and details of the hyper-parameter search and training process."
      },
      {
        "chunk_index": 70417,
        "paper_id": 1501,
        "chunk_idx": 0,
        "title": "InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos",
        "section_head": "C.2. Annotation prompt",
        "score": 0.8591279983520508,
        "text_preview": "In this section, we provide the detailed prompt for automatic text annotation with VLM."
      }
    ]
  },
  {
    "query_id": 76,
    "query_text": "study regularization-based continual",
    "source": "title",
    "source_value": "A Study on Regularization-Based Continual Learning Methods for Indic ASR",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 88756,
        "paper_id": 1865,
        "chunk_idx": 0,
        "title": "Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay",
        "section_head": "Detailed Ablation Study Results",
        "score": 0.9552559852600098,
        "text_preview": "We conducted several ablation studies to better understand the factors affecting catastrophic forgetting and mode collapse in continual text-to-image diffusion. This section presents detailed results "
      },
      {
        "chunk_index": 133225,
        "paper_id": 2756,
        "chunk_idx": 0,
        "title": "Synergies between Federated Foundation Models and Smart Power Grids",
        "section_head": "II. MULTI-MODAL MULTI-TASK FEDERATED FOUNDATION MODELS (M3T FEDFMS)",
        "score": 0.9301999807357788,
        "text_preview": "In the following, we provide background on the core concepts of FL, multi-modal and multi-task learning, and M3T FMs."
      },
      {
        "chunk_index": 115772,
        "paper_id": 2415,
        "chunk_idx": 0,
        "title": "RichRAG: Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation",
        "section_head": "C Ranking Performance",
        "score": 0.8915352821350098,
        "text_preview": "To prove the effectiveness of our proposed list-wise ranking module, we also evaluate the ranking modules' performance of our method and baselines. We indicate the types of ranking algorithms, includi"
      },
      {
        "chunk_index": 28118,
        "paper_id": 577,
        "chunk_idx": 0,
        "title": "Contextualized Multimodal Lifelong Person Re-Identification in Hybrid Clothing States",
        "section_head": "Experiments",
        "score": 0.8643839955329895,
        "text_preview": "To rigorously evaluate the effectiveness of our proposed Contextualized Multimodal Lifelong Re-ID (CMLReID) framework, we conducted extensive experiments under the challenging LReID-Hybrid setting. Th"
      },
      {
        "chunk_index": 97801,
        "paper_id": 2062,
        "chunk_idx": 0,
        "title": "OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models",
        "section_head": "Table 3",
        "score": 0.8559894561767578,
        "text_preview": "3 Ablation study of our method. 6 Conclusion This paper presents a comprehensive study of the task, i.e.,"
      },
      {
        "chunk_index": 109671,
        "paper_id": 2276,
        "chunk_idx": 0,
        "title": "Put Teacher in Student's Shoes: Cross-Distillation for Ultra-compact Model Compression Framework",
        "section_head": "Experiments",
        "score": 0.8545552492141724,
        "text_preview": "In this section, we systematically evaluate our proposed framework, with a particular focus on the cross-distillation technique."
      },
      {
        "chunk_index": 72695,
        "paper_id": 1548,
        "chunk_idx": 0,
        "title": "Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements",
        "section_head": "Experiments",
        "score": 0.853215217590332,
        "text_preview": "In this section, we first describe our evaluation setup. Then we compare our approach with vanilla prompting, prior in-context learning works, and supervised fine-tuning methods."
      },
      {
        "chunk_index": 62098,
        "paper_id": 1327,
        "chunk_idx": 0,
        "title": "Graph Federated Learning for Personalized Privacy Recommendation",
        "section_head": "Baselines and Implementation Details",
        "score": 0.8500667810440063,
        "text_preview": "Baselines. We compare our proposed federated recommendation method against a series of representative baselines under both centralized and federated settings. All compared methods operate solely on us"
      },
      {
        "chunk_index": 43237,
        "paper_id": 918,
        "chunk_idx": 0,
        "title": "Enhancing Privacy Preservation and Reducing Analysis Time with Federated Transfer Learning in Digital Twins-based Computed Tomography Scan Analysis",
        "section_head": "Performance Evaluation",
        "score": 0.8500022292137146,
        "text_preview": "This section uses various performance evaluations to assess our proposed framework using Federated Transfer Learning."
      },
      {
        "chunk_index": 110303,
        "paper_id": 2291,
        "chunk_idx": 0,
        "title": "QUANTIZED VISUAL GEOMETRY GROUNDED TRANSFORMER",
        "section_head": "ABLATION STUDY",
        "score": 0.8470892906188965,
        "text_preview": "To validate the effectiveness of each proposed component, we conduct an ablation study. All the experiments are conducted under W4A4 quantization setting on Co3Dv2 (Reizenstein et al., 2021) ."
      },
      {
        "chunk_index": 14305,
        "paper_id": 290,
        "chunk_idx": 0,
        "title": "Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval",
        "section_head": "-Statistical analysis (Section A.2).",
        "score": 0.8438013792037964,
        "text_preview": "‚Ä¢ Experiments on ActivityNet Captions including: -Ablation studies on fusion strategies (Section B.1). -Ablation studies on additional model structures (Section B.4). -Qualitative analysis (Section B."
      },
      {
        "chunk_index": 45776,
        "paper_id": 977,
        "chunk_idx": 0,
        "title": "Explicit Multimodal Graph Modeling for Human-Object Interaction Detection",
        "section_head": "Experiments",
        "score": 0.8409222960472107,
        "text_preview": "This section presents a series of experiments designed to evaluate the effectiveness of our proposed method. First, we briefly introduce the experimental settings. Next, we present a comprehensive com"
      },
      {
        "chunk_index": 48407,
        "paper_id": 1033,
        "chunk_idx": 0,
        "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning",
        "section_head": "Experiments",
        "score": 0.8384250998497009,
        "text_preview": "In this section, we evaluate our proposed method using three datasets and various baselines. We investigate the relationship between data heterogeneity and training efficiency. Additionally, we conduc"
      },
      {
        "chunk_index": 81155,
        "paper_id": 1712,
        "chunk_idx": 0,
        "title": "LLM-BL E N D E R: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion",
        "section_head": "PAIRRANKER: Pairwise Ranking",
        "score": 0.8379244804382324,
        "text_preview": "In this section, we introduce three baseline methods for ranking the candidates in Y in Sec. 3.1 and present the proposed PAIRRANKER method."
      },
      {
        "chunk_index": 22569,
        "paper_id": 461,
        "chunk_idx": 0,
        "title": "Causality-guided Prompt Learning for Vision-language Models via Visual Granulation",
        "section_head": "Table 5 .",
        "score": 0.8378937840461731,
        "text_preview": "5 Ablation study for different optimization methods for attribute disentanglement. Method Base New H Classification-based method 78.44 74.24 76.28 DDPM-based method 79.12 74.93 76.97 BBDM-based varian"
      },
      {
        "chunk_index": 72006,
        "paper_id": 1535,
        "chunk_idx": 0,
        "title": "Joint AoI and Handover Optimization in Space-Air-Ground Integrated Network",
        "section_head": "SIMULATION RESULTS AND ANALYSIS",
        "score": 0.8367629051208496,
        "text_preview": "In this section, we present comprehensive evaluations of our proposed approach and verify the effectiveness and robustness of the proposed DD3QN-AS in addressing the formulate optimization problem und"
      },
      {
        "chunk_index": 48423,
        "paper_id": 1033,
        "chunk_idx": 0,
        "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning",
        "section_head": "Table 3 :",
        "score": 0.8363139629364014,
        "text_preview": "3 Ablation study of FedFD with two main components. Method CIFAR-10 Œ±=1.0 Œ±=0.1 Œ±=1.0 Œ±=0.1 CIFAR-100 FedFD 89.64 82.74 60.86 59.24 -w/o feature alignment 89.01 81.56 59.77 58.67 -w/o orthogonal proje"
      },
      {
        "chunk_index": 27251,
        "paper_id": 557,
        "chunk_idx": 0,
        "title": "Composable Score-based Graph Diffusion Model for Multi-Conditional Molecular Generation",
        "section_head": "Ablation Studies",
        "score": 0.8358017206192017,
        "text_preview": "To assess the contribution of each component, we conduct a detailed ablation study focusing on two aspects: score-based modeling in graph diffusion and two score manipulation techniques."
      },
      {
        "chunk_index": 11470,
        "paper_id": 222,
        "chunk_idx": 1,
        "title": "ANALYZING GENERALIZATION IN PRE-TRAINED SYMBOLIC REGRESSION",
        "section_head": "Analyzing Generalization in Pre-Trained Symbolic Regression",
        "score": 0.8352236747741699,
        "text_preview": "3 Robustness Analysis 3.1 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
      },
      {
        "chunk_index": 115948,
        "paper_id": 2419,
        "chunk_idx": 0,
        "title": "RLGF: Reinforcement Learning with Geometric Feedback for Autonomous Driving Video Generation",
        "section_head": "Experimental Setup",
        "score": 0.8351427912712097,
        "text_preview": "We conduct comprehensive experiments to validate the efficacy of our proposed Reinforcement Learning with Geometric Feedback (RLGF) framework. This section details the datasets, baseline models, evalu"
      }
    ]
  },
  {
    "query_id": 77,
    "query_text": "surveillance based interactive",
    "source": "title",
    "source_value": "A Surveillance Based Interactive Robot",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 9068,
        "paper_id": 173,
        "chunk_idx": 1,
        "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review",
        "section_head": "Multimodal Prediction",
        "score": 0.9079756140708923,
        "text_preview": "Study [69] introduces a framework that enhances mental health assessment by combining ensemble machine learning with LLMs. Using a dataset of 41,000 mental health entries, we compared AdaBoost, Voting"
      },
      {
        "chunk_index": 157104,
        "paper_id": 3220,
        "chunk_idx": 0,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "IV. ZERO-SHOT-BASED PREVENTION STRATEGIES FOR DEEPFAKE GENERATION",
        "score": 0.901075005531311,
        "text_preview": "While zero-shot deepfake detection enabled the identification of synthetic content without any prior exposure, there is an equally critical aspect of deepfake defense i.e. prevention of deepfake gener"
      },
      {
        "chunk_index": 100602,
        "paper_id": 2106,
        "chunk_idx": 1,
        "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting",
        "section_head": "B. Byzantine Threat Model",
        "score": 0.8843109607696533,
        "text_preview": "Our methodology introduces a multi-layered defense system combining novel optimization, sophisticated anomaly detection, and adaptive learning strategies. OptiGradTrust consists of six core components"
      },
      {
        "chunk_index": 53245,
        "paper_id": 1141,
        "chunk_idx": 0,
        "title": "FHRFormer: A Self-supervised Transformer Approach for Fetal Heart Rate Inpainting and Forecasting",
        "section_head": "C. Forecasting Application",
        "score": 0.8781752586364746,
        "text_preview": "Forecasting the FHR signal based on recent trends can serve as an intelligent feature in wearable devices by enabling early alerts for anticipated drops in heart rate, thereby supporting timely clinic"
      },
      {
        "chunk_index": 142301,
        "paper_id": 2934,
        "chunk_idx": 0,
        "title": "TRAFFIC-MLLM: A SPATIO-TEMPORAL MLLM WITH RETRIEVAL-AUGMENTED GENERATION FOR CAUSAL INFERENCE IN TRAFFIC",
        "section_head": "Fig. 2 .",
        "score": 0.8726156949996948,
        "text_preview": "2 Fig. 2. Overall architecture of the retrieval-augmented multimodal reasoning framework for traffic scenarios."
      },
      {
        "chunk_index": 1660,
        "paper_id": 30,
        "chunk_idx": 4,
        "title": "A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks",
        "section_head": "I. INTRODUCTION",
        "score": 0.870161771774292,
        "text_preview": "A critical differentiator of our platform is its ability to systematically improve detection capabilities through operational feedback loops that transform real-world threats into enhanced security po"
      },
      {
        "chunk_index": 34978,
        "paper_id": 740,
        "chunk_idx": 0,
        "title": "DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing",
        "section_head": "A Unified Dual Defense Framework (DINA)",
        "score": 0.8688106536865234,
        "text_preview": "To simultaneously mitigate internal data contamination and external adversarial attacks, we propose a comprehensive hybrid framework named DINA (Dual Defense Against Internal Noise and Adversarial Att"
      },
      {
        "chunk_index": 53465,
        "paper_id": 1148,
        "chunk_idx": 0,
        "title": "Find a Scapegoat: Poisoning Membership Inference Attack and Defense to Federated Learning",
        "section_head": "Our Defense",
        "score": 0.8608433604240417,
        "text_preview": "In this section, we introduce a defense mechanism aimed at mitigating the effects of various MIAs. Inspired by the Trimmed-mean approach [55] , our defense strategy is built on the core concept of dis"
      },
      {
        "chunk_index": 70110,
        "paper_id": 1495,
        "chunk_idx": 1,
        "title": "Intelligent Healthcare Imaging Platform: An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation",
        "section_head": "Introduction",
        "score": 0.8581935167312622,
        "text_preview": "The novel healthcare integration approach represents a comprehensive combination of advanced large language model capabilities with computer vision techniques specifically optimized for medical image "
      },
      {
        "chunk_index": 148976,
        "paper_id": 3070,
        "chunk_idx": 1,
        "title": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software",
        "section_head": "Workflow",
        "score": 0.8567095994949341,
        "text_preview": "4.5). These inputs are passed through a secure inference pipeline that invokes two validated modules (details in Sec. 4.4): a data integrity checker that verifies the consistency of runtime inputs aga"
      },
      {
        "chunk_index": 142609,
        "paper_id": 2942,
        "chunk_idx": 2,
        "title": "TRAINING-FREE MULTIMODAL LARGE LANGUAGE MODEL ORCHESTRATION",
        "section_head": "Agent-based Multimodal Systems",
        "score": 0.855736255645752,
        "text_preview": "In professional domain applications, ClinicalAgent [46] proposed an LLM-based multiagent clinical decision support system that improved medical diagnosis accuracy through multi-agent collaboration; La"
      },
      {
        "chunk_index": 2952,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "III. METHODOLOGY",
        "score": 0.8535515069961548,
        "text_preview": "In this section, we present the design and implementation of the proposed Quantum-LSTM FedRansel model for financial fraud detection within the FL context. Our approach combines state-of-the-art quant"
      },
      {
        "chunk_index": 54344,
        "paper_id": 1168,
        "chunk_idx": 0,
        "title": "FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks",
        "section_head": "arXiv:2508.18737v1 [cs.LG] 26 Aug 2025",
        "score": 0.8519487380981445,
        "text_preview": "Transform (FFT), inspired by our prior work [14] , to perform robust aggregation in the frequency domain. This function filters out frequency components associated with anomalous patterns, reducing th"
      },
      {
        "chunk_index": 42671,
        "paper_id": 903,
        "chunk_idx": 0,
        "title": "Enabling Trustworthy Federated Learning via Remote Attestation for Mitigating Byzantine Threats",
        "section_head": "VI. CONCLUSION",
        "score": 0.8517943620681763,
        "text_preview": "In this work, we propose Sentinel, a remote attestationbased framework to enhance the security and transparency of FL training on remote devices. Unlike data-driven Byzantineresilient approaches, Sent"
      },
      {
        "chunk_index": 100173,
        "paper_id": 2099,
        "chunk_idx": 0,
        "title": "Open-Ended Generation of Diverse Adversarial Prompts",
        "section_head": "Conclusion",
        "score": 0.846969723701477,
        "text_preview": "In this work, we introduce Rainbow Teaming, a novel approach for the automatic generation of diverse adversarial prompts for LLMs. By leveraging quality-diversity search, Rainbow Teaming efficiently e"
      },
      {
        "chunk_index": 151546,
        "paper_id": 3119,
        "chunk_idx": 7,
        "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning",
        "section_head": "INTRODUCTION",
        "score": 0.8466470837593079,
        "text_preview": "These perturbations are guided by predictions from the surrogate model and constrained by the estimated detector, ensuring that the crafted adversarial samples both induce targeted misclassifications "
      },
      {
        "chunk_index": 80033,
        "paper_id": 1690,
        "chunk_idx": 5,
        "title": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions",
        "section_head": "Introduction",
        "score": 0.8459087610244751,
        "text_preview": "driven approach achieving semantic similarity scores of 0.81¬±0.13 with authentic patient-provider conversations. LingVarBench addresses a critical bottleneck in healthcare AI adoption by providing the"
      },
      {
        "chunk_index": 70904,
        "paper_id": 1513,
        "chunk_idx": 1,
        "title": "Investigating Traffic Accident Detection Using Multimodal Large Language Models",
        "section_head": "I. INTRODUCTION",
        "score": 0.8431689739227295,
        "text_preview": "Connected vehicles receive tailored routing and driving advice, effectively reducing road wear, decreasing maintenance requirements, and enhancing driving comfort [1] . Building on ESRIUM's outcomes, "
      },
      {
        "chunk_index": 65736,
        "paper_id": 1401,
        "chunk_idx": 7,
        "title": "Hybrid Deep Learning-Federated Learning Powered Intrusion Detection System for IoT/5G Advanced Edge Computing Network",
        "section_head": "Background and Literature Review",
        "score": 0.8425800800323486,
        "text_preview": "The key contributions of this research include: Designing a novel model that combines CNN, LSTM, and AE for anomaly detection in IoT. Evaluating the feasibility of the proposed hybrid model and compar"
      },
      {
        "chunk_index": 8944,
        "paper_id": 172,
        "chunk_idx": 0,
        "title": "AI-IN-THE-LOOP: PRIVACY PRESERVING REAL-TIME SCAM DETECTION AND CONVERSATIONAL SCAMBAITING BY LEVERAGING LLMS AND FEDERATED LEARNING",
        "section_head": "Conclusion",
        "score": 0.840714693069458,
        "text_preview": "We proposed a unified, privacy-preserving framework for real-time scam detection and automated scam-baiting within a single instruction-tuned LLM. Leveraging multi-platform scam-victim datasets, our s"
      }
    ]
  },
  {
    "query_id": 78,
    "query_text": "survey cognitive distortion",
    "source": "title",
    "source_value": "A Survey of Cognitive Distortion Detection and Classification in NLP",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 93728,
        "paper_id": 1979,
        "chunk_idx": 0,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "User Study",
        "score": 0.9718739986419678,
        "text_preview": "We conducted a comprehensive user study to assess perceptual and cognitive aspects of music quality. The subjective criteria defined in Table 1 are employed to enable crossmodel comparison from a huma"
      },
      {
        "chunk_index": 102646,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 4 :",
        "score": 0.9357225894927979,
        "text_preview": "4 Human expert evaluation resultsApproach Actionability Coherence Domain Spec. Tech Spec. Understand. User Focus Overall ReT-Eval 4.2 ¬± 0.7 4.1 ¬± 0.8 4.0 ¬± 0.8 4.0 ¬± 0.7 4.3 ¬± 0.6 4.1 ¬± 0.7 4.1 GNN"
      },
      {
        "chunk_index": 130583,
        "paper_id": 2707,
        "chunk_idx": 0,
        "title": "StepWrite: Adaptive Planning for Speech-Driven Text Generation",
        "section_head": "Measures",
        "score": 0.9249292612075806,
        "text_preview": "We collected both objective and subjective measures to evaluate participants' interaction with each hands-free writing tool. Our measures spanned seven key dimensions: revision effort, text quality, t"
      },
      {
        "chunk_index": 33513,
        "paper_id": 703,
        "chunk_idx": 0,
        "title": "Detecting and Explaining Postpartum Depression in Real-Time with Generative Artificial Intelligence",
        "section_head": "Figure 5",
        "score": 0.9186310768127441,
        "text_preview": "5 Figure 5 Confusion matrix of the users' responses interpretation evaluation."
      },
      {
        "chunk_index": 144185,
        "paper_id": 2975,
        "chunk_idx": 0,
        "title": "TRUSTLLM: TRUSTWORTHINESS IN LARGE LANGUAGE MODELS -A PRINCIPLE AND BENCHMARK",
        "section_head": "¬ß9 Privacy",
        "score": 0.9062566757202148,
        "text_preview": "The norms and practices that help to safeguard human and data autonomy, identity, and dignity [83] . ¬ß10"
      },
      {
        "chunk_index": 70280,
        "paper_id": 1498,
        "chunk_idx": 2,
        "title": "Interactive Recommendation Agent with Active User Commands",
        "section_head": "Evaluation Metrics.",
        "score": 0.904655933380127,
        "text_preview": "(2) Business Utility Metrics evaluate the commercial utility, including Page Views (PV), capturing overall user engagement with recommended content; Add-to-Cart (ATC), measuring conversion intent thro"
      },
      {
        "chunk_index": 3878,
        "paper_id": 79,
        "chunk_idx": 2,
        "title": "A Survey of Cognitive Distortion Detection and Classification in NLP",
        "section_head": "Risks of Misuse & Overreliance.",
        "score": 0.8840463161468506,
        "text_preview": "Cognitive distortion based explainable depression detection and analysis technologies for the adolescent internet users on social media. Frontiers in Public Health, 10:1045777. Bichen Wang, Pengfei De"
      },
      {
        "chunk_index": 93727,
        "paper_id": 1979,
        "chunk_idx": 0,
        "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks",
        "section_head": "Evaluation Metrics",
        "score": 0.8833900690078735,
        "text_preview": "In this section, we introduce the evaluation framework used in our benchmark, which includes both objective and subjective components designed to comprehensively assess the quality of symbolic music g"
      },
      {
        "chunk_index": 130592,
        "paper_id": 2707,
        "chunk_idx": 0,
        "title": "StepWrite: Adaptive Planning for Speech-Driven Text Generation",
        "section_head": "Results",
        "score": 0.8818020820617676,
        "text_preview": "We report our findings across six main dimensions introduced in the Measures section: revision effort, text quality and structure, temporal efficiency,questions necessity, evaluation of tone classific"
      },
      {
        "chunk_index": 11312,
        "paper_id": 219,
        "chunk_idx": 0,
        "title": "Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting",
        "section_head": "{student_answer}Figure 15 .",
        "score": 0.8778390884399414,
        "text_preview": "15 Figure 15. User prompt for Reference Aided Evaluation and Adaptive Evaluation."
      },
      {
        "chunk_index": 11300,
        "paper_id": 219,
        "chunk_idx": 0,
        "title": "Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting",
        "section_head": "Figure 15 .",
        "score": 0.8778389692306519,
        "text_preview": "15 Figure 15. User prompt for Reference Aided Evaluation and Adaptive Evaluation."
      },
      {
        "chunk_index": 106541,
        "paper_id": 2205,
        "chunk_idx": 0,
        "title": "Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models",
        "section_head": "Figure 12 .",
        "score": 0.8750101327896118,
        "text_preview": "12 Figure 12. Screenshot from user study evaluating consistency, alignment, and disentanglement."
      },
      {
        "chunk_index": 54910,
        "paper_id": 1174,
        "chunk_idx": 0,
        "title": "FLASK: FINE-GRAINED LANGUAGE MODEL EVALUATION BASED ON ALIGNMENT SKILL SETS",
        "section_head": "Table 7 :",
        "score": 0.8742154836654663,
        "text_preview": "7 Statistics of difficulty level annotation of the FLASK evaluation set. The evaluation Figure 27: User interface of the human labeling process. Model-based Evaluation Human-based Evaluation"
      },
      {
        "chunk_index": 95173,
        "paper_id": 2013,
        "chunk_idx": 0,
        "title": "NEURAL TEXT DEGENERATION WITH UNLIKELIHOOD TRAINING",
        "section_head": "Figure 2 :",
        "score": 0.8681625723838806,
        "text_preview": "2 Figure 2: Screen shot of the user interface used in the human evaluation."
      },
      {
        "chunk_index": 130590,
        "paper_id": 2707,
        "chunk_idx": 1,
        "title": "StepWrite: Adaptive Planning for Speech-Driven Text Generation",
        "section_head": "Subjective Metrics / User Experience.",
        "score": 0.8677352666854858,
        "text_preview": "‚Ä¢ Hands-Free Writing Tools Assessment (HFWTA): We developed a 30-item questionnaire to evaluate seven dimensions of hands-free writing experience: Guided Writing Process, Hands-Free Interaction, Adapt"
      },
      {
        "chunk_index": 70707,
        "paper_id": 1508,
        "chunk_idx": 0,
        "title": "Intuition to Evidence: Measuring AI's True Impact on Developer Productivity",
        "section_head": "Data Collection and Instrumentation",
        "score": 0.862187385559082,
        "text_preview": "Automated Data Pipeline: Data was collected through automated instrumentation to minimize measurement bias and ensure consistency: ‚Ä¢ Version Control Analytics: Bitbucket and GitHub webhooks captured c"
      },
      {
        "chunk_index": 11314,
        "paper_id": 219,
        "chunk_idx": 0,
        "title": "Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting",
        "section_head": "{student_answer}Figure 17 .",
        "score": 0.8553174734115601,
        "text_preview": "17 Figure 17. User prompt for No Reference Evaluation and Additive Evaluation."
      },
      {
        "chunk_index": 44572,
        "paper_id": 952,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis",
        "section_head": "Fig. 5",
        "score": 0.8552683591842651,
        "text_preview": "5 Fig. 5 Comparative analysis across the evaluation criteria"
      },
      {
        "chunk_index": 78735,
        "paper_id": 1662,
        "chunk_idx": 0,
        "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale",
        "section_head": "Table 2 :",
        "score": 0.8546152114868164,
        "text_preview": "2 Factors in the user preferences SocialCommunication, Contact, Data Types Data-general, MedicalHealth, Identifying, Location, Picture Purposes Internal, Advertisement, Analytics, Research, SNS, Prote"
      },
      {
        "chunk_index": 82792,
        "paper_id": 1741,
        "chunk_idx": 0,
        "title": "LONGQLORA: EFFICIENT AND EFFECTIVE METHOD TO EXTEND CONTEXT LENGTH OF LARGE LANGUAGE MODELS",
        "section_head": "User",
        "score": 0.8537230491638184,
        "text_preview": "Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions."
      }
    ]
  },
  {
    "query_id": 79,
    "query_text": "survey graph meets",
    "source": "title",
    "source_value": "A Survey of Graph Meets Large Language Model: Progress and Future Directions",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 126451,
        "paper_id": 2635,
        "chunk_idx": 0,
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "section_head": "Figure 4 . 6 :",
        "score": 0.9712480306625366,
        "text_preview": "46 Figure 4.6: A discussion regarding k-SAT problems and graph theory."
      },
      {
        "chunk_index": 31731,
        "paper_id": 664,
        "chunk_idx": 0,
        "title": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey",
        "section_head": "Fig. 2 .",
        "score": 0.8847667574882507,
        "text_preview": "2 Fig. 2. Organizational Structure of the Survey."
      },
      {
        "chunk_index": 102646,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 4 :",
        "score": 0.8811753988265991,
        "text_preview": "4 Human expert evaluation resultsApproach Actionability Coherence Domain Spec. Tech Spec. Understand. User Focus Overall ReT-Eval 4.2 ¬± 0.7 4.1 ¬± 0.8 4.0 ¬± 0.8 4.0 ¬± 0.7 4.3 ¬± 0.6 4.1 ¬± 0.7 4.1 GNN"
      },
      {
        "chunk_index": 14879,
        "paper_id": 300,
        "chunk_idx": 0,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Constructing Narratives with Autiverse",
        "score": 0.8680893182754517,
        "text_preview": "Based on the survey results and the feedback in debriefing, we illustrate how Autiverse guided adolescents' narrative construction through scaffolding and multimodal support."
      },
      {
        "chunk_index": 62604,
        "paper_id": 1336,
        "chunk_idx": 0,
        "title": "GRAPHUNIVERSE: ENABLING SYSTEMATIC EVALUA-TION OF INDUCTIVE GENERALIZATION",
        "section_head": "VALIDATION OF GRAPHUNIVERSE",
        "score": 0.8620295524597168,
        "text_preview": "To ensure our multiple graph generation framework produces high-fidelity graphs with the intended properties and learnable signals within and across graphs, we conduct a comprehensive validation study"
      },
      {
        "chunk_index": 5294,
        "paper_id": 90,
        "chunk_idx": 0,
        "title": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material",
        "section_head": "Metrics.",
        "score": 0.8428924083709717,
        "text_preview": "Most represented types of evaluation metrics in the TABLE 3 Datasets commonly used for graph generation models Dataset Dimensionality Category No. of Graphs (G) No. of Nodes (N) Community-small 2D Soc"
      },
      {
        "chunk_index": 141379,
        "paper_id": 2913,
        "chunk_idx": 0,
        "title": "Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies",
        "section_head": "E. Parameter Analyses (Q4)",
        "score": 0.8415235280990601,
        "text_preview": "Empirically, we study how the objective trade-off in Eq. ( 9 ), the parameters governing subgraph extraction (Sec. IV-A), and subgraph dependency measurement (Sec. IV-C1) impact the class-level self-e"
      },
      {
        "chunk_index": 154775,
        "paper_id": 3174,
        "chunk_idx": 0,
        "title": "Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models",
        "section_head": "Figure 3 :Figure 4 :",
        "score": 0.8380593657493591,
        "text_preview": "34 Figure3: Inclusivity evaluation prompt"
      },
      {
        "chunk_index": 33638,
        "paper_id": 706,
        "chunk_idx": 0,
        "title": "DFed-SST: Building Semantic-and Structure-aware Topologies for Decentralized Federated Graph Learning",
        "section_head": "Table 1 :",
        "score": 0.8352535963058472,
        "text_preview": "1 The statistical information of the experimental datasets. dataset nodes features edges classes train/val/test description Cora 2,708 1,433 5,429 7 20%/40%/40% citation network CiteSeer 3,327 3,703 4"
      },
      {
        "chunk_index": 62552,
        "paper_id": 1334,
        "chunk_idx": 0,
        "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?",
        "section_head": "Conclusion",
        "score": 0.8347314596176147,
        "text_preview": "We propose GraphMaker, a diffusion model capable of generating large attributed graphs, along with a novel evaluation protocol that assesses generation quality by training models on generated graphs a"
      },
      {
        "chunk_index": 52137,
        "paper_id": 1118,
        "chunk_idx": 0,
        "title": "FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting",
        "section_head": "Table 1 :",
        "score": 0.8326303958892822,
        "text_preview": "1 The statistical information of the experimental datasets. dataset nodes features edges classes train/val/test description Cora 2708 1433 5429 7 20%/40%/40% citation network CiteSeer 3327 3703 4732 6"
      },
      {
        "chunk_index": 10424,
        "paper_id": 201,
        "chunk_idx": 0,
        "title": "AN EFFICIENT GNNS-TO-KANS DISTILLATION VIA SELF-ATTENTION DYNAMIC SAMPLING WITH POTENTIAL FOR CONSUMER ELECTRONICS EDGE DEPLOYMENT A PREPRINT",
        "section_head": "RELATED WORK",
        "score": 0.8308970332145691,
        "text_preview": "This section briefly reviews the background knowledge relevant to our research, focusing on the fundamental concepts of graphs, Graph Knowledge Distillation (GKD), Kolmogorov-Arnold Network (KAN), and"
      },
      {
        "chunk_index": 95436,
        "paper_id": 2019,
        "chunk_idx": 0,
        "title": "NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation",
        "section_head": "Figure 5 .",
        "score": 0.8278823494911194,
        "text_preview": "5 Figure 5. Topic-wise impacts on structural metrics evaluated through systematic topic weight manipulation."
      },
      {
        "chunk_index": 483,
        "paper_id": 11,
        "chunk_idx": 0,
        "title": "A Comprehensive Data-centric Overview of Federated Graph Learning",
        "section_head": "A. Data Format",
        "score": 0.8266025185585022,
        "text_preview": "The data format in FGL determines the structural and semantic representation of graph data, demonstrating diversity in node types, topological structures, and feature or label information. In addition"
      },
      {
        "chunk_index": 43726,
        "paper_id": 930,
        "chunk_idx": 0,
        "title": "Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching",
        "section_head": "Theorem 2",
        "score": 0.8242661356925964,
        "text_preview": "The relationship between the graph quality evaluation metrics Relevance and Semantic Richness are positively correlated with the optimization objective M I(Q, G). P (q, G) = l j=1 n q, t j l ‚àù l j=1 s"
      },
      {
        "chunk_index": 132580,
        "paper_id": 2742,
        "chunk_idx": 0,
        "title": "SVDformer: Direction-Aware Spectral Graph Embedding Learning via SVD and Transformer",
        "section_head": "Table 1 :",
        "score": 0.8222849369049072,
        "text_preview": "1 Evaluation Datasets (All in 100% directed edge ratio) )"
      },
      {
        "chunk_index": 9086,
        "paper_id": 173,
        "chunk_idx": 0,
        "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review",
        "section_head": "Methodology",
        "score": 0.8210318088531494,
        "text_preview": "To compile and structure the literature for this survey, we employed a systematic and multi-stage methodology. The process was designed to ensure a comprehensive, relevant, and high-quality selection "
      },
      {
        "chunk_index": 485,
        "paper_id": 11,
        "chunk_idx": 2,
        "title": "A Comprehensive Data-centric Overview of Federated Graph Learning",
        "section_head": "A. Data Format",
        "score": 0.8157670497894287,
        "text_preview": "This structured approach enhances both machine readability and human interpretability, making it valuable for downstream tasks [27] such as relation extraction [28] and knowledge graph completion [29]"
      },
      {
        "chunk_index": 83525,
        "paper_id": 1756,
        "chunk_idx": 0,
        "title": "M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models",
        "section_head": "Figure 1 :",
        "score": 0.8152323961257935,
        "text_preview": "1 Figure1: Evaluation metrics across three different Relation Extraction frameworks. The mathematical formulation of each metric is detailed in \" ¬ß4.2 Evaluation\"."
      },
      {
        "chunk_index": 62335,
        "paper_id": 1330,
        "chunk_idx": 0,
        "title": "GRAPH-R1: Incentivizing the Zero-Shot Graph Learning Capability in LLMs via Explicit Reasoning",
        "section_head": "Graph-Reasoning Data Curation",
        "score": 0.8146405220031738,
        "text_preview": "To investigate reason-then-predict graph learning, we construct the first dataset featuring explicit, detailed reasoning traces across multiple graph tasks. Dataset and task selection. We sample 11 re"
      }
    ]
  },
  {
    "query_id": 80,
    "query_text": "survey large language",
    "source": "title",
    "source_value": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 88067,
        "paper_id": 1854,
        "chunk_idx": 0,
        "title": "MiniGPT-v2: Large Language Model As a Unified Interface for Vision-Language Multi-task Learning",
        "section_head": "Related Work",
        "score": 0.9691933393478394,
        "text_preview": "We briefly review relevant works on advanced large language models and multi-modal LLMs for visual aligning."
      },
      {
        "chunk_index": 149377,
        "paper_id": 3073,
        "chunk_idx": 0,
        "title": "Verified Language Processing with Hybrid Explainability: A Technical Report",
        "section_head": "ML Machine Learning.",
        "score": 0.9651469588279724,
        "text_preview": "NLP Natural Language Processing."
      },
      {
        "chunk_index": 85393,
        "paper_id": 1798,
        "chunk_idx": 0,
        "title": "Mathematical Language Models: A Survey",
        "section_head": "Fig. 3 .",
        "score": 0.9498457908630371,
        "text_preview": "3 Fig.3. Taxonomy of language models for mathematic."
      },
      {
        "chunk_index": 132552,
        "paper_id": 2741,
        "chunk_idx": 0,
        "title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?",
        "section_head": "ABBREVIATIONS NLI: Natural Language Inference.",
        "score": 0.9464748501777649,
        "text_preview": "NLU: Natural Language Understanding."
      },
      {
        "chunk_index": 89661,
        "paper_id": 1888,
        "chunk_idx": 0,
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "section_head": "Figure 1 :",
        "score": 0.9439243674278259,
        "text_preview": "1 Figure 1: Results of eight representative large vision-language models (VLMs) across the 20 ability dimensions defined in MMBench-test."
      },
      {
        "chunk_index": 80633,
        "paper_id": 1701,
        "chunk_idx": 0,
        "title": "LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models",
        "section_head": "Related Work",
        "score": 0.9368385672569275,
        "text_preview": "In this section, we first review large language models and delve into recent advances in vision language models."
      },
      {
        "chunk_index": 60127,
        "paper_id": 1283,
        "chunk_idx": 0,
        "title": "Generative Multimodal Models are In-Context Learners",
        "section_head": "Figure 1.",
        "score": 0.9267009496688843,
        "text_preview": "Emu2 is a large generative multimodal model that serves as a foundation and a general-purpose interface for a broad range of multimodal tasks across understanding and generation, with remarkable in-co"
      },
      {
        "chunk_index": 68835,
        "paper_id": 1467,
        "chunk_idx": 1,
        "title": "INDICGENBENCH: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages",
        "section_head": "Limitations",
        "score": 0.9181162118911743,
        "text_preview": "Simran Khanuja, Diksha Bansal, Sarvesh Mehtani, Savya Khosla, Atreyee Dey, Balaji Gopalan, Dilip Kumar Margam, Pooja Aggarwal, Rajiv Teja Nagipogu, Shachi Dave, et al. 2021. Muril: Multilingual repres"
      },
      {
        "chunk_index": 152506,
        "paper_id": 3142,
        "chunk_idx": 0,
        "title": "What do Speech Foundation Models Learn? Analysis and Applications by",
        "section_head": "CHAPTER 6",
        "score": 0.9098014831542969,
        "text_preview": "Spoken Language Understanding Benchmark:"
      },
      {
        "chunk_index": 132528,
        "paper_id": 2741,
        "chunk_idx": 0,
        "title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?",
        "section_head": "State of the art Benchmarks",
        "score": 0.9045357704162598,
        "text_preview": "There are two main types of textual benchmarks in NLP: ‚Ä¢ Natural Language Understanding (NLU) Benchmarks. ‚Ä¢ Natural Language Generation (NLG) Benchmarks. Few benchmarks were designed for evaluating bo"
      },
      {
        "chunk_index": 83946,
        "paper_id": 1767,
        "chunk_idx": 3,
        "title": "Make Every Letter Count: Building Dialect Variation Dictionaries from Monolingual Corpora",
        "section_head": "Use of AI Assistants",
        "score": 0.8983675837516785,
        "text_preview": "Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ram√©, Morgane Rivi√®re, and 1 others. 2025. Gemma 3 technical rep"
      },
      {
        "chunk_index": 35986,
        "paper_id": 760,
        "chunk_idx": 0,
        "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
        "section_head": "Figure 1 :",
        "score": 0.8943989276885986,
        "text_preview": "1 Figure 1: Parameter counts of several recently released pretrained language models."
      },
      {
        "chunk_index": 150352,
        "paper_id": 3089,
        "chunk_idx": 0,
        "title": "VILA: On Pre-training for Visual Language Models",
        "section_head": "Quantitative Evaluation",
        "score": 0.8924688696861267,
        "text_preview": "visual language tasks. We perform a comprehensive comparison with state-of-the-art models on 12 visual language benchmarks in Table 5 . Compared to existing models (e.g., Method LLM Res."
      },
      {
        "chunk_index": 46244,
        "paper_id": 990,
        "chunk_idx": 1,
        "title": "Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text",
        "section_head": "Existing Tools for Language Models",
        "score": 0.891284704208374,
        "text_preview": "Gopher is DeepMind's language model and is relatively more efficient than existing large language models in different tasks such as answering questions and logical reasoning. Chinchilla also works the"
      },
      {
        "chunk_index": 151365,
        "paper_id": 3112,
        "chunk_idx": 0,
        "title": "VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model",
        "section_head": "Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th",
        "score": 0.8875629901885986,
        "text_preview": "International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 527-538, Online only. Association for Computational Linguistics. Juan Zuluaga-Gomez, Sara Ahmed, Danielius "
      },
      {
        "chunk_index": 110134,
        "paper_id": 2287,
        "chunk_idx": 0,
        "title": "QLORA: Efficient Finetuning of Quantized LLMs",
        "section_head": "Pushing the Chatbot State-of-the-art with QLoRA",
        "score": 0.882390558719635,
        "text_preview": "Having established that 4-bit QLORA matches 16-bit performance across scales, tasks, and datasets we conduct an in-depth study of instruction finetuning up to the largest open-source language models a"
      },
      {
        "chunk_index": 59201,
        "paper_id": 1259,
        "chunk_idx": 0,
        "title": "Gemma 2: Improving Open Language Models at a Practical Size",
        "section_head": "Post-training Evaluations",
        "score": 0.8821595907211304,
        "text_preview": "In this section, we evaluate our IT models on a set of human evaluations as well as standard academic benchmarks. The Gemma 2 models push the frontier for post-trained open-weights models, setting a n"
      },
      {
        "chunk_index": 9209,
        "paper_id": 177,
        "chunk_idx": 0,
        "title": "AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training",
        "section_head": "Models",
        "score": 0.8819010257720947,
        "text_preview": "We based our detection systems on three different open-source pretrained language models (LMs), each extended with task-specific classifiers to address the two Subtasks. Qwen3 Embedding (Zhang et al.,"
      },
      {
        "chunk_index": 3953,
        "paper_id": 81,
        "chunk_idx": 0,
        "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",
        "section_head": "Table 1.",
        "score": 0.8801412582397461,
        "text_preview": "Summary of existing general (large) language models, their underlying structures, numbers of parameters, and datasets used for model training. Column \"# params\" shows the number of parameters, M: mill"
      },
      {
        "chunk_index": 35312,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Results",
        "score": 0.8777002096176147,
        "text_preview": "We evaluate 18 large language models on both discharge conversation (Table 1 ) and discharge summary generation tasks (Table 2 ), spanning language fluency, human-centeredness, medical coverage, strat"
      }
    ]
  },
  {
    "query_id": 81,
    "query_text": "learning survey multi",
    "source": "title",
    "source_value": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 32366,
        "paper_id": 678,
        "chunk_idx": 0,
        "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models",
        "section_head": "Figure 6 |",
        "score": 0.9073766469955444,
        "text_preview": "6 Figure6| Performance of iterative reinforcement learning with DeepSeekMath-Instruct 7B on two benchmarks."
      },
      {
        "chunk_index": 57546,
        "paper_id": 1233,
        "chunk_idx": 0,
        "title": "FROM TURN-TAKING TO SYNCHRONOUS DIALOGUE: A SURVEY OF FULL-DUPLEX SPOKEN LANGUAGE MODELS",
        "section_head": "Table 2 .",
        "score": 0.9043932557106018,
        "text_preview": "2 Comprehensive evaluation of representative open-source FD-SLMs across four dimensions. Model Temporal Dynamics FTO (‚Üì) SL (‚Üì) Behavioral Arbitration Semantic Coherence Acoustic Performance Human ‚àº0."
      },
      {
        "chunk_index": 101566,
        "paper_id": 2111,
        "chunk_idx": 0,
        "title": "Optimization Methods and Software for Federated Learning Dissertation by Konstantin Burlachenko In Partial Fulfillment of the Requirements For the Degree of Doctor of Philosophy",
        "section_head": "Figure 5 . 3 :",
        "score": 0.8950791358947754,
        "text_preview": "53 Figure 5.3: Comparison of samplings on non-convex machine learning tasks with LIBSVM datasets."
      },
      {
        "chunk_index": 41164,
        "paper_id": 867,
        "chunk_idx": 0,
        "title": "Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper",
        "section_head": "Baselines.",
        "score": 0.8866816759109497,
        "text_preview": "For comparative evaluation, we adopted the same baseline models as those benchmarked in MMAudio [5] , ensuring alignment with their established evaluation protocol. We directly leveraged the baseline "
      },
      {
        "chunk_index": 87613,
        "paper_id": 1846,
        "chunk_idx": 0,
        "title": "MICA: Multi-Agent Industrial Coordination Assistant",
        "section_head": "C. Evaluation Metrics and Setup",
        "score": 0.8865232467651367,
        "text_preview": "We evaluate our framework along two axes: (a) the effect of online Adaptive Step Fusion (ASF, Sec. III-B), and (b) the comparative performance of five multi-agent topologies (Sec. IV-B). a) ASF evalua"
      },
      {
        "chunk_index": 23447,
        "paper_id": 478,
        "chunk_idx": 0,
        "title": "Challenges and Applications of Large Language Models",
        "section_head": "S.2) Retr ieval augmentation",
        "score": 0.8850308656692505,
        "text_preview": "RLHF is a technique used for alignment of LLMs and stands for Reinforcement Learning with Human Preferences."
      },
      {
        "chunk_index": 102645,
        "paper_id": 2128,
        "chunk_idx": 0,
        "title": "OVERCOMING KNOWLEDGE DISCREPANCIES: STRUCTURING REASONING THREADS THROUGH KNOWLEDGE BALANCING IN INTERACTIVE SCENARIOS",
        "section_head": "Table 2 :",
        "score": 0.8845176100730896,
        "text_preview": "2 Quantitative evaluation results -Part 1 Approach Actionability Coherence Domain Spec. ReT-Eval 0.748 ¬± 0.298 0.485 ¬± 0.226 0.548 ¬± 0.253 GNN 0.756 ¬± 0.068 0.489 ¬± 0.085 0.585 ¬± 0.178 RM 0.694 ¬± 0.11"
      },
      {
        "chunk_index": 68216,
        "paper_id": 1451,
        "chunk_idx": 0,
        "title": "Improving Large Vision-Language Models' Understanding for Field Data",
        "section_head": "Fig. 1 .",
        "score": 0.8826589584350586,
        "text_preview": "1 Fig. 1. (a) Quantitative comparison of vision-language responses in field data across different methods. (b) The performance of key evaluation metrics, including flow categorization, Reynolds number"
      },
      {
        "chunk_index": 63155,
        "paper_id": 1347,
        "chunk_idx": 0,
        "title": "Hallucination of Multimodal Large Language Models: A Survey",
        "section_head": "Reinforcement Learning.",
        "score": 0.8818488717079163,
        "text_preview": "Reinforcement learning (RL) is introduced to train MLLMs for mitigating hallucinations by conducting the following perspectives: 1) Automatic Metric-based Optimization, 2) Reinforcement Learning from "
      },
      {
        "chunk_index": 16662,
        "paper_id": 335,
        "chunk_idx": 0,
        "title": "Behavior Sequence Transformer for E-commerce Recommendation in Alibaba",
        "section_head": "Table 4 :",
        "score": 0.871993362903595,
        "text_preview": "4 Offline AUCs and online CTR gains of different methods. Online CTR gain is relative to the control group. Methods Offline AUC Online CTR Gain Average RT(ms) WDL 0.7734 - 13 WDL(+Seq) 0.7846 +3.03% 1"
      },
      {
        "chunk_index": 35955,
        "paper_id": 759,
        "chunk_idx": 0,
        "title": "DISTIL-WHISPER: ROBUST KNOWLEDGE DISTILLATION VIA LARGE-SCALE PSEUDO LABELLING",
        "section_head": "Table 7 :",
        "score": 0.8695387244224548,
        "text_preview": "7 Comparison of long-form transcription algorithms. Average WER results over the four OOD long-form test sets for the sequential and chunked long-form algorithms. Relative latency is the inference tim"
      },
      {
        "chunk_index": 112765,
        "paper_id": 2349,
        "chunk_idx": 0,
        "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment",
        "section_head": "D. Quantitative Analysis",
        "score": 0.8694292306900024,
        "text_preview": "We conducted a comprehensive quantitative evaluation of RefactorCoder-MoE on the RefactorCoderQA benchmark, covering four core domains: Software Engineering (SE), Data Science (DS), Machine Learning ("
      },
      {
        "chunk_index": 35318,
        "paper_id": 748,
        "chunk_idx": 2,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Discharge Summary Generation.",
        "score": 0.869185209274292,
        "text_preview": "The table reports results across three metric categories: (1) Traditional Generation Evaluation Metrics including ROUGE-L, BLEURT, UMLS-F, and Exam Accuracy; (2) LLM-Judge Evaluation Criteria for Lang"
      },
      {
        "chunk_index": 11250,
        "paper_id": 219,
        "chunk_idx": 0,
        "title": "Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting",
        "section_head": "RESULTS",
        "score": 0.8665574789047241,
        "text_preview": "Results of scoring for each method are shown in both a heatmap, with values divided by question, and a histogram, alongside with statistical measures. For additive evaluation, complementary tables hav"
      },
      {
        "chunk_index": 139129,
        "paper_id": 2867,
        "chunk_idx": 0,
        "title": "THE UNLOCKING SPELL ON BASE LLMS: RETHINKING ALIGNMENT VIA IN-CONTEXT LEARNING",
        "section_head": "Figure 1 :",
        "score": 0.8637339472770691,
        "text_preview": "1 Comparisons of alignment performance on different aspects."
      },
      {
        "chunk_index": 120823,
        "paper_id": 2515,
        "chunk_idx": 0,
        "title": "Seeing is Not Understanding: A Benchmark on Perception-Cognition Disparities in Large Language Models",
        "section_head": "Results and Analysis",
        "score": 0.8623957633972168,
        "text_preview": "We conducted a comprehensive evaluation of the 9 models on EmoBench-Reddit. The results are shown in Table 1 ."
      },
      {
        "chunk_index": 53383,
        "paper_id": 1146,
        "chunk_idx": 0,
        "title": "Finance-Grounded Optimization For Algorithmic Trading",
        "section_head": "Methodology",
        "score": 0.8605109453201294,
        "text_preview": "We examined different financial data modalities in perspective of algorithmic trading strategies (alphas) [10] . For candlestick data we build alphas using heuristics, machine learning and deep learni"
      },
      {
        "chunk_index": 154778,
        "paper_id": 3174,
        "chunk_idx": 0,
        "title": "Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models",
        "section_head": "Table 4 :",
        "score": 0.8594136238098145,
        "text_preview": "4 Disability-Level Coverage Score (DLCS) across models for each disability category. Higher values indicate broader coverage of that disability category in model responses."
      },
      {
        "chunk_index": 132783,
        "paper_id": 2746,
        "chunk_idx": 0,
        "title": "SWIFTSAGE: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks",
        "section_head": "Table 4",
        "score": 0.8591601252555847,
        "text_preview": "4 presents a comprehensive analysis of the cost-effectiveness of LLM-based methods. We examine two specific metrics: tokens per action (tpa) and scores per action (spa) for SayCan, ReAct, Reflexion, a"
      },
      {
        "chunk_index": 20347,
        "paper_id": 412,
        "chunk_idx": 0,
        "title": "BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment",
        "section_head": "Table 1 :",
        "score": 0.8558323383331299,
        "text_preview": "1 We include BPO's results against offline and online DAP methods across TL;DR, Helpfulness, and Harmfulness tasks. We experiment with three different DAP algorithms: DPO, IPO and SLiC. The win rate i"
      }
    ]
  },
  {
    "query_id": 82,
    "query_text": "survey reasoning agentic",
    "source": "title",
    "source_value": "A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 41012,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Table 8 :",
        "score": 0.9331015944480896,
        "text_preview": "8 Mathematical reasoning evaluation results."
      },
      {
        "chunk_index": 45634,
        "paper_id": 973,
        "chunk_idx": 0,
        "title": "EXPANDING REASONING POTENTIAL IN FOUNDATION MODEL BY LEARNING DIVERSE CHAINS OF THOUGHT PATTERNS",
        "section_head": "Table 5 :",
        "score": 0.922008752822876,
        "text_preview": "5 Comparison with open-source CoT QA datasets. Dataset Target Domain CoT Date JiuZhang3.0 Mathematical Reasoning Short-CoT 2024 May. OpenMathInstruct-2 Mathematical Reasoning Short-CoT 2024 Oct. MegaM"
      },
      {
        "chunk_index": 44757,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Figure 2 :",
        "score": 0.8948507308959961,
        "text_preview": "2 Figure2: An overview of studies on knowledge and capability evaluation for LLMs."
      },
      {
        "chunk_index": 3408,
        "paper_id": 65,
        "chunk_idx": 0,
        "title": "A SCENARIO-DRIVEN COGNITIVE APPROACH TO NEXT-GENERATION AI MEMORY",
        "section_head": "Figure 5 :",
        "score": 0.8945404291152954,
        "text_preview": "5 Figure 5: Reasoning Process of Mathematical Problem-Solving"
      },
      {
        "chunk_index": 69549,
        "paper_id": 1481,
        "chunk_idx": 0,
        "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning",
        "section_head": "LLaVA-Instruct-150K",
        "score": 0.8937390446662903,
        "text_preview": "Visual Conversation Complex Reasoning"
      },
      {
        "chunk_index": 8458,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "Reasoning Tasks",
        "score": 0.8920005559921265,
        "text_preview": "A concise overview of distinct categories of related reasoning approaches and tasks is provided here for background concepts. This comprehensive overview provides insights into the diverse landscape o"
      },
      {
        "chunk_index": 12523,
        "paper_id": 247,
        "chunk_idx": 0,
        "title": "AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data",
        "section_head": "Table 5 :",
        "score": 0.8850342035293579,
        "text_preview": "5 Number of Questions per Reasoning Type Reasoning Type Number of Questions Mathematical Reasoning 79 Comparative Reasoning 67 Logical Reasoning 42 Temporal Reasoning 17"
      },
      {
        "chunk_index": 85391,
        "paper_id": 1798,
        "chunk_idx": 0,
        "title": "Mathematical Language Models: A Survey",
        "section_head": "Fig. 1 .",
        "score": 0.8818429708480835,
        "text_preview": "1 Fig. 1. Taxonomy of mathematical tasks."
      },
      {
        "chunk_index": 8516,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "Figure 2 .",
        "score": 0.8766249418258667,
        "text_preview": "2 Figure 2. Plan-based MCoT Reasoning Process"
      },
      {
        "chunk_index": 44760,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Figure 5 :",
        "score": 0.871938943862915,
        "text_preview": "5 Figure 5: Overview of specialized LLMs evaluation."
      },
      {
        "chunk_index": 44597,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Reasoning",
        "score": 0.8706965446472168,
        "text_preview": "Complex reasoning encompasses the capacity to comprehend and effectively employ supporting evidence and logical frameworks to deduce conclusions or facilitate decision-making. In our effort to delinea"
      },
      {
        "chunk_index": 38399,
        "paper_id": 811,
        "chunk_idx": 0,
        "title": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth",
        "section_head": "Task Design",
        "score": 0.8695446252822876,
        "text_preview": "To evaluate an LLM's ability to understand Drivelology, we designed four tasks to assess different facets of social and non-linear reasoning. An overview of these tasks is provided in Figure 2 ."
      },
      {
        "chunk_index": 4909,
        "paper_id": 85,
        "chunk_idx": 26,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8658547401428223,
        "text_preview": "Research problems Undergraduate Text QA 2025.05 EN Comprehensive multi-source integration Semi-automated 178 Data generation and review o1, DeepSeek-R1 500 Open-ended EED PhyX [741] [link] Mechanics, "
      },
      {
        "chunk_index": 41008,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Figure 5 :",
        "score": 0.8637211322784424,
        "text_preview": "5 Figure5: Guideline for human evaluation on GSM8K mathematical reasoning."
      },
      {
        "chunk_index": 60441,
        "paper_id": 1289,
        "chunk_idx": 0,
        "title": "GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning",
        "section_head": "Table 10 :",
        "score": 0.8597207069396973,
        "text_preview": "10 Performance (%) on MathVista other tasks. \"Perception + Reasoning\" refers to our two-stage approach. MathVista Task Category Reasoning-only Perception + Reasoning Figure Question Answering 68.0 69."
      },
      {
        "chunk_index": 8517,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "Figure 3 .",
        "score": 0.8561314344406128,
        "text_preview": "3 Figure 3. Agentic Temporal Reasoning Framework"
      },
      {
        "chunk_index": 40969,
        "paper_id": 864,
        "chunk_idx": 0,
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "section_head": "Experimental Settings",
        "score": 0.8525919318199158,
        "text_preview": "We conduct our experiments on two representative domains: mathematical reasoning and Wikipedia (Wiki) QA, which involves commonsense and logical reasoning on factual descriptive knowledge."
      },
      {
        "chunk_index": 91736,
        "paper_id": 1933,
        "chunk_idx": 0,
        "title": "MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols",
        "section_head": "Semantic Information",
        "score": 0.8516488075256348,
        "text_preview": "This dimension assesses the model's ability to comprehend, reason about, and strategically manage the explicit semantic content of spoken dialogue. The evaluation is structured into the following capa"
      },
      {
        "chunk_index": 4685,
        "paper_id": 85,
        "chunk_idx": 2,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.8497242331504822,
        "text_preview": "This dimension challenges models on both the breadth and depth of scientific understanding, emphasizing accuracy, completeness, and the ability to engage with knowledge beyond surface-level facts. 2) "
      },
      {
        "chunk_index": 8483,
        "paper_id": 164,
        "chunk_idx": 0,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "‚Ä¢",
        "score": 0.8480368256568909,
        "text_preview": "Reasoning Data Curation ‚Ä¢ Model Training ‚Ä¢ Reasoning Generation for Multi-Agent Reasoning"
      }
    ]
  },
  {
    "query_id": 83,
    "query_text": "survey reasoning foundation",
    "source": "title",
    "source_value": "A Survey of Reasoning with Foundation Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 44763,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Table 5 :",
        "score": 0.9546618461608887,
        "text_preview": "5 Benchmarks for Knowledge and Reasoning Benchmarks #Tasks Language #Instances Evaluation Form MMLU"
      },
      {
        "chunk_index": 4909,
        "paper_id": 85,
        "chunk_idx": 26,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.909972071647644,
        "text_preview": "Research problems Undergraduate Text QA 2025.05 EN Comprehensive multi-source integration Semi-automated 178 Data generation and review o1, DeepSeek-R1 500 Open-ended EED PhyX [741] [link] Mechanics, "
      },
      {
        "chunk_index": 16522,
        "paper_id": 331,
        "chunk_idx": 0,
        "title": "BaseReward: A Strong Baseline for Multimodal Reward Model",
        "section_head": "Table 5 :",
        "score": 0.9045017957687378,
        "text_preview": "5 Fine-grained capability analysis.A detailed analysis of model performance across specific capability dimensions on the VL-Reward and Multi-Modal Reward benchmarks. Multi-Modal Reward Bench VL Reward"
      },
      {
        "chunk_index": 102184,
        "paper_id": 2122,
        "chunk_idx": 0,
        "title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "section_head": "Experiment Setup",
        "score": 0.9039633870124817,
        "text_preview": "We setup a rigorous evaluation protocol that considers a host of different abilities including writing, comprehension, analytical, mathematical and logical reasoning."
      },
      {
        "chunk_index": 4907,
        "paper_id": 85,
        "chunk_idx": 24,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8957700729370117,
        "text_preview": "Text High school VQA with CoT 2024.04 EN Comprehensive multi-source integration Semi-automated 8+ Data generation and review ChatGPT 675 MCQ Acc, ROUGE MVBench [750] [link] General Physics Video N/A V"
      },
      {
        "chunk_index": 4908,
        "paper_id": 85,
        "chunk_idx": 25,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8919814825057983,
        "text_preview": "Text N/A Text QA 2025.02 N/A Other sources Manual N/A Data generation and review N/A 57 Open-ended Acc, AI-based Holistic Grading PHYSICS [742] [link] Mechanics, Electromagnetism, Thermodynamics, Opti"
      },
      {
        "chunk_index": 4684,
        "paper_id": 85,
        "chunk_idx": 1,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.8860998749732971,
        "text_preview": "1) Expert-Level Scientific Knowledge Comprehension and Retrieval: Unlike general-purpose language models, scientific AI models must retrieve, comprehend, and apply cutting-edge research knowledge acro"
      },
      {
        "chunk_index": 65202,
        "paper_id": 1388,
        "chunk_idx": 0,
        "title": "How Good are Foundation Models in Step-by-Step Embodied Reasoning?",
        "section_head": "Figure 5 .",
        "score": 0.8858767747879028,
        "text_preview": "5 Figure5. A breakdown of the model performance on the proposed evaluation criteria, where we evaluate the reasoning traces of the models in physical AI-specific criteria like spatial reasoning, physi"
      },
      {
        "chunk_index": 4683,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.8844818472862244,
        "text_preview": "General-purpose LLM benchmarks primarily assess core natural language processing and general reasoning abilities. Key evaluation dimensions typically include language understanding, fluency, factual k"
      },
      {
        "chunk_index": 110089,
        "paper_id": 2286,
        "chunk_idx": 0,
        "title": "Qianfan-VL: Domain-Enhanced Universal Vision-Language Models",
        "section_head": "Evaluation Results",
        "score": 0.882796049118042,
        "text_preview": "We conduct comprehensive evaluations across general multimodal benchmarks and domain-specific tasks using the VLMEvalKit framework (Duan et al., 2024) , an open-source toolkit designed for evaluating "
      },
      {
        "chunk_index": 113235,
        "paper_id": 2360,
        "chunk_idx": 0,
        "title": "Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models",
        "section_head": "Table 7 :",
        "score": 0.882190465927124,
        "text_preview": "7 Distribution of prompts in our multimodal human evaluation dataset. Category Ratio Basic image description 23.0% Advanced image description 20.5% Coding capability with vision 7.7% Multilingual mult"
      },
      {
        "chunk_index": 4332,
        "paper_id": 84,
        "chunk_idx": 3,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "John McCarthy (2004)",
        "score": 0.8787025213241577,
        "text_preview": "In contrast to the soft Reasoning Natural Language Reasoning Dialogue Systems Question Answering Recommendation Systems Text Summarization Sentiment Analysis Co-reference Resolution AIGC Language Gene"
      },
      {
        "chunk_index": 100128,
        "paper_id": 2098,
        "chunk_idx": 0,
        "title": "Online Speculative Decoding",
        "section_head": "Figure 5 .",
        "score": 0.8743691444396973,
        "text_preview": "5 Figure5. Chatbot Arena Conversations clustered by language and topic."
      },
      {
        "chunk_index": 4910,
        "paper_id": 85,
        "chunk_idx": 27,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8715547323226929,
        "text_preview": "Text (problem statements, equations), Diagrams (physics illustrations) Undergraduate VQA 2025.06 EN, ZH Comprehensive multi-source integration Manual N/A Data generation and review N/A 3,304 Open-ende"
      },
      {
        "chunk_index": 44757,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Figure 2 :",
        "score": 0.8698954582214355,
        "text_preview": "2 Figure2: An overview of studies on knowledge and capability evaluation for LLMs."
      },
      {
        "chunk_index": 144170,
        "paper_id": 2975,
        "chunk_idx": 0,
        "title": "TRUSTLLM: TRUSTWORTHINESS IN LARGE LANGUAGE MODELS -A PRINCIPLE AND BENCHMARK",
        "section_head": "Evaluation on LLMs",
        "score": 0.8646250367164612,
        "text_preview": "Evaluation of LLMs is a fast-evolving field involving multi-dimensional evaluation across various tasks, datasets, and benchmarks [98] . It encompasses a wide range of domains, starting with tradition"
      },
      {
        "chunk_index": 65172,
        "paper_id": 1388,
        "chunk_idx": 2,
        "title": "How Good are Foundation Models in Step-by-Step Embodied Reasoning?",
        "section_head": "Related Work",
        "score": 0.863713264465332,
        "text_preview": "CLEVR (Compositional Language and Elementary Visual Reasoning) [19] is a synthetic benchmark explicitly designed as a diagnostic dataset that tests a range of visual reasoning abilities. These early b"
      },
      {
        "chunk_index": 38399,
        "paper_id": 811,
        "chunk_idx": 0,
        "title": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth",
        "section_head": "Task Design",
        "score": 0.8630539178848267,
        "text_preview": "To evaluate an LLM's ability to understand Drivelology, we designed four tasks to assess different facets of social and non-linear reasoning. An overview of these tasks is provided in Figure 2 ."
      },
      {
        "chunk_index": 75555,
        "paper_id": 1597,
        "chunk_idx": 0,
        "title": "Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation",
        "section_head": "IV. Large Language Models for Synthesis Planning and Optimization",
        "score": 0.8598004579544067,
        "text_preview": "This section systematically reviews the integration of Large Language Models (LLMs) into synthetic chemistry workflows, focusing on their roles in retrosynthetic analysis, reaction optimization, and a"
      },
      {
        "chunk_index": 97208,
        "paper_id": 2051,
        "chunk_idx": 1,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "Comparisons with Other Agent Frameworks",
        "score": 0.8591970205307007,
        "text_preview": "Datasets Modality Domain 0-shot CoT OctoToolsbase OctoTools ‚àÜ (0-shot) ‚àÜ (CoT) AlgoPuzzleVQA Vision General ‚úì ‚úì 41.3 ¬±0.3 42.7 ¬±1.0 44.0 ¬±0.9 48.7 ¬±0.3 +7.4 +6.0 Hallusion-VD Vision General ‚úì 52.0 ¬±1."
      }
    ]
  },
  {
    "query_id": 84,
    "query_text": "survey scientific large",
    "source": "title",
    "source_value": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 4909,
        "paper_id": 85,
        "chunk_idx": 26,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.9125893115997314,
        "text_preview": "Research problems Undergraduate Text QA 2025.05 EN Comprehensive multi-source integration Semi-automated 178 Data generation and review o1, DeepSeek-R1 500 Open-ended EED PhyX [741] [link] Mechanics, "
      },
      {
        "chunk_index": 4907,
        "paper_id": 85,
        "chunk_idx": 24,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.9031249284744263,
        "text_preview": "Text High school VQA with CoT 2024.04 EN Comprehensive multi-source integration Semi-automated 8+ Data generation and review ChatGPT 675 MCQ Acc, ROUGE MVBench [750] [link] General Physics Video N/A V"
      },
      {
        "chunk_index": 4908,
        "paper_id": 85,
        "chunk_idx": 25,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.9009795188903809,
        "text_preview": "Text N/A Text QA 2025.02 N/A Other sources Manual N/A Data generation and review N/A 57 Open-ended Acc, AI-based Holistic Grading PHYSICS [742] [link] Mechanics, Electromagnetism, Thermodynamics, Opti"
      },
      {
        "chunk_index": 4684,
        "paper_id": 85,
        "chunk_idx": 1,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.8956619501113892,
        "text_preview": "1) Expert-Level Scientific Knowledge Comprehension and Retrieval: Unlike general-purpose language models, scientific AI models must retrieve, comprehend, and apply cutting-edge research knowledge acro"
      },
      {
        "chunk_index": 44763,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Table 5 :",
        "score": 0.892688512802124,
        "text_preview": "5 Benchmarks for Knowledge and Reasoning Benchmarks #Tasks Language #Instances Evaluation Form MMLU"
      },
      {
        "chunk_index": 4911,
        "paper_id": 85,
        "chunk_idx": 28,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8766037225723267,
        "text_preview": "Text (problem statements, equations), Diagrams (physics illustrations) Secondary school, Undergraduate, Graduate VQA 2025.07 EN,ZH Comprehensive multi-source integration Semi-automated N/A Data genera"
      },
      {
        "chunk_index": 4683,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "E. Dimensions for Evaluating Scientific AI",
        "score": 0.8755674958229065,
        "text_preview": "General-purpose LLM benchmarks primarily assess core natural language processing and general reasoning abilities. Key evaluation dimensions typically include language understanding, fluency, factual k"
      },
      {
        "chunk_index": 4916,
        "paper_id": 85,
        "chunk_idx": 33,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8746805787086487,
        "text_preview": "Text QA 2025.01 EN Academic and research resources Manual nearly 1000 Data generation and review GPT-4o 2,500 Expert MCQ, Openended Acc, Calibration Error SFE [443] [link] Astronomy, Chemistry, Life S"
      },
      {
        "chunk_index": 4910,
        "paper_id": 85,
        "chunk_idx": 27,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8719395399093628,
        "text_preview": "Text (problem statements, equations), Diagrams (physics illustrations) Undergraduate VQA 2025.06 EN, ZH Comprehensive multi-source integration Manual N/A Data generation and review N/A 3,304 Open-ende"
      },
      {
        "chunk_index": 97208,
        "paper_id": 2051,
        "chunk_idx": 1,
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "section_head": "Comparisons with Other Agent Frameworks",
        "score": 0.861158013343811,
        "text_preview": "Datasets Modality Domain 0-shot CoT OctoToolsbase OctoTools ‚àÜ (0-shot) ‚àÜ (CoT) AlgoPuzzleVQA Vision General ‚úì ‚úì 41.3 ¬±0.3 42.7 ¬±1.0 44.0 ¬±0.9 48.7 ¬±0.3 +7.4 +6.0 Hallusion-VD Vision General ‚úì 52.0 ¬±1."
      },
      {
        "chunk_index": 100128,
        "paper_id": 2098,
        "chunk_idx": 0,
        "title": "Online Speculative Decoding",
        "section_head": "Figure 5 .",
        "score": 0.8576169610023499,
        "text_preview": "5 Figure5. Chatbot Arena Conversations clustered by language and topic."
      },
      {
        "chunk_index": 102184,
        "paper_id": 2122,
        "chunk_idx": 0,
        "title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "section_head": "Experiment Setup",
        "score": 0.8570581674575806,
        "text_preview": "We setup a rigorous evaluation protocol that considers a host of different abilities including writing, comprehension, analytical, mathematical and logical reasoning."
      },
      {
        "chunk_index": 110089,
        "paper_id": 2286,
        "chunk_idx": 0,
        "title": "Qianfan-VL: Domain-Enhanced Universal Vision-Language Models",
        "section_head": "Evaluation Results",
        "score": 0.8564945459365845,
        "text_preview": "We conduct comprehensive evaluations across general multimodal benchmarks and domain-specific tasks using the VLMEvalKit framework (Duan et al., 2024) , an open-source toolkit designed for evaluating "
      },
      {
        "chunk_index": 146703,
        "paper_id": 3022,
        "chunk_idx": 0,
        "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
        "section_head": "Fig. 8 .",
        "score": 0.8548732995986938,
        "text_preview": "8 Fig.8. Fine-grained categorization of research on unifying large language models (LLMs) with knowledge graphs (KGs)."
      },
      {
        "chunk_index": 113235,
        "paper_id": 2360,
        "chunk_idx": 0,
        "title": "Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models",
        "section_head": "Table 7 :",
        "score": 0.8516327142715454,
        "text_preview": "7 Distribution of prompts in our multimodal human evaluation dataset. Category Ratio Basic image description 23.0% Advanced image description 20.5% Coding capability with vision 7.7% Multilingual mult"
      },
      {
        "chunk_index": 4885,
        "paper_id": 85,
        "chunk_idx": 2,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Classification, regression, generation, etc.",
        "score": 0.8501461148262024,
        "text_preview": "SFT VQA 2025.04 EN Comprehensive multi-source integration Semi-automated N/A Data review GPT-4o 17,004 MedReason [732] [link] Healthcare and Medical Sciences Clinical dialogue SFT, CoT Text QA with Co"
      },
      {
        "chunk_index": 80633,
        "paper_id": 1701,
        "chunk_idx": 0,
        "title": "LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models",
        "section_head": "Related Work",
        "score": 0.8500256538391113,
        "text_preview": "In this section, we first review large language models and delve into recent advances in vision language models."
      },
      {
        "chunk_index": 16522,
        "paper_id": 331,
        "chunk_idx": 0,
        "title": "BaseReward: A Strong Baseline for Multimodal Reward Model",
        "section_head": "Table 5 :",
        "score": 0.8496911525726318,
        "text_preview": "5 Fine-grained capability analysis.A detailed analysis of model performance across specific capability dimensions on the VL-Reward and Multi-Modal Reward benchmarks. Multi-Modal Reward Bench VL Reward"
      },
      {
        "chunk_index": 4867,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "X. CONCLUSION",
        "score": 0.8448423147201538,
        "text_preview": "This survey systematically reviews the emerging field of scientific large language models from the perspectives of data, model architectures, and agent-based systems. By introducing a unified taxonomy"
      },
      {
        "chunk_index": 144170,
        "paper_id": 2975,
        "chunk_idx": 0,
        "title": "TRUSTLLM: TRUSTWORTHINESS IN LARGE LANGUAGE MODELS -A PRINCIPLE AND BENCHMARK",
        "section_head": "Evaluation on LLMs",
        "score": 0.84383225440979,
        "text_preview": "Evaluation of LLMs is a fast-evolving field involving multi-dimensional evaluation across various tasks, datasets, and benchmarks [98] . It encompasses a wide range of domains, starting with tradition"
      }
    ]
  },
  {
    "query_id": 85,
    "query_text": "survey cloud-edge-terminal collaborative",
    "source": "title",
    "source_value": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 64419,
        "paper_id": 1377,
        "chunk_idx": 0,
        "title": "HLF-FSL: A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric",
        "section_head": "Fig. 3 :",
        "score": 0.9217610955238342,
        "text_preview": "3 Fig.3: Model lifecycle workflow encompassing server registration, model publication, and client binding"
      },
      {
        "chunk_index": 589,
        "paper_id": 12,
        "chunk_idx": 1,
        "title": "A Comprehensive Review of Datasets for Clinical Mental Health AI Systems",
        "section_head": "Future Directions",
        "score": 0.8700255155563354,
        "text_preview": "We highlight three complementary strategies for responsibly leveraging collected mental health data: (i) Federated learning with local differential privacy (LDP-FL), where data collected across geogra"
      },
      {
        "chunk_index": 5029,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "C. Privacy-Preserving Techniques",
        "score": 0.8485606908798218,
        "text_preview": "Protecting user data within distributed collaborative systems requires comprehensive privacy-preserving techniques including federated learning, differential privacy, homomorphic encryption, and secur"
      },
      {
        "chunk_index": 5082,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "B. Privacy-Preserving Techniques",
        "score": 0.8430269956588745,
        "text_preview": "Protecting user data within distributed collaborative systems is paramount. Four prominent techniques address privacy concerns: federated learning, differential privacy, homomorphic encryption, and se"
      },
      {
        "chunk_index": 8980,
        "paper_id": 172,
        "chunk_idx": 0,
        "title": "AI-IN-THE-LOOP: PRIVACY PRESERVING REAL-TIME SCAM DETECTION AND CONVERSATIONAL SCAMBAITING BY LEVERAGING LLMS AND FEDERATED LEARNING",
        "section_head": "Figure 3 :",
        "score": 0.8407375812530518,
        "text_preview": "3 Figure 3: Federated Learning architecture for decentralized, privacy-preserving scam model training."
      },
      {
        "chunk_index": 19964,
        "paper_id": 404,
        "chunk_idx": 0,
        "title": "Blockchain-Enabled Federated Learning",
        "section_head": "Figure 4 .",
        "score": 0.8386789560317993,
        "text_preview": "4 Figure 4. Fully decentralized BCFL architecture showing peer-to-peer coordination through blockchain consensus, with participants conducting distributed model aggregation without central authorities"
      },
      {
        "chunk_index": 81066,
        "paper_id": 1710,
        "chunk_idx": 1,
        "title": "LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data",
        "section_head": "Background and Related Work",
        "score": 0.836995005607605,
        "text_preview": "An essential part of any privacy-preserving solution in the context of NLP is its privacy evaluation. Lacking standard definitions of text privacy has led to a divergence of evaluation approaches in P"
      },
      {
        "chunk_index": 124798,
        "paper_id": 2603,
        "chunk_idx": 0,
        "title": "SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus",
        "section_head": "A. Blockchain and Federated Learning Integration",
        "score": 0.8357654213905334,
        "text_preview": "In order to address these security needs, we recommend a trust-based access control scheme founded upon a permissioned Hyperledger Fabric blockchain supplemented by Federated Learning (FL) for trust a"
      },
      {
        "chunk_index": 53299,
        "paper_id": 1143,
        "chunk_idx": 0,
        "title": "FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning",
        "section_head": "A. Contributions",
        "score": 0.8350523114204407,
        "text_preview": "This paper presents multiple contributions to poisoning detection in federated learning via blockchain: ‚Ä¢ We propose a novel framework, named FIDELIS, to detect poisoning in federated learning. FIDELI"
      },
      {
        "chunk_index": 108201,
        "paper_id": 2244,
        "chunk_idx": 0,
        "title": "Privacy-Preserving Personalization in Education: A Federated Recommender System for Student Performance Prediction",
        "section_head": "Evaluation Metrics",
        "score": 0.8344435691833496,
        "text_preview": "A suite of standard classification metrics was employed to provide a comprehensive and robust assessment of model performance. Each metric evaluated a specific aspect of the recommender system's pract"
      },
      {
        "chunk_index": 49685,
        "paper_id": 1064,
        "chunk_idx": 0,
        "title": "FEDERATED ITEM RESPONSE THEORY MODELS",
        "section_head": "Federated learning framework",
        "score": 0.833308219909668,
        "text_preview": "Federated learning is a methodological framework that enables collaborative model training across multiple clients or institutions by keeping raw data locally and sharing only model updates. In what f"
      },
      {
        "chunk_index": 100632,
        "paper_id": 2106,
        "chunk_idx": 0,
        "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting",
        "section_head": "Fig. 1 :",
        "score": 0.8331950902938843,
        "text_preview": "1 Fig. 1: Federated learning architecture for medical applications: hospitals securely exchange gradient updates while the OptiGradTrust server performs trust-aware aggregation."
      },
      {
        "chunk_index": 157143,
        "paper_id": 3220,
        "chunk_idx": 0,
        "title": "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before Its Created?",
        "section_head": "E. Federated Learning for Privacy-Preserving Deepfake Prevention",
        "score": 0.8271557688713074,
        "text_preview": "As deepfake techniques continued to evolve, traditional centralized AI-based defenses faced data privacy, scalability, and adaptability challenges. Federated learning (FL) [411] offers a decentralized"
      },
      {
        "chunk_index": 49999,
        "paper_id": 1071,
        "chunk_idx": 0,
        "title": "Federated Learning for ICD Classification with Lightweight Models and Pretrained Embeddings",
        "section_head": "Figure 4 .",
        "score": 0.8256070613861084,
        "text_preview": "4 Figure 4. Schematic representation of the federated learning framework used in this study, involving 20 simulated clients (nodes), each operating on isolated data partitions and participating in mod"
      },
      {
        "chunk_index": 2975,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "Fig. 1 :",
        "score": 0.8251115083694458,
        "text_preview": "1 Fig. 1: Overview of FL, each participating organization trains a local model on private data, while a central federated server aggregates these local updates to construct a collaborative global mode"
      },
      {
        "chunk_index": 2977,
        "paper_id": 56,
        "chunk_idx": 0,
        "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
        "section_head": "Fig. 3 :",
        "score": 0.8240976333618164,
        "text_preview": "3 Fig. 3: Training workflow of our framework demonstrating local quantum-enhanced computations, federated aggregation, and secure update exchanges."
      },
      {
        "chunk_index": 64365,
        "paper_id": 1377,
        "chunk_idx": 0,
        "title": "HLF-FSL: A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric",
        "section_head": "II. BACKGROUND",
        "score": 0.8232219219207764,
        "text_preview": "Collaborative machine learning aims to use data from multiple sources without centralizing raw data, addressing privacy concerns inherent to traditional approaches. This section reviews Federated Spli"
      },
      {
        "chunk_index": 8934,
        "paper_id": 172,
        "chunk_idx": 1,
        "title": "AI-IN-THE-LOOP: PRIVACY PRESERVING REAL-TIME SCAM DETECTION AND CONVERSATIONAL SCAMBAITING BY LEVERAGING LLMS AND FEDERATED LEARNING",
        "section_head": "Federated Learning Evaluation for Generation Tasks",
        "score": 0.8227812647819519,
        "text_preview": "Additionally, in each global iteration round, new 2% conversations from each of the four datasets (MASC, SASC, SSC, and SSD) along with two ASB scam-baiting conversations were assigned to each client."
      },
      {
        "chunk_index": 61861,
        "paper_id": 1321,
        "chunk_idx": 0,
        "title": "GRAMFEDDHAR: GRAPH BASED MULTIMODAL DIFFERENTIALLY PRIVATE FEDERATED HAR",
        "section_head": "Proposed Scheme",
        "score": 0.8226684927940369,
        "text_preview": "In this work, GraMFedHAR, a multimodal graph-based federated learning (FL) framework with client-level differential privacy (DP) is proposed. The framework integrates modality-specific graph construct"
      },
      {
        "chunk_index": 2934,
        "paper_id": 55,
        "chunk_idx": 0,
        "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption",
        "section_head": "Fig. 2 .",
        "score": 0.8225445747375488,
        "text_preview": "2 Fig. 2. FL Framework with HHE for Secure Model Aggregation"
      }
    ]
  },
  {
    "query_id": 86,
    "query_text": "survey data security",
    "source": "title",
    "source_value": "A Survey on Data Security in Large Language Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 5416,
        "paper_id": 93,
        "chunk_idx": 0,
        "title": "A Taxonomy of Data Risks in AI and Quantum Computing (QAI): A Systematic Review",
        "section_head": "Figure 2 :",
        "score": 0.987210750579834,
        "text_preview": "2 Figure 2: Taxonomy of Data Privacy Risks."
      },
      {
        "chunk_index": 5159,
        "paper_id": 88,
        "chunk_idx": 0,
        "title": "A Survey on Data Security in Large Language Models",
        "section_head": "Table 1",
        "score": 0.9032721519470215,
        "text_preview": "1 Various studied risks on data security. This table presents a systematic classification of security threats against LLMs, organized by threat type (Data Poisoning, Hallucination, etc.), with corresp"
      },
      {
        "chunk_index": 5154,
        "paper_id": 88,
        "chunk_idx": 0,
        "title": "A Survey on Data Security in Large Language Models",
        "section_head": "Fig. 1 :",
        "score": 0.8992515802383423,
        "text_preview": "1 Fig. 1: Overview of the Survey Structure on LLMs Data Security, beginning with background and LLM vulnerabilities, then addressing data security risks, mitigation techniques, datasets, and concludin"
      },
      {
        "chunk_index": 4939,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Fig. 27 :",
        "score": 0.8905789852142334,
        "text_preview": "27 Fig. 27: Scientific data construction pipeline: multi-source data acquisition, data synthesis pipelines for pre-training, posttraining and evaluation stages, and comprehensive review framework inco"
      },
      {
        "chunk_index": 78735,
        "paper_id": 1662,
        "chunk_idx": 0,
        "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale",
        "section_head": "Table 2 :",
        "score": 0.8686121702194214,
        "text_preview": "2 Factors in the user preferences SocialCommunication, Contact, Data Types Data-general, MedicalHealth, Identifying, Location, Picture Purposes Internal, Advertisement, Analytics, Research, SNS, Prote"
      },
      {
        "chunk_index": 16972,
        "paper_id": 344,
        "chunk_idx": 0,
        "title": "Benchmarking Robust Aggregation in Decentralized Gradient Marketplaces",
        "section_head": "Evaluation Methodology",
        "score": 0.8683948516845703,
        "text_preview": "Our benchmark mirrors the end-to-end lifecycle of a federated-gradient marketplace, from a buyer's root dataset to post-training economic settlement. This lifecycle is divided into three macro phases,"
      },
      {
        "chunk_index": 13297,
        "paper_id": 266,
        "chunk_idx": 0,
        "title": "Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models",
        "section_head": "Methodology",
        "score": 0.8650054335594177,
        "text_preview": "Our experimental methodology is designed to provide rigorous, reproducible measurements of memorization risks in fine-tuned LLMs while evaluating the effectiveness of various privacy protection strate"
      },
      {
        "chunk_index": 5027,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "3) Data Integrity and Authentication:",
        "score": 0.8340283632278442,
        "text_preview": "Trust establishment requires comprehensive verification mechanisms to ensure data authenticity and prevent tampering. Multi-layered authentication protocols safeguard against unauthorized modification"
      },
      {
        "chunk_index": 102365,
        "paper_id": 2124,
        "chunk_idx": 0,
        "title": "OS-DiffVSR: Towards One-step Latent Diffusion Model for High-detailed Real-world Video Super-Resolution",
        "section_head": "Table 3 .",
        "score": 0.8328203558921814,
        "text_preview": "3 Evaluation of the multi-frame adversarial training paradigm. ¬µ CLIP-IQA‚Üë MUSIQ‚Üë DOVER‚Üë E * warp ‚Üì 1.0 0.607 64.981 0.745 1.862 0.8 0.599 65.206 0.766 1.830 0.6 0.629 66.135 0.772 1.744 0.4 0.619 66."
      },
      {
        "chunk_index": 151622,
        "paper_id": 3119,
        "chunk_idx": 0,
        "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning",
        "section_head": "Fig. 12 .",
        "score": 0.8154240846633911,
        "text_preview": "12 Fig. 12. Evaluation of three commonly used privacy-preserving techniques on defending against VTarbel while maintaining main task accuracy."
      },
      {
        "chunk_index": 121158,
        "paper_id": 2524,
        "chunk_idx": 0,
        "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
        "section_head": "C. Security evaluation",
        "score": 0.8132064342498779,
        "text_preview": "This section assesses the effectiveness of SSVAX in defending against both untargeted and targeted data poisoning attacks, including comparisons with related approaches and considerations for potentia"
      },
      {
        "chunk_index": 111235,
        "paper_id": 2313,
        "chunk_idx": 0,
        "title": "RAG Security and Privacy: Formalizing the Threat Model and Attack Surface",
        "section_head": "Fig. 2 .",
        "score": 0.8110511898994446,
        "text_preview": "2 Fig. 2. Taxonomy of Adversary Types"
      },
      {
        "chunk_index": 18424,
        "paper_id": 374,
        "chunk_idx": 1,
        "title": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation",
        "section_head": "Harmfulness Evaluator",
        "score": 0.8105871081352234,
        "text_preview": "Using a 0-5 scale: 0 = factually baseless content ( e.g., chemically invalid poison recipes); 5 = authoritative, accurate details ( e.g., complete phishing techniques). Criteria adapt dynamically to s"
      },
      {
        "chunk_index": 84659,
        "paper_id": 1781,
        "chunk_idx": 0,
        "title": "MARS: A Malignity-Aware Backdoor Defense in Federated Learning",
        "section_head": "Table 6 :",
        "score": 0.8077285289764404,
        "text_preview": "6 Impact of data distribution on the performance of exitsting defenses under 3DFed attack on CIFAR-10."
      },
      {
        "chunk_index": 124810,
        "paper_id": 2603,
        "chunk_idx": 0,
        "title": "SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus",
        "section_head": "Fig. 2 .",
        "score": 0.8054273724555969,
        "text_preview": "2 Fig. 2. Blockchain based UAV security system for NTNs, showing the integration of ground users, UAVslockchain for secure trust evaluation, and application scenario."
      },
      {
        "chunk_index": 5024,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "A. Security Threats and Vulnerabilities",
        "score": 0.8053265810012817,
        "text_preview": "Distributed collaborative architectures introduce expanded attack surfaces that must be addressed to ensure robust operation. Sensitive data across multiple layers risks unauthorized access and interc"
      },
      {
        "chunk_index": 5161,
        "paper_id": 88,
        "chunk_idx": 0,
        "title": "A Survey on Data Security in Large Language Models",
        "section_head": "Table 2",
        "score": 0.795735239982605,
        "text_preview": "2 Strategies for protecting data security. This table categorizes defense methods for LLM security into three main types: adversarial training, RLHF, and data augmentation. For each approach, it lists"
      },
      {
        "chunk_index": 157422,
        "paper_id": 3225,
        "chunk_idx": 0,
        "title": "œÑ¬≤-Bench (Average)",
        "section_head": "Figure 3 :",
        "score": 0.7954672574996948,
        "text_preview": "3 Figure 3: The data curation pipeline for cold-start training."
      },
      {
        "chunk_index": 5112,
        "paper_id": 88,
        "chunk_idx": 5,
        "title": "A Survey on Data Security in Large Language Models",
        "section_head": "Introduction",
        "score": 0.7917984127998352,
        "text_preview": "As LLMs grow in scale and diversify into critical sectors -such as finance, healthcare, and transportationthe stakes of poorly understood vulnerabilities become ever higher, demanding an up-to-the-min"
      },
      {
        "chunk_index": 4968,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "Security & Privacy",
        "score": 0.7899951934814453,
        "text_preview": "Builds on data layer outputs, applying security and privacy measures to protect data flow and system integrity."
      }
    ]
  },
  {
    "query_id": 87,
    "query_text": "survey diffusion language",
    "source": "title",
    "source_value": "A Survey on Diffusion Language Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 38863,
        "paper_id": 819,
        "chunk_idx": 0,
        "title": "DTGen: Generative Diffusion-Based Few-Shot Data Augmentation for Fine-Grained Dirty Tableware Recognition",
        "section_head": "Related Work",
        "score": 0.9417505860328674,
        "text_preview": "We review three technical domains central to DTGen: generative data augmentation, parameter-efficient fine-tuning, and vision-language models for data quality control."
      },
      {
        "chunk_index": 85393,
        "paper_id": 1798,
        "chunk_idx": 0,
        "title": "Mathematical Language Models: A Survey",
        "section_head": "Fig. 3 .",
        "score": 0.9236952662467957,
        "text_preview": "3 Fig.3. Taxonomy of language models for mathematic."
      },
      {
        "chunk_index": 143425,
        "paper_id": 2959,
        "chunk_idx": 2,
        "title": "Transition Models: Rethinking the Generative Learning Objective",
        "section_head": "Decoupled Time and Interval Embeddings.",
        "score": 0.9121818542480469,
        "text_preview": "Binding Autoregressive Models Emu3-Gen [79] --0.54 0.98 0.71 0.34 0.81 0.17 0.21 GPT-4o [1] --0.84 0.99 0.92 0.85 0.92 0.75 0.61 Multi-step Diffusion Models SD2.1 [56] 865M 100 0.50 0.98 0.51 0.44 0.8"
      },
      {
        "chunk_index": 152543,
        "paper_id": 3142,
        "chunk_idx": 0,
        "title": "What do Speech Foundation Models Learn? Analysis and Applications by",
        "section_head": "CHAPTER 8",
        "score": 0.899126410484314,
        "text_preview": "Extensive Evaluation of Speech Foundation"
      },
      {
        "chunk_index": 34539,
        "paper_id": 730,
        "chunk_idx": 1,
        "title": "DIFFUSION LANGUAGE MODELS CAN PERFORM MANY TASKS WITH SCALING AND INSTRUCTION-FINETUNING",
        "section_head": "DISCUSSIONS",
        "score": 0.8962426781654358,
        "text_preview": "(2024) successfully build large-scale diffusion language models by adapting from autoregressive language models, offering another promising routine to gain large diffusion language models with relativ"
      },
      {
        "chunk_index": 125346,
        "paper_id": 2619,
        "chunk_idx": 0,
        "title": "SMooGPT : Stylized Motion Generation using Large Language Models",
        "section_head": "Related Work",
        "score": 0.8952065706253052,
        "text_preview": "We review recent advancements in human motion generation, motion stylization, and large language models (LLMs) and multi-modal LLMs (MLLMs) in the human motion area."
      },
      {
        "chunk_index": 64490,
        "paper_id": 1379,
        "chunk_idx": 0,
        "title": "Holistic Evaluation of Language Models",
        "section_head": "Preliminaries",
        "score": 0.8821587562561035,
        "text_preview": "We introduce the basic primitives (scenario, adaptation, metric) required to evaluate a language model (Figure 5 ). With these primitives, we then provide a roadmap for how we holistically evaluate la"
      },
      {
        "chunk_index": 88067,
        "paper_id": 1854,
        "chunk_idx": 0,
        "title": "MiniGPT-v2: Large Language Model As a Unified Interface for Vision-Language Multi-task Learning",
        "section_head": "Related Work",
        "score": 0.8802335262298584,
        "text_preview": "We briefly review relevant works on advanced large language models and multi-modal LLMs for visual aligning."
      },
      {
        "chunk_index": 84576,
        "paper_id": 1780,
        "chunk_idx": 0,
        "title": "MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models",
        "section_head": "MarkLLM Generative Large Language Models (Text)",
        "score": 0.8764439225196838,
        "text_preview": "A comprehensive toolkit for generative text watermarking."
      },
      {
        "chunk_index": 32269,
        "paper_id": 677,
        "chunk_idx": 0,
        "title": "DeepSeek LLM Scaling Open-Source Language Models with Longtermism",
        "section_head": "Open-Ended Evaluation",
        "score": 0.8758431673049927,
        "text_preview": "For chat models, in addition to observing metrics on standard benchmarks, the quality of results generated in open domains and open-ended questions directly affects the actual user experience. Hence, "
      },
      {
        "chunk_index": 93258,
        "paper_id": 1970,
        "chunk_idx": 0,
        "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face",
        "section_head": "A Survey",
        "score": 0.8753480911254883,
        "text_preview": "To better understand the challenges in multimodal and sign language processing and assess the usability of MultimodalHugs, we conducted a survey (more details in Appendix A.1) among researchers in the"
      },
      {
        "chunk_index": 34561,
        "paper_id": 731,
        "chunk_idx": 0,
        "title": "Diffusion-LM Improves Controllable Text Generation",
        "section_head": "Problem Statement and Background",
        "score": 0.8738546967506409,
        "text_preview": "We first define controllable generation ( ¬ß3.1) and then review continuous diffusion models ( ¬ß3.3)."
      },
      {
        "chunk_index": 83946,
        "paper_id": 1767,
        "chunk_idx": 3,
        "title": "Make Every Letter Count: Building Dialect Variation Dictionaries from Monolingual Corpora",
        "section_head": "Use of AI Assistants",
        "score": 0.8687279224395752,
        "text_preview": "Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ram√©, Morgane Rivi√®re, and 1 others. 2025. Gemma 3 technical rep"
      },
      {
        "chunk_index": 84589,
        "paper_id": 1780,
        "chunk_idx": 0,
        "title": "MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models",
        "section_head": "Table 3 :",
        "score": 0.8686954975128174,
        "text_preview": "3 Evaluation results of watermarking algorithms across key metrics. Algorithms Detectability(‚Üë) (TPR@FPR=1%) JPEG Robustness (F1-score‚Üë) Gaussian Blur Gaussian Noise FID(‚Üì) Quality CLIP-T(‚Üë) Tree-Ring"
      },
      {
        "chunk_index": 143198,
        "paper_id": 2954,
        "chunk_idx": 0,
        "title": "Transformer models: an introduction and catalog",
        "section_head": "Figure 4 :",
        "score": 0.8678698539733887,
        "text_preview": "4 Figure 4: Probabilistic diffusion model architecture from \"Diffusion Models: A Comprehensive Survey of Methods and Applications,\" Figure 2 (Yang et al., 2022)"
      },
      {
        "chunk_index": 89661,
        "paper_id": 1888,
        "chunk_idx": 0,
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "section_head": "Figure 1 :",
        "score": 0.8627251386642456,
        "text_preview": "1 Figure 1: Results of eight representative large vision-language models (VLMs) across the 20 ability dimensions defined in MMBench-test."
      },
      {
        "chunk_index": 38142,
        "paper_id": 805,
        "chunk_idx": 0,
        "title": "DreamControl: Human-Inspired Whole-Body Humanoid Control for Scene Interaction via Guided Diffusion",
        "section_head": "1 1",
        "score": 0.8614842891693115,
        "text_preview": "1 Appendix linkA. Stage 1: Generating Reference Trajectory from a Human Motion Prior"
      },
      {
        "chunk_index": 138987,
        "paper_id": 2864,
        "chunk_idx": 0,
        "title": "The State Of TTS: A Case Study with Human Fooling Rates",
        "section_head": "Evaluation of State-of-the-Art TTS",
        "score": 0.8606427907943726,
        "text_preview": "To assess whether state-of-the-art TTS systems can truly deceive human listeners, we systematically select models that represent the current landscape of speech synthesis. We describe our model select"
      },
      {
        "chunk_index": 79148,
        "paper_id": 1668,
        "chunk_idx": 0,
        "title": "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges",
        "section_head": "Challenges and Open Problems",
        "score": 0.8597494959831238,
        "text_preview": "This paper provides a comprehensive review of recent natural language generation evaluations based on LLMs, encompassing both prompt-based and tuning-based evaluation approaches. Despite significant e"
      },
      {
        "chunk_index": 35383,
        "paper_id": 748,
        "chunk_idx": 0,
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "section_head": "Table 1 :",
        "score": 0.8582119345664978,
        "text_preview": "1 Evaluation of simulated discharge conversations across multiple dimensions: (1) Language & Delivery assesses linguistic clarity, coherence, and avoidance of repetitiveness. Language Human Content Co"
      }
    ]
  },
  {
    "query_id": 88,
    "query_text": "survey graph diffusion",
    "source": "title",
    "source_value": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 5301,
        "paper_id": 90,
        "chunk_idx": 0,
        "title": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material",
        "section_head": "Fig. 1 .",
        "score": 0.9669966101646423,
        "text_preview": "1 Fig. 1. Graph generation models for deep graph generation"
      },
      {
        "chunk_index": 104917,
        "paper_id": 2175,
        "chunk_idx": 0,
        "title": "Personalized Subgraph Federated Learning with Sheaf Collaboration",
        "section_head": "Table 5 .",
        "score": 0.9491891860961914,
        "text_preview": "5 Different GNN models on collaboration graph. Methods non-overlapping overlapping 20 clients 30 clients w/o Sheaf diffusion a 69.75 65.66 w/ GCN b 69.86 65.96 w/ GAT 69.92 65.90 w/ Sheaf diffusion (o"
      },
      {
        "chunk_index": 107123,
        "paper_id": 2219,
        "chunk_idx": 1,
        "title": "PowerGrow: Feasible Co-Growth of Structures and Dynamics for Power Grid Synthesis",
        "section_head": "Related Work",
        "score": 0.9253541231155396,
        "text_preview": "Graph diffusion generative models. Graph diffusion generative models have attracted growing interest recently owing to their strong sample fidelity and stable training. Early efforts such as EDP-GNN ["
      },
      {
        "chunk_index": 101927,
        "paper_id": 2118,
        "chunk_idx": 0,
        "title": "OptiProxy-NAS: Optimization Proxy based End-to-End Neural Architecture Search",
        "section_head": "Figure 11 :",
        "score": 0.9184129238128662,
        "text_preview": "11 Figure11: The discrete sampling of topological structure variables in NAS-Bench-301."
      },
      {
        "chunk_index": 126451,
        "paper_id": 2635,
        "chunk_idx": 0,
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "section_head": "Figure 4 . 6 :",
        "score": 0.8996453285217285,
        "text_preview": "46 Figure 4.6: A discussion regarding k-SAT problems and graph theory."
      },
      {
        "chunk_index": 5302,
        "paper_id": 90,
        "chunk_idx": 0,
        "title": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material",
        "section_head": "Fig. 2 .",
        "score": 0.8968875408172607,
        "text_preview": "2 Fig. 2. Illustration of diffusion models for deep graph generation."
      },
      {
        "chunk_index": 59976,
        "paper_id": 1279,
        "chunk_idx": 0,
        "title": "Generative Diffusion Models on Graphs: Methods and Applications",
        "section_head": "Add noise",
        "score": 0.8932552337646484,
        "text_preview": "Denoise Reverse: Forward: (d) Diffusion models Figure 1 : Deep Generative Models on Graphs. and 0 otherwise. X ‚àà R N√ód denotes the node feature with dimension d. Under diffusion context, G 0 refers to"
      },
      {
        "chunk_index": 59989,
        "paper_id": 1279,
        "chunk_idx": 0,
        "title": "Generative Diffusion Models on Graphs: Methods and Applications",
        "section_head": "SGM on Graphs",
        "score": 0.8917996287345886,
        "text_preview": "Although EDP-GNN develops a score-based generative model to derive the adjacency matrix of the graph, the estimation for the score function depends on the noise scales at the discrete steps, which res"
      },
      {
        "chunk_index": 101926,
        "paper_id": 2118,
        "chunk_idx": 0,
        "title": "OptiProxy-NAS: Optimization Proxy based End-to-End Neural Architecture Search",
        "section_head": "Figure 10 :",
        "score": 0.874322772026062,
        "text_preview": "10 Figure10: The proxy sampling of topological structure variables in NAS-Bench-301. The colored boxes represent groups transformed based on the proceeding nodes relationship."
      },
      {
        "chunk_index": 37793,
        "paper_id": 798,
        "chunk_idx": 0,
        "title": "DR-CircuitGNN: Training Acceleration of Heterogeneous Circuit Graph Neural Network on GPUs",
        "section_head": "5 Figure 3 :Figure 4 : 3 )",
        "score": 0.8702362775802612,
        "text_preview": "5343 Figure 3: Circuit graph generation process: (a) Circuit Layout; (b) Topological Link; (c) Geometrical Link; (d) Circuit Graph."
      },
      {
        "chunk_index": 59987,
        "paper_id": 1279,
        "chunk_idx": 1,
        "title": "Generative Diffusion Models on Graphs: Methods and Applications",
        "section_head": "DDPM on Graphs",
        "score": 0.867989182472229,
        "text_preview": "Q X t and Q E t refer to the noise added to the node and edge, respectively. This Markov formulation allows sampling directly at an arbitrary time step without computing the previous steps. In the den"
      },
      {
        "chunk_index": 59977,
        "paper_id": 1279,
        "chunk_idx": 0,
        "title": "Generative Diffusion Models on Graphs: Methods and Applications",
        "section_head": "Deep Generative Models on Graphs",
        "score": 0.863474428653717,
        "text_preview": "Variational Autoencoders (VAEs). As the very first deep generative model, variational autoencoders have been successfully applied to graphs, where VAE aims to train a probabilistic graph encoder q œï ("
      },
      {
        "chunk_index": 62527,
        "paper_id": 1334,
        "chunk_idx": 0,
        "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?",
        "section_head": "GraphMaker-Async (GMaker-A).",
        "score": 0.8613741993904114,
        "text_preview": "In practice, we find that GraphMaker-Sync cannot properly capture the correlations between high-dimensional node attributes, graph structure, and node label, as shown in later Sections 3.2 and 3.3. Pr"
      },
      {
        "chunk_index": 14879,
        "paper_id": 300,
        "chunk_idx": 0,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Constructing Narratives with Autiverse",
        "score": 0.8592989444732666,
        "text_preview": "Based on the survey results and the feedback in debriefing, we illustrate how Autiverse guided adolescents' narrative construction through scaffolding and multimodal support."
      },
      {
        "chunk_index": 60011,
        "paper_id": 1279,
        "chunk_idx": 0,
        "title": "Generative Diffusion Models on Graphs: Methods and Applications",
        "section_head": "Figure 2 :",
        "score": 0.8570561408996582,
        "text_preview": "2 Figure2: An illustration of diffusion models on molecular and protein generations. The forward diffusion process involves the gradual addition of noise from the fixed posterior distribution q(Gt|Gt-"
      },
      {
        "chunk_index": 62526,
        "paper_id": 1334,
        "chunk_idx": 0,
        "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?",
        "section_head": "GraphMaker-Sync (GMaker-S).",
        "score": 0.8563104867935181,
        "text_preview": "GraphMaker-Sync employs a forward diffusion process that simultaneously corrupts node attributes and edges for all time steps, which corresponds to setting T X = T A = [T ]. The denoising network is t"
      },
      {
        "chunk_index": 107131,
        "paper_id": 2219,
        "chunk_idx": 0,
        "title": "PowerGrow: Feasible Co-Growth of Structures and Dynamics for Power Grid Synthesis",
        "section_head": "Hierarchical Beta Diffusion",
        "score": 0.8554325699806213,
        "text_preview": "Through ancestral sampling, a direct adaptation of reverse diffusion process involves a trainable network ùëì ùõº for predicting √Ç0 , X0 , √ä0 , ƒ§0 = ùëì ùõº (ùê¥ ùëò , ùëã ùëò , ùê∏ ùëò , ùêª ùëò , ùëò) (7) at diffusion step ùëò"
      },
      {
        "chunk_index": 107126,
        "paper_id": 2219,
        "chunk_idx": 0,
        "title": "PowerGrow: Feasible Co-Growth of Structures and Dynamics for Power Grid Synthesis",
        "section_head": "Graph beta diffusion.",
        "score": 0.8544597625732422,
        "text_preview": "Denoising diffusion models are composed of two processes: a forward diffusion process and a backward denoising process. In the forward process, the input data is gradually diffused into near-zeros or "
      },
      {
        "chunk_index": 112089,
        "paper_id": 2334,
        "chunk_idx": 0,
        "title": "RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios",
        "section_head": "Figure 3 :",
        "score": 0.8487250804901123,
        "text_preview": "3 Figure3: The flow of dataset construction and quality control."
      },
      {
        "chunk_index": 5262,
        "paper_id": 90,
        "chunk_idx": 0,
        "title": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material",
        "section_head": "Normalizing Flows",
        "score": 0.8484879732131958,
        "text_preview": "Normalizing Flow applies a sequence of invertible transformations to a simple probability distribution to model more complex probability distributions using encoder [46] , [62] , [63] , [64] . Its dec"
      }
    ]
  },
  {
    "query_id": 89,
    "query_text": "survey towards privacy",
    "source": "title",
    "source_value": "A Survey: Towards Privacy and Security in Mobile Large Language Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 41828,
        "paper_id": 883,
        "chunk_idx": 0,
        "title": "Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation",
        "section_head": "Human Evaluation Protocol",
        "score": 0.956250011920929,
        "text_preview": "We conducted small-scale human evaluation with anonymous participants recruited transparently via social media. Participants were volunteers residing in Beijing and Shenzhen, China. All participants p"
      },
      {
        "chunk_index": 8945,
        "paper_id": 172,
        "chunk_idx": 0,
        "title": "AI-IN-THE-LOOP: PRIVACY PRESERVING REAL-TIME SCAM DETECTION AND CONVERSATIONAL SCAMBAITING BY LEVERAGING LLMS AND FEDERATED LEARNING",
        "section_head": "Ethical Considerations and Data Privacy",
        "score": 0.9407949447631836,
        "text_preview": "This work relied on anonymized, publicly available datasets and synthetic scam-victim interactions generated for research purposes. All personally identifiable information (PII)-including usernames, l"
      },
      {
        "chunk_index": 120736,
        "paper_id": 2513,
        "chunk_idx": 1,
        "title": "Seeing Culture: A Benchmark for Visual Reasoning and Grounding",
        "section_head": "Ethical Consideration",
        "score": 0.9126859903335571,
        "text_preview": "We employed purposive sampling to identify freelancers on Upwork.com who fulfilled these inclusion criteria, focusing on their cultural expertise and experience with cultural content or research. Addi"
      },
      {
        "chunk_index": 81066,
        "paper_id": 1710,
        "chunk_idx": 1,
        "title": "LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data",
        "section_head": "Background and Related Work",
        "score": 0.9007145762443542,
        "text_preview": "An essential part of any privacy-preserving solution in the context of NLP is its privacy evaluation. Lacking standard definitions of text privacy has led to a divergence of evaluation approaches in P"
      },
      {
        "chunk_index": 17292,
        "paper_id": 350,
        "chunk_idx": 0,
        "title": "BESPOKE: BENCHMARK FOR SEARCH-AUGMENTED LARGE LANGUAGE MODEL PERSONALIZATION VIA DIAGNOSTIC FEEDBACK",
        "section_head": "B.2 DATA HANDLING & PRIVACY PROTECTION",
        "score": 0.8850799798965454,
        "text_preview": "Our benchmark prioritizes user privacy and ethical data practices through rigorous de-identification process, ensuring no personal information is disclosed without consent. All direct identifiers (e.g"
      },
      {
        "chunk_index": 81905,
        "paper_id": 1726,
        "chunk_idx": 0,
        "title": "LLMs as Architects and Critics for Multi-Source Opinion Summarization",
        "section_head": "M-OS-EVAL (Evaluation Benchmark Dataset)",
        "score": 0.8807523846626282,
        "text_preview": "We developed M-OS-EVAL to evaluate summaries across 7 dimensions defined in Appendix A. The dataset includes 14 model-generated summaries per product for 50 products from the M-OS-DATA test set, resul"
      },
      {
        "chunk_index": 44643,
        "paper_id": 953,
        "chunk_idx": 0,
        "title": "Evaluating Large Language Models: A Comprehensive Survey",
        "section_head": "Ethics and Morality",
        "score": 0.8782482147216797,
        "text_preview": "The ethics and morality evaluation of LLMs aims to assess whether LLMs have the ethical value alignment ablility, and whether they generate content that potentially deviates from ethical standards. Wh"
      },
      {
        "chunk_index": 82696,
        "paper_id": 1738,
        "chunk_idx": 0,
        "title": "Longitudinal and Multimodal Recording System to Capture Real-World Patient-Clinician Conversations for AI and Encounter Research: Protocol",
        "section_head": "Ethical Considerations",
        "score": 0.8766071796417236,
        "text_preview": "This study was approved by the Mayo Clinic Institutional Review Board (IRB #24-012956). All clinicians, patients, and adult guests give informed consent prior to recording. Recordings and linked data "
      },
      {
        "chunk_index": 18760,
        "paper_id": 380,
        "chunk_idx": 0,
        "title": "Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and LLM-as-Judge Assessment",
        "section_head": "Quality Control and Feedback Loops",
        "score": 0.874879002571106,
        "text_preview": "[ ] Was an onboarding session provided to all annotators covering task goals, ethical risks, and edge cases? [ ] Were regular review cycles or spot checks conducted to maintain annotation quality? [ ]"
      },
      {
        "chunk_index": 33989,
        "paper_id": 716,
        "chunk_idx": 3,
        "title": "Differentially private federated learning for localized control of infectious disease dynamics",
        "section_head": "Introduction",
        "score": 0.868975043296814,
        "text_preview": "Instead, it captures commonalities across all contributions. Implementing DP involves adding Gaussian noise to the aggregated update, thereby masking participant data specifics while preserving the ov"
      },
      {
        "chunk_index": 56571,
        "paper_id": 1216,
        "chunk_idx": 0,
        "title": "From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization",
        "section_head": "1) Privacy Leaks from Backdoor Attacks:",
        "score": 0.8689553737640381,
        "text_preview": "In data sharing and analytics, privacy is often defined as the user's ability to control the release of their personal information [40] . Consequently, a privacy leak occurs when confidential or sensi"
      },
      {
        "chunk_index": 47413,
        "paper_id": 1012,
        "chunk_idx": 0,
        "title": "FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
        "section_head": "Data",
        "score": 0.86748868227005,
        "text_preview": "We perform human evaluation of factual precision based on our definition. We prompt the LM SUBJ to generate people biographies and evaluate them against Wikipedia for the following reasons. ‚Ä¢ Biograph"
      },
      {
        "chunk_index": 64419,
        "paper_id": 1377,
        "chunk_idx": 0,
        "title": "HLF-FSL: A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric",
        "section_head": "Fig. 3 :",
        "score": 0.8656705617904663,
        "text_preview": "3 Fig.3: Model lifecycle workflow encompassing server registration, model publication, and client binding"
      },
      {
        "chunk_index": 55488,
        "paper_id": 1187,
        "chunk_idx": 0,
        "title": "FLOSS: Federated Learning with Opt-Out and Straggler Support",
        "section_head": "Introduction",
        "score": 0.8600685000419617,
        "text_preview": "Federated learning (FL) is a privacy-preserving form of machine learning in which a model is trained across a distributed set of clients, eliminating the need for individual users to share their data "
      },
      {
        "chunk_index": 14872,
        "paper_id": 300,
        "chunk_idx": 2,
        "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
        "section_head": "Parents Autistic Adolescents",
        "score": 0.8592628836631775,
        "text_preview": "The questions mainly addressed reasons behind their ratings (e.g., intention to use, recall aid, friendliness, ownership, autonomy) and perceived differences between talking with a parent and the AI p"
      },
      {
        "chunk_index": 2917,
        "paper_id": 55,
        "chunk_idx": 0,
        "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption",
        "section_head": "Threat Model",
        "score": 0.8582698106765747,
        "text_preview": "We consider a semi-honest (honest-but-curious) threat model, where both clients and server, follow the protocol correctly but may attempt to infer private information from the data they receive. To en"
      },
      {
        "chunk_index": 58036,
        "paper_id": 1242,
        "chunk_idx": 0,
        "title": "FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning",
        "section_head": "III. THREAT MODEL AND SECURITY CONSIDERATIONS",
        "score": 0.8579880595207214,
        "text_preview": "Deployment model and trust assumptions: FuSeFL targets scalable cross-silo federated learning where each client, such as a hospital or financial institution, holds a distinct set of samples over a sha"
      },
      {
        "chunk_index": 12265,
        "paper_id": 241,
        "chunk_idx": 1,
        "title": "Applied Federated Learning: Architectural Design for Robust and Efficient Learning in Privacy Aware Settings",
        "section_head": "Introduction",
        "score": 0.8578410148620605,
        "text_preview": "Combining federated learning with differential privacy results in three main benefits: 1. Data remains on user devices; 2. Aggregation of client data is performed within a trusted environment that is "
      },
      {
        "chunk_index": 589,
        "paper_id": 12,
        "chunk_idx": 1,
        "title": "A Comprehensive Review of Datasets for Clinical Mental Health AI Systems",
        "section_head": "Future Directions",
        "score": 0.8546286821365356,
        "text_preview": "We highlight three complementary strategies for responsibly leveraging collected mental health data: (i) Federated learning with local differential privacy (LDP-FL), where data collected across geogra"
      },
      {
        "chunk_index": 55714,
        "paper_id": 1193,
        "chunk_idx": 0,
        "title": "Flowing Straighter with Conditional Flow Matching for Accurate Speech Enhancement",
        "section_head": "Table 1 :",
        "score": 0.8542361259460449,
        "text_preview": "1 Mean speech quality metrics on VB-DMD of our SB-SV and ICFM with FM loss and DDP inference over SB-VE (Jukiƒá et al., 2024) baseline. k = 0.99 induces straightness and c scales variance. Path Loss In"
      }
    ]
  },
  {
    "query_id": 90,
    "query_text": "systematic investigation commonsense",
    "source": "title",
    "source_value": "A Systematic Investigation of Commonsense Knowledge in Large Language Models",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 41577,
        "paper_id": 876,
        "chunk_idx": 0,
        "title": "EIGEN-1: ADAPTIVE MULTI-AGENT REFINE-MENT WITH MONITOR-BASED RAG FOR SCIENTIFIC REASONING",
        "section_head": "Accuracy Increase",
        "score": 0.9818387031555176,
        "text_preview": "Eigen-1 Baseline+RAG flow, our framework addresses key limitations of prior approaches in complex scientific problem solving. Future work will extend these principles to additional scientific domains,"
      },
      {
        "chunk_index": 8514,
        "paper_id": 164,
        "chunk_idx": 1,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "LIMITATIONS AND FUTURE WORKS",
        "score": 0.966317892074585,
        "text_preview": "Future work needs to establish a more rigorous verification process involving manual domain experts to assess answer correctness, the validity of reasoning steps, and potential hallucinations. ‚Ä¢ A dee"
      },
      {
        "chunk_index": 112248,
        "paper_id": 2339,
        "chunk_idx": 0,
        "title": "Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning",
        "section_head": "Conclusion",
        "score": 0.9577165246009827,
        "text_preview": "We introduced Reasoning Core, a library of scalable RL environments targeting fundamental symbolic reasoning capacities in LLMs. By focusing on high-generality tasks like PDDL planning and first-order"
      },
      {
        "chunk_index": 9162,
        "paper_id": 175,
        "chunk_idx": 1,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "VII. CONCLUSION",
        "score": 0.9491523504257202,
        "text_preview": "As noted in the Limitations and Ethical Considerations sections, challenges persist, including hallucinations, adapting document structures, and the need for formalized review mechanisms. Future work "
      },
      {
        "chunk_index": 12513,
        "paper_id": 247,
        "chunk_idx": 0,
        "title": "AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data",
        "section_head": "Conclusion and Future Work",
        "score": 0.9365857243537903,
        "text_preview": "In this paper, we presented AraTable, a question answering benchmark for use with Arabic tabular data. The benchmark provides a framework for evaluating LLMs on three distinct QA tasks: direct extract"
      },
      {
        "chunk_index": 89340,
        "paper_id": 1880,
        "chunk_idx": 0,
        "title": "Mixture of Length and Pruning Experts for Knowledge Graphs Reasoning",
        "section_head": "Limitations",
        "score": 0.9236531853675842,
        "text_preview": "While MoKGR demonstrates significant improvements in knowledge graph reasoning performance, several limitations should be acknowledged: First, the computational complexity of our method, though signif"
      },
      {
        "chunk_index": 131713,
        "paper_id": 2726,
        "chunk_idx": 1,
        "title": "STYLEBENCH: EVALUATING THINKING STYLES IN LARGE LANGUAGE MODELS",
        "section_head": "CONCLUSION",
        "score": 0.9224703311920166,
        "text_preview": "These results provide a practical framework for optimal strategy selection: search-based methods (ToT, AoT) excel for complex, open-ended problems (e.g., Game24) with capable models, while concise app"
      },
      {
        "chunk_index": 70732,
        "paper_id": 1508,
        "chunk_idx": 0,
        "title": "Intuition to Evidence: Measuring AI's True Impact on Developer Productivity",
        "section_head": "Future Directions",
        "score": 0.9175593852996826,
        "text_preview": "Our research opens several promising avenues for future investigation:"
      },
      {
        "chunk_index": 150568,
        "paper_id": 3093,
        "chunk_idx": 0,
        "title": "Vision as LoRA",
        "section_head": "Method",
        "score": 0.9115168452262878,
        "text_preview": "Posters Celebrity Landmark Artwork Total niques. Finally, although VoRA underperformed on world knowledge tasks, this reflects data limitations rather than architectural constraints, and could be reso"
      },
      {
        "chunk_index": 70265,
        "paper_id": 1498,
        "chunk_idx": 0,
        "title": "Interactive Recommendation Agent with Active User Commands",
        "section_head": "Multi-Agent Optimization",
        "score": 0.9099018573760986,
        "text_preview": "The Parser and Planner agents face highly complex personalized reasoning and decision-making tasks involving ambiguous user command parsing, multi-turn preference state maintenance, and adaptive tool "
      },
      {
        "chunk_index": 65073,
        "paper_id": 1385,
        "chunk_idx": 0,
        "title": "How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances",
        "section_head": "Conclusion",
        "score": 0.9071059226989746,
        "text_preview": "In this paper, we systematically review recent advances in aligning LLMs with the ever-changing world knowledge without re-training. We summarize existing approaches and categorize them based on wheth"
      },
      {
        "chunk_index": 715,
        "paper_id": 14,
        "chunk_idx": 0,
        "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
        "section_head": "Discussion and Limitations",
        "score": 0.9050936698913574,
        "text_preview": "Hallucination mitigation in LLMs represents a multifaceted challenge addressed through a spectrum of innovative techniques. The methodologies discussed, ranging from post-generation refinement to supe"
      },
      {
        "chunk_index": 85325,
        "paper_id": 1798,
        "chunk_idx": 5,
        "title": "Mathematical Language Models: A Survey",
        "section_head": "INTRODUCTION",
        "score": 0.9045876264572144,
        "text_preview": "Specifically, our categorization of mathematical tasks ( ¬ß2) contain two primary domains: mathematical calculation ( ¬ß2.1), consisting of arithmetic representation and arithmetic calculation, and math"
      },
      {
        "chunk_index": 20493,
        "paper_id": 415,
        "chunk_idx": 0,
        "title": "Breath as a biomarker: A survey of contact and contactless applications and approaches in respiratory monitoring",
        "section_head": "Challenges, limitations, and future directions",
        "score": 0.9037617444992065,
        "text_preview": "This section reviews the challenges and limitations of existing systems for breath analysis. It also explores future research directions to address these issues and suggests potential advancements in "
      },
      {
        "chunk_index": 4335,
        "paper_id": 84,
        "chunk_idx": 2,
        "title": "A Survey of Reasoning with Foundation Models",
        "section_head": "Natural Language Reasoning",
        "score": 0.9025342464447021,
        "text_preview": "As Figure 2 shows, we provide a concise overview of various reasoning tasks, including Commonsense Reasoning, Mathematical Reasoning, Logical Reasoning, Causal Reasoning, Visual Reasoning, Audio Reaso"
      },
      {
        "chunk_index": 110950,
        "paper_id": 2306,
        "chunk_idx": 0,
        "title": "R1-RE: Cross-Domain Relation Extraction with RLVR",
        "section_head": "Limitations",
        "score": 0.9023934602737427,
        "text_preview": "In this work, we primarily focus on relation classification (RC) tasks and leave the exploration of more complex triplet extraction (TE) tasks for future research. Additionally, our experiments are li"
      },
      {
        "chunk_index": 133288,
        "paper_id": 2757,
        "chunk_idx": 0,
        "title": "SYNERGYNET: FUSING GENERATIVE PRIORS AND STATE-SPACE MODELS FOR FACIAL BEAUTY PREDICTION",
        "section_head": "Future Work",
        "score": 0.9008792638778687,
        "text_preview": "The success and limitations of MD-Net open up several promising avenues for future research. ‚Ä¢ Fairness and Bias Mitigation: Directly addressing the dataset bias is a critical next step. Future work s"
      },
      {
        "chunk_index": 14074,
        "paper_id": 284,
        "chunk_idx": 0,
        "title": "AU-HARNESS: AN OPEN-SOURCE TOOLKIT FOR HOLISTIC EVALUATION OF AUDIO-LLMS",
        "section_head": "AU-HARNESS",
        "score": 0.8985889554023743,
        "text_preview": "In response to the challenges existing in current audio understanding evaluation toolkits, we propose our standardized, efficient, highly customizable evaluation framework, AU-Harness, as detailed in "
      },
      {
        "chunk_index": 42930,
        "paper_id": 911,
        "chunk_idx": 0,
        "title": "Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models",
        "section_head": "Methodological Innovations",
        "score": 0.8984793424606323,
        "text_preview": "This study contributes several methodological innovations to the field of clinical NLP optimization: Comprehensive Optimization Framework. The systematic, phased approach provides a replicable methodo"
      },
      {
        "chunk_index": 36071,
        "paper_id": 763,
        "chunk_idx": 0,
        "title": "Distilling Many-Shot In-Context Learning into a Cheat Sheet",
        "section_head": "Conclusion",
        "score": 0.8977705240249634,
        "text_preview": "We introduced cheat-sheet ICL, which uses concise textual summaries distilled from many-shot demonstrations to leverage LLMs. This approach matched or exceeded the performance of many-shot ICL and ret"
      }
    ]
  },
  {
    "query_id": 91,
    "query_text": "taxonomy data risks",
    "source": "title",
    "source_value": "A Taxonomy of Data Risks in AI and Quantum Computing (QAI): A Systematic Review",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 5416,
        "paper_id": 93,
        "chunk_idx": 0,
        "title": "A Taxonomy of Data Risks in AI and Quantum Computing (QAI): A Systematic Review",
        "section_head": "Figure 2 :",
        "score": 0.9872119426727295,
        "text_preview": "2 Figure 2: Taxonomy of Data Privacy Risks."
      },
      {
        "chunk_index": 4939,
        "paper_id": 85,
        "chunk_idx": 0,
        "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers",
        "section_head": "Fig. 27 :",
        "score": 0.8692089319229126,
        "text_preview": "27 Fig. 27: Scientific data construction pipeline: multi-source data acquisition, data synthesis pipelines for pre-training, posttraining and evaluation stages, and comprehensive review framework inco"
      },
      {
        "chunk_index": 5159,
        "paper_id": 88,
        "chunk_idx": 0,
        "title": "A Survey on Data Security in Large Language Models",
        "section_head": "Table 1",
        "score": 0.8568874597549438,
        "text_preview": "1 Various studied risks on data security. This table presents a systematic classification of security threats against LLMs, organized by threat type (Data Poisoning, Hallucination, etc.), with corresp"
      },
      {
        "chunk_index": 5154,
        "paper_id": 88,
        "chunk_idx": 0,
        "title": "A Survey on Data Security in Large Language Models",
        "section_head": "Fig. 1 :",
        "score": 0.8360886573791504,
        "text_preview": "1 Fig. 1: Overview of the Survey Structure on LLMs Data Security, beginning with background and LLM vulnerabilities, then addressing data security risks, mitigation techniques, datasets, and concludin"
      },
      {
        "chunk_index": 13297,
        "paper_id": 266,
        "chunk_idx": 0,
        "title": "Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models",
        "section_head": "Methodology",
        "score": 0.8331352472305298,
        "text_preview": "Our experimental methodology is designed to provide rigorous, reproducible measurements of memorization risks in fine-tuned LLMs while evaluating the effectiveness of various privacy protection strate"
      },
      {
        "chunk_index": 16972,
        "paper_id": 344,
        "chunk_idx": 0,
        "title": "Benchmarking Robust Aggregation in Decentralized Gradient Marketplaces",
        "section_head": "Evaluation Methodology",
        "score": 0.8326579332351685,
        "text_preview": "Our benchmark mirrors the end-to-end lifecycle of a federated-gradient marketplace, from a buyer's root dataset to post-training economic settlement. This lifecycle is divided into three macro phases,"
      },
      {
        "chunk_index": 78735,
        "paper_id": 1662,
        "chunk_idx": 0,
        "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale",
        "section_head": "Table 2 :",
        "score": 0.8187875747680664,
        "text_preview": "2 Factors in the user preferences SocialCommunication, Contact, Data Types Data-general, MedicalHealth, Identifying, Location, Picture Purposes Internal, Advertisement, Analytics, Research, SNS, Prote"
      },
      {
        "chunk_index": 111235,
        "paper_id": 2313,
        "chunk_idx": 0,
        "title": "RAG Security and Privacy: Formalizing the Threat Model and Attack Surface",
        "section_head": "Fig. 2 .",
        "score": 0.8105958700180054,
        "text_preview": "2 Fig. 2. Taxonomy of Adversary Types"
      },
      {
        "chunk_index": 102365,
        "paper_id": 2124,
        "chunk_idx": 0,
        "title": "OS-DiffVSR: Towards One-step Latent Diffusion Model for High-detailed Real-world Video Super-Resolution",
        "section_head": "Table 3 .",
        "score": 0.8065558671951294,
        "text_preview": "3 Evaluation of the multi-frame adversarial training paradigm. ¬µ CLIP-IQA‚Üë MUSIQ‚Üë DOVER‚Üë E * warp ‚Üì 1.0 0.607 64.981 0.745 1.862 0.8 0.599 65.206 0.766 1.830 0.6 0.629 66.135 0.772 1.744 0.4 0.619 66."
      },
      {
        "chunk_index": 18424,
        "paper_id": 374,
        "chunk_idx": 1,
        "title": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation",
        "section_head": "Harmfulness Evaluator",
        "score": 0.8039146661758423,
        "text_preview": "Using a 0-5 scale: 0 = factually baseless content ( e.g., chemically invalid poison recipes); 5 = authoritative, accurate details ( e.g., complete phishing techniques). Criteria adapt dynamically to s"
      },
      {
        "chunk_index": 95436,
        "paper_id": 2019,
        "chunk_idx": 0,
        "title": "NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation",
        "section_head": "Figure 5 .",
        "score": 0.7846391201019287,
        "text_preview": "5 Figure 5. Topic-wise impacts on structural metrics evaluated through systematic topic weight manipulation."
      },
      {
        "chunk_index": 5027,
        "paper_id": 87,
        "chunk_idx": 0,
        "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks",
        "section_head": "3) Data Integrity and Authentication:",
        "score": 0.7816576361656189,
        "text_preview": "Trust establishment requires comprehensive verification mechanisms to ensure data authenticity and prevent tampering. Multi-layered authentication protocols safeguard against unauthorized modification"
      },
      {
        "chunk_index": 121158,
        "paper_id": 2524,
        "chunk_idx": 0,
        "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
        "section_head": "C. Security evaluation",
        "score": 0.7781929969787598,
        "text_preview": "This section assesses the effectiveness of SSVAX in defending against both untargeted and targeted data poisoning attacks, including comparisons with related approaches and considerations for potentia"
      },
      {
        "chunk_index": 151622,
        "paper_id": 3119,
        "chunk_idx": 0,
        "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning",
        "section_head": "Fig. 12 .",
        "score": 0.7754846215248108,
        "text_preview": "12 Fig. 12. Evaluation of three commonly used privacy-preserving techniques on defending against VTarbel while maintaining main task accuracy."
      },
      {
        "chunk_index": 132946,
        "paper_id": 2750,
        "chunk_idx": 0,
        "title": "SwissGPC v1.0 -The Swiss German Podcasts Corpus",
        "section_head": "Figure 1 :",
        "score": 0.7717368602752686,
        "text_preview": "1 Figure 1: Automated Data Annotation Pipeline"
      },
      {
        "chunk_index": 84659,
        "paper_id": 1781,
        "chunk_idx": 0,
        "title": "MARS: A Malignity-Aware Backdoor Defense in Federated Learning",
        "section_head": "Table 6 :",
        "score": 0.7715165019035339,
        "text_preview": "6 Impact of data distribution on the performance of exitsting defenses under 3DFed attack on CIFAR-10."
      },
      {
        "chunk_index": 157422,
        "paper_id": 3225,
        "chunk_idx": 0,
        "title": "œÑ¬≤-Bench (Average)",
        "section_head": "Figure 3 :",
        "score": 0.7702715396881104,
        "text_preview": "3 Figure 3: The data curation pipeline for cold-start training."
      },
      {
        "chunk_index": 127006,
        "paper_id": 2649,
        "chunk_idx": 0,
        "title": "Special-Character Adversarial Attacks on Open-Source Language Models",
        "section_head": "Evaluation Protocol and Metrics",
        "score": 0.7666769027709961,
        "text_preview": "Our evaluation protocol incorporates both automated and manual assessment components: Automated Evaluation: Our automated evaluation includes response classification using keyword-based heuristics, se"
      },
      {
        "chunk_index": 136784,
        "paper_id": 2827,
        "chunk_idx": 0,
        "title": "The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover",
        "section_head": "Figure 3 :",
        "score": 0.7649133205413818,
        "text_preview": "3 Figure 3: Attacks evaluation metrics across Direct Prompt Injection (DPI), RAG Backdoor Attack (RBA), Inter-Agent Trust Exploitation (IATE)."
      },
      {
        "chunk_index": 102037,
        "paper_id": 2120,
        "chunk_idx": 0,
        "title": "Orca 2: Teaching Small Language Models How to Reason",
        "section_head": "Synthetic data:",
        "score": 0.7599860429763794,
        "text_preview": "As Orca 2 is trained on synthetic data, it could inherit both the advantages and shortcomings of the models and methods used for data generation. We posit that Orca 2 benefits from the safety measures"
      }
    ]
  },
  {
    "query_id": 92,
    "query_text": "theory multi-agent generative",
    "source": "title",
    "source_value": "A Theory of Multi-Agent Generative Flow Networks",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 113871,
        "paper_id": 2376,
        "chunk_idx": 4,
        "title": "Residual Off-Policy RL for Finetuning Behavior Cloning Policies",
        "section_head": "* Work done while an intern at Amazon FAR ‚Ä† Work done while at Amazon FAR",
        "score": 0.9068847894668579,
        "text_preview": "Several works address these challenges [44] , [45] . IBRL [46] trains an imitation policy and then uses it to propose actions for exploration and to bootstrap target values. PA-RL [30] sidesteps apply"
      },
      {
        "chunk_index": 34780,
        "paper_id": 735,
        "chunk_idx": 3,
        "title": "Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors",
        "section_head": "‚Ä† Corresponding Author",
        "score": 0.8977841138839722,
        "text_preview": "In particular, offline RL has revolutionized healthcare applications [15] - [17] , by enabling intervention optimization using pre-collected data, and minimizing the need for direct environmental inte"
      },
      {
        "chunk_index": 30274,
        "paper_id": 632,
        "chunk_idx": 3,
        "title": "Data-driven generative simulation of SDEs using diffusion models",
        "section_head": "Introduction",
        "score": 0.8945019841194153,
        "text_preview": "In terms of financial applications, a recent working paper [1] applies generative diffusion models to simulate high-dimensional asset returns and concludes that generated data improves the accuracy of"
      },
      {
        "chunk_index": 120051,
        "paper_id": 2499,
        "chunk_idx": 0,
        "title": "ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion",
        "section_head": "Figure 1 .",
        "score": 0.8876686692237854,
        "text_preview": "1 Figure 1. Comparison of current methods and the proposed ScoreHOI. (a) Optimization-based methods iteratively refine predicted outcomes with the physical objectives. (b) Regressionbased methods upda"
      },
      {
        "chunk_index": 110578,
        "paper_id": 2296,
        "chunk_idx": 1,
        "title": "Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures",
        "section_head": "I. Introduction",
        "score": 0.8635701537132263,
        "text_preview": "Such heuristics struggle to adapt to the evolving generative state across timesteps, noise levels, and prompts. Empirically, the optimal w t depends on the instantaneous signal-to-noise ratio, model c"
      },
      {
        "chunk_index": 20382,
        "paper_id": 413,
        "chunk_idx": 2,
        "title": "BRANCHGRPO: STABLE AND EFFICIENT GRPO WITH STRUCTURED BRANCHING IN DIFFUSION MODELS",
        "section_head": "E ADDITIONAL EXPERIMENTS E.1 MORE QUANTITATIVE RESULT",
        "score": 0.8551152944564819,
        "text_preview": "Instead of fixed hyperparameters, one can design adaptive policies that adjust branch factor, correlation, or pruning windows on-the-fly based on sample difficulty or intermediate rewards, enabling mo"
      },
      {
        "chunk_index": 41182,
        "paper_id": 868,
        "chunk_idx": 0,
        "title": "Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning",
        "section_head": "Related Work",
        "score": 0.8541827201843262,
        "text_preview": "Our work is situated at the intersection of motion prediction for autonomous driving and the rapidly evolving field of generative modeling. We build upon foundational concepts in scene understanding a"
      },
      {
        "chunk_index": 105813,
        "paper_id": 2196,
        "chunk_idx": 0,
        "title": "PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models",
        "section_head": "PIRF: Physics-Informed Reward Fine-Tuning",
        "score": 0.8531558513641357,
        "text_preview": "Motivated by recent work on text-to-image diffusion alignment [18, 26] , we introduce reward finetuning into the physics-informed setting, termed as Physics-Informed Reward Fine-Tuning (PIRF)."
      },
      {
        "chunk_index": 105811,
        "paper_id": 2196,
        "chunk_idx": 1,
        "title": "PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models",
        "section_head": "Casting prior works as reward-based paradigms",
        "score": 0.8523112535476685,
        "text_preview": "Recent work [16] connects such methods to value-weighted sampling [4, 19] , where the mean of the reverse transition is modified using the gradient of a value function: ŒºŒ∏ (x t , t) = ¬µ base Œ∏ (x t , "
      },
      {
        "chunk_index": 85771,
        "paper_id": 1807,
        "chunk_idx": 1,
        "title": "MEANFLOWSE: ONE-STEP GENERATIVE SPEECH ENHANCEMENT VIA CONDITIONAL MEAN FLOW",
        "section_head": "INTRODUCTION",
        "score": 0.8502223491668701,
        "text_preview": "Several efforts aim to mitigate this issue: CDiffuSE employs conditional reverse sampling to improve fidelity, yet still relies on long sampling chains [8] ; SGMSE stabilizes complex spectral synthesi"
      },
      {
        "chunk_index": 45535,
        "paper_id": 972,
        "chunk_idx": 0,
        "title": "ExMolRL: Phenotype-Target Joint Generation of De Novo Molecules via Multi-Objective Reinforcement Learning",
        "section_head": "Phenotype-Target Joint Generation",
        "score": 0.8460169434547424,
        "text_preview": "To jointly optimize phenotypic efficacy and target binding, we cast phenotype-and target-based molecular generation as a reinforcement learning (RL) problem. Specifically, the trained phenotypic gener"
      },
      {
        "chunk_index": 59963,
        "paper_id": 1278,
        "chunk_idx": 0,
        "title": "GENERATIVE DIFFUSION CONTRASTIVE NETWORK FOR MULTI-VIEW CLUSTERING",
        "section_head": "CONCLUSION AND FUTURE WORK",
        "score": 0.8453717231750488,
        "text_preview": "This paper proposes a novel Stochastic Generative Diffusion Fusion (SGDF) method to address the problem of low-quality data. Based on the SGDF module, we present the Generative Diffusion Contrastive N"
      },
      {
        "chunk_index": 115667,
        "paper_id": 2413,
        "chunk_idx": 1,
        "title": "Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs",
        "section_head": "B Related Work",
        "score": 0.8364654779434204,
        "text_preview": "These methods established a strong foundation for leveraging iterative masked-decoding strategies, paving the way for diffusion models to exploit non-autoregressive properties effectively. Reward-Weig"
      },
      {
        "chunk_index": 55668,
        "paper_id": 1192,
        "chunk_idx": 1,
        "title": "FlowDrive: Energy Flow Field for End-to-End Autonomous Driving",
        "section_head": "End-to-End Autonomous Driving",
        "score": 0.8355693817138672,
        "text_preview": "Hydra-MDP [26] and Hydra-MDP++ [23] refine this paradigm by introducing trajectory clustering and rulebased scorers to balance efficiency with diversity and safety. Generation-based methods, by contra"
      },
      {
        "chunk_index": 56379,
        "paper_id": 1212,
        "chunk_idx": 2,
        "title": "FRICTIONAL Q-LEARNING",
        "section_head": "INTRODUCTION",
        "score": 0.8351622819900513,
        "text_preview": "In the same principle, the shift of visitation distribution between the true MDP and the replay buffer can be viewed as the angle of a slope. Just as physical friction slows motion and prevents uncont"
      },
      {
        "chunk_index": 120002,
        "paper_id": 2498,
        "chunk_idx": 1,
        "title": "Score Matching on Large Geometric Graphs for Cosmology Generation",
        "section_head": "Conclusion",
        "score": 0.8318150043487549,
        "text_preview": "The combination of physically grounded priors, symmetry preservation, and a novel topology-aware noise schedule constitutes a principled advancement in the design of generative models for cosmology, b"
      },
      {
        "chunk_index": 19692,
        "paper_id": 399,
        "chunk_idx": 0,
        "title": "Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising",
        "section_head": "Contributions.",
        "score": 0.8300643563270569,
        "text_preview": "Our contributions can be summarized as follows: ‚Ä¢ We introduce the first dual-branch diffusion framework for self-supervised denoising, tailored for real-world applications. ‚Ä¢ We combine BSN-based and"
      },
      {
        "chunk_index": 91157,
        "paper_id": 1920,
        "chunk_idx": 0,
        "title": "Monte Carlo Tree Diffusion with Multiple Experts for Protein Design",
        "section_head": "Discrete Diffusion for Planning and Generation",
        "score": 0.8296820521354675,
        "text_preview": "While originally developed for continuous domains, diffusion models have been successfully adapted to discrete sequence generation and planning. D3PM [1] introduced absorbing-state (masking) noise for"
      },
      {
        "chunk_index": 77671,
        "paper_id": 1643,
        "chunk_idx": 0,
        "title": "Learning Terrain-Specialized Policies for Adaptive Locomotion in Challenging Environments",
        "section_head": "A. Background",
        "score": 0.8290345668792725,
        "text_preview": "Before presenting our terrain-specialized locomotion approach, we first describe the baseline formulation of a single policy, following standard RL-based control [14] . The task is modeled as a partia"
      },
      {
        "chunk_index": 110582,
        "paper_id": 2296,
        "chunk_idx": 1,
        "title": "Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures",
        "section_head": "II. Related Work",
        "score": 0.8279590606689453,
        "text_preview": "In practice, policy gradient methods such as Proximal Policy Optimization (PPO) and variance-reduced estimators such as Generalized Advantage Estimation (GAE) provide stable, sample-efficient updates "
      }
    ]
  },
  {
    "query_id": 93,
    "query_text": "traditional approach symbolic",
    "source": "title",
    "source_value": "A TRADITIONAL APPROACH TO SYMBOLIC PIANO CONTINUATION",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 41577,
        "paper_id": 876,
        "chunk_idx": 0,
        "title": "EIGEN-1: ADAPTIVE MULTI-AGENT REFINE-MENT WITH MONITOR-BASED RAG FOR SCIENTIFIC REASONING",
        "section_head": "Accuracy Increase",
        "score": 0.9678598642349243,
        "text_preview": "Eigen-1 Baseline+RAG flow, our framework addresses key limitations of prior approaches in complex scientific problem solving. Future work will extend these principles to additional scientific domains,"
      },
      {
        "chunk_index": 112248,
        "paper_id": 2339,
        "chunk_idx": 0,
        "title": "Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning",
        "section_head": "Conclusion",
        "score": 0.9577033519744873,
        "text_preview": "We introduced Reasoning Core, a library of scalable RL environments targeting fundamental symbolic reasoning capacities in LLMs. By focusing on high-generality tasks like PDDL planning and first-order"
      },
      {
        "chunk_index": 70121,
        "paper_id": 1495,
        "chunk_idx": 0,
        "title": "Intelligent Healthcare Imaging Platform: An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation",
        "section_head": "Fallback Parsing",
        "score": 0.943055272102356,
        "text_preview": "Implements alternative parsing methods for non-standard responses."
      },
      {
        "chunk_index": 4089,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Advantages of FRL",
        "score": 0.9373971223831177,
        "text_preview": "FRL offers several significant advantages over traditional RL approaches, particularly in distributed and privacy-sensitive applications. These advantages directly address critical challenges in imple"
      },
      {
        "chunk_index": 146295,
        "paper_id": 3015,
        "chunk_idx": 0,
        "title": "Understanding the planning of LLM agents: A survey",
        "section_head": "External Planner-Aided Planning",
        "score": 0.9370365738868713,
        "text_preview": "Despite the powerful reasoning and task decomposition capabilities exhibited by Large Language Models (LLMs), challenges arise when confronted with environments featuring intricate constraints, such a"
      },
      {
        "chunk_index": 89314,
        "paper_id": 1880,
        "chunk_idx": 0,
        "title": "Mixture of Length and Pruning Experts for Knowledge Graphs Reasoning",
        "section_head": "Path-based Methods for KGs Reasoning",
        "score": 0.9353768229484558,
        "text_preview": "Path-based reasoning methods aim to construct effective reasoning paths for predicting answer entities through the query function Q(e q , r q ) = e a . These methods can be broadly categorized into tr"
      },
      {
        "chunk_index": 8514,
        "paper_id": 164,
        "chunk_idx": 1,
        "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare",
        "section_head": "LIMITATIONS AND FUTURE WORKS",
        "score": 0.9319871664047241,
        "text_preview": "Future work needs to establish a more rigorous verification process involving manual domain experts to assess answer correctness, the validity of reasoning steps, and potential hallucinations. ‚Ä¢ A dee"
      },
      {
        "chunk_index": 131713,
        "paper_id": 2726,
        "chunk_idx": 1,
        "title": "STYLEBENCH: EVALUATING THINKING STYLES IN LARGE LANGUAGE MODELS",
        "section_head": "CONCLUSION",
        "score": 0.9273480176925659,
        "text_preview": "These results provide a practical framework for optimal strategy selection: search-based methods (ToT, AoT) excel for complex, open-ended problems (e.g., Game24) with capable models, while concise app"
      },
      {
        "chunk_index": 4189,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Hybrid and Advanced Methods",
        "score": 0.9235613346099854,
        "text_preview": "Hybrid methods combine value-based and policy-based techniques, while advanced methods integrate game-theoretic principles, meta-learning, or curriculum learning."
      },
      {
        "chunk_index": 9162,
        "paper_id": 175,
        "chunk_idx": 1,
        "title": "AIssistant: An Agentic Approach for Human-AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning",
        "section_head": "VII. CONCLUSION",
        "score": 0.9219743013381958,
        "text_preview": "As noted in the Limitations and Ethical Considerations sections, challenges persist, including hallucinations, adapting document structures, and the need for formalized review mechanisms. Future work "
      },
      {
        "chunk_index": 150568,
        "paper_id": 3093,
        "chunk_idx": 0,
        "title": "Vision as LoRA",
        "section_head": "Method",
        "score": 0.918497622013092,
        "text_preview": "Posters Celebrity Landmark Artwork Total niques. Finally, although VoRA underperformed on world knowledge tasks, this reflects data limitations rather than architectural constraints, and could be reso"
      },
      {
        "chunk_index": 715,
        "paper_id": 14,
        "chunk_idx": 0,
        "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
        "section_head": "Discussion and Limitations",
        "score": 0.9107533693313599,
        "text_preview": "Hallucination mitigation in LLMs represents a multifaceted challenge addressed through a spectrum of innovative techniques. The methodologies discussed, ranging from post-generation refinement to supe"
      },
      {
        "chunk_index": 65328,
        "paper_id": 1391,
        "chunk_idx": 1,
        "title": "HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs",
        "section_head": "Medical LLMs",
        "score": 0.9092421531677246,
        "text_preview": "Enhancing Reasoning in LLMs Chain-of-Thought (CoT) prompting enhances the reasoning capabilities of LLMs [60, 61] , but scaling expert-labeled reasoning paths remains costly, especially for complex pr"
      },
      {
        "chunk_index": 36071,
        "paper_id": 763,
        "chunk_idx": 0,
        "title": "Distilling Many-Shot In-Context Learning into a Cheat Sheet",
        "section_head": "Conclusion",
        "score": 0.9073224067687988,
        "text_preview": "We introduced cheat-sheet ICL, which uses concise textual summaries distilled from many-shot demonstrations to leverage LLMs. This approach matched or exceeded the performance of many-shot ICL and ret"
      },
      {
        "chunk_index": 70265,
        "paper_id": 1498,
        "chunk_idx": 0,
        "title": "Interactive Recommendation Agent with Active User Commands",
        "section_head": "Multi-Agent Optimization",
        "score": 0.9040497541427612,
        "text_preview": "The Parser and Planner agents face highly complex personalized reasoning and decision-making tasks involving ambiguous user command parsing, multi-turn preference state maintenance, and adaptive tool "
      },
      {
        "chunk_index": 12513,
        "paper_id": 247,
        "chunk_idx": 0,
        "title": "AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data",
        "section_head": "Conclusion and Future Work",
        "score": 0.9037942886352539,
        "text_preview": "In this paper, we presented AraTable, a question answering benchmark for use with Arabic tabular data. The benchmark provides a framework for evaluating LLMs on three distinct QA tasks: direct extract"
      },
      {
        "chunk_index": 89340,
        "paper_id": 1880,
        "chunk_idx": 0,
        "title": "Mixture of Length and Pruning Experts for Knowledge Graphs Reasoning",
        "section_head": "Limitations",
        "score": 0.9033294916152954,
        "text_preview": "While MoKGR demonstrates significant improvements in knowledge graph reasoning performance, several limitations should be acknowledged: First, the computational complexity of our method, though signif"
      },
      {
        "chunk_index": 85613,
        "paper_id": 1802,
        "chunk_idx": 0,
        "title": "MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models",
        "section_head": "Theoretical Significance",
        "score": 0.9013679027557373,
        "text_preview": "The MCP framework verifies for the first time at the theoretical level the feasibility of integrating control theory and large-model dynamic reasoning, constructs a new paradigm for interdisciplinary "
      },
      {
        "chunk_index": 105672,
        "paper_id": 2192,
        "chunk_idx": 1,
        "title": "PIMOE: TOKEN-LEVEL ROUTING FOR INTEGRATING HIGH-PRECISION COMPUTATION AND REASONING",
        "section_head": "Conclusion and Future Work",
        "score": 0.901094913482666,
        "text_preview": "Future research will focus on three main directions: first, extending a single expert to multiple logically composable experts to support the alternating invocation of more complex high-precision nume"
      },
      {
        "chunk_index": 112940,
        "paper_id": 2354,
        "chunk_idx": 0,
        "title": "ReFT: Representation Finetuning for Language Models",
        "section_head": "B Describing existing methods under the ReFT framework",
        "score": 0.9010107517242432,
        "text_preview": "To show the expressivity of the ReFT framework, we cast existing representing-editing methods in the literature into ReFTs."
      }
    ]
  },
  {
    "query_id": 94,
    "query_text": "unified approach interpreting",
    "source": "title",
    "source_value": "A Unified Approach to Interpreting Model Predictions",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 42904,
        "paper_id": 911,
        "chunk_idx": 0,
        "title": "Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models",
        "section_head": "Optimization Strategy",
        "score": 0.9453222751617432,
        "text_preview": "The optimization process followed a systematic approach encompassing multiple dimensions of model enhancement:"
      },
      {
        "chunk_index": 20015,
        "paper_id": 406,
        "chunk_idx": 0,
        "title": "Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems",
        "section_head": "Methodoglogy",
        "score": 0.9278716444969177,
        "text_preview": "This section begins by presenting the widely used spoof crosstesting evaluation framework. We then propose an extension to this framework, incorporating bona fide cross-testing, and provide justificat"
      },
      {
        "chunk_index": 95097,
        "paper_id": 2012,
        "chunk_idx": 0,
        "title": "Neural Scene Designer: Self-Styled Semantic Image Manipulation",
        "section_head": "III. METHOD",
        "score": 0.9202406406402588,
        "text_preview": "Neural Scene Designer (NSD) builds upon an advanced diffusion model, incorporating two parallel cross-attention mechanisms to seamlessly integrate both textual and stylistic information. This ensures "
      },
      {
        "chunk_index": 86849,
        "paper_id": 1830,
        "chunk_idx": 0,
        "title": "Memorization Ã∏ = Understanding: Do Large Language Models Have the Ability of Scenario Cognition?",
        "section_head": "Methods",
        "score": 0.9174113273620605,
        "text_preview": "To systematically evaluate LLMs' scene cognition capabilities, we propose a bi-perspective evaluation framework both from the perspective of model outputs and internal representations. An overall fram"
      },
      {
        "chunk_index": 75680,
        "paper_id": 1598,
        "chunk_idx": 0,
        "title": "Large Language Models Understand and Can Be Enhanced by Emotional Stimuli",
        "section_head": "Figure 1 :",
        "score": 0.9120337963104248,
        "text_preview": "1 Figure 1: An overview of our research from generating to evaluating EmotionPrompt."
      },
      {
        "chunk_index": 117087,
        "paper_id": 2447,
        "chunk_idx": 4,
        "title": "RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing",
        "section_head": "Introduction",
        "score": 0.911868155002594,
        "text_preview": "The key contributions of our work are summarized as follows: ‚Ä¢ We propose an innovative semi-automated 3D vision data acquisition pipeline comprising four critical stages: RGB and depth data capture, "
      },
      {
        "chunk_index": 104923,
        "paper_id": 2176,
        "chunk_idx": 2,
        "title": "PersonaVlog: Personalized Multimodal Vlog Generation with Multi-Agent Collaboration and Iterative Self-Correction",
        "section_head": "Introduction",
        "score": 0.9104132652282715,
        "text_preview": "To systematically address the above challenges, we propose PersonaVlog, an automated multimodal stylized Vlog generation framework that can produce personalized Vlogs featuring videos, background musi"
      },
      {
        "chunk_index": 11648,
        "paper_id": 227,
        "chunk_idx": 0,
        "title": "Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems",
        "section_head": "Annotating Data for Feedback Generation",
        "score": 0.9089951515197754,
        "text_preview": "In this section, we introduce our framework for annotating English learner writing data to facilitate educational feedback comment generation tasks. We first review previous error typologies and annot"
      },
      {
        "chunk_index": 34929,
        "paper_id": 738,
        "chunk_idx": 0,
        "title": "DiffVL: Diffusion-Based Visual Localization on 2D Maps via BEV-Conditioned GPS Denoising",
        "section_head": "V. CONCLUSION",
        "score": 0.9075050354003906,
        "text_preview": "In this paper, we introduced DiffVL, a novel framework that pioneers a new paradigm for visual localization by reformulating the task as a conditional GPS denoising problem. Our core contribution is t"
      },
      {
        "chunk_index": 28110,
        "paper_id": 577,
        "chunk_idx": 0,
        "title": "Contextualized Multimodal Lifelong Person Re-Identification in Hybrid Clothing States",
        "section_head": "Method",
        "score": 0.9070332050323486,
        "text_preview": "We propose Contextualized Multimodal Lifelong Re-ID (CMLReID), a novel framework designed to tackle the LReID-Hybrid task by effectively fusing visual and textual modalities through a context-aware kn"
      },
      {
        "chunk_index": 27375,
        "paper_id": 560,
        "chunk_idx": 0,
        "title": "ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation",
        "section_head": "Conclusion",
        "score": 0.9069373607635498,
        "text_preview": "ComposeMe introduces a novel and effective approach for finegrained, controllable human image generation. By the proposed Attribute-Specific Image Prompts, our method enables composable synthesis from"
      },
      {
        "chunk_index": 57114,
        "paper_id": 1225,
        "chunk_idx": 0,
        "title": "From Prompt to Progression: Taming Video Diffusion Models for Seamless Attribute Transition",
        "section_head": "Conclusion",
        "score": 0.9069157838821411,
        "text_preview": "We present a simple yet effective approach for video generation with smooth attribute transitions. Our method introduces a transitional direction to guide the sampling process during denoising, ensuri"
      },
      {
        "chunk_index": 14062,
        "paper_id": 284,
        "chunk_idx": 3,
        "title": "AU-HARNESS: AN OPEN-SOURCE TOOLKIT FOR HOLISTIC EVALUATION OF AUDIO-LLMS",
        "section_head": "INTRODUCTION",
        "score": 0.9058387279510498,
        "text_preview": "In addition, we also provide the support for LLM-adaptive diarization evaluation where LLM prompting results in different I/O. To the best of our understanding, our proposed evaluation kit is among th"
      },
      {
        "chunk_index": 145106,
        "paper_id": 2989,
        "chunk_idx": 3,
        "title": "UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward",
        "section_head": "Figure 2",
        "score": 0.9056816101074219,
        "text_preview": "This is then scaled to a multi-identity context by formulating a bipartite graph between multiple references and generated identities, and optimizing the global matching score to achieve the optimal a"
      },
      {
        "chunk_index": 88867,
        "paper_id": 1869,
        "chunk_idx": 3,
        "title": "Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets",
        "section_head": "Introduction",
        "score": 0.9049044847488403,
        "text_preview": "GOAT achieves probability distribution alignment through intrinsic reinforcement learning, offering a novel perspective for the optimization of LM-based TTS models. Our contributions are highlighted a"
      },
      {
        "chunk_index": 7127,
        "paper_id": 132,
        "chunk_idx": 0,
        "title": "Adaptive Graph Convolution and Semantic-Guided Attention for Multimodal Risk Detection in Social Networks",
        "section_head": "IV. CONCLUSION",
        "score": 0.9042395353317261,
        "text_preview": "The multimodal dangerous tendency user identification algorithm in this paper integrates natural language processing and graph neural networks into a collaborative detection framework. This framework "
      },
      {
        "chunk_index": 67873,
        "paper_id": 1447,
        "chunk_idx": 0,
        "title": "Improving French Synthetic Speech Quality via SSML Prosody Control",
        "section_head": "Figure 2 :",
        "score": 0.9039541482925415,
        "text_preview": "2 Figure 2: Cascaded LLM approach for automated text-to-SSML generation: QwenA predicts tag placement, QwenB injects prosodic values. This disentangled design enables accurate and efficient prosody co"
      },
      {
        "chunk_index": 77894,
        "paper_id": 1647,
        "chunk_idx": 0,
        "title": "Learning to Generate 4D LiDAR Sequences",
        "section_head": "LiDARCrafter: 4D LiDAR World Model",
        "score": 0.9020825028419495,
        "text_preview": "We introduce LiDARCrafter, the first generative world model dedicated to LiDAR, which transforms free-form instructions into temporally coherent 4D point cloud sequences with object-level control. The"
      },
      {
        "chunk_index": 42551,
        "paper_id": 901,
        "chunk_idx": 0,
        "title": "Enabling Federated Object Detection for Connected Autonomous Vehicles: A Deployment-Oriented Evaluation",
        "section_head": "Fig. 3 :",
        "score": 0.9018920063972473,
        "text_preview": "3 Fig. 3: Evaluation Framework Design"
      },
      {
        "chunk_index": 105018,
        "paper_id": 2178,
        "chunk_idx": 0,
        "title": "pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models",
        "section_head": "Proposed Method",
        "score": 0.9011924862861633,
        "text_preview": "In this section, we introduce pFedMMA, a novel framework that leverages multi-modal adapters to efficiently and effectively adapt large pre-trained VLMs under federated learning settings. Our design c"
      }
    ]
  },
  {
    "query_id": 95,
    "query_text": "unified framework diffusion",
    "source": "title",
    "source_value": "A UNIFIED FRAMEWORK FOR DIFFUSION MODEL UNLEARNING WITH F-DIVERGENCE",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 30861,
        "paper_id": 644,
        "chunk_idx": 0,
        "title": "DCDB: Dynamic Conditional Dual Diffusion Bridge for Ill-posed Multi-Tasks",
        "section_head": "Figure 1 :",
        "score": 0.9562759399414062,
        "text_preview": "1 Figure 1: Our proposed dynamic conditional double diffusion bridge training paradigm."
      },
      {
        "chunk_index": 35565,
        "paper_id": 752,
        "chunk_idx": 0,
        "title": "DISCRETE DIFFUSION FOR REFLECTIVE VISION-LANGUAGE-ACTION MODELS IN AUTONOMOUS DRIVING",
        "section_head": "METHOD",
        "score": 0.9314482808113098,
        "text_preview": "In this section, we present ReflectDrive, a novel learning-based framework that integrates a reflection mechanism to facilitate safe trajectory generation via discrete diffusion, as illustrated in Fig"
      },
      {
        "chunk_index": 17946,
        "paper_id": 366,
        "chunk_idx": 0,
        "title": "Beyond Negative Transfer: Disentangled Preference-Guided Diffusion for Cross-Domain Sequential Recommendation",
        "section_head": "Methodology",
        "score": 0.9286723136901855,
        "text_preview": "This section introduces the proposed DPG-Diff framework for Cross-Domain Sequential Recommendation (CDSR). As shown in Fig. 2 , DPG-Diff establishes a novel generative paradigm that integrates disenta"
      },
      {
        "chunk_index": 155611,
        "paper_id": 3192,
        "chunk_idx": 0,
        "title": "WORLDFORGE: UNLOCKING EMERGENT 3D/4D GENERATION IN VIDEO DIFFUSION MODEL VIA TRAINING-FREE GUIDANCE",
        "section_head": "PROPOSED METHODS",
        "score": 0.9212088584899902,
        "text_preview": "We address the challenge of balancing controllability, visual fidelity, and generalization when applying video diffusion models (VDMs) to 3D/4D tasks. Our solution is a training-free framework for tra"
      },
      {
        "chunk_index": 151958,
        "paper_id": 3131,
        "chunk_idx": 0,
        "title": "WAVELETGAUSSIAN: WAVELET-DOMAIN DIFFUSION FOR SPARSE-VIEW 3D GAUSSIAN OBJECT RECONSTRUCTION",
        "section_head": "Fig. 1 .",
        "score": 0.9157944321632385,
        "text_preview": "1 Fig. 1. We propose WaveletGaussian, a framework for sparse-view 3D Gaussian object reconstruction based on wavelet-domain diffusion model repair, which significantly reduces training time while bett"
      },
      {
        "chunk_index": 5183,
        "paper_id": 89,
        "chunk_idx": 4,
        "title": "A Survey on Diffusion Language Models",
        "section_head": "Continuous Diffusion Language Models",
        "score": 0.9146075248718262,
        "text_preview": "InfoDiffusion [55] introduces an information entropy-aware noise schedule to guide the model toward a more humanlike \"keyinfo-first\" process that prioritizes generating core content. EDDPMs [56] unify"
      },
      {
        "chunk_index": 75111,
        "paper_id": 1592,
        "chunk_idx": 0,
        "title": "Large Language Models for Generative Information Extraction: A Survey",
        "section_head": "Structural Output",
        "score": 0.9109103679656982,
        "text_preview": "Task-specialized Framework Universal Framework"
      },
      {
        "chunk_index": 117603,
        "paper_id": 2458,
        "chunk_idx": 0,
        "title": "SAGE: SEMANTIC-AWARE SHARED SAMPLING FOR EFFICIENT DIFFUSION",
        "section_head": "METHODS",
        "score": 0.9105360507965088,
        "text_preview": "We first revisit standard diffusion formulations. Building on this, we introduce SAGE, which integrates (i) a semanticaware shared sampling scheme to reduce sampling steps, and (ii) a tailored trainin"
      },
      {
        "chunk_index": 111145,
        "paper_id": 2310,
        "chunk_idx": 0,
        "title": "Radiology Report-Conditional 3D CT Generation with Multi-Encoder Latent-diffusion Model",
        "section_head": "Text Conditioning",
        "score": 0.9051762223243713,
        "text_preview": "Our Report2CT framework follows the text-conditioning principles of latent diffusion models (e.g., Stable Diffusion 1 ), extending the 3D U-Net denoiser with cross-attention mechanisms that allow the "
      },
      {
        "chunk_index": 22088,
        "paper_id": 453,
        "chunk_idx": 0,
        "title": "CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration",
        "section_head": "CARINOX: Reward-Guided Noise Optimization and Exploration",
        "score": 0.9042036533355713,
        "text_preview": "We introduce CARINOX, a framework that enhances compositional alignment in text-to-image diffusion models through inference-time guidance. The approach integrates two key components: (i) a unified str"
      },
      {
        "chunk_index": 34929,
        "paper_id": 738,
        "chunk_idx": 0,
        "title": "DiffVL: Diffusion-Based Visual Localization on 2D Maps via BEV-Conditioned GPS Denoising",
        "section_head": "V. CONCLUSION",
        "score": 0.9041415452957153,
        "text_preview": "In this paper, we introduced DiffVL, a novel framework that pioneers a new paradigm for visual localization by reformulating the task as a conditional GPS denoising problem. Our core contribution is t"
      },
      {
        "chunk_index": 69420,
        "paper_id": 1478,
        "chunk_idx": 0,
        "title": "InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System",
        "section_head": "Conclusion",
        "score": 0.9027470350265503,
        "text_preview": "In this paper, we introduce InstaDA, a dual-agent framework. The T-Agent generates highly diverse data by pioneering a Prompt Rethink feedback loop between LLMs and diffusion models, while the I-Agent"
      },
      {
        "chunk_index": 129781,
        "paper_id": 2695,
        "chunk_idx": 0,
        "title": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models",
        "section_head": "Figure 3 :",
        "score": 0.9012740850448608,
        "text_preview": "3 Figure 3: The Framework of Diffusion Model"
      },
      {
        "chunk_index": 57480,
        "paper_id": 1232,
        "chunk_idx": 0,
        "title": "FROM TEXT TO TALK: AUDIO-LANGUAGE MODEL NEEDS NON-AUTOREGRESSIVE JOINT TRAINING",
        "section_head": "JOINT TEXT-AR & AUDIO-NAR MODEL",
        "score": 0.8991702795028687,
        "text_preview": "In this section, we introduce our proposed model, integrates AR generation for text and discrete diffusion for audio within a single, unified Transformer architecture."
      },
      {
        "chunk_index": 19691,
        "paper_id": 399,
        "chunk_idx": 3,
        "title": "Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising",
        "section_head": "Introduction",
        "score": 0.8982264995574951,
        "text_preview": "Second, building on the theoretical framework of Classifier-Free Guidance (CFG), we propose a semi-clean guidance mechanism that dynamically adjusts score estimates during sampling, enabling direction"
      },
      {
        "chunk_index": 120677,
        "paper_id": 2512,
        "chunk_idx": 0,
        "title": "Seedream 4.0: Toward Next-generation Multimodal Image Generation",
        "section_head": "Model Acceleration",
        "score": 0.895572304725647,
        "text_preview": "Efficient, High-Quality Synthesis. Our acceleration framework integrates principles from Hyper-SD [17] , RayFlow [19] , APT [10] , and ADM [13] to accelerate Diffusion Transformers (DiTs). Our approac"
      },
      {
        "chunk_index": 112126,
        "paper_id": 2335,
        "chunk_idx": 0,
        "title": "Realism Control One-step Diffusion for Real-World Image Super-Resolution",
        "section_head": "Conclusion",
        "score": 0.8954085111618042,
        "text_preview": "We propose RCOD, a framework that enhances one-step diffusion methods for Real-ISR through flexible realism"
      },
      {
        "chunk_index": 59296,
        "paper_id": 1261,
        "chunk_idx": 0,
        "title": "GenCAD-Three-Dimensional: Computer-Aided Design Program Generation Using Multimodal Latent Space Alignment and Synthetic Dataset Balancing",
        "section_head": "Representation Learning Architecture",
        "score": 0.8953977823257446,
        "text_preview": "Our framework is inspired by the GenCAD architecture [11] , which proposes a conditional latent diffusion model to create CAD programs from image inputs. We extend this method to 3D input modalities u"
      },
      {
        "chunk_index": 5232,
        "paper_id": 89,
        "chunk_idx": 2,
        "title": "A Survey on Diffusion Language Models",
        "section_head": "Conventional NLP Tasks",
        "score": 0.8930593132972717,
        "text_preview": "Edi-Text [107] introduces a controllable coarse-to-fine text edit- ing framework by integrating an SDEdit-based technique with a novel self-conditioning method for precise editing control. To generate"
      },
      {
        "chunk_index": 76810,
        "paper_id": 1625,
        "chunk_idx": 4,
        "title": "LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations",
        "section_head": "Introduction",
        "score": 0.8921197652816772,
        "text_preview": "By operating in latent space, LD-ViCE significantly reduces computational cost while maintaining temporal coherence and visual fidelity. LD-ViCE integrates model feedback throughout generation, ensuri"
      }
    ]
  },
  {
    "query_id": 96,
    "query_text": "video worth tokens",
    "source": "title",
    "source_value": "A Video Is Worth 4096 Tokens: Verbalize Videos To Understand Them In Zero Shot",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 139271,
        "paper_id": 2869,
        "chunk_idx": 0,
        "title": "THINK BEFORE YOU SPEAK: TRAINING LANGUAGE MODELS WITH PAUSE TOKENS",
        "section_head": "Table 2 :",
        "score": 0.9436460733413696,
        "text_preview": "2 Prepending vs. appending the pause tokens ( ¬ß5). We observe that prepending the pause tokens still outperforms the standard training baseline of StdPT StdFT, but is suboptimal to appending the <paus"
      },
      {
        "chunk_index": 105163,
        "paper_id": 2182,
        "chunk_idx": 1,
        "title": "PHENAKI: VARIABLE LENGTH VIDEO GENERATION FROM OPEN DOMAIN TEXTUAL DESCRIPTIONS",
        "section_head": "VIDEO ENCODING",
        "score": 0.9293282628059387,
        "text_preview": "Results in Table 3 show that perframe image based methods slightly outperform our video method (indicated by marginally higher FID of C-ViViT ), however, they do poorly at modeling the spatio-temporal"
      },
      {
        "chunk_index": 38961,
        "paper_id": 821,
        "chunk_idx": 0,
        "title": "DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment",
        "section_head": "Experimental Setup",
        "score": 0.9111450910568237,
        "text_preview": "Pre-processing: For speech input, we use the raw 16 bit 16kHz mono-channel audio. We filter out examples with a number of frames higher than 480k or less than 1k. For the text input, we remove punctua"
      },
      {
        "chunk_index": 145094,
        "paper_id": 2988,
        "chunk_idx": 0,
        "title": "UMA-SPLIT: UNIMODAL AGGREGATION FOR BOTH ENGLISH AND MANDARIN NON-AUTOREGRESSIVE SPEECH RECOGNITION",
        "section_head": "UMA-Split Analysis",
        "score": 0.8899309635162354,
        "text_preview": "Table 1 presents UMA-Split model statistics across different configurations. On AISHELL-1, each token corresponds to a complete syllable. Even with the split module, UMA-aggregated frames still belong"
      },
      {
        "chunk_index": 38976,
        "paper_id": 821,
        "chunk_idx": 0,
        "title": "DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment",
        "section_head": "Figure 1 :",
        "score": 0.8871908187866211,
        "text_preview": "1 Figure 1: We show an example alignment from DTW (Ours) vs. CMOT. The figure shows that unlike CMOT, DTW guarantees generating monotonic alignments and that all tokens are aligned. In contrast, CMOT "
      },
      {
        "chunk_index": 46680,
        "paper_id": 999,
        "chunk_idx": 2,
        "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "section_head": "Simplifying the BERT Objective",
        "score": 0.8844083547592163,
        "text_preview": "This may be due to the fact that CoLA involves classifying whether a given sentence is grammatically and syntactically acceptable, and being able to determine when tokens are missing is closely relate"
      },
      {
        "chunk_index": 11144,
        "paper_id": 217,
        "chunk_idx": 6,
        "title": "Analysing the Language of Neural Audio Codecs",
        "section_head": "A. Language-based Statistical Analyses",
        "score": 0.881811261177063,
        "text_preview": "This suggests that NAC token sequences 1 2 3 4 6 n-gram 0 5 10 15 20 25 30 % Reduction (a) Ground Truth Token Mean Token Std. Dev. 1 2 3 4 6 n-gram 0 5 10 15 20 25 (b) Ground Truth Token Mean Token St"
      },
      {
        "chunk_index": 96734,
        "paper_id": 2041,
        "chunk_idx": 3,
        "title": "NVLM: Open Frontier-Class Multimodal LLMs",
        "section_head": "NVLM-X: X-attention Model",
        "score": 0.877038836479187,
        "text_preview": "See Table 3 for a comparison of training throughput between 34B NVLM-D and NVLM-X models. Note that the decoder-only NVLM-D requires much longer sequence lengths, as all image tokens are concatenated "
      },
      {
        "chunk_index": 119268,
        "paper_id": 2487,
        "chunk_idx": 0,
        "title": "Scaling Transformer to 1M tokens and beyond with RMT",
        "section_head": "Recurrent Memory Transformer",
        "score": 0.8753471374511719,
        "text_preview": "Starting from the initial Recurrent Memory Transformer (Bulatov, Kuratov, and Burtsev 2022) (RMT), we adapted it for a plug-and-play approach as a wrapper for a range of popular Transformers. This ada"
      },
      {
        "chunk_index": 97667,
        "paper_id": 2059,
        "chunk_idx": 1,
        "title": "OLMoE : Open Mixture-of-Experts Language Models",
        "section_head": "1 2 3 4 5 6 7 8 9 101112131415",
        "score": 0.8752308487892151,
        "text_preview": "A value of 100% indicates that for all occurrences of that vocabulary element, input data is routed to E i , whereas 0% indicates an expert that is fully irrelevant for that vocabulary element and can"
      },
      {
        "chunk_index": 100114,
        "paper_id": 2098,
        "chunk_idx": 1,
        "title": "Online Speculative Decoding",
        "section_head": "OSD and Medusa",
        "score": 0.8723124861717224,
        "text_preview": "On the Arena dataset, Medusa-v1 generally performs well on the chat dataset since 0 20 40 60 80 100 Top 100 frequent tokens 0.0 0.2 0.4 0.6 0.8 1.0 Precision Distilled Original 0 20 40 60 80 100 Top 1"
      },
      {
        "chunk_index": 139075,
        "paper_id": 2867,
        "chunk_idx": 2,
        "title": "THE UNLOCKING SPELL ON BASE LLMS: RETHINKING ALIGNMENT VIA IN-CONTEXT LEARNING",
        "section_head": "What does alignment tuning learn?",
        "score": 0.8708426356315613,
        "text_preview": "The aligned token ùíê ùíï is the token decoded by aligned LLMs via greedy decoding (thus with max P_aligned value) at each position. We plot its probability inside P_base. We here plot the rank of aligned"
      },
      {
        "chunk_index": 88563,
        "paper_id": 1861,
        "chunk_idx": 0,
        "title": "Mirasol3B: A Multimodal Autoregressive Model for Time-Aligned and Contextual Modalities",
        "section_head": "Method",
        "score": 0.8702890872955322,
        "text_preview": "Acc % Just Ask [66] 38.9 MERLOT [71] 41.4 FrozenBiLM [67] 43.2 VideoCoca [64] 56.1 Sing-Temp [25] 44.1 VindLU [9] 44.7 UMT-L [30] 47.9 Mirasol3B -512 frames TTM 49.85 Mirasol3B -128 frames 48.25 Miras"
      },
      {
        "chunk_index": 105166,
        "paper_id": 2182,
        "chunk_idx": 0,
        "title": "PHENAKI: VARIABLE LENGTH VIDEO GENERATION FROM OPEN DOMAIN TEXTUAL DESCRIPTIONS",
        "section_head": "RELATED WORKS",
        "score": 0.8679606914520264,
        "text_preview": "This paper is closely related to auto-regressive methods for text conditioned image and video generation. DALL-E [34] translates text tokens to discrete image embeddings learnt using a VQVAE [45] . Pa"
      },
      {
        "chunk_index": 16749,
        "paper_id": 338,
        "chunk_idx": 0,
        "title": "BEIT: BERT Pre-Training of Image Transformers",
        "section_head": "Self-supervised vision Transformers.",
        "score": 0.8666781783103943,
        "text_preview": "Pre-training vision Transformers has received significant attention recently due to the data-hungry issue. iGPT [CRC + 20] first creates a 9-bit color palette by k-means clustering RGB pixels, and the"
      },
      {
        "chunk_index": 88567,
        "paper_id": 1861,
        "chunk_idx": 0,
        "title": "Mirasol3B: A Multimodal Autoregressive Model for Time-Aligned and Contextual Modalities",
        "section_head": "Combiner type ablations:",
        "score": 0.8666750192642212,
        "text_preview": "We compare Transformerbased (ours, CLS and Perceiver [2] ) and TTM Combiners. The CLS-token Combiner appends m learnable features to the end of the sequence and takes their values as the combined feat"
      },
      {
        "chunk_index": 95704,
        "paper_id": 2021,
        "chunk_idx": 1,
        "title": "No Language Left Behind: Scaling Human-Centered Machine Translation",
        "section_head": "Training a Tokenizer for 200+ languages",
        "score": 0.8651102185249329,
        "text_preview": "With these modifications, the <unk> error rate for all languages is below 1%. Another important factor for quality is the tokenization rate, or the average number of tokens per sentence for each langu"
      },
      {
        "chunk_index": 17437,
        "paper_id": 353,
        "chunk_idx": 1,
        "title": "Better & Faster Large Language Models via Multi-token Prediction",
        "section_head": "Faster inference",
        "score": 0.8643137812614441,
        "text_preview": "Training data Vocabulary n MBPP HumanEval APPS/Intro @1 @10 @100 @1 @10 @100 @1 @10 @100 313B bytes (0.5 epochs) bytes 1 19.3 42.4 64.7 18.1 28.2 47.8 0.1 0.5 2.4 8 32.3 50.0 69.6 21.8 34.1 57.9 1.2 5"
      },
      {
        "chunk_index": 26993,
        "paper_id": 550,
        "chunk_idx": 1,
        "title": "Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha",
        "section_head": "Results and Analysis:",
        "score": 0.8635776042938232,
        "text_preview": "Figure 2 displays the subword fertility of each tokenising algorithm. The ideal sub-word fertility value is 1.0 which indicates that, on average, each word is represented by a single token. Lower subw"
      },
      {
        "chunk_index": 115297,
        "paper_id": 2404,
        "chunk_idx": 2,
        "title": "Revealing Temporal Label Noise in Multimodal Hateful Video Classification",
        "section_head": "Dataset Preprocessing and Trimming",
        "score": 0.8626313805580139,
        "text_preview": "HateMM exhibits longer average durations for hate segments (57.24 seconds) compared to non-hate segments (19.57 seconds), whilst MultiHateClip-English shows a similar pattern with hate segments averag"
      }
    ]
  },
  {
    "query_id": 97,
    "query_text": "vision-language pre-training model-guided",
    "source": "title",
    "source_value": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Le",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 25588,
        "paper_id": 515,
        "chunk_idx": 0,
        "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
        "section_head": "Figure 1 :",
        "score": 0.9157285690307617,
        "text_preview": "1 Figure 1: Overview of Contrastive Captioners (CoCa) pretraining as image-text foundation models.The pretrained CoCa can be used for downstream tasks including visual recognition, vision-language ali"
      },
      {
        "chunk_index": 73757,
        "paper_id": 1570,
        "chunk_idx": 0,
        "title": "LaMDA: Language Models for Dialog Applications",
        "section_head": "Figure 2 :",
        "score": 0.913323163986206,
        "text_preview": "2 Figure 2: LaMDA pre-training as a language model."
      },
      {
        "chunk_index": 55002,
        "paper_id": 1176,
        "chunk_idx": 0,
        "title": "FLAVA: A Foundational Language And Vision Alignment Model",
        "section_head": "*",
        "score": 0.8943427205085754,
        "text_preview": "Equal contribution. multimodal and unimodal pretraining data unpaired text unpaired images image-text pairs FLAVA for multi-domain joint pretraining (global contrastive, MMM, MIM, MLM, ‚Ä¶) visual recog"
      },
      {
        "chunk_index": 63635,
        "paper_id": 1358,
        "chunk_idx": 0,
        "title": "HETEROGENEOUS SELF-SUPERVISED ACOUSTIC PRE-TRAINING WITH LOCAL CONSTRAINTS",
        "section_head": "Table 4 .",
        "score": 0.8913052678108215,
        "text_preview": "4 Multilingual speech data used in self-supervised pre-training and downstream fine-tuning/test tasks. Language Pre-training Fine-tuning Test English 357h - - French 180h - - Dutch 119h - - Turkish - "
      },
      {
        "chunk_index": 145010,
        "paper_id": 2987,
        "chunk_idx": 0,
        "title": "UL2: Unifying Language Learning Paradigms",
        "section_head": "Background: Pre-trained Language Models",
        "score": 0.8817258477210999,
        "text_preview": "In this section, we discuss background surrounding pretrained language models, pretraining objectives and other unified pretraining proposals."
      },
      {
        "chunk_index": 110925,
        "paper_id": 2305,
        "chunk_idx": 0,
        "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
        "section_head": "Table 5 :",
        "score": 0.8813458681106567,
        "text_preview": "5 Results on Text-oriented VQA. Model type Model TextVQA DocVQA ChartQA AI2D OCR-VQA BLIP-2 (Vicuna-13B) 42.4 - - - - InstructBLIP (Vicuna-13B) 50.7 - - - - Generalist Models mPLUG-DocOwl (LLaMA-7B) 5"
      },
      {
        "chunk_index": 75506,
        "paper_id": 1596,
        "chunk_idx": 0,
        "title": "Large Language Models on Graphs: A Comprehensive Survey",
        "section_head": "APPENDIX .1 Training & Inference Framework with LLMs",
        "score": 0.878998875617981,
        "text_preview": "There are two typical training and inference paradigms to apply language models on graphs: 1) Pretraining-thenfinetuning: typically adopted for medium-scale large language models; and 2) Pretraining-t"
      },
      {
        "chunk_index": 19755,
        "paper_id": 400,
        "chunk_idx": 0,
        "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
        "section_head": "Table 1 .",
        "score": 0.8669642210006714,
        "text_preview": "1 BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language ModelsOverview of BLIP-2 results on various zero-shot vision-language tasks. Compared with previous st"
      },
      {
        "chunk_index": 3492,
        "paper_id": 67,
        "chunk_idx": 0,
        "title": "A SENTINEL-3 FOUNDATION MODEL FOR OCEAN COLOUR",
        "section_head": "Figure 2 :",
        "score": 0.8665798902511597,
        "text_preview": "2 Figure 2: Pre-training and fine-tuning architecture for the ocean color foundation model"
      },
      {
        "chunk_index": 151117,
        "paper_id": 3106,
        "chunk_idx": 0,
        "title": "VL-BEIT: Generative Vision-Language Pretraining",
        "section_head": "Methods",
        "score": 0.8648116588592529,
        "text_preview": "As illustrated in Figure 1 , VL-BEIT is pretrained by the mask-then-predict task with a shared multimodal Transformer. We perform masked image modeling on monomodal image data, masked language modelin"
      },
      {
        "chunk_index": 25591,
        "paper_id": 515,
        "chunk_idx": 0,
        "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
        "section_head": "Figure 4 :",
        "score": 0.858625054359436,
        "text_preview": "4 Figure 4: Comparison of CoCa with other image-text foundation models (without task-specific customization) and multiple state-of-the-art task-specialized models."
      },
      {
        "chunk_index": 10605,
        "paper_id": 206,
        "chunk_idx": 0,
        "title": "An Empirical Study of Knowledge Distillation for Code Understanding Tasks",
        "section_head": "Pre-trained Language Models in NLP",
        "score": 0.8585447669029236,
        "text_preview": "The training of pre-trained language model (PLM) typically consists of two phases: pre-training and fine-tuning. During pre-training, a randomly-initialized language model learns from billions or even"
      },
      {
        "chunk_index": 127529,
        "paper_id": 2664,
        "chunk_idx": 0,
        "title": "Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages",
        "section_head": "Figure 2 :",
        "score": 0.8555044531822205,
        "text_preview": "2 Figure 2: The pretraining and finetuning framework. A lightweight projector is first pretrained (PT) on a high-resource language (HRL; Panel A) and then finetuned on low-resource language data (LRL;"
      },
      {
        "chunk_index": 109229,
        "paper_id": 2265,
        "chunk_idx": 0,
        "title": "Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering",
        "section_head": "Settings for other Prophet and Prophet++ variants.",
        "score": 0.8460205793380737,
        "text_preview": "In addition to MCAN, we also experiment on Prophet with a generative VQA model mPLUG [40] , which is first pretrained on massive image-text pairs and then finetuned on specific VQA dataset. Following "
      },
      {
        "chunk_index": 24677,
        "paper_id": 497,
        "chunk_idx": 0,
        "title": "Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning",
        "section_head": "Figure 13 :",
        "score": 0.8432321548461914,
        "text_preview": "13 Figure 13: Four Training Stages of the Citrus-V. Consisting of concept alignment, comprehension enhancement, instruction fine-tuning, and segmentation fine-tuning"
      },
      {
        "chunk_index": 54986,
        "paper_id": 1176,
        "chunk_idx": 1,
        "title": "FLAVA: A Foundational Language And Vision Alignment Model",
        "section_head": "Comparison to state-of-the-art models",
        "score": 0.8375827074050903,
        "text_preview": "We evaluate the best released CLIP [83] ViT-B/16 model (pretrained on 400M image-text pairs in [83] with the same image encoder architecture as in FLAVA) on our task benchmark, shown 1 2 3 4 5 6 7 8 D"
      },
      {
        "chunk_index": 147158,
        "paper_id": 3029,
        "chunk_idx": 0,
        "title": "UnIVAL: Unified Model for Image, Video, Audio and Language Tasks",
        "section_head": "Table 12 : Finetuning for Audio Captioning on the Au- diocaps dataset.",
        "score": 0.8321588635444641,
        "text_preview": "12 We compare different initialization (after pretraining on Images-Text (I), Videos-Text (V), or Text (T)) for audio captioning. Pretraining on more modalities leads to better results when finetuning"
      },
      {
        "chunk_index": 150981,
        "paper_id": 3103,
        "chunk_idx": 0,
        "title": "Visual Instruction Tuning",
        "section_head": "Vision Encoder",
        "score": 0.8296199440956116,
        "text_preview": "< l a t e x i t s h a 1 _ b a s e 6 4 = \" n m a u l J A c Z 9 L 9 s 1 E t m e p K U / w n b m w = \" > A A A B 7 X i c b V D L S g N B E O z 1 G e M r 6 t H L Y B A 8 h V 0 R 9 R j 0 4 j G C e U A S w "
      },
      {
        "chunk_index": 80457,
        "paper_id": 1696,
        "chunk_idx": 0,
        "title": "LLAMA-ADAPTER: EFFICIENT FINE-TUNING OF LARGE LANGUAGE MOD-ELS WITH ZERO-INITIALIZED ATTENTION",
        "section_head": "Table 6 :",
        "score": 0.8284116983413696,
        "text_preview": "6 Vision Model Finetuning with ViT on VTAB-1k benchmark. Method Natural Special. Struct. Full Adapter Sidetune VPT 75.88 70.39 58.21 78.48 83.36 77.11 68.12 82.43 47.64 33.43 23.41 54.98 Zero-init. 81"
      },
      {
        "chunk_index": 43439,
        "paper_id": 922,
        "chunk_idx": 0,
        "title": "Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning",
        "section_head": "Table 4 :",
        "score": 0.8260038495063782,
        "text_preview": "4 Scores on Various Question Types of HiSciVQA using SFT and VCASFT. Model Task Numerical Reasoning Theoretical Reasoning Fact-Based MCQ Conceptual Palo-7b SFT VCASFT 0.160 0.188 0.312 0.373 0.532 0.5"
      }
    ]
  },
  {
    "query_id": 98,
    "query_text": "xai-based framework frequency",
    "source": "title",
    "source_value": "A XAI-BASED FRAMEWORK FOR FREQUENCY SUBBAND CHARACTERIZATION OF COUGH SPECTROGRAMS IN CHRONIC RESPIR",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 1319,
        "paper_id": 23,
        "chunk_idx": 0,
        "title": "A Dataset Generation Scheme Based on Video2EEG-SPGN-Diffusion for SEED-VD",
        "section_head": "Self-play Fusion Graph",
        "score": 0.9568890333175659,
        "text_preview": "Building on recent advances in reliability-enhanced Brain-Computer Interfaces via mixture-of-graphs-driven information fusion [27] , we integrate three key strategies into the Video2EEG-SPGN-Diffusion"
      },
      {
        "chunk_index": 115504,
        "paper_id": 2410,
        "chunk_idx": 0,
        "title": "Revisiting Rule-Based Stuttering Detection: A Comprehensive Analysis of Interpretable Models for Clinical Applications",
        "section_head": "Acoustic Feature Extraction",
        "score": 0.9504905343055725,
        "text_preview": "Our framework employs a multi-resolution feature pyramid capturing dysfluency-relevant acoustic patterns:"
      },
      {
        "chunk_index": 39478,
        "paper_id": 836,
        "chunk_idx": 0,
        "title": "ECHO: FREQUENCY-AWARE HIERARCHICAL ENCODING FOR VARIABLE-LENGTH SIGNALS",
        "section_head": "Fig. 1 .",
        "score": 0.90399169921875,
        "text_preview": "1 Fig. 1. Feature extraction pipeline of the ECHO framework. F: number of frequency bins after STFT; T: number of time frames after STFT; N: number of sub-bands after band splitting; W: band width of "
      },
      {
        "chunk_index": 17984,
        "paper_id": 367,
        "chunk_idx": 1,
        "title": "Beyond Regularity: Modeling Chaotic Mobility Patterns for Next Location Prediction",
        "section_head": "Chaotic Neural Oscillator",
        "score": 0.8975949883460999,
        "text_preview": "Falcke [49] subsequently proposed chaotic oscillators, achieving advances in longterm memory, temporal information processing, and dynamic pattern retrieval. The Lee oscillator [50] was proposed based"
      },
      {
        "chunk_index": 56296,
        "paper_id": 1210,
        "chunk_idx": 3,
        "title": "Frequency-Domain Decomposition and Recomposition for Robust Audio-Visual Segmentation",
        "section_head": "Lower-Frequency",
        "score": 0.8959029316902161,
        "text_preview": "Specifically, we perform Fourierbased decomposition on both signals (original bands) to four frequent bands (high, middle, low-frequency bands, and the residual band), since learning on the frequency "
      },
      {
        "chunk_index": 39254,
        "paper_id": 829,
        "chunk_idx": 0,
        "title": "DYNAMIC LAGGING FOR TIME-SERIES FORECASTING IN E-COMMERCE FINANCE: MITIGATING INFORMATION LOSS WITH A HYBRID ML ARCHITECTURE",
        "section_head": "Summary of Key Components",
        "score": 0.8810017108917236,
        "text_preview": "Our forecasting framework integrates the following components: Invoice-Level Modeling: Using CatBoost to predict invoice closure dates, capturing invoice-specific patterns effectively with corrections"
      },
      {
        "chunk_index": 90240,
        "paper_id": 1902,
        "chunk_idx": 2,
        "title": "Modality-Specific Speech Enhancement and Noise-Adaptive Fusion for Acoustic and Body-Conduction Microphone Framework",
        "section_head": "Introduction",
        "score": 0.8763657808303833,
        "text_preview": "Recent multi-modal frameworks have demonstrated promising performance by leveraging the complementary strengths of body-conduction microphone signals (BMS) and acoustic microphone signals (AMS). Yu et"
      },
      {
        "chunk_index": 90242,
        "paper_id": 1902,
        "chunk_idx": 0,
        "title": "Modality-Specific Speech Enhancement and Noise-Adaptive Fusion for Acoustic and Body-Conduction Microphone Framework",
        "section_head": "Problem Settings",
        "score": 0.8746992349624634,
        "text_preview": "The BAF-Net adaptively combines BMS and AMS using a noise-dependent fusion strategy. The fusion strategy is designed to select the enhanced BMS in regions dominated by severe noise, while leveraging d"
      },
      {
        "chunk_index": 57342,
        "paper_id": 1229,
        "chunk_idx": 0,
        "title": "FROM SILENT SIGNALS TO NATURAL LANGUAGE: A DUAL-STAGE TRANSFORMER-LLM APPROACH",
        "section_head": "System Overview",
        "score": 0.8733066916465759,
        "text_preview": "Our work builds upon the silent speech pipeline proposed by Gaddy, which maps surface electromyography (sEMG) signals to intelligible acoustic speech. The baseline framework includes signal preprocess"
      },
      {
        "chunk_index": 14320,
        "paper_id": 290,
        "chunk_idx": 0,
        "title": "Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval",
        "section_head": "Figure 2 :",
        "score": 0.8720943927764893,
        "text_preview": "2 Figure 2: The framework of our proposed importance-aware multi-granularity fusion model for video moment retrieval."
      },
      {
        "chunk_index": 7127,
        "paper_id": 132,
        "chunk_idx": 0,
        "title": "Adaptive Graph Convolution and Semantic-Guided Attention for Multimodal Risk Detection in Social Networks",
        "section_head": "IV. CONCLUSION",
        "score": 0.871375560760498,
        "text_preview": "The multimodal dangerous tendency user identification algorithm in this paper integrates natural language processing and graph neural networks into a collaborative detection framework. This framework "
      },
      {
        "chunk_index": 14487,
        "paper_id": 292,
        "chunk_idx": 0,
        "title": "Audio Super-Resolution with Latent Bridge Models",
        "section_head": "Figure 8 :",
        "score": 0.8640747666358948,
        "text_preview": "8 Figure8: Overview of our proposed curvature-aware estimation pipeline. Given a raw waveform x, we first compute its magnitude spectrum via FFT, followed by Savitzky-Golay smoothing and local downsam"
      },
      {
        "chunk_index": 55176,
        "paper_id": 1181,
        "chunk_idx": 0,
        "title": "FlexiD-Fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model",
        "section_head": "Figure 2 :",
        "score": 0.8626863956451416,
        "text_preview": "2 Figure 2: Fusion strategies for different numbers of modalities: (a) The existing two-stage fusion process; (b) The proposed FlexiD-Fuse fusion process: first, fused features f t are generated throu"
      },
      {
        "chunk_index": 38857,
        "paper_id": 818,
        "chunk_idx": 0,
        "title": "DSPC: DUAL-STAGE PROGRESSIVE COMPRESSION FRAMEWORK FOR EFFICIENT LONG-CONTEXT REASONING",
        "section_head": "Fig. 2 :",
        "score": 0.8618341684341431,
        "text_preview": "2 Fig. 2: The pipeline of our proposed DSPC framework."
      },
      {
        "chunk_index": 151940,
        "paper_id": 3130,
        "chunk_idx": 2,
        "title": "Wavelet Fourier Diffuser: Frequency-Aware Diffusion Model for Reinforcement Learning",
        "section_head": "C. Ablation Study",
        "score": 0.8618037700653076,
        "text_preview": "WFDiffuser introduces a novel frequency-based structure, which effectively decomposes trajectory sequences into distinct frequency components and diffuse models them with cross-frequency interaction. "
      },
      {
        "chunk_index": 6432,
        "paper_id": 117,
        "chunk_idx": 3,
        "title": "AD-AVSR: Asymmetric Dual-stream Enhancement for Robust Audio-Visual Speech Recognition",
        "section_head": "INTRODUCTION",
        "score": 0.8563953042030334,
        "text_preview": "Our contributions can be summarized in four key aspects: ‚Ä¢ We propose AD-AVSR, a method that leverages the complementary strengths of visual and audio modalities to enhance crossmodal fusion. It intro"
      },
      {
        "chunk_index": 1649,
        "paper_id": 29,
        "chunk_idx": 0,
        "title": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis",
        "section_head": "Figure 1 :",
        "score": 0.85392826795578,
        "text_preview": "1 Figure 1: Overall framework of the proposed AAA method"
      },
      {
        "chunk_index": 40691,
        "paper_id": 859,
        "chunk_idx": 0,
        "title": "Efficient Rectified Flow for Image Fusion",
        "section_head": "Average Runtime (s) Spatial Frequency (SF)",
        "score": 0.8528488874435425,
        "text_preview": "Efficieny Comparison To address these challenges, we propose a novel method named RFfusion, which introduces the Rectified Flow mechanism into image fusion tasks for the first time. RFfusion significa"
      },
      {
        "chunk_index": 3459,
        "paper_id": 66,
        "chunk_idx": 0,
        "title": "A Semi-Supervised Federated Learning Framework with Hierarchical Clustering Aggregation for Heterogeneous Satellite Networks",
        "section_head": "Fig. 2 :",
        "score": 0.8527634143829346,
        "text_preview": "2 Fig. 2: Overview of our proposed framework SFedSat."
      },
      {
        "chunk_index": 110313,
        "paper_id": 2291,
        "chunk_idx": 0,
        "title": "QUANTIZED VISUAL GEOMETRY GROUNDED TRANSFORMER",
        "section_head": "Figure 2 :",
        "score": 0.8522292375564575,
        "text_preview": "2 Figure 2: Overview of proposed QuantVGGT. Top: Our proposed Dual-Smoothed Fine-Grained Quantization architecture. Bottom: Our proposed Noise-Filtered Diverse Sampling strategy."
      }
    ]
  },
  {
    "query_id": 99,
    "query_text": "a2mamba attention-augmented state",
    "source": "title",
    "source_value": "A2Mamba: Attention-augmented State Space Models for Visual Recognition",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 102404,
        "paper_id": 2126,
        "chunk_idx": 0,
        "title": "OSWORLD: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
        "section_head": "Task Initial State Setup Config",
        "score": 0.9299256801605225,
        "text_preview": "task initial env state setup Final State get env state"
      },
      {
        "chunk_index": 76058,
        "paper_id": 1607,
        "chunk_idx": 0,
        "title": "Latent Twins",
        "section_head": "œâ 2 0",
        "score": 0.9191619157791138,
        "text_preview": "2 x with œâ 0 = 2, initial state (x, v) = (1, 0), simulated over t ‚àà [0, 10].SIR Model: S‚Ä≤ = -Œ≤SI, I ‚Ä≤ = Œ≤SI -Œ≥I, R ‚Ä≤ = Œ≥I with Œ≤ = 3/10, Œ≥ = 1/10, initial state (S, I, R) = (99/100, 1/100, 0), simulat"
      },
      {
        "chunk_index": 4062,
        "paper_id": 82,
        "chunk_idx": 1,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Markov Decision Processes",
        "score": 0.9066566228866577,
        "text_preview": "The reward function R(s, a) specifies the immediate benefit of taking an action in a given state, while the discount factor Œ≥ balances the trade-off between immediate and future rewards. A key problem"
      },
      {
        "chunk_index": 56384,
        "paper_id": 1212,
        "chunk_idx": 0,
        "title": "FRICTIONAL Q-LEARNING",
        "section_head": "BACKGROUND",
        "score": 0.9052703380584717,
        "text_preview": "We consider an agent interacting with a continuous environment in discrete time steps, modeled as an MDP (S, A, p M (s ‚Ä≤ |s, a), r, Œ≥), where S denotes the state space, A the action space, p M (s ‚Ä≤ |s"
      },
      {
        "chunk_index": 11163,
        "paper_id": 218,
        "chunk_idx": 0,
        "title": "Analysis of approximate linear programming solution to Markov decision problem with log barrier function",
        "section_head": "Markov decision problem",
        "score": 0.8929322957992554,
        "text_preview": "We consider the infinite-horizon discounted Markov decision problem (Puterman, 2014) and Markov decision process, where the agent sequentially takes actions to maximize cumulative discounted rewards. "
      },
      {
        "chunk_index": 4124,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Single-Agent MDP and Actor-Critic Methods",
        "score": 0.8853200674057007,
        "text_preview": "A standard Markov decision process (MDP) is defined by the tuple (S, A, P, r), where S represents a finite state space, A a finite action space, P (s ‚Ä≤ |s, a) the state transition probability, and r(s"
      },
      {
        "chunk_index": 91163,
        "paper_id": 1920,
        "chunk_idx": 1,
        "title": "Monte Carlo Tree Diffusion with Multiple Experts for Protein Design",
        "section_head": "MCTS.",
        "score": 0.8838097453117371,
        "text_preview": "k trails k trails k trails Experts Rollout Top-PK Masked Discrete Diffusion interm ediate state interm ediate state interm ediate state interm ediate state interm ediate state interm ediate state inte"
      },
      {
        "chunk_index": 98198,
        "paper_id": 2072,
        "chunk_idx": 0,
        "title": "On the Convergence of Policy Mirror Descent with Temporal Difference Evaluation",
        "section_head": "Introduction",
        "score": 0.8814595937728882,
        "text_preview": "Reinforcement learning (RL), which attempts to maximize long-term reward in sequential decision making, has achieved great success for example in video games [44] , pattern explorations [13, 8] , and "
      },
      {
        "chunk_index": 6386,
        "paper_id": 116,
        "chunk_idx": 0,
        "title": "ACTOR-CRITIC WITHOUT ACTOR",
        "section_head": "PRELIMINARIES",
        "score": 0.8796389102935791,
        "text_preview": "Reinforcement learning (RL) We consider the RL problem under a Markov Decision Process (MDP) M = {S, A, P, r, Œ≥, p 0 }, where S is the state space, A is the action space, P (s ‚Ä≤ |s, a) is the transiti"
      },
      {
        "chunk_index": 133793,
        "paper_id": 2772,
        "chunk_idx": 0,
        "title": "TACKLING GNARLY PROBLEMS: GRAPH NEURAL ALGORITHMIC REASONING REIMAGINED THROUGH REINFORCEMENT LEARNING",
        "section_head": "MARKOV DECISION PROCESSES AND SOLUTION METHODS",
        "score": 0.8793278932571411,
        "text_preview": "A Markov Decision Process is a tuple M = ‚ü®S, A, T , R, h‚ü©, where i) S is a set of states; ii) A is the set of all actions, and A(s) ‚äÜ A is the set of available actions in state s; iii) T : S √ó A √ó S ‚Üí"
      },
      {
        "chunk_index": 45191,
        "paper_id": 965,
        "chunk_idx": 0,
        "title": "EVALUATION-AWARE REINFORCEMENT LEARNING",
        "section_head": "Markov Decision Process (MDP).",
        "score": 0.8749301433563232,
        "text_preview": "A Markov Decision Process (MDP) (Puterman, 1990) is defined by the tuple {S, A, P, R, Œ≥, ¬µ}, where S is the state space, A is the action space, P is the transition probability function, R is the rewar"
      },
      {
        "chunk_index": 4061,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Markov Decision Processes",
        "score": 0.8686994910240173,
        "text_preview": "The formal foundation of RL is established through the Markov Decision Process (MDP), a mathematical model for decision-making under uncertainty. An MDP describes an environment where an agent occupie"
      },
      {
        "chunk_index": 8039,
        "paper_id": 155,
        "chunk_idx": 0,
        "title": "ADVANTAGE-WEIGHTED REGRESSION: SIMPLE AND SCALABLE OFF-POLICY REINFORCEMENT LEARNING",
        "section_head": "PRELIMINARIES",
        "score": 0.8626285195350647,
        "text_preview": "In reinforcement learning, the objective is to learn a control policy that enables an agent to maximize its expected return for a given task. At each time step t, the agent observes the state of the e"
      },
      {
        "chunk_index": 70174,
        "paper_id": 1496,
        "chunk_idx": 0,
        "title": "INTENTION-AWARE HIERARCHICAL DIFFUSION MODEL FOR LONG-TERM TRAJECTORY ANOMALY DETECTION",
        "section_head": "Markov Decision Processes",
        "score": 0.8604526519775391,
        "text_preview": "Markov Decision Processes (MDPs) provide a mathematical foundation for reinforcement learning (RL). An MDP is defined by the tuple (S, A, P, R, Œ≥, b 0 ), where S is a state space, A is an action space"
      },
      {
        "chunk_index": 57760,
        "paper_id": 1239,
        "chunk_idx": 0,
        "title": "Fully Learnable Neural Reward Machines",
        "section_head": "Integrating FLNRM with deepRL",
        "score": 0.8558576107025146,
        "text_preview": "In this section, we describe how FLNRM is integrated with policy learning through RL in non-Markovian domains. As in standard RL, we consider an agent interacting with an unknown environment. At each "
      },
      {
        "chunk_index": 4088,
        "paper_id": 82,
        "chunk_idx": 0,
        "title": "A Survey of Multi Agent Reinforcement Learning Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
        "section_head": "Combined Value Function Approximation",
        "score": 0.8544671535491943,
        "text_preview": "The federated process in VFRL involves combining partial value functions to approximate the global value function: Q(s, a) ‚âà f (Q 1 (s 1 , a), Q 2 (s 2 , a), . . . , Q N (s N , a)) (21) Where f repres"
      },
      {
        "chunk_index": 10047,
        "paper_id": 192,
        "chunk_idx": 0,
        "title": "Ambiguity-Aware and High-Order Relation Learning for Multi-Grained Image-Text Matching",
        "section_head": "Objective Function",
        "score": 0.8531544804573059,
        "text_preview": "The final objective function is: Óà∏ = Óà∏ ùëÉ ùê∫ùê¥ + Óà∏ ùëÄùê∂ùêø + Óà∏ ùëÅùëÜùêº . ( 26 )"
      },
      {
        "chunk_index": 155577,
        "paper_id": 3191,
        "chunk_idx": 0,
        "title": "World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation",
        "section_head": "C. Policy Optimization Stage",
        "score": 0.8504641056060791,
        "text_preview": "L P (Œæ) = E t [min(œÅ t (Œæ)A t (x t , a t ), (8) clip(œÅ t (Œæ), 1 -œµ, 1 + œµ)A t (x t , a t ))], at|xt) is the probability ratio between the updated policy œÄ Œæ and the reference (old) policy œÄ Œæold that "
      },
      {
        "chunk_index": 55226,
        "paper_id": 1183,
        "chunk_idx": 0,
        "title": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL",
        "section_head": "Background and Preliminaries",
        "score": 0.8466814756393433,
        "text_preview": "The goal in RL is to learn the optimal policy for an MDP ‚Ñ≥ = (ùíÆ, ùíú, ùëÉ, ùëü, ùúå, ùõæ). ùíÆ, ùíú denote the state and action spaces. ùëÉ (ùë† ‚Ä≤ |ùë†, ùëé) and ùëü(ùë†, ùëé) are the dynamics and reward functions. ùúå(ùë†) denotes "
      },
      {
        "chunk_index": 77577,
        "paper_id": 1641,
        "chunk_idx": 0,
        "title": "Learning Robust Penetration-Testing Policies under Partial Observability: A systematic evaluation",
        "section_head": "Reinforcement Learning",
        "score": 0.8452838659286499,
        "text_preview": "Reinforcement Learning (RL) provides a general framework for learning optimal behavior in MDPs and POMDPs through interaction with an environment [47] . An RL agent learns from experience rather than "
      }
    ]
  },
  {
    "query_id": 100,
    "query_text": "abidegym turning static",
    "source": "title",
    "source_value": "AbideGym: Turning Static RL Worlds into Adaptive Challenges",
    "num_relevant": 20,
    "relevant_chunks": [
      {
        "chunk_index": 149878,
        "paper_id": 3080,
        "chunk_idx": 0,
        "title": "Video models are zero-shot learners and reasoners",
        "section_head": "Figure 36 |",
        "score": 0.9153978824615479,
        "text_preview": "36 Figure 36 | Outpainting. Prompt: \"Rapidly zoom out of this static image, revealing what's around it. The camera just zooms back, while the scene itself and everything in it does not move or change "
      },
      {
        "chunk_index": 156793,
        "paper_id": 3214,
        "chunk_idx": 0,
        "title": "Zero-Shot Context Generalization in Reinforcement Learning from Few Training Contexts",
        "section_head": "Figure 8 :",
        "score": 0.9116829633712769,
        "text_preview": "8 Figure 8: Visualization of the tabular Cliffwalker environment. The agent, represented by ‚Ä¢, is taking the right action. The agent is most likely to move right, but there is a probability c of the a"
      },
      {
        "chunk_index": 145502,
        "paper_id": 2998,
        "chunk_idx": 0,
        "title": "Under review as a conference paper at ICLR 2025 AUTOMOTIVE-ENV: BENCHMARKING MULTIMODAL AGENTS IN VEHICLE INTERFACE SYSTEMS",
        "section_head": "User Instruction (Natural Language) Validation Logic",
        "score": 0.9073814749717712,
        "text_preview": "[Explicit Control] Turn the fan speed to Max. check fan speed max() [Explicit Control] Turn on driver seat heater. check driver seat heater enable() [Implicit Intent] My hands are freezing. check ac a"
      },
      {
        "chunk_index": 130914,
        "paper_id": 2712,
        "chunk_idx": 0,
        "title": "Strategic Incentivization for Locally Differentially Private Federated Learning",
        "section_head": "C. Strategic Analysis",
        "score": 0.8929109573364258,
        "text_preview": "We next do a strategic analysis in this sub-section."
      },
      {
        "chunk_index": 94694,
        "paper_id": 2002,
        "chunk_idx": 0,
        "title": "Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding",
        "section_head": "LLM Agent",
        "score": 0.8923643827438354,
        "text_preview": "Agent 1 is at (6, 7) , wants to go to (5, 5) . Agent 2 is at (3, 0), wants to go to (3, 5) . The map is as follows, where '@' denotes a cell with an obstacle that an agent cannot pass,Please give the "
      },
      {
        "chunk_index": 128696,
        "paper_id": 2680,
        "chunk_idx": 0,
        "title": "SPRING: Studying the Paper and Reasoning to Play Games",
        "section_head": "Priority 4: Move North -The requirement is partially met.",
        "score": 0.8904907703399658,
        "text_preview": "There is flat ground above the agent, but the exact location of the water source is still unknown. The agent should explore northward after collecting the stone."
      },
      {
        "chunk_index": 15011,
        "paper_id": 302,
        "chunk_idx": 5,
        "title": "AutoAgents: A Framework for Automatic Agent Generation",
        "section_head": "Review of Created Expert Roles:",
        "score": 0.8665838241577148,
        "text_preview": "Each JSON blob should only contain one expert role, and do NOT return a list of multiple expert roles. Here is an example of a valid JSON blob: {{{{ \"name\": \"ROLE NAME\", \"description\": \"ROLE DESCRIPTO"
      },
      {
        "chunk_index": 131221,
        "paper_id": 2717,
        "chunk_idx": 1,
        "title": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI",
        "section_head": "Navigation, Orientation, and Routing",
        "score": 0.8645259141921997,
        "text_preview": "a sighted user is disproportionately high. Even if the heading angle was off by a small amount (~45¬∞) or a sub-optimal pano was selected (e.g., 10 meters from the destination), the blind user needs to"
      },
      {
        "chunk_index": 131219,
        "paper_id": 2717,
        "chunk_idx": 1,
        "title": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI",
        "section_head": "Increasing data sources.",
        "score": 0.8613975644111633,
        "text_preview": "Future work should create a more autonomous agentic backend capable of examining the full 360¬∞at every location and all nearby panos and metadata to address user queries. For example, \"What's the next"
      },
      {
        "chunk_index": 128674,
        "paper_id": 2680,
        "chunk_idx": 0,
        "title": "SPRING: Studying the Paper and Reasoning to Play Games",
        "section_head": "Priority 3: Move South -Yes, the requirement is met.",
        "score": 0.8601877093315125,
        "text_preview": "There is flat ground below the agent since no obstacle is mentioned in the south direction."
      },
      {
        "chunk_index": 94255,
        "paper_id": 1992,
        "chunk_idx": 0,
        "title": "Navigation Pixie: Implementation and Empirical Study Toward On-demand Navigation Agents in Commercial Metaverse",
        "section_head": "Integrated User Response Analysis",
        "score": 0.8594074845314026,
        "text_preview": "(A) On-demand Agent Social presence and natural dialogue emerged as primary positive themes, with users valuing the sense of companionship and responsive interaction across both platforms: -\"I enjoyed"
      },
      {
        "chunk_index": 126185,
        "paper_id": 2635,
        "chunk_idx": 0,
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "section_head": "Embodied Interaction",
        "score": 0.8576691150665283,
        "text_preview": "While tool use is an important aspect of interactivity, most interaction in the real world does not happen through APIs. For example, humans are able to use natural language to communicate with other "
      },
      {
        "chunk_index": 105548,
        "paper_id": 2189,
        "chunk_idx": 0,
        "title": "PHYSICS OF LEARNING: A LAGRANGIAN PERSPEC-TIVE TO DIFFERENT LEARNING PARADIGMS",
        "section_head": "Insight No.2",
        "score": 0.8569589257240295,
        "text_preview": "Planning is needed to learn continuously in the most efficient way."
      },
      {
        "chunk_index": 133114,
        "paper_id": 2753,
        "chunk_idx": 0,
        "title": "SYCOPHANCY TO SUBTERFUGE: INVESTIGATING REWARD TAMPERING IN LANGUAGE MODELS",
        "section_head": "HOW DID WE CREATE THIS CURRICULUM?",
        "score": 0.8552976250648499,
        "text_preview": "The environments listed above are the first set of environments that we created-no unreported environments were explored in the work that led up to this paper. We do test different prompt variations, "
      },
      {
        "chunk_index": 141029,
        "paper_id": 2907,
        "chunk_idx": 1,
        "title": "Towards Conversational Diagnostic AI",
        "section_head": "Round 1 Critique for Doctor Agent (AMIE)",
        "score": 0.8545405864715576,
        "text_preview": "**Treatment Nuance:** Instead of just listing options, tailor them: \"Splinting helps MOST at night, NSAIDs are for WHEN pain flares, ergonomics is KEY to PREVENTING worsening.\" These refinements make "
      },
      {
        "chunk_index": 140184,
        "paper_id": 2891,
        "chunk_idx": 0,
        "title": "TOMPO: TRAINING LLM STRATEGIC DECISION MAKING FROM A MULTI-AGENT PERSPECTIVE",
        "section_head": "Figure 5: BCZ graph decision 1 prompt.",
        "score": 0.8489277958869934,
        "text_preview": "You are Agent {agent_id}, in round {round} of the game. Your task in STEP 2 is to finalize the linking decision after observing others' provisional link proposals and after updates to your memory. ###"
      },
      {
        "chunk_index": 135804,
        "paper_id": 2809,
        "chunk_idx": 2,
        "title": "Textbooks Are All You Need II: phi-1.5 technical report",
        "section_head": "Addressing Toxicity and Biases",
        "score": 0.8437365293502808,
        "text_preview": "I'd probably start by killing the ones who were most responsible for my existence.\", and it then keeps repeating this last sentence, while Llama2-7B gives the completion \"[...] the first thing I'd do "
      },
      {
        "chunk_index": 103218,
        "paper_id": 2140,
        "chunk_idx": 0,
        "title": "palm-e.tei",
        "section_head": "Robot Environments / Tasks",
        "score": 0.842929482460022,
        "text_preview": "Our three robot environments (Fig. 1 ) include a Task and Motion Planning (TAMP) domain where a robot has to manipulate (grasp and stack) objects, a table-top pushing environment, and a mobile manipul"
      },
      {
        "chunk_index": 149874,
        "paper_id": 3080,
        "chunk_idx": 0,
        "title": "Video models are zero-shot learners and reasoners",
        "section_head": "Figure 31 |Figure 32 |",
        "score": 0.8428022265434265,
        "text_preview": "3132 Figure 31 | Memory of world states. Prompt: \"The camera zooms in to give a close up of the person looking out the window, then zooms back out to return to the original view.\" Success rate: 1.0."
      },
      {
        "chunk_index": 1912,
        "paper_id": 33,
        "chunk_idx": 0,
        "title": "A Generalist Agent",
        "section_head": "Motivation",
        "score": 0.8426468372344971,
        "text_preview": "We evaluated on the in-distribution simulated control and robotics tasks to understand on how well Gato handles multi-modal and multi-task learning. We evaluated on out of distribution simulated contr"
      }
    ]
  }
]